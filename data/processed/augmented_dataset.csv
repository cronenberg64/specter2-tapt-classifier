text,label
"Do brains and language models converge toward the same internal representations of the world? Recent years have seen a rise in studies of neural activations and model alignment. In this work, we review 25 fMRI-based studies published between 2023 and 2025 and explicitly confront their findings with two key hypotheses: (i) the Platonic Representation Hypothesis -- that as models scale and improve, they converge to a representation of the real world, and (ii) the Intermediate-Layer Advantage -- that intermediate (mid-depth) layers often encode richer, more generalizable features. Our findings provide converging evidence that models and brains may share abstract representational structures, supporting both hypotheses and motivating further research on brain-model alignment.",Neuroscience
"Do brains and language models converge toward the same internal representations of the world? Recent years have seen a rise in studies of neural activations and model alignment. In this work, we review 25 fMRI-based studies published between 2023 and 2025 and explicitly confront their findings with two key hypotheses: (i) the Platonic Representation Hypothesis -- that as models scale and improve, they converge to a representation of the real world, and (ii) the Intermediate-Layer Advantage -- that intermediate (mid-depth) layers often encode richer, more generalizable features. Our findings provide converging evidence that models and brains may share abstract representational structures, supporting both hypotheses and motivating further research on brain-model alignment. [SEP] [HINT] language -> Neuroscience (Syns: linguistic process, linguistic communication, spoken communication) | scale -> Bioinformatics (Syns: shell, graduated table, plate) | findings -> Neuroscience (Syns: determination, finding)",Neuroscience
"Biomarker discovery from high-throughput transcriptomic data is crucial for advancing precision medicine. However, existing methods often neglect gene-gene regulatory relationships and lack stability across datasets, leading to conflation of spurious correlations with genuine causal effects. To address these issues, we develop a causal graph neural network (Causal-GNN) method that integrates causal inference with multi-layer graph neural networks (GNNs). The key innovation is the incorporation of causal effect estimation for identifying stable biomarkers, coupled with a GNN-based propensity scoring mechanism that leverages cross-gene regulatory networks. Experimental results demonstrate that our method achieves consistently high predictive accuracy across four distinct datasets and four independent classifiers. Moreover, it enables the identification of more stable biomarkers compared to traditional methods. Our work provides a robust, efficient, and biologically interpretable tool for biomarker discovery, demonstrating strong potential for broad application across medical disciplines.",Bioinformatics
"Biomarker discovery from high-throughput transcriptomic data is crucial for advancing precision medicine. However, existing methods often neglect gene-gene regulatory relationships and lack stability across datasets, leading to conflation of spurious correlations with genuine causal effects. To address these issues, we develop a causal graph neural network (Causal-GNN) method that integrates causal inference with multi-layer graph neural networks (GNNs). The key innovation is the incorporation of causal effect estimation for identifying stable biomarkers, coupled with a GNN-based propensity scoring mechanism that leverages cross-gene regulatory networks. Experimental results demonstrate that our method achieves consistently high predictive accuracy across four distinct datasets and four independent classifiers. Moreover, it enables the identification of more stable biomarkers compared to traditional methods. Our work provides a robust, efficient, and biologically interpretable tool for biomarker discovery, demonstrating strong potential for broad application across medical disciplines. [SEP] [HINT] networks -> Neuroscience (Syns: network, meshwork, electronic network) | datasets -> Bioinformatics (Syns: ) | work -> Bioinformatics (Syns: work out, process, bring)",Bioinformatics
"Event cameras are bio-inspired vision sensor that encode visual information with high dynamic range, high temporal resolution, and low latency.Current state-of-the-art event stream processing methods rely on end-to-end deep learning techniques. However, these models are heavily dependent on data structures, limiting their stability and generalization capabilities across tasks, thereby hindering their deployment in real-world scenarios. To address this issue, we propose a chaotic dynamics event signal processing framework inspired by the dorsal visual pathway of the brain. Specifically, we utilize Continuous-coupled Neural Network (CCNN) to encode the event stream. CCNN encodes polarity-invariant event sequences as periodic signals and polarity=changing event sequences as chaotic signals. We then use continuous wavelet transforms to analyze the dynamical states of CCNN neurons and establish the high-order mappings of the event stream. The effectiveness of our method is validated through integration with conventional classification networks, achieving state-of-the-art classification accuracy on the N-Caltech101 and N-CARS datasets, with results of 84.3% and 99.9%, respectively. Our method improves the accuracy of event camera-based object classification while significantly enhancing the generalization and stability of event representation. Our code is available in https://github.com/chenyu0193/ACDF.",Neuroscience
"Event cameras are bio-inspired vision sensor that encode visual information with high dynamic range, high temporal resolution, and low latency.Current state-of-the-art event stream processing methods rely on end-to-end deep learning techniques. However, these models are heavily dependent on data structures, limiting their stability and generalization capabilities across tasks, thereby hindering their deployment in real-world scenarios. To address this issue, we propose a chaotic dynamics event signal processing framework inspired by the dorsal visual pathway of the brain. Specifically, we utilize Continuous-coupled Neural Network (CCNN) to encode the event stream. CCNN encodes polarity-invariant event sequences as periodic signals and polarity=changing event sequences as chaotic signals. We then use continuous wavelet transforms to analyze the dynamical states of CCNN neurons and establish the high-order mappings of the event stream. The effectiveness of our method is validated through integration with conventional classification networks, achieving state-of-the-art classification accuracy on the N-Caltech101 and N-CARS datasets, with results of 84.3% and 99.9%, respectively. Our method improves the accuracy of event camera-based object classification while significantly enhancing the generalization and stability of event representation. Our code is available in https://github.com/chenyu0193/ACDF. [SEP] [HINT] low -> Materials Science (Syns: low-spirited, scurvy, depressed) | learning -> Bioinformatics (Syns: take, teach, acquire) | information -> Bioinformatics (Syns: entropy, data, info)",Neuroscience
"Isolated rapid eye movement sleep behavior disorder (iRBD) is a major prodromal marker of $α$-synucleinopathies, often preceding the clinical onset of Parkinson's disease, dementia with Lewy bodies, or multiple system atrophy. While wrist-worn actimeters hold significant potential for detecting RBD in large-scale screening efforts by capturing abnormal nocturnal movements, they become inoperable without a reliable and efficient analysis pipeline. This study presents ActiTect, a fully automated, open-source machine learning tool to identify RBD from actigraphy recordings. To ensure generalizability across heterogeneous acquisition settings, our pipeline includes robust preprocessing and automated sleep-wake detection to harmonize multi-device data and extract physiologically interpretable motion features characterizing activity patterns. Model development was conducted on a cohort of 78 individuals, yielding strong discrimination under nested cross-validation (AUROC = 0.95). Generalization was confirmed on a blinded local test set (n = 31, AUROC = 0.86) and on two independent external cohorts (n = 113, AUROC = 0.84; n = 57, AUROC = 0.94). To assess real-world robustness, leave-one-dataset-out cross-validation across the internal and external cohorts demonstrated consistent performance (AUROC range = 0.84-0.89). A complementary stability analysis showed that key predictive features remained reproducible across datasets, supporting the final pooled multi-center model as a robust pre-trained resource for broader deployment. By being open-source and easy to use, our tool promotes widespread adoption and facilitates independent validation and collaborative improvements, thereby advancing the field toward a unified and generalizable RBD detection model using wearable devices.",Neuroscience
"Isolated rapid eye movement sleep behavior disorder (iRBD) is a major prodromal marker of $α$-synucleinopathies, often preceding the clinical onset of Parkinson's disease, dementia with Lewy bodies, or multiple system atrophy. While wrist-worn actimeters hold significant potential for detecting RBD in large-scale screening efforts by capturing abnormal nocturnal movements, they become inoperable without a reliable and efficient analysis pipeline. This study presents ActiTect, a fully automated, open-source machine learning tool to identify RBD from actigraphy recordings. To ensure generalizability across heterogeneous acquisition settings, our pipeline includes robust preprocessing and automated sleep-wake detection to harmonize multi-device data and extract physiologically interpretable motion features characterizing activity patterns. Model development was conducted on a cohort of 78 individuals, yielding strong discrimination under nested cross-validation (AUROC = 0.95). Generalization was confirmed on a blinded local test set (n = 31, AUROC = 0.86) and on two independent external cohorts (n = 113, AUROC = 0.84; n = 57, AUROC = 0.94). To assess real-world robustness, leave-one-dataset-out cross-validation across the internal and external cohorts demonstrated consistent performance (AUROC range = 0.84-0.89). A complementary stability analysis showed that key predictive features remained reproducible across datasets, supporting the final pooled multi-center model as a robust pre-trained resource for broader deployment. By being open-source and easy to use, our tool promotes widespread adoption and facilitates independent validation and collaborative improvements, thereby advancing the field toward a unified and generalizable RBD detection model using wearable devices. [SEP] [HINT] field -> Materials Science (Syns: field of honor, line of business, orbit) | clinical -> Bioinformatics (Syns: ) | features -> Bioinformatics (Syns: characteristic, lineament, feature of speech)",Neuroscience
"This study introduces a novel method for predicting cognitive age using psychophysiological tests. To determine cognitive age, subjects were asked to complete a series of psychological tests measuring various cognitive functions, including reaction time and cognitive conflict, short-term memory, verbal functions, and color and spatial perception. Based on the tests completed, the average completion time, proportion of correct answers, average absolute delta of the color campimetry test, number of guessed words in the Münsterberg matrix, and other parameters were calculated for each subject. The obtained characteristics of the subjects were preprocessed and used to train a machine learning algorithm implementing a regression task for predicting a person's cognitive age. These findings contribute to the field of remote screening using mobile devices for human health for diagnosing and monitoring cognitive aging.",Neuroscience
"This study introduces a novel method for predicting cognitive age using psychophysiological tests. To determine cognitive age, subjects were asked to complete a series of psychological tests measuring various cognitive functions, including reaction time and cognitive conflict, short-term memory, verbal functions, and color and spatial perception. Based on the tests completed, the average completion time, proportion of correct answers, average absolute delta of the color campimetry test, number of guessed words in the Münsterberg matrix, and other parameters were calculated for each subject. The obtained characteristics of the subjects were preprocessed and used to train a machine learning algorithm implementing a regression task for predicting a person's cognitive age. These findings contribute to the field of remote screening using mobile devices for human health for diagnosing and monitoring cognitive aging. [SEP] [HINT] used -> Bioinformatics (Syns: utilize, ill-used, apply) | field -> Materials Science (Syns: field of honor, line of business, orbit) | task -> Neuroscience (Syns: tax, project, chore)",Neuroscience
"Foundation models have transformed AI by reducing reliance on task-specific data through large-scale pretraining. While successful in language and vision, their adoption in EEG has lagged due to the heterogeneity of public datasets, which are collected under varying protocols, devices, and electrode configurations. Existing EEG foundation models struggle to generalize across these variations, often restricting pretraining to a single setup, resulting in suboptimal performance, in particular under linear probing. We present REVE (Representation for EEG with Versatile Embeddings), a pretrained model explicitly designed to generalize across diverse EEG signals. REVE introduces a novel 4D positional encoding scheme that enables it to process signals of arbitrary length and electrode arrangement. Using a masked autoencoding objective, we pretrain REVE on over 60,000 hours of EEG data from 92 datasets spanning 25,000 subjects, representing the largest EEG pretraining effort to date. REVE achieves state-of-the-art results on 10 downstream EEG tasks, including motor imagery classification, seizure detection, sleep staging, cognitive load estimation, and emotion recognition. With little to no fine-tuning, it demonstrates strong generalization, and nuanced spatio-temporal modeling. We release code, pretrained weights, and tutorials to support standardized EEG research and accelerate progress in clinical neuroscience.",Neuroscience
"Foundation models have transformed AI by reducing reliance on task-specific data through large-scale pretraining. While successful in language and vision, their adoption in EEG has lagged due to the heterogeneity of public datasets, which are collected under varying protocols, devices, and electrode configurations. Existing EEG foundation models struggle to generalize across these variations, often restricting pretraining to a single setup, resulting in suboptimal performance, in particular under linear probing. We present REVE (Representation for EEG with Versatile Embeddings), a pretrained model explicitly designed to generalize across diverse EEG signals. REVE introduces a novel 4D positional encoding scheme that enables it to process signals of arbitrary length and electrode arrangement. Using a masked autoencoding objective, we pretrain REVE on over 60,000 hours of EEG data from 92 datasets spanning 25,000 subjects, representing the largest EEG pretraining effort to date. REVE achieves state-of-the-art results on 10 downstream EEG tasks, including motor imagery classification, seizure detection, sleep staging, cognitive load estimation, and emotion recognition. With little to no fine-tuning, it demonstrates strong generalization, and nuanced spatio-temporal modeling. We release code, pretrained weights, and tutorials to support standardized EEG research and accelerate progress in clinical neuroscience. [SEP] [HINT] clinical -> Bioinformatics (Syns: ) | language -> Neuroscience (Syns: linguistic process, linguistic communication, spoken communication) | datasets -> Bioinformatics (Syns: )",Neuroscience
"Reconstruction of 3D erythrocyte or red blood cell (RBC) morphology from partial observations, such as microscope images, is essential for understanding the physiology of RBC aging and the pathology of various RBC disorders. In this study, we propose a multi-fidelity neural network (MFNN) approach to fuse high-fidelity cross-sections of an RBC, with a morphologically similar low-fidelity reference 3D RBC shape to recover its full 3D surface. The MFNN predictor combines a convolutional neural network trained on low-fidelity reference RBC data with a feedforward neural network that captures nonlinear morphological correlations, and augments training with surface area and volume constraints for regularization in the low-fidelity branch. This approach is theoretically grounded by a topological homeomorphism between a sphere and 3D RBC surfaces, with training data generated by dissipative particle dynamics simulations of stomatocyte-discocyte-echinocyte transformation. Benchmarking across diverse RBC shapes observed in normal and aged populations, our results show that the MFNN predictor can reconstruct complex RBC morphologies with over 95% coordinate accuracy when provided with at least two orthogonal cross-sections. It is observed that informative oblique cross-sections intersecting spicule tips of echinocytes improve both local and global feature reconstruction, highlighting the value of feature-aware sampling. Our study further evaluates the influence of sampling strategies, shape dissimilarity, and noise, showing enhanced robustness under physically constrained training. Altogether, these results demonstrate the capability of MFNN to reconstruct the 3D shape of normal and aged RBCs from partial cross-sections as observed in conventional microscope images, which could facilitate the quantitative analysis of RBC morphological parameters in normal and disease-related RBC samples.",Bioinformatics
"Reconstruction of 3D erythrocyte or red blood cell (RBC) morphology from partial observations, such as microscope images, is essential for understanding the physiology of RBC aging and the pathology of various RBC disorders. In this study, we propose a multi-fidelity neural network (MFNN) approach to fuse high-fidelity cross-sections of an RBC, with a morphologically similar low-fidelity reference 3D RBC shape to recover its full 3D surface. The MFNN predictor combines a convolutional neural network trained on low-fidelity reference RBC data with a feedforward neural network that captures nonlinear morphological correlations, and augments training with surface area and volume constraints for regularization in the low-fidelity branch. This approach is theoretically grounded by a topological homeomorphism between a sphere and 3D RBC surfaces, with training data generated by dissipative particle dynamics simulations of stomatocyte-discocyte-echinocyte transformation. Benchmarking across diverse RBC shapes observed in normal and aged populations, our results show that the MFNN predictor can reconstruct complex RBC morphologies with over 95% coordinate accuracy when provided with at least two orthogonal cross-sections. It is observed that informative oblique cross-sections intersecting spicule tips of echinocytes improve both local and global feature reconstruction, highlighting the value of feature-aware sampling. Our study further evaluates the influence of sampling strategies, shape dissimilarity, and noise, showing enhanced robustness under physically constrained training. Altogether, these results demonstrate the capability of MFNN to reconstruct the 3D shape of normal and aged RBCs from partial cross-sections as observed in conventional microscope images, which could facilitate the quantitative analysis of RBC morphological parameters in normal and disease-related RBC samples. [SEP] [HINT] understanding -> Neuroscience (Syns: savvy, intellect, sympathy) | complex -> Bioinformatics (Syns: building complex, coordination compound, composite) | results -> Bioinformatics (Syns: final result, consequence, resultant role)",Bioinformatics
"Place cells are neurons that act as biological position sensors, associated with and firing in response to regions of an environment to situate an organism in space. These associations are recorded in (combinatorial) neural codes, motivating the following mathematical question: Which neural codes are generated by a collection of convex open sets in Euclidean space? Giusti and Itskov showed that a necessary condition for convexity is the absence of ``local obstructions."" This necessary condition is, in fact, sufficient for certain families of codes. One such family consists of all codes with up to three maximal codewords. In this article, we investigate codes with four maximal codewords, showing that for many such codes, convexity is characterized by the absence of local obstructions, whereas for other such codes, convexity is characterized by the absence of local obstructions and a second type of obstruction, a ``wheel"". Key to our analysis is a case-by-case investigation based on the nerve complex of the set of maximal codewords of a neural code. Up to symmetry, there are 20 possible nerves; and our results fully characterize convexity in 15 of the 20 cases.",Neuroscience
"Place cells are neurons that act as biological position sensors, associated with and firing in response to regions of an environment to situate an organism in space. These associations are recorded in (combinatorial) neural codes, motivating the following mathematical question: Which neural codes are generated by a collection of convex open sets in Euclidean space? Giusti and Itskov showed that a necessary condition for convexity is the absence of ``local obstructions."" This necessary condition is, in fact, sufficient for certain families of codes. One such family consists of all codes with up to three maximal codewords. In this article, we investigate codes with four maximal codewords, showing that for many such codes, convexity is characterized by the absence of local obstructions, whereas for other such codes, convexity is characterized by the absence of local obstructions and a second type of obstruction, a ``wheel"". Key to our analysis is a case-by-case investigation based on the nerve complex of the set of maximal codewords of a neural code. Up to symmetry, there are 20 possible nerves; and our results fully characterize convexity in 15 of the 20 cases. [SEP] [HINT] based -> Bioinformatics (Syns: ground, free-base, base) | complex -> Bioinformatics (Syns: building complex, coordination compound, composite) | results -> Bioinformatics (Syns: final result, consequence, resultant role)",Neuroscience
"Building autonomous experiment workflows requires transcending beyond the data-driven surrogate models to incorporate and dynamically refine physical theory during exploration. Here we demonstrate the first fully automated experimental realization of Bayesian co-navigation - a framework in which an autonomous agent simultaneously runs a physical experiment and a computationally expensive physical model. Using an automated AFM platform coupled to a kinetic Monte Carlo (kMC) model of thin-film growth, the system infers a set of effective bond energies for the (CrTaWV)x-Mo(1-x) pseudo-binary combinatorial library, progressively adjusting the kMC parameters to decrease the epistemic disparity between simulation and experiment. This real-time theoretical refinement enables the kMC model to capture the behavior of the specific materials system and reveals the mechanistic role of hetero-bonding in governing surface diffusion. Together, these results establish co-navigation as a general strategy for tightly integrating physical models with autonomous experimental platforms to produce interpretable and continually self-correcting theoretical modelling of complex materials systems.",Materials Science
"Building autonomous experiment workflows requires transcending beyond the data-driven surrogate models to incorporate and dynamically refine physical theory during exploration. Here we demonstrate the first fully automated experimental realization of Bayesian co-navigation - a framework in which an autonomous agent simultaneously runs a physical experiment and a computationally expensive physical model. Using an automated AFM platform coupled to a kinetic Monte Carlo (kMC) model of thin-film growth, the system infers a set of effective bond energies for the (CrTaWV)x-Mo(1-x) pseudo-binary combinatorial library, progressively adjusting the kMC parameters to decrease the epistemic disparity between simulation and experiment. This real-time theoretical refinement enables the kMC model to capture the behavior of the specific materials system and reveals the mechanistic role of hetero-bonding in governing surface diffusion. Together, these results establish co-navigation as a general strategy for tightly integrating physical models with autonomous experimental platforms to produce interpretable and continually self-correcting theoretical modelling of complex materials systems. [SEP] [HINT] complex -> Bioinformatics (Syns: building complex, coordination compound, composite) | results -> Bioinformatics (Syns: final result, consequence, resultant role) | framework -> Bioinformatics (Syns: theoretical account, model, fabric)",Materials Science
We demonstrate that moving edge dislocations can induce the reversal of magnetization in a ferromagnetic film due to the Barnett effect. The dynamics of magnetization is studied numerically within a discretized Landau-Lifshitz equation on a hexagonal lattice containing over $10^5$ sites. Local coordinate frames coupled to the crystallographic axes for each spin are used together with the laboratory coordinate frame. The parameters of a hexagonal close-packed cobalt lattice have been chosen for illustration. The magnetization reversal from a metastable initial state created by the external magnetic field occurs on a time scale of a few picoseconds. Our results imply that fast local elastic twists generated by moving dislocations serve as an important mechanism of magnetization dynamics in solids subjected to a mechanical stress.,Materials Science
"We demonstrate that moving edge dislocations can induce the reversal of magnetization in a ferromagnetic film due to the Barnett effect. The dynamics of magnetization is studied numerically within a discretized Landau-Lifshitz equation on a hexagonal lattice containing over $10^5$ sites. Local coordinate frames coupled to the crystallographic axes for each spin are used together with the laboratory coordinate frame. The parameters of a hexagonal close-packed cobalt lattice have been chosen for illustration. The magnetization reversal from a metastable initial state created by the external magnetic field occurs on a time scale of a few picoseconds. Our results imply that fast local elastic twists generated by moving dislocations serve as an important mechanism of magnetization dynamics in solids subjected to a mechanical stress. [SEP] [HINT] used -> Bioinformatics (Syns: utilize, ill-used, apply) | field -> Materials Science (Syns: field of honor, line of business, orbit) | spin -> Materials Science (Syns: twisting, whirl, tailspin)",Materials Science
"Diffusion MRI has revealed important insights into white matter microstructure, but its application to gray matter remains comparatively less explored. Here, we investigate whether global patterns of gray-matter microstructure can be captured through neurite orientation dispersion and density imaging (NODDI) and whether such patterns are predictive of cognitive performance. Our findings demonstrate that PCA-based global indicators of gray-matter microstructure provide complementary markers of structure-function relationships, extending beyond region-specific analyses. Our results suggest that general microstructure factors may serve as robust, interpretable biomarkers for studying cognition and cortical organization at the population level. Using diffusion MRI and behavioral data from the Human Connectome Project Young Adult study, we derived region-averaged NODDI parameters and applied principal component analysis (PCA) to construct general gray-matter microstructure factors. We found that the factor derived from isotropic volume fraction explained substantial inter-individual variability and was significantly correlated with specific cognitive scores collected from the NIH Toolbox. In particular, the isotropic volume fraction factor was linked to reading and vocabulary performance and to cognitive fluidity.",Bioinformatics
"Diffusion MRI has revealed important insights into white matter microstructure, but its application to gray matter remains comparatively less explored. Here, we investigate whether global patterns of gray-matter microstructure can be captured through neurite orientation dispersion and density imaging (NODDI) and whether such patterns are predictive of cognitive performance. Our findings demonstrate that PCA-based global indicators of gray-matter microstructure provide complementary markers of structure-function relationships, extending beyond region-specific analyses. Our results suggest that general microstructure factors may serve as robust, interpretable biomarkers for studying cognition and cortical organization at the population level. Using diffusion MRI and behavioral data from the Human Connectome Project Young Adult study, we derived region-averaged NODDI parameters and applied principal component analysis (PCA) to construct general gray-matter microstructure factors. We found that the factor derived from isotropic volume fraction explained substantial inter-individual variability and was significantly correlated with specific cognitive scores collected from the NIH Toolbox. In particular, the isotropic volume fraction factor was linked to reading and vocabulary performance and to cognitive fluidity. [SEP] [HINT] cortical -> Neuroscience (Syns: ) | performance -> Bioinformatics (Syns: functioning, operation, carrying out) | results -> Bioinformatics (Syns: final result, consequence, resultant role)",Bioinformatics
"Current non-invasive neuroimaging techniques trade off between spatial resolution and temporal resolution. While magnetoencephalography (MEG) can capture rapid neural dynamics and functional magnetic resonance imaging (fMRI) can spatially localize brain activity, a unified picture that preserves both high resolutions remains an unsolved challenge with existing source localization or MEG-fMRI fusion methods, especially for single-trial naturalistic data. We collected whole-head MEG when subjects listened passively to more than seven hours of narrative stories, using the same stimuli in an open fMRI dataset (LeBel et al., 2023). We developed a transformer-based encoding model that combines the MEG and fMRI from these two naturalistic speech comprehension experiments to estimate latent cortical source responses with high spatiotemporal resolution. Our model is trained to predict MEG and fMRI from multiple subjects simultaneously, with a latent layer that represents our estimates of reconstructed cortical sources. Our model predicts MEG better than the common standard of single-modality encoding models, and it also yields source estimates with higher spatial and temporal fidelity than classic minimum-norm solutions in simulation experiments. We validated the estimated latent sources by showing its strong generalizability across unseen subjects and modalities. Estimated activity in our source space predict electrocorticography (ECoG) better than an ECoG-trained encoding model in an entirely new dataset. By integrating the power of large naturalistic experiments, MEG, fMRI, and encoding models, we propose a practical route towards millisecond-and-millimeter brain mapping.",Neuroscience
"Current non-invasive neuroimaging techniques trade off between spatial resolution and temporal resolution. While magnetoencephalography (MEG) can capture rapid neural dynamics and functional magnetic resonance imaging (fMRI) can spatially localize brain activity, a unified picture that preserves both high resolutions remains an unsolved challenge with existing source localization or MEG-fMRI fusion methods, especially for single-trial naturalistic data. We collected whole-head MEG when subjects listened passively to more than seven hours of narrative stories, using the same stimuli in an open fMRI dataset (LeBel et al., 2023). We developed a transformer-based encoding model that combines the MEG and fMRI from these two naturalistic speech comprehension experiments to estimate latent cortical source responses with high spatiotemporal resolution. Our model is trained to predict MEG and fMRI from multiple subjects simultaneously, with a latent layer that represents our estimates of reconstructed cortical sources. Our model predicts MEG better than the common standard of single-modality encoding models, and it also yields source estimates with higher spatial and temporal fidelity than classic minimum-norm solutions in simulation experiments. We validated the estimated latent sources by showing its strong generalizability across unseen subjects and modalities. Estimated activity in our source space predict electrocorticography (ECoG) better than an ECoG-trained encoding model in an entirely new dataset. By integrating the power of large naturalistic experiments, MEG, fMRI, and encoding models, we propose a practical route towards millisecond-and-millimeter brain mapping. [SEP] [HINT] cortical -> Neuroscience (Syns: ) | space -> Neuroscience (Syns: distance, place, outer space) | functional -> Neuroscience (Syns: working, usable, running)",Neuroscience
"Subjective cognitive decline (SCD) approximately doubles the risk of progressing to MCI and dementia. The present study investigates how one's subjective concerns of his/her own cognition are manifested in the neural dynamics during speech perception. EEG was collected from 56 Cantonese, cognitively normal older adults (aged 60 - 70) while they listened to stimuli of four expressive styles that varied in prosody: scrambled, descriptive, dialogue, and exciting. Using encoding models to predict EEG signals from acoustic, segmentation, and phonotactic features, we found that greater subjective concern was associated with weaker cortical tracking of (1) higher-level linguistic features but not acoustic features and (2) less engaging stimuli (scrambled and descriptive styles) but not prosodically rich stimuli. Overall, our results suggest that early signs of cognitive impairment can be revealed from speech perception via cortical tracking, especially while listening to prosodically flat speech.",Neuroscience
"Subjective cognitive decline (SCD) approximately doubles the risk of progressing to MCI and dementia. The present study investigates how one's subjective concerns of his/her own cognition are manifested in the neural dynamics during speech perception. EEG was collected from 56 Cantonese, cognitively normal older adults (aged 60 - 70) while they listened to stimuli of four expressive styles that varied in prosody: scrambled, descriptive, dialogue, and exciting. Using encoding models to predict EEG signals from acoustic, segmentation, and phonotactic features, we found that greater subjective concern was associated with weaker cortical tracking of (1) higher-level linguistic features but not acoustic features and (2) less engaging stimuli (scrambled and descriptive styles) but not prosodically rich stimuli. Overall, our results suggest that early signs of cognitive impairment can be revealed from speech perception via cortical tracking, especially while listening to prosodically flat speech. [SEP] [HINT] features -> Bioinformatics (Syns: characteristic, lineament, feature of speech) | cortical -> Neuroscience (Syns: ) | results -> Bioinformatics (Syns: final result, consequence, resultant role)",Neuroscience
"Layered Zintl compounds exhibit significant tunability of thermoelectric (TE) parameters facilitated by their multiple elemental combinations and flexibility in stacking order within the layers. In this work, the effect of stacking order on TE properties of theoretically predicted layered Zintl compounds XZnBi (X = Rb, Cs) is studied using 1st-principles calculations and Boltzmann equations. The materials are semiconductors having moderate band gaps ranging from 0.44 to 0.52 eV. There exist six identical hole pockets for valence band maxima due to the crystal symmetry. This leads to high band degeneracy but simultaneously promotes intervalley scatterings. While as for conduction bands, the Fermi surface consists of a single but highly anisotropic, quasi-two dimensional electron pockets with cylindrical shape along z-axis. This kind of Fermi surface is a characteristic of a pudding mold band shape. It facilitates a unique combination of heavy and light electron masses, simultaneously optimizing Seebeck coefficient and electrical conductivity. At first, electronic transport coefficients are calculated using constant relaxation time approximation (CRTA) or electron-phonon coupling matrix elements (el-ph). The calculated relaxation times are then integrated with transport results to get the realistic values of TE parameters. The analysis of three-phonon scattering reveals low thermal conductivity ($k_{l}$) below 2 W/m/K in these compounds. The $k_{l}$ also depends on stacking order with the values of nearly half in AB stacking as compared to that of AA stacking. These combined factors lead to a high ZT at 900 K, reaching to a maximum of 2.42 using CRTA and 0.52 when el-ph are included. The study highlights the potential of XZnBi systems as promising TE materials as well as the critical roles of stacking and el-ph in accurately evaluating TE properties.",Materials Science
"Layered Zintl compounds exhibit significant tunability of thermoelectric (TE) parameters facilitated by their multiple elemental combinations and flexibility in stacking order within the layers. In this work, the effect of stacking order on TE properties of theoretically predicted layered Zintl compounds XZnBi (X = Rb, Cs) is studied using 1st-principles calculations and Boltzmann equations. The materials are semiconductors having moderate band gaps ranging from 0.44 to 0.52 eV. There exist six identical hole pockets for valence band maxima due to the crystal symmetry. This leads to high band degeneracy but simultaneously promotes intervalley scatterings. While as for conduction bands, the Fermi surface consists of a single but highly anisotropic, quasi-two dimensional electron pockets with cylindrical shape along z-axis. This kind of Fermi surface is a characteristic of a pudding mold band shape. It facilitates a unique combination of heavy and light electron masses, simultaneously optimizing Seebeck coefficient and electrical conductivity. At first, electronic transport coefficients are calculated using constant relaxation time approximation (CRTA) or electron-phonon coupling matrix elements (el-ph). The calculated relaxation times are then integrated with transport results to get the realistic values of TE parameters. The analysis of three-phonon scattering reveals low thermal conductivity ($k_{l}$) below 2 W/m/K in these compounds. The $k_{l}$ also depends on stacking order with the values of nearly half in AB stacking as compared to that of AA stacking. These combined factors lead to a high ZT at 900 K, reaching to a maximum of 2.42 using CRTA and 0.52 when el-ph are included. The study highlights the potential of XZnBi systems as promising TE materials as well as the critical roles of stacking and el-ph in accurately evaluating TE properties. [SEP] [HINT] low -> Materials Science (Syns: low-spirited, scurvy, depressed) | transport -> Materials Science (Syns: transferral, enthral, shipping) | electronic -> Materials Science (Syns: )",Materials Science
"In addressing the challenge of Crystal Structure Prediction (CSP), symmetry-aware deep learning models, particularly diffusion models, have been extensively studied, which treat CSP as a conditional generation task. However, ensuring permutation, rotation, and periodic translation equivariance during diffusion process remains incompletely addressed. In this work, we propose EquiCSP, a novel equivariant diffusion-based generative model. We not only address the overlooked issue of lattice permutation equivariance in existing models, but also develop a unique noising algorithm that rigorously maintains periodic translation equivariance throughout both training and inference processes. Our experiments indicate that EquiCSP significantly surpasses existing models in terms of generating accurate structures and demonstrates faster convergence during the training process.",Materials Science
"In addressing the challenge of Crystal Structure Prediction (CSP), symmetry-aware deep learning models, particularly diffusion models, have been extensively studied, which treat CSP as a conditional generation task. However, ensuring permutation, rotation, and periodic translation equivariance during diffusion process remains incompletely addressed. In this work, we propose EquiCSP, a novel equivariant diffusion-based generative model. We not only address the overlooked issue of lattice permutation equivariance in existing models, but also develop a unique noising algorithm that rigorously maintains periodic translation equivariance throughout both training and inference processes. Our experiments indicate that EquiCSP significantly surpasses existing models in terms of generating accurate structures and demonstrates faster convergence during the training process. [SEP] [HINT] learning -> Bioinformatics (Syns: take, teach, acquire) | structure -> Bioinformatics (Syns: social system, complex body part, social structure) | crystal -> Materials Science (Syns: crystallization, quartz, lechatelierite)",Materials Science
"In multicellular organisms, cells coordinate their activities through cell-cell communication (CCC), which are crucial for development, tissue homeostasis, and disease progression. Recent advances in single-cell and spatial omics technologies provide unprecedented opportunities to systematically infer and analyze CCC from these omics data, either by integrating prior knowledge of ligand-receptor interactions (LRIs) or through de novo approaches. A variety of computational methods have been developed, focusing on methodological innovations, accurate modeling of complex signaling mechanisms, and investigation of broader biological questions. These advances have greatly enhanced our ability to analyze CCC and generate biological hypotheses. Here, we introduce the biological mechanisms and modeling strategies of CCC, and provide a focused overview of more than 140 computational methods for inferring CCC from single-cell and spatial transcriptomic data, emphasizing the diversity in methodological frameworks and biological questions. Finally, we discuss the current challenges and future opportunities in this rapidly evolving field.",Bioinformatics
"In multicellular organisms, cells coordinate their activities through cell-cell communication (CCC), which are crucial for development, tissue homeostasis, and disease progression. Recent advances in single-cell and spatial omics technologies provide unprecedented opportunities to systematically infer and analyze CCC from these omics data, either by integrating prior knowledge of ligand-receptor interactions (LRIs) or through de novo approaches. A variety of computational methods have been developed, focusing on methodological innovations, accurate modeling of complex signaling mechanisms, and investigation of broader biological questions. These advances have greatly enhanced our ability to analyze CCC and generate biological hypotheses. Here, we introduce the biological mechanisms and modeling strategies of CCC, and provide a focused overview of more than 140 computational methods for inferring CCC from single-cell and spatial transcriptomic data, emphasizing the diversity in methodological frameworks and biological questions. Finally, we discuss the current challenges and future opportunities in this rapidly evolving field. [SEP] [HINT] tissue -> Bioinformatics (Syns: tissue paper, weave) | computational -> Neuroscience (Syns: ) | complex -> Bioinformatics (Syns: building complex, coordination compound, composite)",Bioinformatics
"Foundation models have revolutionized various fields such as natural language processing (NLP) and computer vision (CV). While efforts have been made to transfer the success of the foundation models in general AI domains to biology, existing works focus on directly adopting the existing foundation model architectures from general machine learning domains without a systematic design considering the unique physicochemical and structural properties of each biological data modality. This leads to suboptimal performance, as these repurposed architectures struggle to capture the long-range dependencies, sparse information, and complex underlying ``grammars'' inherent to biological data. To address this gap, we introduce BioArc, a novel framework designed to move beyond intuition-driven architecture design towards principled, automated architecture discovery for biological foundation models. Leveraging Neural Architecture Search (NAS), BioArc systematically explores a vast architecture design space, evaluating architectures across multiple biological modalities while rigorously analyzing the interplay between architecture, tokenization, and training strategies. This large-scale analysis identifies novel, high-performance architectures, allowing us to distill a set of empirical design principles to guide future model development. Furthermore, to make the best of this set of discovered principled architectures, we propose and compare several architecture prediction methods that effectively and efficiently predict optimal architectures for new biological tasks. Overall, our work provides a foundational resource and a principled methodology to guide the creation of the next generation of task-specific and foundation models for biology.",Bioinformatics
"Foundation models have revolutionized various fields such as natural language processing (NLP) and computer vision (CV). While efforts have been made to transfer the success of the foundation models in general AI domains to biology, existing works focus on directly adopting the existing foundation model architectures from general machine learning domains without a systematic design considering the unique physicochemical and structural properties of each biological data modality. This leads to suboptimal performance, as these repurposed architectures struggle to capture the long-range dependencies, sparse information, and complex underlying ``grammars'' inherent to biological data. To address this gap, we introduce BioArc, a novel framework designed to move beyond intuition-driven architecture design towards principled, automated architecture discovery for biological foundation models. Leveraging Neural Architecture Search (NAS), BioArc systematically explores a vast architecture design space, evaluating architectures across multiple biological modalities while rigorously analyzing the interplay between architecture, tokenization, and training strategies. This large-scale analysis identifies novel, high-performance architectures, allowing us to distill a set of empirical design principles to guide future model development. Furthermore, to make the best of this set of discovered principled architectures, we propose and compare several architecture prediction methods that effectively and efficiently predict optimal architectures for new biological tasks. Overall, our work provides a foundational resource and a principled methodology to guide the creation of the next generation of task-specific and foundation models for biology. [SEP] [HINT] language -> Neuroscience (Syns: linguistic process, linguistic communication, spoken communication) | learning -> Bioinformatics (Syns: take, teach, acquire) | complex -> Bioinformatics (Syns: building complex, coordination compound, composite)",Bioinformatics
"The accuracy of bulk property predictions in density functional theory (DFT) calculations depends on the choice of exchange-correlation functional. While the Perdew-Burke-Ernzerhof (PBE) functional systematically overestimates lattice parameters and strongly underestimates electronic band gaps, hybrid functionals such as Heyd-Scuseria-Ernzerhof (HSE) offer better overall agreement across a broad range of materials. Using germanium as a critical test case, we challenge the ability of both functionals to capture semiconductor properties. Although HSE improves PBE's gap error, it fails to reproduce germanium's correct $Γ$-L indirect and $Γ$-$Γ$ band gaps simultaneously. Noting that the PBE underestimated energy separation between the 4p valence-band maximum and 4s conduction-band minimum causes unphysical $sp$ mixing, we propose DFT+$α$, a semi-empirical correction scheme applied selectively to 4s-like orbitals. For germanium, DFT+$α$ restores the proper ordering and orbital character of the band edges and yields accurate lattice constant, bulk modulus, elastic constants and phonon frequencies at a fraction of hybrid-functional computational cost.",Materials Science
"The accuracy of bulk property predictions in density functional theory (DFT) calculations depends on the choice of exchange-correlation functional. While the Perdew-Burke-Ernzerhof (PBE) functional systematically overestimates lattice parameters and strongly underestimates electronic band gaps, hybrid functionals such as Heyd-Scuseria-Ernzerhof (HSE) offer better overall agreement across a broad range of materials. Using germanium as a critical test case, we challenge the ability of both functionals to capture semiconductor properties. Although HSE improves PBE's gap error, it fails to reproduce germanium's correct $Γ$-L indirect and $Γ$-$Γ$ band gaps simultaneously. Noting that the PBE underestimated energy separation between the 4p valence-band maximum and 4s conduction-band minimum causes unphysical $sp$ mixing, we propose DFT+$α$, a semi-empirical correction scheme applied selectively to 4s-like orbitals. For germanium, DFT+$α$ restores the proper ordering and orbital character of the band edges and yields accurate lattice constant, bulk modulus, elastic constants and phonon frequencies at a fraction of hybrid-functional computational cost. [SEP] [HINT] phonon -> Materials Science (Syns: ) | computational -> Neuroscience (Syns: ) | electronic -> Materials Science (Syns: )",Materials Science
"Collective behaviors in cellular systems are regulated not only by biochemical signalling pathways but also by intercellular mechanical forces, whose quantification in contractile monolayers remains poorly understood. Here, by integrating traction force microscopy and numerical simulations, we reconstruct the stress distribution in C2C12 myoblast monolayers to reveal the roles of local mechanical forces in determining the collective cellular structures. We find that contractile monolayers exhibit positive maximum and negative minimum principal stresses, reflecting the intrinsic anisotropy of active tension. Distinct stress patterns emerge around topological defects, coinciding with singularities in cell alignment, density, and morphology, indicating a strong coupling between mechanical forces and structural organization. Moreover, tensile stresses are preferentially transmitted along the cell elongation axis and compressive stresses transversely, demonstrating that local stress guides cell arrangement. This mechanical guidance appears to be universal among contractile systems, as observed also in bone marrow-derived mesenchymal stem cells. Together, our work establishes a quantitative framework for characterizing mechanical anisotropy in active cellular monolayers and reveals a general principle of force-structure coupling, providing a physical basis for understanding how mechanics governs myogenesis, morphogenesis, and collective organization in contractile cellular systems.",Bioinformatics
"Collective behaviors in cellular systems are regulated not only by biochemical signalling pathways but also by intercellular mechanical forces, whose quantification in contractile monolayers remains poorly understood. Here, by integrating traction force microscopy and numerical simulations, we reconstruct the stress distribution in C2C12 myoblast monolayers to reveal the roles of local mechanical forces in determining the collective cellular structures. We find that contractile monolayers exhibit positive maximum and negative minimum principal stresses, reflecting the intrinsic anisotropy of active tension. Distinct stress patterns emerge around topological defects, coinciding with singularities in cell alignment, density, and morphology, indicating a strong coupling between mechanical forces and structural organization. Moreover, tensile stresses are preferentially transmitted along the cell elongation axis and compressive stresses transversely, demonstrating that local stress guides cell arrangement. This mechanical guidance appears to be universal among contractile systems, as observed also in bone marrow-derived mesenchymal stem cells. Together, our work establishes a quantitative framework for characterizing mechanical anisotropy in active cellular monolayers and reveals a general principle of force-structure coupling, providing a physical basis for understanding how mechanics governs myogenesis, morphogenesis, and collective organization in contractile cellular systems. [SEP] [HINT] understanding -> Neuroscience (Syns: savvy, intellect, sympathy) | work -> Bioinformatics (Syns: work out, process, bring) | systems -> Bioinformatics (Syns: organization, organisation, system)",Bioinformatics
"Human emotions are difficult to convey through words and are often abstracted in the process; however, electroencephalogram (EEG) signals can offer a more direct lens into emotional brain activity. Recent studies show that deep learning models can process these signals to perform emotion recognition with high accuracy. However, many existing approaches overlook the dynamic interplay between distinct brain regions, which can be crucial to understanding how emotions unfold and evolve over time, potentially aiding in more accurate emotion recognition. To address this, we propose RBTransformer, a Transformer-based neural network architecture that models inter-cortical neural dynamics of the brain in latent space to better capture structured neural interactions for effective EEG-based emotion recognition. First, the EEG signals are converted into Band Differential Entropy (BDE) tokens, which are then passed through Electrode Identity embeddings to retain spatial provenance. These tokens are processed through successive inter-cortical multi-head attention blocks that construct an electrode x electrode attention matrix, allowing the model to learn the inter-cortical neural dependencies. The resulting features are then passed through a classification head to obtain the final prediction. We conducted extensive experiments, specifically under subject-dependent settings, on the SEED, DEAP, and DREAMER datasets, over all three dimensions, Valence, Arousal, and Dominance (for DEAP and DREAMER), under both binary and multi-class classification settings. The results demonstrate that the proposed RBTransformer outperforms all previous state-of-the-art methods across all three datasets, over all three dimensions under both classification settings. The source code is available at: https://github.com/nnilayy/RBTransformer.",Neuroscience
"Human emotions are difficult to convey through words and are often abstracted in the process; however, electroencephalogram (EEG) signals can offer a more direct lens into emotional brain activity. Recent studies show that deep learning models can process these signals to perform emotion recognition with high accuracy. However, many existing approaches overlook the dynamic interplay between distinct brain regions, which can be crucial to understanding how emotions unfold and evolve over time, potentially aiding in more accurate emotion recognition. To address this, we propose RBTransformer, a Transformer-based neural network architecture that models inter-cortical neural dynamics of the brain in latent space to better capture structured neural interactions for effective EEG-based emotion recognition. First, the EEG signals are converted into Band Differential Entropy (BDE) tokens, which are then passed through Electrode Identity embeddings to retain spatial provenance. These tokens are processed through successive inter-cortical multi-head attention blocks that construct an electrode x electrode attention matrix, allowing the model to learn the inter-cortical neural dependencies. The resulting features are then passed through a classification head to obtain the final prediction. We conducted extensive experiments, specifically under subject-dependent settings, on the SEED, DEAP, and DREAMER datasets, over all three dimensions, Valence, Arousal, and Dominance (for DEAP and DREAMER), under both binary and multi-class classification settings. The results demonstrate that the proposed RBTransformer outperforms all previous state-of-the-art methods across all three datasets, over all three dimensions under both classification settings. The source code is available at: https://github.com/nnilayy/RBTransformer. [SEP] [HINT] features -> Bioinformatics (Syns: characteristic, lineament, feature of speech) | understanding -> Neuroscience (Syns: savvy, intellect, sympathy) | learning -> Bioinformatics (Syns: take, teach, acquire)",Neuroscience
"Accurately predicting the three-dimensional structures of protein-ligand complexes remains a fundamental challenge in computational drug discovery that limits the pace and success of therapeutic design. Deep learning methods have recently shown strong potential as structural prediction tools, achieving promising accuracy across diverse biomolecular systems. However, their performance and utility are constrained by scarce experimental data, inefficient architectures, physically invalid poses, and the limited ability to exploit auxiliary information available at inference. To address these issues, we introduce Pearl (Placing Every Atom in the Right Location), a foundation model for protein-ligand cofolding at scale. Pearl addresses these challenges with three key innovations: (1) training recipes that include large-scale synthetic data to overcome data scarcity; (2) architectures that incorporate an SO(3)-equivariant diffusion module to inherently respect 3D rotational symmetries, improving generalization and sample efficiency, and (3) controllable inference, including a generalized multi-chain templating system supporting both protein and non-polymeric components as well as dual unconditional/conditional modes. Pearl establishes a new state-of-the-art performance in protein-ligand cofolding. On the key metric of generating accurate (RMSD < 2 Å) and physically valid poses, Pearl surpasses AlphaFold 3 and other open source baselines on the public Runs N' Poses and PoseBusters benchmarks, delivering 14.5% and 14.2% improvements, respectively, over the next best model. In the pocket-conditional cofolding regime, Pearl delivers $3.6\times$ improvement on a proprietary set of challenging, real-world drug targets at the more rigorous RMSD < 1 Å threshold. Finally, we demonstrate that model performance correlates directly with synthetic dataset size used in training.",Bioinformatics
"Accurately predicting the three-dimensional structures of protein-ligand complexes remains a fundamental challenge in computational drug discovery that limits the pace and success of therapeutic design. Deep learning methods have recently shown strong potential as structural prediction tools, achieving promising accuracy across diverse biomolecular systems. However, their performance and utility are constrained by scarce experimental data, inefficient architectures, physically invalid poses, and the limited ability to exploit auxiliary information available at inference. To address these issues, we introduce Pearl (Placing Every Atom in the Right Location), a foundation model for protein-ligand cofolding at scale. Pearl addresses these challenges with three key innovations: (1) training recipes that include large-scale synthetic data to overcome data scarcity; (2) architectures that incorporate an SO(3)-equivariant diffusion module to inherently respect 3D rotational symmetries, improving generalization and sample efficiency, and (3) controllable inference, including a generalized multi-chain templating system supporting both protein and non-polymeric components as well as dual unconditional/conditional modes. Pearl establishes a new state-of-the-art performance in protein-ligand cofolding. On the key metric of generating accurate (RMSD < 2 Å) and physically valid poses, Pearl surpasses AlphaFold 3 and other open source baselines on the public Runs N' Poses and PoseBusters benchmarks, delivering 14.5% and 14.2% improvements, respectively, over the next best model. In the pocket-conditional cofolding regime, Pearl delivers $3.6\times$ improvement on a proprietary set of challenging, real-world drug targets at the more rigorous RMSD < 1 Å threshold. Finally, we demonstrate that model performance correlates directly with synthetic dataset size used in training. [SEP] [HINT] used -> Bioinformatics (Syns: utilize, ill-used, apply) | computational -> Neuroscience (Syns: ) | learning -> Bioinformatics (Syns: take, teach, acquire)",Bioinformatics
"The transport dynamics of itinerant charge carriers and their interactions with the environment. For two-dimensional oxide thermoelectrics, predominantly represented by doped SrTiO3-based superlattices, reduced spatial dimensions and increased effective mass are known to enhance thermopower (S). However, because of their large effective Bohr radius resulting from their high dielectric constant, SrTiO3-based systems have limitations in exhibiting the 2D characteristic. Here, we focus on EuTiO3 as an alternative perovskite platform in which fractional LaxEu1-xTiO3/EuTiO3 artificial superlattices demonstrate the improvement in 2D nature for the dimensionality-induced improvement of S. We observed a quasi-2D thermopower S2D of -950 uV K-1 and S2D/S3D of ~20 resulting from the improved 2D confinement. Thermopower measurements, combined with hybrid density functional theory calculations, show the enhanced S originates from the confinement of Ti 3dxy-states within the LaxEu1-xTiO3 layers and the associated increase in the 2D density of states. In detail, a smaller effective Bohr radius and modified electronic band structures, in conjunction with the presence of the Eu 4f-states in EuTiO3 which modified the local electronic potential and strengthened the spatial confinement of Ti 3d-states. This approach to improving the dimensional confinement establishes a small effective Bohr radius and Eu 4f-state assisted 2D confinement provides valuable insights into the design of high-performance applications in artificial oxide superlattices.",Materials Science
"The transport dynamics of itinerant charge carriers and their interactions with the environment. For two-dimensional oxide thermoelectrics, predominantly represented by doped SrTiO3-based superlattices, reduced spatial dimensions and increased effective mass are known to enhance thermopower (S). However, because of their large effective Bohr radius resulting from their high dielectric constant, SrTiO3-based systems have limitations in exhibiting the 2D characteristic. Here, we focus on EuTiO3 as an alternative perovskite platform in which fractional LaxEu1-xTiO3/EuTiO3 artificial superlattices demonstrate the improvement in 2D nature for the dimensionality-induced improvement of S. We observed a quasi-2D thermopower S2D of -950 uV K-1 and S2D/S3D of ~20 resulting from the improved 2D confinement. Thermopower measurements, combined with hybrid density functional theory calculations, show the enhanced S originates from the confinement of Ti 3dxy-states within the LaxEu1-xTiO3 layers and the associated increase in the 2D density of states. In detail, a smaller effective Bohr radius and modified electronic band structures, in conjunction with the presence of the Eu 4f-states in EuTiO3 which modified the local electronic potential and strengthened the spatial confinement of Ti 3d-states. This approach to improving the dimensional confinement establishes a small effective Bohr radius and Eu 4f-state assisted 2D confinement provides valuable insights into the design of high-performance applications in artificial oxide superlattices. [SEP] [HINT] perovskite -> Materials Science (Syns: ) | transport -> Materials Science (Syns: transferral, enthral, shipping) | charge -> Materials Science (Syns: tear, bearing, burster)",Materials Science
"Objective: Tinnitus affects 10-15% of the population yet lacks objective diagnostic biomarkers. This study applied machine learning to EEG and fMRI data to identify neural signatures distinguishing tinnitus patients from healthy controls. Methods: Two datasets were analyzed: 64-channel EEG recordings from 80 participants (40 tinnitus, 40 controls) and resting-state fMRI data from 38 participants (19 tinnitus, 19 controls). EEG analysis extracted microstate features across four to seven clustering states and five frequency bands, producing 440 features per subject. Global Field Power signals were also transformed into wavelet images for deep learning. fMRI data were analyzed using slice-wise convolutional neural networks and hybrid models combining pre-trained architectures (VGG16, ResNet50) with Decision Tree, Random Forest, and SVM classifiers. Model performance was evaluated using 5-fold cross-validation based on accuracy, precision, recall, F1-score, and ROC-AUC. Results: EEG microstate analysis revealed altered network dynamics in tinnitus, particularly reduced gamma-band microstate B occurrence (healthy: 56.56 vs tinnitus: 43.81, p < 0.001) and diminished alpha coverage. Tree-based classifiers achieved up to 98.8% accuracy, while VGG16 on wavelet-transformed EEG yielded 95.4% and 94.1% accuracy for delta and alpha bands, respectively. fMRI analysis identified 12 high-performing axial slices (>=90% accuracy), with slice 17 reaching 99.0%. The hybrid VGG16-Decision Tree model achieved 98.95% +/- 2.94% accuracy. Conclusion: EEG and fMRI provided effective neural biomarkers for tinnitus classification. Tree-based and hybrid models demonstrated superior performance, highlighting tinnitus as a multi-network disorder requiring multimodal analysis.",Neuroscience
"Objective: Tinnitus affects 10-15% of the population yet lacks objective diagnostic biomarkers. This study applied machine learning to EEG and fMRI data to identify neural signatures distinguishing tinnitus patients from healthy controls. Methods: Two datasets were analyzed: 64-channel EEG recordings from 80 participants (40 tinnitus, 40 controls) and resting-state fMRI data from 38 participants (19 tinnitus, 19 controls). EEG analysis extracted microstate features across four to seven clustering states and five frequency bands, producing 440 features per subject. Global Field Power signals were also transformed into wavelet images for deep learning. fMRI data were analyzed using slice-wise convolutional neural networks and hybrid models combining pre-trained architectures (VGG16, ResNet50) with Decision Tree, Random Forest, and SVM classifiers. Model performance was evaluated using 5-fold cross-validation based on accuracy, precision, recall, F1-score, and ROC-AUC. Results: EEG microstate analysis revealed altered network dynamics in tinnitus, particularly reduced gamma-band microstate B occurrence (healthy: 56.56 vs tinnitus: 43.81, p < 0.001) and diminished alpha coverage. Tree-based classifiers achieved up to 98.8% accuracy, while VGG16 on wavelet-transformed EEG yielded 95.4% and 94.1% accuracy for delta and alpha bands, respectively. fMRI analysis identified 12 high-performing axial slices (>=90% accuracy), with slice 17 reaching 99.0%. The hybrid VGG16-Decision Tree model achieved 98.95% +/- 2.94% accuracy. Conclusion: EEG and fMRI provided effective neural biomarkers for tinnitus classification. Tree-based and hybrid models demonstrated superior performance, highlighting tinnitus as a multi-network disorder requiring multimodal analysis. [SEP] [HINT] field -> Materials Science (Syns: field of honor, line of business, orbit) | based -> Bioinformatics (Syns: ground, free-base, base) | features -> Bioinformatics (Syns: characteristic, lineament, feature of speech)",Neuroscience
"Traumatic Brain Injury (TBI) results from an impact or concussion to the head with the injury being specifically characterized through pathological degradation at various biological length scales. Following injury, various mechanical modeling techniques have been proposed in the literature that seek to quantify neuronal-scale to tissue-scale metrics of brain damage. Broadly, the two categories of degradation encompass physiological deterioration of neurons and upregulation of chemical entities such as neurotransmitters which causes initiation of downstream pathophysiological effects. Despite the many contributing pathways, in this work, we delineate and model a potential glia-initiated injury pathway that leads to secondary injury. The goal of this work is to demonstrate a continuum framework which models the multiphysics of mechano-chemical interactions underlying TBI. Using a coupled PDE (partial differential equation) formulation and FEM (finite element method) discretization, the framework highlights evolution of field variables which spatio-temporally resolve mechanical metrics and chemical species across neuronal clusters. The modeling domain encompasses microglia, neurons and the extracellular matrix. The continuum framework used to model the mechano-chemical interactions assumes a three dimensional viscoelastic network to capture the mechanical response underlying proteins constituting the neuron microstructure and advection-diffusion equations modeling spatio-temporal evolution of chemical species. We use this framework to numerically estimate key concentrations of chemical species produced by the strain field. In this work, we identify key biomarkers within the labyrinth of molecular pathways and build a framework that captures the core mechano-chemical interactions. This framework is an attempt to quantify secondary injury and thus assist in developing targeted TBI treatments.",Bioinformatics
"Traumatic Brain Injury (TBI) results from an impact or concussion to the head with the injury being specifically characterized through pathological degradation at various biological length scales. Following injury, various mechanical modeling techniques have been proposed in the literature that seek to quantify neuronal-scale to tissue-scale metrics of brain damage. Broadly, the two categories of degradation encompass physiological deterioration of neurons and upregulation of chemical entities such as neurotransmitters which causes initiation of downstream pathophysiological effects. Despite the many contributing pathways, in this work, we delineate and model a potential glia-initiated injury pathway that leads to secondary injury. The goal of this work is to demonstrate a continuum framework which models the multiphysics of mechano-chemical interactions underlying TBI. Using a coupled PDE (partial differential equation) formulation and FEM (finite element method) discretization, the framework highlights evolution of field variables which spatio-temporally resolve mechanical metrics and chemical species across neuronal clusters. The modeling domain encompasses microglia, neurons and the extracellular matrix. The continuum framework used to model the mechano-chemical interactions assumes a three dimensional viscoelastic network to capture the mechanical response underlying proteins constituting the neuron microstructure and advection-diffusion equations modeling spatio-temporal evolution of chemical species. We use this framework to numerically estimate key concentrations of chemical species produced by the strain field. In this work, we identify key biomarkers within the labyrinth of molecular pathways and build a framework that captures the core mechano-chemical interactions. This framework is an attempt to quantify secondary injury and thus assist in developing targeted TBI treatments. [SEP] [HINT] used -> Bioinformatics (Syns: utilize, ill-used, apply) | field -> Materials Science (Syns: field of honor, line of business, orbit) | molecular -> Bioinformatics (Syns: )",Bioinformatics
"Studying learning-related plasticity is central to understanding the acquisition of complex skills, for example learning to master a musical instrument. Over the past three decades, conventional group-based functional magnetic resonance imaging (fMRI) studies have advanced our understanding of how humans' neural representations change during skill acquisition. However, group-based fMRI studies average across heterogeneous learners and often rely on coarse pre- versus post-training comparisons, limiting the spatial and temporal precision with which neural changes can be estimated. Here, we outline an individual-specific precision approach that tracks neural changes within individuals by collecting high-quality neuroimaging data frequently over the course of training, mapping brain function in each person's own anatomical space, and gathering detailed behavioral measures of learning, allowing neural trajectories to be directly linked to individual learning progress. Complementing fMRI with mobile neuroimaging methods, such as functional near-infrared spectroscopy (fNIRS), will enable researchers to track plasticity during naturalistic practice and across extended time scales. This multi-modal approach will enhance sensitivity to individual learning trajectories and will offer more nuanced insights into how neural representations change with training. We also discuss how findings can be generalized beyond individuals, including through statistical methods based on replication in additional individuals. Together, this approach allows researchers to design highly informative longitudinal training studies that advance a mechanistic, personalized account of skill learning in the human brain.",Neuroscience
"Studying learning-related plasticity is central to understanding the acquisition of complex skills, for example learning to master a musical instrument. Over the past three decades, conventional group-based functional magnetic resonance imaging (fMRI) studies have advanced our understanding of how humans' neural representations change during skill acquisition. However, group-based fMRI studies average across heterogeneous learners and often rely on coarse pre- versus post-training comparisons, limiting the spatial and temporal precision with which neural changes can be estimated. Here, we outline an individual-specific precision approach that tracks neural changes within individuals by collecting high-quality neuroimaging data frequently over the course of training, mapping brain function in each person's own anatomical space, and gathering detailed behavioral measures of learning, allowing neural trajectories to be directly linked to individual learning progress. Complementing fMRI with mobile neuroimaging methods, such as functional near-infrared spectroscopy (fNIRS), will enable researchers to track plasticity during naturalistic practice and across extended time scales. This multi-modal approach will enhance sensitivity to individual learning trajectories and will offer more nuanced insights into how neural representations change with training. We also discuss how findings can be generalized beyond individuals, including through statistical methods based on replication in additional individuals. Together, this approach allows researchers to design highly informative longitudinal training studies that advance a mechanistic, personalized account of skill learning in the human brain. [SEP] [HINT] based -> Bioinformatics (Syns: ground, free-base, base) | understanding -> Neuroscience (Syns: savvy, intellect, sympathy) | learning -> Bioinformatics (Syns: take, teach, acquire)",Neuroscience
"While machine learning has enabled the rapid prediction of inorganic materials with novel properties, the challenge of determining how to synthesize these materials remains largely unsolved. Previous work has largely focused on predicting precursors or reaction conditions, but only rarely on full synthesis pathways. We introduce the ActionGraph, a directed acyclic graph framework that encodes both the chemical and procedural structure, in terms of synthesis operations, of inorganic synthesis reactions. Using 13,017 text-mined solid-state synthesis reactions from the Materials Project, we show that incorporating PCA-reduced ActionGraph adjacency matrices into a $k$-nearest neighbors retrieval model significantly improves synthesis pathway prediction. While the ActionGraph framework only results in a 1.34% and 2.76% increase in precursor and operation F1 scores (average over varying numbers of PCA components) respectively, the operation length matching accuracy rises 3.4 times (from 15.8% to 53.3%). We observe an interesting trade-off where precursor prediction performance peaks at 10-11 PCA components while operation prediction continues improving up to 30 components. This suggests composition information dominates precursor selection while structural information is critical for operation sequencing. Overall, the ActionGraph framework demonstrates strong potential, and with further adoption, its full range of benefits can be effectively realized.",Materials Science
"While machine learning has enabled the rapid prediction of inorganic materials with novel properties, the challenge of determining how to synthesize these materials remains largely unsolved. Previous work has largely focused on predicting precursors or reaction conditions, but only rarely on full synthesis pathways. We introduce the ActionGraph, a directed acyclic graph framework that encodes both the chemical and procedural structure, in terms of synthesis operations, of inorganic synthesis reactions. Using 13,017 text-mined solid-state synthesis reactions from the Materials Project, we show that incorporating PCA-reduced ActionGraph adjacency matrices into a $k$-nearest neighbors retrieval model significantly improves synthesis pathway prediction. While the ActionGraph framework only results in a 1.34% and 2.76% increase in precursor and operation F1 scores (average over varying numbers of PCA components) respectively, the operation length matching accuracy rises 3.4 times (from 15.8% to 53.3%). We observe an interesting trade-off where precursor prediction performance peaks at 10-11 PCA components while operation prediction continues improving up to 30 components. This suggests composition information dominates precursor selection while structural information is critical for operation sequencing. Overall, the ActionGraph framework demonstrates strong potential, and with further adoption, its full range of benefits can be effectively realized. [SEP] [HINT] learning -> Bioinformatics (Syns: take, teach, acquire) | information -> Bioinformatics (Syns: entropy, data, info) | work -> Bioinformatics (Syns: work out, process, bring)",Materials Science
"In the context of spiking neural networks, temporal coding of signals is increasingly preferred over the rate coding hypothesis due to its advantages in processing speed and energy efficiency. In temporal coding, synaptic delays are crucial for processing signals with precise spike timings, known as spiking motifs. Synaptic delays are however bounded in the brain and can thus be shorter than the duration of a motif. This prevents the use of motif recognition methods that consist of setting heterogeneous delays to synchronize the input spikes on a single output neuron acting as a coincidence detector. To address this issue, we developed a method to detect motifs of arbitrary length using a sequence of output neurons connected to input neurons by bounded synaptic delays. Each output neuron is associated with a sub-motif of bounded duration. A motif is recognized if all sub-motifs are sequentially detected by the output neurons. We simulated this network using leaky integrate-and-fire neurons and tested it on the Spiking Heidelberg Digits (SHD) database, that is, on audio data converted to spikes via a cochlear model, as well as on random simultaneous motifs. The results demonstrate that the network can effectively recognize motifs of arbitrary length extracted from the SHD database. Our method features a correct detection rate of about 60% in presence of ten simultaneous motifs from the SHD dataset and up to 80% for five motifs, showing the robustness of the network to noise. Results on random overlapping patterns show that the recognition of a single motif overlapping with other motifs is most effective for a large number of input neurons and sparser motifs. Our method provides a foundation for more general models for the storage and retrieval of neural information of arbitrary temporal lengths.",Neuroscience
"In the context of spiking neural networks, temporal coding of signals is increasingly preferred over the rate coding hypothesis due to its advantages in processing speed and energy efficiency. In temporal coding, synaptic delays are crucial for processing signals with precise spike timings, known as spiking motifs. Synaptic delays are however bounded in the brain and can thus be shorter than the duration of a motif. This prevents the use of motif recognition methods that consist of setting heterogeneous delays to synchronize the input spikes on a single output neuron acting as a coincidence detector. To address this issue, we developed a method to detect motifs of arbitrary length using a sequence of output neurons connected to input neurons by bounded synaptic delays. Each output neuron is associated with a sub-motif of bounded duration. A motif is recognized if all sub-motifs are sequentially detected by the output neurons. We simulated this network using leaky integrate-and-fire neurons and tested it on the Spiking Heidelberg Digits (SHD) database, that is, on audio data converted to spikes via a cochlear model, as well as on random simultaneous motifs. The results demonstrate that the network can effectively recognize motifs of arbitrary length extracted from the SHD database. Our method features a correct detection rate of about 60% in presence of ten simultaneous motifs from the SHD dataset and up to 80% for five motifs, showing the robustness of the network to noise. Results on random overlapping patterns show that the recognition of a single motif overlapping with other motifs is most effective for a large number of input neurons and sparser motifs. Our method provides a foundation for more general models for the storage and retrieval of neural information of arbitrary temporal lengths. [SEP] [HINT] features -> Bioinformatics (Syns: characteristic, lineament, feature of speech) | information -> Bioinformatics (Syns: entropy, data, info) | processing -> Neuroscience (Syns: work, process, march)",Neuroscience
"Remote epitaxy relaxes the constraints of conventional epitaxy, to enable low defect density, chemically abrupt heterostructures and exfoliation of single crystalline membranes. However, definitive evidence for a true remote mechanism remains elusive because most experiments can be explained by alternative mechanism that are macroscopically indistinguishable from true remote epitaxy. Using GdAuGe films grown on graphene/SiC (0001), we present two signatures that cannot be explained by the leading alternatives to the remote mechanism: (1) a few atomic layer thick disordered interlayer at the GdAuGe/graphene interface and (2) a $30\degree$ rotated epitaxial relationship between the GdAuGe film and the SiC substrate. Density functional theory calculations indicate these signatures arise from remote epitaxial \textit{frustration}, a competition amongst epitaxy to the remotely screened substrate, to graphene, and to the graphene-induced interfacial reconstruction. Tuning the amplitudes and periodicities of these competing potentials provides new opportunities to intentionally disrupt long-range order.",Materials Science
"Remote epitaxy relaxes the constraints of conventional epitaxy, to enable low defect density, chemically abrupt heterostructures and exfoliation of single crystalline membranes. However, definitive evidence for a true remote mechanism remains elusive because most experiments can be explained by alternative mechanism that are macroscopically indistinguishable from true remote epitaxy. Using GdAuGe films grown on graphene/SiC (0001), we present two signatures that cannot be explained by the leading alternatives to the remote mechanism: (1) a few atomic layer thick disordered interlayer at the GdAuGe/graphene interface and (2) a $30\degree$ rotated epitaxial relationship between the GdAuGe film and the SiC substrate. Density functional theory calculations indicate these signatures arise from remote epitaxial \textit{frustration}, a competition amongst epitaxy to the remotely screened substrate, to graphene, and to the graphene-induced interfacial reconstruction. Tuning the amplitudes and periodicities of these competing potentials provides new opportunities to intentionally disrupt long-range order. [SEP] [HINT] low -> Materials Science (Syns: low-spirited, scurvy, depressed) | defect -> Materials Science (Syns: mar, shortcoming, fault) | functional -> Neuroscience (Syns: working, usable, running)",Materials Science
"Neural encoding models aim to predict fMRI-measured brain responses to natural images. fMRI data is acquired as a 3D volume of voxels, where each voxel has a defined spatial location in the brain. However, conventional encoding models often flatten this volume into a 1D vector and treat voxel responses as independent outputs. This removes spatial context, discards anatomical information, and ties each model to a subject-specific voxel grid. We introduce the Neural Response Function (NRF), a framework that models fMRI activity as a continuous function over anatomical space rather than a flat vector of voxels. NRF represents brain activity as a continuous implicit function: given an image and a spatial coordinate (x, y, z) in standardized MNI space, the model predicts the response at that location. This formulation decouples predictions from the training grid, supports querying at arbitrary spatial resolutions, and enables resolution-agnostic analyses. By grounding the model in anatomical space, NRF exploits two key properties of brain responses: (1) local smoothness -- neighboring voxels exhibit similar response patterns; modeling responses continuously captures these correlations and improves data efficiency, and (2) cross-subject alignment -- MNI coordinates unify data across individuals, allowing a model pretrained on one subject to be fine-tuned on new subjects. In experiments, NRF outperformed baseline models in both intrasubject encoding and cross-subject adaptation, achieving high performance while reducing the data size needed by orders of magnitude. To our knowledge, NRF is the first anatomically aware encoding model to move beyond flattened voxels, learning a continuous mapping from images to brain responses in 3D space.",Neuroscience
"Neural encoding models aim to predict fMRI-measured brain responses to natural images. fMRI data is acquired as a 3D volume of voxels, where each voxel has a defined spatial location in the brain. However, conventional encoding models often flatten this volume into a 1D vector and treat voxel responses as independent outputs. This removes spatial context, discards anatomical information, and ties each model to a subject-specific voxel grid. We introduce the Neural Response Function (NRF), a framework that models fMRI activity as a continuous function over anatomical space rather than a flat vector of voxels. NRF represents brain activity as a continuous implicit function: given an image and a spatial coordinate (x, y, z) in standardized MNI space, the model predicts the response at that location. This formulation decouples predictions from the training grid, supports querying at arbitrary spatial resolutions, and enables resolution-agnostic analyses. By grounding the model in anatomical space, NRF exploits two key properties of brain responses: (1) local smoothness -- neighboring voxels exhibit similar response patterns; modeling responses continuously captures these correlations and improves data efficiency, and (2) cross-subject alignment -- MNI coordinates unify data across individuals, allowing a model pretrained on one subject to be fine-tuned on new subjects. In experiments, NRF outperformed baseline models in both intrasubject encoding and cross-subject adaptation, achieving high performance while reducing the data size needed by orders of magnitude. To our knowledge, NRF is the first anatomically aware encoding model to move beyond flattened voxels, learning a continuous mapping from images to brain responses in 3D space. [SEP] [HINT] learning -> Bioinformatics (Syns: take, teach, acquire) | space -> Neuroscience (Syns: distance, place, outer space) | performance -> Bioinformatics (Syns: functioning, operation, carrying out)",Neuroscience
"Recent discoveries of multi-\textbf{Q} magnetic structures in centrosymmetric   compounds have stimulated growing interest in their microscopic origin and observable properties.   Here, we calculate the dynamical magnetic structure factor for a double-\textbf{Q} magnetic   structure and compare it with that of a single-\textbf{Q} configuration.",Materials Science
"Recent discoveries of multi-\textbf{Q} magnetic structures in centrosymmetric   compounds have stimulated growing interest in their microscopic origin and observable properties.   Here, we calculate the dynamical magnetic structure factor for a double-\textbf{Q} magnetic   structure and compare it with that of a single-\textbf{Q} configuration. [SEP] [HINT] magnetic -> Materials Science (Syns: charismatic, magnetised, magnetized) | structure -> Bioinformatics (Syns: social system, complex body part, social structure)",Materials Science
"Low-rank recurrent neural networks (lrRNNs) are a class of models that uncover low-dimensional latent dynamics underlying neural population activity. Although their functional connectivity is low-rank, it lacks disentanglement interpretations, making it difficult to assign distinct computational roles to different latent dimensions. To address this, we propose the Disentangled Recurrent Neural Network (DisRNN), a generative lrRNN framework that assumes group-wise independence among latent dynamics while allowing flexible within-group entanglement. These independent latent groups allow latent dynamics to evolve separately, but are internally rich for complex computation. We reformulate the lrRNN under a variational autoencoder (VAE) framework, enabling us to introduce a partial correlation penalty that encourages disentanglement between groups of latent dimensions. Experiments on synthetic, monkey M1, and mouse voltage imaging data show that DisRNN consistently improves the disentanglement and interpretability of learned neural latent trajectories in low-dimensional space and low-rank connectivity over baseline lrRNNs that do not encourage partial disentanglement.",Neuroscience
"Low-rank recurrent neural networks (lrRNNs) are a class of models that uncover low-dimensional latent dynamics underlying neural population activity. Although their functional connectivity is low-rank, it lacks disentanglement interpretations, making it difficult to assign distinct computational roles to different latent dimensions. To address this, we propose the Disentangled Recurrent Neural Network (DisRNN), a generative lrRNN framework that assumes group-wise independence among latent dynamics while allowing flexible within-group entanglement. These independent latent groups allow latent dynamics to evolve separately, but are internally rich for complex computation. We reformulate the lrRNN under a variational autoencoder (VAE) framework, enabling us to introduce a partial correlation penalty that encourages disentanglement between groups of latent dimensions. Experiments on synthetic, monkey M1, and mouse voltage imaging data show that DisRNN consistently improves the disentanglement and interpretability of learned neural latent trajectories in low-dimensional space and low-rank connectivity over baseline lrRNNs that do not encourage partial disentanglement. [SEP] [HINT] connectivity -> Neuroscience (Syns: ) | computational -> Neuroscience (Syns: ) | networks -> Neuroscience (Syns: network, meshwork, electronic network)",Neuroscience
"Nonlinear transport has emerged as a powerful approach to probe the quantum geometry of electronic wavefunctions, such as Berry curvature and quantum metric, in topological materials. While nonlinear responses governed by bulk quantum geometry and band topology are well understood, the role of boundary modes (e.g., edge, surface, and hinge states) in nonlinear transport of topological materials remains largely unexplored. In this work, we demonstrate boundary-bulk interplay in nonlinear transport, including second-harmonic Hall and nonreciprocal longitudinal responses, in molecular beam epitaxy-grown magnetic topological insulator heterostructures. We find that the nonlinear transport is maximized when the sample is tuned slightly away from the well-quantized states, including the quantum anomalous Hall and axion insulator states. The sign and amplitude of the nonlinear transport depend on electrode configuration, magnetic order, and carrier type, establishing boundary mode transport as the dominant contributor. These findings, supported by symmetry analysis and nonlinear Landauer-Büttiker formalism, demonstrate that nonlinear transport in topological materials is governed by the interplay between boundary and bulk states. We further derive a universal relation between different lead voltages from electrode geometry symmetry, which allows us to distinguish nonlinear boundary transport from bulk contributions. Our work highlights the critical role of electrodes in nonlinear transport, which is absent in nonlinear optics, and establishes boundary modes as a key origin of the giant nonlinear response in nearly bulk-insulating topological materials. This insight opens new opportunities for engineering nonlinear transport through boundary-bulk interplay in future device applications of topological materials.",Materials Science
"Nonlinear transport has emerged as a powerful approach to probe the quantum geometry of electronic wavefunctions, such as Berry curvature and quantum metric, in topological materials. While nonlinear responses governed by bulk quantum geometry and band topology are well understood, the role of boundary modes (e.g., edge, surface, and hinge states) in nonlinear transport of topological materials remains largely unexplored. In this work, we demonstrate boundary-bulk interplay in nonlinear transport, including second-harmonic Hall and nonreciprocal longitudinal responses, in molecular beam epitaxy-grown magnetic topological insulator heterostructures. We find that the nonlinear transport is maximized when the sample is tuned slightly away from the well-quantized states, including the quantum anomalous Hall and axion insulator states. The sign and amplitude of the nonlinear transport depend on electrode configuration, magnetic order, and carrier type, establishing boundary mode transport as the dominant contributor. These findings, supported by symmetry analysis and nonlinear Landauer-Büttiker formalism, demonstrate that nonlinear transport in topological materials is governed by the interplay between boundary and bulk states. We further derive a universal relation between different lead voltages from electrode geometry symmetry, which allows us to distinguish nonlinear boundary transport from bulk contributions. Our work highlights the critical role of electrodes in nonlinear transport, which is absent in nonlinear optics, and establishes boundary modes as a key origin of the giant nonlinear response in nearly bulk-insulating topological materials. This insight opens new opportunities for engineering nonlinear transport through boundary-bulk interplay in future device applications of topological materials. [SEP] [HINT] transport -> Materials Science (Syns: transferral, enthral, shipping) | electronic -> Materials Science (Syns: ) | molecular -> Bioinformatics (Syns: )",Materials Science
"Metal-assisted exfoliation of two-dimensional (2D) materials has emerged as an efficient route to isolating large-area monolayer crystals, yet the influence of the supporting metal substrate on their intrinsic properties remains poorly understood. Here, we demonstrate successful gold-assisted exfoliation of monolayer IrTe$_2$ up to the millimeter scale. Angle-resolved photoemission spectroscopy (ARPES), combined with first-principles calculations, reveals that the low-energy electronic structure closely resembles that of a freestanding monolayer 1T-IrTe$_2$. We find that quasi-covalent hybridization together with substrate-induced strain leads to only modest modifications of the electronic bands. Although strain contributes to phase stability, it is essentially hybridization that drives the stabilization of the 1T-phase of the monolayer IrTe$_2$ by suppressing stripe-ordered phase transitions. These results establish gold-assisted exfoliation as a robust route to prepare a large-area monolayer IrTe$_2$ and highlight the role of metal-substrate interaction in engineering 2D materials with tailored structural phases.",Materials Science
"Metal-assisted exfoliation of two-dimensional (2D) materials has emerged as an efficient route to isolating large-area monolayer crystals, yet the influence of the supporting metal substrate on their intrinsic properties remains poorly understood. Here, we demonstrate successful gold-assisted exfoliation of monolayer IrTe$_2$ up to the millimeter scale. Angle-resolved photoemission spectroscopy (ARPES), combined with first-principles calculations, reveals that the low-energy electronic structure closely resembles that of a freestanding monolayer 1T-IrTe$_2$. We find that quasi-covalent hybridization together with substrate-induced strain leads to only modest modifications of the electronic bands. Although strain contributes to phase stability, it is essentially hybridization that drives the stabilization of the 1T-phase of the monolayer IrTe$_2$ by suppressing stripe-ordered phase transitions. These results establish gold-assisted exfoliation as a robust route to prepare a large-area monolayer IrTe$_2$ and highlight the role of metal-substrate interaction in engineering 2D materials with tailored structural phases. [SEP] [HINT] electronic -> Materials Science (Syns: ) | structure -> Bioinformatics (Syns: social system, complex body part, social structure) | results -> Bioinformatics (Syns: final result, consequence, resultant role)",Materials Science
The formation of permanent laser-induced periodic surface structures (LIPSS) on solid surfaces under impulsive laser irradiation above the damage threshold has been subject of extensive research. We demonstrate the formation of transient surface displacement patterns under femtosecond laser irradiation at fluences well below this threshold. Time-resolved extreme ultraviolet scattering measurements reveal distinct reciprocal-space features similar to those observed for permanent LIPSS but dissipating on the hundreds-of-picoseconds time scale. We show that the transient surface displacement patterns responsible for these features are produced via thermal expansion by the spatial modulation of absorbed laser intensity caused by scattering of the laser radiation by surface roughness and present a model accounting for the experimental observations. We suggest that our experiment revealed a universal phenomenon that will be observed on any strongly absorbing material under ultrafast laser irradiation.,Materials Science
"The formation of permanent laser-induced periodic surface structures (LIPSS) on solid surfaces under impulsive laser irradiation above the damage threshold has been subject of extensive research. We demonstrate the formation of transient surface displacement patterns under femtosecond laser irradiation at fluences well below this threshold. Time-resolved extreme ultraviolet scattering measurements reveal distinct reciprocal-space features similar to those observed for permanent LIPSS but dissipating on the hundreds-of-picoseconds time scale. We show that the transient surface displacement patterns responsible for these features are produced via thermal expansion by the spatial modulation of absorbed laser intensity caused by scattering of the laser radiation by surface roughness and present a model accounting for the experimental observations. We suggest that our experiment revealed a universal phenomenon that will be observed on any strongly absorbing material under ultrafast laser irradiation. [SEP] [HINT] features -> Bioinformatics (Syns: characteristic, lineament, feature of speech) | thermal -> Materials Science (Syns: thermic, caloric) | material -> Materials Science (Syns: stuff, cloth, real)",Materials Science
"Bond breaking in the presence of highly energetic carriers is central to many important phenomena in physics and chemistry, including radiation damage, hot-carrier degradation, activation of dopant-hydrogen complexes in semiconductors, and photocatalysis. Describing these processes from first principles has remained an elusive goal. Here we introduce a comprehensive theoretical framework for the dissociation process, emphasizing the need for a non-adiabatic approach. We benchmark the results for the case of silicon-hydrogen bond dissocation, a primary process for hot-carrier degradation. Passivation of Si dangling bonds by hydrogen is vital in all Si devices because it eliminates electrically active mid-gap states; understanding the mechanism for dissociation of these bonds is therefore crucial for device technology. While the need for a non-adiabatic approach has been previously recognized, explicitly obtaining diabatic states for solid-state systems has been an outstanding challenge. We demonstrate how to obtain these states by applying a partitioning scheme to the Hamiltonian obtained from first-principles density functional theory. Our results demonstrate that bond dissociation can occur when electrons temporarily occupy the antibonding states, generating a highly repulsive excited-state potential that causes the hydrogen nuclear wavepacket to shift and propagate rapidly. Based on the Menzel-Gomer-Redhead (MGR) model, we show that after moving on this excited-state potential on femtosecond timescales, a portion of the nuclear wavepacket can continue to propagate even after the system relaxes back to the ground state, allowing us to determine the dissociation probability. Our results provide essential insights into the fundamental processes that drive carrier-induced bond breaking in general, and specifically elucidate hydrogen-related degradation in Si devices.",Materials Science
"Bond breaking in the presence of highly energetic carriers is central to many important phenomena in physics and chemistry, including radiation damage, hot-carrier degradation, activation of dopant-hydrogen complexes in semiconductors, and photocatalysis. Describing these processes from first principles has remained an elusive goal. Here we introduce a comprehensive theoretical framework for the dissociation process, emphasizing the need for a non-adiabatic approach. We benchmark the results for the case of silicon-hydrogen bond dissocation, a primary process for hot-carrier degradation. Passivation of Si dangling bonds by hydrogen is vital in all Si devices because it eliminates electrically active mid-gap states; understanding the mechanism for dissociation of these bonds is therefore crucial for device technology. While the need for a non-adiabatic approach has been previously recognized, explicitly obtaining diabatic states for solid-state systems has been an outstanding challenge. We demonstrate how to obtain these states by applying a partitioning scheme to the Hamiltonian obtained from first-principles density functional theory. Our results demonstrate that bond dissociation can occur when electrons temporarily occupy the antibonding states, generating a highly repulsive excited-state potential that causes the hydrogen nuclear wavepacket to shift and propagate rapidly. Based on the Menzel-Gomer-Redhead (MGR) model, we show that after moving on this excited-state potential on femtosecond timescales, a portion of the nuclear wavepacket can continue to propagate even after the system relaxes back to the ground state, allowing us to determine the dissociation probability. Our results provide essential insights into the fundamental processes that drive carrier-induced bond breaking in general, and specifically elucidate hydrogen-related degradation in Si devices. [SEP] [HINT] based -> Bioinformatics (Syns: ground, free-base, base) | understanding -> Neuroscience (Syns: savvy, intellect, sympathy) | functional -> Neuroscience (Syns: working, usable, running)",Materials Science
"Long-range moire patterns in twisted WSe2 enable a built-in, moire-length-scale ferroelectric polarization that can be directly harnessed in electronic devices. Such a built-in ferroic landscape offers a compelling means to enable ultralow-voltage and non-volatile electronic functionality in two-dimensional materials; however, achieving stable polarization control without charge trapping has remained a persistent challenge. Here, we demonstrate a moire-engineered ferroelectric field-effect transistor (FeFET) utilizing twisted WSe2 bilayers that leverages atomically clean van der Waals interfaces to achieve efficient polarization-channel coupling and trap-suppressed, ultralow-voltage operation (subthreshold swing of 64 mV per decade). The device exhibits a stable non-volatile memory window of 0.10 V and high mobility, exceeding the performance of previously reported two-dimensional FeFET and matching that of advanced silicon-based devices. In addition, capacitance-voltage spectroscopy, corroborated by self-consistent Landau-Ginzburg-Devonshire modeling, indicates ultrafast ferroelectric switching (~0.5 microseconds). These results establish moire-engineered ferroelectricity as a practical and scalable route toward ultraclean, low-power, and non-volatile 2D electronics, bridging atomistic lattice engineering with functional device architectures for next-generation memory and logic technologies.",Materials Science
"Long-range moire patterns in twisted WSe2 enable a built-in, moire-length-scale ferroelectric polarization that can be directly harnessed in electronic devices. Such a built-in ferroic landscape offers a compelling means to enable ultralow-voltage and non-volatile electronic functionality in two-dimensional materials; however, achieving stable polarization control without charge trapping has remained a persistent challenge. Here, we demonstrate a moire-engineered ferroelectric field-effect transistor (FeFET) utilizing twisted WSe2 bilayers that leverages atomically clean van der Waals interfaces to achieve efficient polarization-channel coupling and trap-suppressed, ultralow-voltage operation (subthreshold swing of 64 mV per decade). The device exhibits a stable non-volatile memory window of 0.10 V and high mobility, exceeding the performance of previously reported two-dimensional FeFET and matching that of advanced silicon-based devices. In addition, capacitance-voltage spectroscopy, corroborated by self-consistent Landau-Ginzburg-Devonshire modeling, indicates ultrafast ferroelectric switching (~0.5 microseconds). These results establish moire-engineered ferroelectricity as a practical and scalable route toward ultraclean, low-power, and non-volatile 2D electronics, bridging atomistic lattice engineering with functional device architectures for next-generation memory and logic technologies. [SEP] [HINT] charge -> Materials Science (Syns: tear, bearing, burster) | electronic -> Materials Science (Syns: ) | functional -> Neuroscience (Syns: working, usable, running)",Materials Science
"Summary: Cell population plots are visualizations showing cell population distributions in biological samples with single-cell data, traditionally shown with stacked bar charts. Here, we address issues with this approach, particularly its limited scalability with increasing number of cell types and samples, and present scellop, a novel interactive cell population viewer combining visual encodings optimized for common user tasks in studying populations of cells across samples or conditions.   Availability and Implementation: Scellop is available under the MIT licence at https://github.com/hms-dbmi/scellop, and is available on PyPI (https://pypi.org/project/cellpop/) and NPM (https://www.npmjs.com/package/cellpop). A demo is available at https://scellop.netlify.app/.",Bioinformatics
"Summary: Cell population plots are visualizations showing cell population distributions in biological samples with single-cell data, traditionally shown with stacked bar charts. Here, we address issues with this approach, particularly its limited scalability with increasing number of cell types and samples, and present scellop, a novel interactive cell population viewer combining visual encodings optimized for common user tasks in studying populations of cells across samples or conditions.   Availability and Implementation: Scellop is available under the MIT licence at https://github.com/hms-dbmi/scellop, and is available on PyPI (https://pypi.org/project/cellpop/) and NPM (https://www.npmjs.com/package/cellpop). A demo is available at https://scellop.netlify.app/. [SEP] [HINT] tasks -> Neuroscience (Syns: tax, task, project) | visual -> Neuroscience (Syns: optical, ocular, optic) | biological -> Bioinformatics (Syns: biologic)",Bioinformatics
"Understanding how neural populations in higher visual areas encode object-centered visual information remains a central challenge in computational neuroscience. Prior works have investigated representational alignment between artificial neural networks and the visual cortex. Nevertheless, these findings are indirect and offer limited insights to the structure of neural populations themselves. Similarly, decoding-based methods have quantified semantic features from neural populations but have not uncovered their underlying organizations. This leaves open a scientific question: ""how feature-specific visual information is distributed across neural populations in higher visual areas, and whether it is organized into structured, semantically meaningful subspaces."" To tackle this problem, we present MIG-Vis, a method that leverages the generative power of diffusion models to visualize and validate the visual-semantic attributes encoded in neural latent subspaces. Our method first uses a variational autoencoder to infer a group-wise disentangled neural latent subspace from neural populations. Subsequently, we propose a mutual information (MI)-guided diffusion synthesis procedure to visualize the specific visual-semantic features encoded by each latent group. We validate MIG-Vis on multi-session neural spiking datasets from the inferior temporal (IT) cortex of two macaques. The synthesized results demonstrate that our method identifies neural latent groups with clear semantic selectivity to diverse visual features, including object pose, inter-category transformations, and intra-class content. These findings provide direct, interpretable evidence of structured semantic representation in the higher visual cortex and advance our understanding of its encoding principles.",Neuroscience
"Understanding how neural populations in higher visual areas encode object-centered visual information remains a central challenge in computational neuroscience. Prior works have investigated representational alignment between artificial neural networks and the visual cortex. Nevertheless, these findings are indirect and offer limited insights to the structure of neural populations themselves. Similarly, decoding-based methods have quantified semantic features from neural populations but have not uncovered their underlying organizations. This leaves open a scientific question: ""how feature-specific visual information is distributed across neural populations in higher visual areas, and whether it is organized into structured, semantically meaningful subspaces."" To tackle this problem, we present MIG-Vis, a method that leverages the generative power of diffusion models to visualize and validate the visual-semantic attributes encoded in neural latent subspaces. Our method first uses a variational autoencoder to infer a group-wise disentangled neural latent subspace from neural populations. Subsequently, we propose a mutual information (MI)-guided diffusion synthesis procedure to visualize the specific visual-semantic features encoded by each latent group. We validate MIG-Vis on multi-session neural spiking datasets from the inferior temporal (IT) cortex of two macaques. The synthesized results demonstrate that our method identifies neural latent groups with clear semantic selectivity to diverse visual features, including object pose, inter-category transformations, and intra-class content. These findings provide direct, interpretable evidence of structured semantic representation in the higher visual cortex and advance our understanding of its encoding principles. [SEP] [HINT] computational -> Neuroscience (Syns: ) | features -> Bioinformatics (Syns: characteristic, lineament, feature of speech) | understanding -> Neuroscience (Syns: savvy, intellect, sympathy)",Neuroscience
"Predicting the fitness impact of mutations is central to protein engineering but constrained by limited assays relative to the size of sequence space. Protein language models (pLMs) trained with masked language modeling (MLM) exhibit strong zero-shot fitness prediction; we provide a unifying view by interpreting natural evolution as implicit reward maximization and MLM as inverse reinforcement learning (IRL), in which extant sequences act as expert demonstrations and pLM log-odds serve as fitness estimates. Building on this perspective, we introduce EvoIF, a lightweight model that integrates two complementary sources of evolutionary signal: (i) within-family profiles from retrieved homologs and (ii) cross-family structural-evolutionary constraints distilled from inverse folding logits. EvoIF fuses sequence-structure representations with these profiles via a compact transition block, yielding calibrated probabilities for log-odds scoring. On ProteinGym (217 mutational assays; >2.5M mutants), EvoIF and its MSA-enabled variant achieve state-of-the-art or competitive performance while using only 0.15% of the training data and fewer parameters than recent large models. Ablations confirm that within-family and cross-family profiles are complementary, improving robustness across function types, MSA depths, taxa, and mutation depths. The codes will be made publicly available at https://github.com/aim-uofa/EvoIF.",Bioinformatics
"Predicting the fitness impact of mutations is central to protein engineering but constrained by limited assays relative to the size of sequence space. Protein language models (pLMs) trained with masked language modeling (MLM) exhibit strong zero-shot fitness prediction; we provide a unifying view by interpreting natural evolution as implicit reward maximization and MLM as inverse reinforcement learning (IRL), in which extant sequences act as expert demonstrations and pLM log-odds serve as fitness estimates. Building on this perspective, we introduce EvoIF, a lightweight model that integrates two complementary sources of evolutionary signal: (i) within-family profiles from retrieved homologs and (ii) cross-family structural-evolutionary constraints distilled from inverse folding logits. EvoIF fuses sequence-structure representations with these profiles via a compact transition block, yielding calibrated probabilities for log-odds scoring. On ProteinGym (217 mutational assays; >2.5M mutants), EvoIF and its MSA-enabled variant achieve state-of-the-art or competitive performance while using only 0.15% of the training data and fewer parameters than recent large models. Ablations confirm that within-family and cross-family profiles are complementary, improving robustness across function types, MSA depths, taxa, and mutation depths. The codes will be made publicly available at https://github.com/aim-uofa/EvoIF. [SEP] [HINT] transition -> Materials Science (Syns: passage, modulation, changeover) | language -> Neuroscience (Syns: linguistic process, linguistic communication, spoken communication) | learning -> Bioinformatics (Syns: take, teach, acquire)",Bioinformatics
"We present an automated approach for identifying and annotating motifs and domains in protein sequences, using pretrained Protein Language Models (PLMs) and Concept Activation Vectors (CAVs), adapted from interpretability research in computer vision. We treat motifs as conceptual entities and represent them through learned CAVs in PLM embedding space by training simple linear classifiers to distinguish motif-containing from non-motif sequences. To identify motif occurrences, we extract embeddings for overlapping sequence windows and compute their inner products with motif CAVs. This scoring mechanism quantifies how strongly each sequence region expresses the motif concept and naturally detects multiple instances of the same motif within the same protein. Using a dataset of sixty-nine well-characterized motifs with curated positive and negative examples, our method achieves over 85\% F1 Score for segments strongly expressing the concept and accurately localizes motif positions across diverse protein families. As each motif is encoded by a single vector, motif detection requires only the pretrained PLM and a lightweight dictionary of CAVs, offering a scalable, interpretable, and computationally efficient framework for automated sequence annotation.",Bioinformatics
"We present an automated approach for identifying and annotating motifs and domains in protein sequences, using pretrained Protein Language Models (PLMs) and Concept Activation Vectors (CAVs), adapted from interpretability research in computer vision. We treat motifs as conceptual entities and represent them through learned CAVs in PLM embedding space by training simple linear classifiers to distinguish motif-containing from non-motif sequences. To identify motif occurrences, we extract embeddings for overlapping sequence windows and compute their inner products with motif CAVs. This scoring mechanism quantifies how strongly each sequence region expresses the motif concept and naturally detects multiple instances of the same motif within the same protein. Using a dataset of sixty-nine well-characterized motifs with curated positive and negative examples, our method achieves over 85\% F1 Score for segments strongly expressing the concept and accurately localizes motif positions across diverse protein families. As each motif is encoded by a single vector, motif detection requires only the pretrained PLM and a lightweight dictionary of CAVs, offering a scalable, interpretable, and computationally efficient framework for automated sequence annotation. [SEP] [HINT] language -> Neuroscience (Syns: linguistic process, linguistic communication, spoken communication) | space -> Neuroscience (Syns: distance, place, outer space) | framework -> Bioinformatics (Syns: theoretical account, model, fabric)",Bioinformatics
"Parkinson's disease (PD) is a neurodegenerative disorder associated with the accumulation of misfolded alpha-synuclein aggregates, forming Lewy bodies and neuritic shape used for pathology diagnostics. Automatic analysis of immunohistochemistry histopathological images with Deep Learning provides a promising tool for better understanding the spatial organization of these aggregates. In this study, we develop an automated image processing pipeline to segment and classify these aggregates in whole-slide images (WSIs) of midbrain tissue from PD and incidental Lewy Body Disease (iLBD) cases based on weakly supervised segmentation, robust to immunohistochemical labelling variability, with a ResNet50 classifier. Our approach allows to differentiate between major aggregate morphologies, including Lewy bodies and neurites with a balanced accuracy of $80\%$. This framework paves the way for large-scale characterization of the spatial distribution and heterogeneity of alpha-synuclein aggregates in brightfield immunohistochemical tissue, and for investigating their poorly understood relationships with surrounding cells such as microglia and astrocytes.",Bioinformatics
"Parkinson's disease (PD) is a neurodegenerative disorder associated with the accumulation of misfolded alpha-synuclein aggregates, forming Lewy bodies and neuritic shape used for pathology diagnostics. Automatic analysis of immunohistochemistry histopathological images with Deep Learning provides a promising tool for better understanding the spatial organization of these aggregates. In this study, we develop an automated image processing pipeline to segment and classify these aggregates in whole-slide images (WSIs) of midbrain tissue from PD and incidental Lewy Body Disease (iLBD) cases based on weakly supervised segmentation, robust to immunohistochemical labelling variability, with a ResNet50 classifier. Our approach allows to differentiate between major aggregate morphologies, including Lewy bodies and neurites with a balanced accuracy of $80\%$. This framework paves the way for large-scale characterization of the spatial distribution and heterogeneity of alpha-synuclein aggregates in brightfield immunohistochemical tissue, and for investigating their poorly understood relationships with surrounding cells such as microglia and astrocytes. [SEP] [HINT] used -> Bioinformatics (Syns: utilize, ill-used, apply) | tissue -> Bioinformatics (Syns: tissue paper, weave) | based -> Bioinformatics (Syns: ground, free-base, base)",Bioinformatics
"Accurate prediction of protein-ligand binding affinity plays a pivotal role in accelerating the discovery of novel drugs and vaccines, particularly for gastrointestinal (GI) diseases such as gastric ulcers, Crohn's disease, and ulcerative colitis. Traditional computational models often rely on structural information alone and thus fail to capture the genetic determinants that influence disease mechanisms and therapeutic responses. To address this gap, we propose GastroDL-Fusion, a dual-modal deep learning framework that integrates protein-ligand complex data with disease-associated gene sequence information for drug and vaccine development. In our approach, protein-ligand complexes are represented as molecular graphs and modeled using a Graph Isomorphism Network (GIN), while gene sequences are encoded into biologically meaningful embeddings via a pre-trained Transformer (ProtBERT/ESM). These complementary modalities are fused through a multi-layer perceptron to enable robust cross-modal interaction learning. We evaluate the model on benchmark datasets of GI disease-related targets, demonstrating that GastroDL-Fusion significantly improves predictive performance over conventional methods. Specifically, the model achieves a mean absolute error (MAE) of 1.12 and a root mean square error (RMSE) of 1.75, outperforming CNN, BiLSTM, GIN, and Transformer-only baselines. These results confirm that incorporating both structural and genetic features yields more accurate predictions of binding affinities, providing a reliable computational tool for accelerating the design of targeted therapies and vaccines in the context of gastrointestinal diseases.",Bioinformatics
"Accurate prediction of protein-ligand binding affinity plays a pivotal role in accelerating the discovery of novel drugs and vaccines, particularly for gastrointestinal (GI) diseases such as gastric ulcers, Crohn's disease, and ulcerative colitis. Traditional computational models often rely on structural information alone and thus fail to capture the genetic determinants that influence disease mechanisms and therapeutic responses. To address this gap, we propose GastroDL-Fusion, a dual-modal deep learning framework that integrates protein-ligand complex data with disease-associated gene sequence information for drug and vaccine development. In our approach, protein-ligand complexes are represented as molecular graphs and modeled using a Graph Isomorphism Network (GIN), while gene sequences are encoded into biologically meaningful embeddings via a pre-trained Transformer (ProtBERT/ESM). These complementary modalities are fused through a multi-layer perceptron to enable robust cross-modal interaction learning. We evaluate the model on benchmark datasets of GI disease-related targets, demonstrating that GastroDL-Fusion significantly improves predictive performance over conventional methods. Specifically, the model achieves a mean absolute error (MAE) of 1.12 and a root mean square error (RMSE) of 1.75, outperforming CNN, BiLSTM, GIN, and Transformer-only baselines. These results confirm that incorporating both structural and genetic features yields more accurate predictions of binding affinities, providing a reliable computational tool for accelerating the design of targeted therapies and vaccines in the context of gastrointestinal diseases. [SEP] [HINT] computational -> Neuroscience (Syns: ) | features -> Bioinformatics (Syns: characteristic, lineament, feature of speech) | learning -> Bioinformatics (Syns: take, teach, acquire)",Bioinformatics
"Machine-learning methods in biochemistry commonly represent molecules as graphs of pairwise intermolecular interactions for property and structure predictions. Most methods operate on a single graph, typically the minimal free energy (MFE) structure, for low-energy ensembles (conformations) representative of structures at thermodynamic equilibrium. We introduce a thermodynamically parameterized exponential-family random graph (ERGM) embedding that models molecules as Boltzmann-weighted ensembles of interaction graphs. We evaluate this embedding on SELEX datasets, where experimental biases (e.g., PCR amplification or sequencing noise) can obscure true aptamer-ligand affinity, producing anomalous candidates whose observed abundance diverges from their actual binding strength. We show that the proposed embedding enables robust community detection and subgraph-level explanations for aptamer ligand affinity, even in the presence of biased observations. This approach may be used to identify low-abundance aptamer candidates for further experimental evaluation.",Bioinformatics
"Machine-learning methods in biochemistry commonly represent molecules as graphs of pairwise intermolecular interactions for property and structure predictions. Most methods operate on a single graph, typically the minimal free energy (MFE) structure, for low-energy ensembles (conformations) representative of structures at thermodynamic equilibrium. We introduce a thermodynamically parameterized exponential-family random graph (ERGM) embedding that models molecules as Boltzmann-weighted ensembles of interaction graphs. We evaluate this embedding on SELEX datasets, where experimental biases (e.g., PCR amplification or sequencing noise) can obscure true aptamer-ligand affinity, producing anomalous candidates whose observed abundance diverges from their actual binding strength. We show that the proposed embedding enables robust community detection and subgraph-level explanations for aptamer ligand affinity, even in the presence of biased observations. This approach may be used to identify low-abundance aptamer candidates for further experimental evaluation. [SEP] [HINT] used -> Bioinformatics (Syns: utilize, ill-used, apply) | structure -> Bioinformatics (Syns: social system, complex body part, social structure) | models -> Bioinformatics (Syns: framework, modelling, good example)",Bioinformatics
"We investigate the out-of-equilibrium lattice dynamics in the spin-ladder system $α'$-NaV$_2$O$_5$ using intense terahertz (THz) pump and near-infrared (NIR) probe spectroscopy. When quasi-single-cycle THz pulses interact with $α'$-NaV$_2$O$_5$ in its low-temperature, dimerized charge-ordered phase, they induce coherent oscillations in the time domain at the zone-folded Raman-active phonon frequency of 1.85 THz. By combining pump-probe measurements with lattice dynamics modeling based on equation-of-motion approach, we propose that these oscillations arise from a nonlinear coupling between Raman-active and infrared (IR)-active phonon modes, with the latter being resonantly excited by the THz pulses. In contrast, excitation with NIR femtosecond laser pulses does not produce measurable vibrational dynamics, highlighting the unique potential of THz-driven, nonlinear light-matter interactions for the coherent and selective control of structural dynamics in quantum materials.",Materials Science
"We investigate the out-of-equilibrium lattice dynamics in the spin-ladder system $α'$-NaV$_2$O$_5$ using intense terahertz (THz) pump and near-infrared (NIR) probe spectroscopy. When quasi-single-cycle THz pulses interact with $α'$-NaV$_2$O$_5$ in its low-temperature, dimerized charge-ordered phase, they induce coherent oscillations in the time domain at the zone-folded Raman-active phonon frequency of 1.85 THz. By combining pump-probe measurements with lattice dynamics modeling based on equation-of-motion approach, we propose that these oscillations arise from a nonlinear coupling between Raman-active and infrared (IR)-active phonon modes, with the latter being resonantly excited by the THz pulses. In contrast, excitation with NIR femtosecond laser pulses does not produce measurable vibrational dynamics, highlighting the unique potential of THz-driven, nonlinear light-matter interactions for the coherent and selective control of structural dynamics in quantum materials. [SEP] [HINT] phonon -> Materials Science (Syns: ) | based -> Bioinformatics (Syns: ground, free-base, base) | using -> Bioinformatics (Syns: utilize, exploitation, apply)",Materials Science
"Boron aluminum nitride (B$_x$Al$_{1-x}$N) is a promising material for next-generation electronic and optoelectronic devices due to its ultra-wide bandgap, high thermal stability, and compatibility with other III-nitride semiconductors. Despite its potential, the band alignments of B$_x$Al$_{1-x}$N remain largely unexplored, although this information is essential for device design. In this study, we compute the valence and conduction band alignments of nonpolar ($a$-plane) and polar ($c$-plane) B$_x$Al$_{1-x}$N, and compare them with those of AlN and GaN. Using density functional theory, many-body perturbation theory, $GW_0$ method, and a novel passivation scheme, we find that they have near-zero valence band alignments for low-$x$ B$_x$Al$_{1-x}$N/AlN, while higher compositions ($x > $0.333) exhibit type I or II band alignments. The band alignments also show a notable dependence on surface polarity and the tetrahedral distortion of the B$_x$Al$_{1-x}$N structures. Our computed offsets are in good agreement with available experimental data. Due to their low valence band alignments and higher conduction band alignments, the B$_x$Al$_{1-x}$N/AlN heterostructures could be well suited for high-electron-mobility transistors and ultraviolet light-emitting diodes. The band alignments of B$_x$Al$_{1-x}$N determined in this study provide essential design guidelines for integrating these ultra-wide bandgap alloys into advanced semiconductor technologies.",Materials Science
"Boron aluminum nitride (B$_x$Al$_{1-x}$N) is a promising material for next-generation electronic and optoelectronic devices due to its ultra-wide bandgap, high thermal stability, and compatibility with other III-nitride semiconductors. Despite its potential, the band alignments of B$_x$Al$_{1-x}$N remain largely unexplored, although this information is essential for device design. In this study, we compute the valence and conduction band alignments of nonpolar ($a$-plane) and polar ($c$-plane) B$_x$Al$_{1-x}$N, and compare them with those of AlN and GaN. Using density functional theory, many-body perturbation theory, $GW_0$ method, and a novel passivation scheme, we find that they have near-zero valence band alignments for low-$x$ B$_x$Al$_{1-x}$N/AlN, while higher compositions ($x > $0.333) exhibit type I or II band alignments. The band alignments also show a notable dependence on surface polarity and the tetrahedral distortion of the B$_x$Al$_{1-x}$N structures. Our computed offsets are in good agreement with available experimental data. Due to their low valence band alignments and higher conduction band alignments, the B$_x$Al$_{1-x}$N/AlN heterostructures could be well suited for high-electron-mobility transistors and ultraviolet light-emitting diodes. The band alignments of B$_x$Al$_{1-x}$N determined in this study provide essential design guidelines for integrating these ultra-wide bandgap alloys into advanced semiconductor technologies. [SEP] [HINT] low -> Materials Science (Syns: low-spirited, scurvy, depressed) | electronic -> Materials Science (Syns: ) | functional -> Neuroscience (Syns: working, usable, running)",Materials Science
"Understanding how protein mutations affect protein structure is essential for advancements in computational biology and bioinformatics. We introduce PRIMRose, a novel approach that predicts energy values for each residue given a mutated protein sequence. Unlike previous models that assess global energy shifts, our method analyzes the localized energetic impact of double amino acid insertions or deletions (InDels) at the individual residue level, enabling residue-specific insights into structural and functional disruption. We implement a Convolutional Neural Network architecture to predict the energy changes of each residue in a protein mutation. We train our model on datasets constructed from nine proteins, grouped into three categories: one set with exhaustive double InDel mutations, another with approximately 145k randomly sampled double InDel mutations, and a third with approximately 80k randomly sampled double InDel mutations. Our model achieves high predictive accuracy across a range of energy metrics as calculated by the Rosetta molecular modeling suite and reveals localized patterns that influence model performance, such as solvent accessibility and secondary structure context. This per-residue analysis offers new insights into the mutational tolerance of specific regions within proteins and provides higher interpretable and biologically meaningful predictions of InDels' effects.",Bioinformatics
"Understanding how protein mutations affect protein structure is essential for advancements in computational biology and bioinformatics. We introduce PRIMRose, a novel approach that predicts energy values for each residue given a mutated protein sequence. Unlike previous models that assess global energy shifts, our method analyzes the localized energetic impact of double amino acid insertions or deletions (InDels) at the individual residue level, enabling residue-specific insights into structural and functional disruption. We implement a Convolutional Neural Network architecture to predict the energy changes of each residue in a protein mutation. We train our model on datasets constructed from nine proteins, grouped into three categories: one set with exhaustive double InDel mutations, another with approximately 145k randomly sampled double InDel mutations, and a third with approximately 80k randomly sampled double InDel mutations. Our model achieves high predictive accuracy across a range of energy metrics as calculated by the Rosetta molecular modeling suite and reveals localized patterns that influence model performance, such as solvent accessibility and secondary structure context. This per-residue analysis offers new insights into the mutational tolerance of specific regions within proteins and provides higher interpretable and biologically meaningful predictions of InDels' effects. [SEP] [HINT] computational -> Neuroscience (Syns: ) | understanding -> Neuroscience (Syns: savvy, intellect, sympathy) | functional -> Neuroscience (Syns: working, usable, running)",Bioinformatics
"Connectomics - the mapping of neural connections in an organism's brain - currently requires extraordinary human effort to proofread the data collected from imaging and machine-learning assisted segmentation. With the growing excitement around using AI agents to automate important scientific tasks, we explore whether current AI systems can perform multiple tasks necessary for data proofreading. We introduce ConnectomeBench, a multimodal benchmark evaluating large language model (LLM) capabilities in three critical proofreading tasks: segment type identification, split error correction, and merge error detection. Using expert annotated data from two large open-source datasets - a cubic millimeter of mouse visual cortex and the complete Drosophila brain - we evaluate proprietary multimodal LLMs including Claude 3.7/4 Sonnet, o4-mini, GPT-4.1, GPT-4o, as well as open source models like InternVL-3 and NVLM. Our results demonstrate that current models achieve surprisingly high performance in segment identification (52-82% balanced accuracy vs. 20-25% chance) and binary/multiple choice split error correction (75-85% accuracy vs. 50% chance) while generally struggling on merge error identification tasks. Overall, while the best models still lag behind expert performance, they demonstrate promising capabilities that could eventually enable them to augment and potentially replace human proofreading in connectomics. Project page: https://github.com/jffbrwn2/ConnectomeBench and Dataset https://huggingface.co/datasets/jeffbbrown2/ConnectomeBench/tree/main",Neuroscience
"Connectomics - the mapping of neural connections in an organism's brain - currently requires extraordinary human effort to proofread the data collected from imaging and machine-learning assisted segmentation. With the growing excitement around using AI agents to automate important scientific tasks, we explore whether current AI systems can perform multiple tasks necessary for data proofreading. We introduce ConnectomeBench, a multimodal benchmark evaluating large language model (LLM) capabilities in three critical proofreading tasks: segment type identification, split error correction, and merge error detection. Using expert annotated data from two large open-source datasets - a cubic millimeter of mouse visual cortex and the complete Drosophila brain - we evaluate proprietary multimodal LLMs including Claude 3.7/4 Sonnet, o4-mini, GPT-4.1, GPT-4o, as well as open source models like InternVL-3 and NVLM. Our results demonstrate that current models achieve surprisingly high performance in segment identification (52-82% balanced accuracy vs. 20-25% chance) and binary/multiple choice split error correction (75-85% accuracy vs. 50% chance) while generally struggling on merge error identification tasks. Overall, while the best models still lag behind expert performance, they demonstrate promising capabilities that could eventually enable them to augment and potentially replace human proofreading in connectomics. Project page: https://github.com/jffbrwn2/ConnectomeBench and Dataset https://huggingface.co/datasets/jeffbbrown2/ConnectomeBench/tree/main [SEP] [HINT] tasks -> Neuroscience (Syns: tax, task, project) | language -> Neuroscience (Syns: linguistic process, linguistic communication, spoken communication) | datasets -> Bioinformatics (Syns: )",Neuroscience
A much-cited 2022 paper by Pekar et al. claimed that Bayesian analysis of the molecular phylogeny of early SARS-CoV-2 cases indicated that it was more likely that two successful introductions to humans had occurred than that just one had. Here I show that after correcting a fundamental error in Bayesian reasoning the results in that paper give larger likelihood for a single introduction than for two.,Bioinformatics
"A much-cited 2022 paper by Pekar et al. claimed that Bayesian analysis of the molecular phylogeny of early SARS-CoV-2 cases indicated that it was more likely that two successful introductions to humans had occurred than that just one had. Here I show that after correcting a fundamental error in Bayesian reasoning the results in that paper give larger likelihood for a single introduction than for two. [SEP] [HINT] molecular -> Bioinformatics (Syns: ) | results -> Bioinformatics (Syns: final result, consequence, resultant role) | single -> Bioinformatics (Syns: undivided, exclusive, bingle)",Bioinformatics
"Deep reinforcement learning (DRL) algorithms have the potential to provide new insights into psychiatric disorders. Here we create a DRL model of schizophrenia: a complex psychotic disorder characterized by anhedonia, avoidance, temporal discounting, catatonia, and hallucinations. Schizophrenia's causes are not well understood: dopaminergic theories emphasize dopamine system dysfunction, while neurodevelopmental theories emphasize abnormal connectivity, including excitation/inhibition (E/I) imbalance in the brain. In this study, we suppressed positive (excitatory) connections within an artificial neural network to simulate E/I imbalance. Interestingly, this is insufficient to create behavioral changes; the network simply compensates for the imbalance. But in doing so it becomes more sensitive to noise. Injecting noise into the network then creates a range of schizophrenic-like behaviours. These findings point to an interesting potential pathology of schizophrenia: E/I imbalance leads to a compensatory response by the network to increase the excitability of neurons, which increases susceptibility to noise. This suggests that the combination of E/I imbalance and neural noise may be key in the emergence of schizophrenic symptoms. We further notice altered response to reward prediction error in our model, and thus propose that E/I imbalance plus noise can account for both schizophrenia symptoms and dopamine system dysfunction: potentially unifying dopaminergic and neurodevelopmental theories of schizophrenia pathology.",Neuroscience
"Deep reinforcement learning (DRL) algorithms have the potential to provide new insights into psychiatric disorders. Here we create a DRL model of schizophrenia: a complex psychotic disorder characterized by anhedonia, avoidance, temporal discounting, catatonia, and hallucinations. Schizophrenia's causes are not well understood: dopaminergic theories emphasize dopamine system dysfunction, while neurodevelopmental theories emphasize abnormal connectivity, including excitation/inhibition (E/I) imbalance in the brain. In this study, we suppressed positive (excitatory) connections within an artificial neural network to simulate E/I imbalance. Interestingly, this is insufficient to create behavioral changes; the network simply compensates for the imbalance. But in doing so it becomes more sensitive to noise. Injecting noise into the network then creates a range of schizophrenic-like behaviours. These findings point to an interesting potential pathology of schizophrenia: E/I imbalance leads to a compensatory response by the network to increase the excitability of neurons, which increases susceptibility to noise. This suggests that the combination of E/I imbalance and neural noise may be key in the emergence of schizophrenic symptoms. We further notice altered response to reward prediction error in our model, and thus propose that E/I imbalance plus noise can account for both schizophrenia symptoms and dopamine system dysfunction: potentially unifying dopaminergic and neurodevelopmental theories of schizophrenia pathology. [SEP] [HINT] learning -> Bioinformatics (Syns: take, teach, acquire) | complex -> Bioinformatics (Syns: building complex, coordination compound, composite) | including -> Bioinformatics (Syns: admit, include, let in)",Neuroscience
"In this study, we propose the use of persistent homology -- specifically Betti curves for brain age prediction and for distinguishing between healthy and pathological aging. The proposed framework is applied to 100 structural MRI scans from the publicly available ADNI dataset. Our results indicate that Betti curve features, particularly those from dimension-1 (connected components) and dimension-2 (1D holes), effectively capture structural brain alterations associated with aging. Furthermore, clinical features are grouped into three categories based on their correlation, or lack thereof, with (i) predicted brain age and (ii) chronological age. The findings demonstrate that this approach successfully differentiates normal from pathological aging and provides a novel framework for understanding how structural brain changes relate to cognitive impairment. The proposed method serves as a foundation for developing potential biomarkers for early detection and monitoring of cognitive decline.",Neuroscience
"In this study, we propose the use of persistent homology -- specifically Betti curves for brain age prediction and for distinguishing between healthy and pathological aging. The proposed framework is applied to 100 structural MRI scans from the publicly available ADNI dataset. Our results indicate that Betti curve features, particularly those from dimension-1 (connected components) and dimension-2 (1D holes), effectively capture structural brain alterations associated with aging. Furthermore, clinical features are grouped into three categories based on their correlation, or lack thereof, with (i) predicted brain age and (ii) chronological age. The findings demonstrate that this approach successfully differentiates normal from pathological aging and provides a novel framework for understanding how structural brain changes relate to cognitive impairment. The proposed method serves as a foundation for developing potential biomarkers for early detection and monitoring of cognitive decline. [SEP] [HINT] based -> Bioinformatics (Syns: ground, free-base, base) | clinical -> Bioinformatics (Syns: ) | features -> Bioinformatics (Syns: characteristic, lineament, feature of speech)",Neuroscience
"This article reviews recent theoretical developments in the ab initio study of polarons in materials. The polaron is an emergent quasiparticle that arises from the interaction between electrons and phonons in solids, and consists of an electron or a hole accompanied by a distortion of the crystal lattice. Recent advances in experiments, theory, and computation have made it possible to investigate these quasiparticles with unprecedented detail, reigniting the interest in this classic problem of condensed matter physics. Recent theoretical and computational advances include ab initio calculations of polaron spectral functions, wavefunctions, lattice distortions, and transport and optical properties. These developments provide new insight into polaron physics, but they have evolved somewhat independently from the earlier effective Hamiltonian approaches that laid the foundation of the field. This article aims to bridge these complementary perspectives by placing them within a single unified conceptual framework. To this end, we start by reviewing effective Hamiltonians of historical significance in polaron theory, ab initio techniques based on density functional theory, and many-body first-principles approaches to polarons. After this survey, we outline a general field-theoretic framework that bridges between these diverse approaches to polaron physics. For completeness, we also review recent progress in the study of exciton polarons and self-trapped excitons and their relations to polarons. Beyond the methodology, we discuss recent applications to several classes of materials that attracted attention in the context of polaron physics.",Materials Science
"This article reviews recent theoretical developments in the ab initio study of polarons in materials. The polaron is an emergent quasiparticle that arises from the interaction between electrons and phonons in solids, and consists of an electron or a hole accompanied by a distortion of the crystal lattice. Recent advances in experiments, theory, and computation have made it possible to investigate these quasiparticles with unprecedented detail, reigniting the interest in this classic problem of condensed matter physics. Recent theoretical and computational advances include ab initio calculations of polaron spectral functions, wavefunctions, lattice distortions, and transport and optical properties. These developments provide new insight into polaron physics, but they have evolved somewhat independently from the earlier effective Hamiltonian approaches that laid the foundation of the field. This article aims to bridge these complementary perspectives by placing them within a single unified conceptual framework. To this end, we start by reviewing effective Hamiltonians of historical significance in polaron theory, ab initio techniques based on density functional theory, and many-body first-principles approaches to polarons. After this survey, we outline a general field-theoretic framework that bridges between these diverse approaches to polaron physics. For completeness, we also review recent progress in the study of exciton polarons and self-trapped excitons and their relations to polarons. Beyond the methodology, we discuss recent applications to several classes of materials that attracted attention in the context of polaron physics. [SEP] [HINT] based -> Bioinformatics (Syns: ground, free-base, base) | computational -> Neuroscience (Syns: ) | transport -> Materials Science (Syns: transferral, enthral, shipping)",Materials Science
"Depression is a major cause of global mental illness and significantly influences suicide rates. Timely and accurate diagnosis is essential for effective intervention. Electroencephalography (EEG) provides a non-invasive and accessible method for examining cerebral activity and identifying disease-associated patterns. We propose a novel graph-based deep learning framework, named Edge-gated, axis-mixed Pooling Attention Network (ExPANet), for differentiating major depressive disorder (MDD) patients from healthy controls (HC). EEG recordings undergo preprocessing to eliminate artifacts and are segmented into short periods of activity. We extract 14 features from each segment, which include time, frequency, fractal, and complexity domains. Electrodes are represented as nodes, whereas edges are determined by the phase-locking value (PLV) to represent functional connectivity. The generated brain graphs are examined utilizing an adapted graph attention network. This architecture acquires both localized electrode characteristics and comprehensive functional connectivity patterns. The proposed framework attains superior performance relative to current EEG-based approaches across two different datasets. A fundamental advantage of our methodology is its explainability. We evaluated the significance of features, channels, and edges, in addition to intrinsic attention weights. These studies highlight features, cerebral areas, and connectivity associations that are especially relevant to MDD, many of which correspond with clinical data. Our findings demonstrate a reliable and transparent method for EEG-based screening of MDD, using deep learning with clinically relevant results.",Neuroscience
"Depression is a major cause of global mental illness and significantly influences suicide rates. Timely and accurate diagnosis is essential for effective intervention. Electroencephalography (EEG) provides a non-invasive and accessible method for examining cerebral activity and identifying disease-associated patterns. We propose a novel graph-based deep learning framework, named Edge-gated, axis-mixed Pooling Attention Network (ExPANet), for differentiating major depressive disorder (MDD) patients from healthy controls (HC). EEG recordings undergo preprocessing to eliminate artifacts and are segmented into short periods of activity. We extract 14 features from each segment, which include time, frequency, fractal, and complexity domains. Electrodes are represented as nodes, whereas edges are determined by the phase-locking value (PLV) to represent functional connectivity. The generated brain graphs are examined utilizing an adapted graph attention network. This architecture acquires both localized electrode characteristics and comprehensive functional connectivity patterns. The proposed framework attains superior performance relative to current EEG-based approaches across two different datasets. A fundamental advantage of our methodology is its explainability. We evaluated the significance of features, channels, and edges, in addition to intrinsic attention weights. These studies highlight features, cerebral areas, and connectivity associations that are especially relevant to MDD, many of which correspond with clinical data. Our findings demonstrate a reliable and transparent method for EEG-based screening of MDD, using deep learning with clinically relevant results. [SEP] [HINT] connectivity -> Neuroscience (Syns: ) | clinical -> Bioinformatics (Syns: ) | features -> Bioinformatics (Syns: characteristic, lineament, feature of speech)",Neuroscience
"Two-dimensional (2D) quartic dispersion materials are known to develop magnetization upon doping. Here we conduct a systematic investigation of magnetization in hole-doped quartic dispersion materials (GaS, InSe, TiO$_{2}$), focusing on the effects of structural confinement from 2D monolayers to quasi-one-dimensional nanoribbons (NRs). Upon hole doping, these NRs develop itinerant magnetization across a broad range of carrier densities and display half-metallic behavior. The spin-polarization energies ($E_{sp}$) of these NRs enhance remarkably relative to their 2D counterparts, with maximum increase being in the case of TiO$_{2}$ from 31 to 103 meV/carrier. The $E_{sp}$ strongly depends on the degree of localization of the magnetic moments along the width of NRs, which is determined by edge passivation and ribbon width. Strong deformation of the topmost valence bands at higher dopings indicates deviation from the Stoner mechanism.",Materials Science
"Two-dimensional (2D) quartic dispersion materials are known to develop magnetization upon doping. Here we conduct a systematic investigation of magnetization in hole-doped quartic dispersion materials (GaS, InSe, TiO$_{2}$), focusing on the effects of structural confinement from 2D monolayers to quasi-one-dimensional nanoribbons (NRs). Upon hole doping, these NRs develop itinerant magnetization across a broad range of carrier densities and display half-metallic behavior. The spin-polarization energies ($E_{sp}$) of these NRs enhance remarkably relative to their 2D counterparts, with maximum increase being in the case of TiO$_{2}$ from 31 to 103 meV/carrier. The $E_{sp}$ strongly depends on the degree of localization of the magnetic moments along the width of NRs, which is determined by edge passivation and ribbon width. Strong deformation of the topmost valence bands at higher dopings indicates deviation from the Stoner mechanism. [SEP] [HINT] materials -> Materials Science (Syns: stuff, cloth, material) | structural -> Materials Science (Syns: geomorphologic, morphologic, morphological) | magnetic -> Materials Science (Syns: charismatic, magnetised, magnetized)",Materials Science
"NeuroAI is an emerging field at the intersection of neuroscience and artificial intelligence, where insights from brain function guide the design of intelligent systems. A central area within this field is synthetic biological intelligence (SBI), which combines the adaptive learning properties of biological neural networks with engineered hardware and software. SBI systems provide a platform for modeling neural computation, developing biohybrid architectures, and enabling new forms of embodied intelligence. In this review, we organize the NeuroAI landscape into three interacting domains: hardware, software, and wetware. We outline computational frameworks that integrate biological and non-biological systems and highlight recent advances in organoid intelligence, neuromorphic computing, and neuro-symbolic learning. These developments collectively point toward a new class of systems that compute through interactions between living neural tissue and digital algorithms.",Neuroscience
"NeuroAI is an emerging field at the intersection of neuroscience and artificial intelligence, where insights from brain function guide the design of intelligent systems. A central area within this field is synthetic biological intelligence (SBI), which combines the adaptive learning properties of biological neural networks with engineered hardware and software. SBI systems provide a platform for modeling neural computation, developing biohybrid architectures, and enabling new forms of embodied intelligence. In this review, we organize the NeuroAI landscape into three interacting domains: hardware, software, and wetware. We outline computational frameworks that integrate biological and non-biological systems and highlight recent advances in organoid intelligence, neuromorphic computing, and neuro-symbolic learning. These developments collectively point toward a new class of systems that compute through interactions between living neural tissue and digital algorithms. [SEP] [HINT] field -> Materials Science (Syns: field of honor, line of business, orbit) | tissue -> Bioinformatics (Syns: tissue paper, weave) | computational -> Neuroscience (Syns: )",Neuroscience
"Deep learning has emerged as a powerful framework for analyzing biomolecular dynamics trajectories, enabling efficient representations that capture essential system dynamics and facilitate mechanistic studies. We propose a neural network architecture incorporating Fourier Transform analysis to process trajectory data, achieving dual objectives: eliminating high-frequency noise while preserving biologically critical slow conformational dynamics, and establishing an isotropic representation space through the last hidden layer for enhanced dynamical quantification. Comparative protein simulations demonstrate our approach generates more uniform feature distributions than linear regression methods, evidenced by smoother state similarity matrices and clearer classification boundaries. Moreover, by using saliency score, we identified key structural determinants linked to effective energy landscapes governing system dynamics. We believe that the fusion of neural network features with physical order parameters creates a robust analytical framework for advancing biomolecular trajectory analysis.",Bioinformatics
"Deep learning has emerged as a powerful framework for analyzing biomolecular dynamics trajectories, enabling efficient representations that capture essential system dynamics and facilitate mechanistic studies. We propose a neural network architecture incorporating Fourier Transform analysis to process trajectory data, achieving dual objectives: eliminating high-frequency noise while preserving biologically critical slow conformational dynamics, and establishing an isotropic representation space through the last hidden layer for enhanced dynamical quantification. Comparative protein simulations demonstrate our approach generates more uniform feature distributions than linear regression methods, evidenced by smoother state similarity matrices and clearer classification boundaries. Moreover, by using saliency score, we identified key structural determinants linked to effective energy landscapes governing system dynamics. We believe that the fusion of neural network features with physical order parameters creates a robust analytical framework for advancing biomolecular trajectory analysis. [SEP] [HINT] features -> Bioinformatics (Syns: characteristic, lineament, feature of speech) | learning -> Bioinformatics (Syns: take, teach, acquire) | space -> Neuroscience (Syns: distance, place, outer space)",Bioinformatics
"Recent advances in large language models (LLMs) and biomedical foundation models (BioFMs) have achieved strong results in biological text reasoning, molecular modeling, and single-cell analysis, yet they remain siloed in disjoint embedding spaces, limiting cross-modal reasoning. We present BIOVERSE (Biomedical Vector Embedding Realignment for Semantic Engagement), a two-stage approach that adapts pretrained BioFMs as modality encoders and aligns them with LLMs through lightweight, modality-specific projection layers. The approach first aligns each modality to a shared LLM space through independently trained projections, allowing them to interoperate naturally, and then applies standard instruction tuning with multi-modal data to bring them together for downstream reasoning. By unifying raw biomedical data with knowledge embedded in LLMs, the approach enables zero-shot annotation, cross-modal question answering, and interactive, explainable dialogue. Across tasks spanning cell-type annotation, molecular description, and protein function reasoning, compact BIOVERSE configurations surpass larger LLM baselines while enabling richer, generative outputs than existing BioFMs, establishing a foundation for principled multi-modal biomedical reasoning.",Bioinformatics
"Recent advances in large language models (LLMs) and biomedical foundation models (BioFMs) have achieved strong results in biological text reasoning, molecular modeling, and single-cell analysis, yet they remain siloed in disjoint embedding spaces, limiting cross-modal reasoning. We present BIOVERSE (Biomedical Vector Embedding Realignment for Semantic Engagement), a two-stage approach that adapts pretrained BioFMs as modality encoders and aligns them with LLMs through lightweight, modality-specific projection layers. The approach first aligns each modality to a shared LLM space through independently trained projections, allowing them to interoperate naturally, and then applies standard instruction tuning with multi-modal data to bring them together for downstream reasoning. By unifying raw biomedical data with knowledge embedded in LLMs, the approach enables zero-shot annotation, cross-modal question answering, and interactive, explainable dialogue. Across tasks spanning cell-type annotation, molecular description, and protein function reasoning, compact BIOVERSE configurations surpass larger LLM baselines while enabling richer, generative outputs than existing BioFMs, establishing a foundation for principled multi-modal biomedical reasoning. [SEP] [HINT] tasks -> Neuroscience (Syns: tax, task, project) | language -> Neuroscience (Syns: linguistic process, linguistic communication, spoken communication) | space -> Neuroscience (Syns: distance, place, outer space)",Bioinformatics
"Background: Adolescence is a critical period of brain maturation and heightened vulnerability to cognitive and mental health disorders. Sleep plays a vital role in neurodevelopment, yet the mechanisms linking insufficient sleep to adverse brain and behavioral outcomes remain unclear. The glymphatic system (GS), a brain-wide clearance pathway, may provide a key mechanistic link. Methods: Participants from the Adolescent Brain Cognitive Development (ABCD) Study (n =6,800; age ~ 11 years) were categorized into sleep-sufficient (>=9 h/night) and sleep-insufficient (<9 h/night) groups. Linear models tested associations among sleep, PVS burden, brain volumes, and behavioral outcomes. Mediation analyses evaluated whether PVS burden explained sleep-related effects. Results: Adolescents with insufficient sleep exhibited significantly greater PVS burden, reduced cortical, subcortical, and white matter volumes, poorer cognitive performance across multiple domains (largest effect in crystallized intelligence), and elevated psychopathology (largest effect in general problems). Sleep duration and quality were strongly associated with PVS burden. Mediation analyses revealed that PVS burden partially mediated sleep effects on cognition and mental health, with indirect proportions up to 10.9%. Sequential models suggested a pathway from sleep -> PVS -> brain volume -> behavior as the most plausible route. Conclusions: Insufficient sleep during adolescence is linked to glymphatic dysfunction, reflected by increased PVS burden, which partially accounts for adverse effects on brain structure, cognition, and mental health. These findings highlight the GS as a potential mechanistic pathway and imaging biomarker, underscoring the importance of promoting adequate sleep to support neurodevelopment and mental health.",Neuroscience
"Background: Adolescence is a critical period of brain maturation and heightened vulnerability to cognitive and mental health disorders. Sleep plays a vital role in neurodevelopment, yet the mechanisms linking insufficient sleep to adverse brain and behavioral outcomes remain unclear. The glymphatic system (GS), a brain-wide clearance pathway, may provide a key mechanistic link. Methods: Participants from the Adolescent Brain Cognitive Development (ABCD) Study (n =6,800; age ~ 11 years) were categorized into sleep-sufficient (>=9 h/night) and sleep-insufficient (<9 h/night) groups. Linear models tested associations among sleep, PVS burden, brain volumes, and behavioral outcomes. Mediation analyses evaluated whether PVS burden explained sleep-related effects. Results: Adolescents with insufficient sleep exhibited significantly greater PVS burden, reduced cortical, subcortical, and white matter volumes, poorer cognitive performance across multiple domains (largest effect in crystallized intelligence), and elevated psychopathology (largest effect in general problems). Sleep duration and quality were strongly associated with PVS burden. Mediation analyses revealed that PVS burden partially mediated sleep effects on cognition and mental health, with indirect proportions up to 10.9%. Sequential models suggested a pathway from sleep -> PVS -> brain volume -> behavior as the most plausible route. Conclusions: Insufficient sleep during adolescence is linked to glymphatic dysfunction, reflected by increased PVS burden, which partially accounts for adverse effects on brain structure, cognition, and mental health. These findings highlight the GS as a potential mechanistic pathway and imaging biomarker, underscoring the importance of promoting adequate sleep to support neurodevelopment and mental health. [SEP] [HINT] quality -> Bioinformatics (Syns: lineament, tone, calibre) | performance -> Bioinformatics (Syns: functioning, operation, carrying out) | imaging -> Bioinformatics (Syns: imagery, imagination, visualise)",Neuroscience
"Predicting the evolving microstructure of hydrating cement is essential for understanding and modeling its mechanical property development. Physics-based continuum approaches offer a rigorous framework for capturing the thermodynamics of dissolution and precipitation processes at the microstructural scale. In this work, we present an adapted Phase-Field (PF) model for cement hydration that resolves key physical inconsistencies in existing PF formulations by introducing a revised free-energy potential and distinct equilibrium constants for clinker dissolution and hydrate precipitation. The resulting PF framework reproduces microstructural evolution, yielding realistic porosity levels and continuous phase boundaries in close agreement with experimental observations. The predicted hydrated microstructures are subsequently used in a computational homogenization scheme to evaluate the elastic response of the material. The PF-derived mechanical properties show good agreement with experimental trends, supporting the ability of the proposed framework to consistently link hydration chemistry, microstructure formation, and the resulting mechanical response.",Materials Science
"Predicting the evolving microstructure of hydrating cement is essential for understanding and modeling its mechanical property development. Physics-based continuum approaches offer a rigorous framework for capturing the thermodynamics of dissolution and precipitation processes at the microstructural scale. In this work, we present an adapted Phase-Field (PF) model for cement hydration that resolves key physical inconsistencies in existing PF formulations by introducing a revised free-energy potential and distinct equilibrium constants for clinker dissolution and hydrate precipitation. The resulting PF framework reproduces microstructural evolution, yielding realistic porosity levels and continuous phase boundaries in close agreement with experimental observations. The predicted hydrated microstructures are subsequently used in a computational homogenization scheme to evaluate the elastic response of the material. The PF-derived mechanical properties show good agreement with experimental trends, supporting the ability of the proposed framework to consistently link hydration chemistry, microstructure formation, and the resulting mechanical response. [SEP] [HINT] used -> Bioinformatics (Syns: utilize, ill-used, apply) | computational -> Neuroscience (Syns: ) | understanding -> Neuroscience (Syns: savvy, intellect, sympathy)",Materials Science
"Traumatic brain injury (TBI) disrupts thalamocortical connectivity, contributing to cognitive impairment and post-traumatic epilepsy (PTE). This study presents a novel tractography-based framework that leverages diffusion maps to capture microstructural and organizational changes in thalamic white matter pathways. By analyzing individual streamline characteristics, we identified significant associations between diffusion map embeddings and functional outcomes (GOSE scores), highlighting potential biomarkers for injury severity and recovery trajectories. Our findings suggest that fine-grained geometric features of white matter tracts may provide a more sensitive marker for TBI-related alterations.",Bioinformatics
"Traumatic brain injury (TBI) disrupts thalamocortical connectivity, contributing to cognitive impairment and post-traumatic epilepsy (PTE). This study presents a novel tractography-based framework that leverages diffusion maps to capture microstructural and organizational changes in thalamic white matter pathways. By analyzing individual streamline characteristics, we identified significant associations between diffusion map embeddings and functional outcomes (GOSE scores), highlighting potential biomarkers for injury severity and recovery trajectories. Our findings suggest that fine-grained geometric features of white matter tracts may provide a more sensitive marker for TBI-related alterations. [SEP] [HINT] potential -> Bioinformatics (Syns: voltage, potential difference, electric potential) | findings -> Neuroscience (Syns: determination, finding) | cognitive -> Neuroscience (Syns: )",Bioinformatics
"The structure and transport of electrolytes in nanoscale channels are known to be affected by the electronic properties of the confining walls. This influence is particularly pronounced in quasi-one-dimensional nanotubes, where the high surface-to-volume ratio makes the wall the dominant source of electrostatic screening. For instance, ideal metallic tubes suppress long-range Coulomb interactions between ions exponentially. Yet, there exists no generic framework for evaluating electrostatic interactions in tubular confinement. Here, we introduce tubular response functions - a generalisation of surface response functions that captures how nanotubes with arbitrary electronic properties screen Coulomb interactions. Using this framework, we evaluate the interaction potential of ions confined in a metallic carbon nanotube, treating its electronic properties exactly within a Luttinger liquid model. We demonstrate that the long-range exponential screening characteristic of ideal metals persists in realistic metallic nanotubes, regardless of their electron density. We trace the origin of this perfect screening property to the quantum confinement of electrons along the tube circumference. Our framework opens the way for quantitative descriptions of ionic correlations and charge storage in nanotube-based electrodes, and can be further extended to address confined ion dynamics.",Materials Science
"The structure and transport of electrolytes in nanoscale channels are known to be affected by the electronic properties of the confining walls. This influence is particularly pronounced in quasi-one-dimensional nanotubes, where the high surface-to-volume ratio makes the wall the dominant source of electrostatic screening. For instance, ideal metallic tubes suppress long-range Coulomb interactions between ions exponentially. Yet, there exists no generic framework for evaluating electrostatic interactions in tubular confinement. Here, we introduce tubular response functions - a generalisation of surface response functions that captures how nanotubes with arbitrary electronic properties screen Coulomb interactions. Using this framework, we evaluate the interaction potential of ions confined in a metallic carbon nanotube, treating its electronic properties exactly within a Luttinger liquid model. We demonstrate that the long-range exponential screening characteristic of ideal metals persists in realistic metallic nanotubes, regardless of their electron density. We trace the origin of this perfect screening property to the quantum confinement of electrons along the tube circumference. Our framework opens the way for quantitative descriptions of ionic correlations and charge storage in nanotube-based electrodes, and can be further extended to address confined ion dynamics. [SEP] [HINT] transport -> Materials Science (Syns: transferral, enthral, shipping) | charge -> Materials Science (Syns: tear, bearing, burster) | electronic -> Materials Science (Syns: )",Materials Science
"Ion migration in halide perovskites is a key factor limiting the operational stability of solar cells due to formation of halogen ion enriched domains and accumulation layers. The present work demonstrates the manifestation of ion migration in two ways via Hoke and Schottky effects. Both effects are induced by external exposure but have its peculiar way of solar cell performance degradation. We demonstrate the effects of ion migration on the device performance by measuring time dependent short-circuit current and different impedance characteristics that allow to see how charge-carrier separation property degrades. The Schottky effect leads to the rapid decrease of charge-carrier separation characteristic of solar cell while Hoke effect leads to the slow defect accumulation in the perovskite layer leading to the enhanced Shockley-Read-Hall recombination. Separation of these two effects can be realized by simple increase of transport layer thickness. A thick transport layer blocks losses of charge-carrier selectivity in a solar cell and leads to an enormous increase of T80 time, from 15 seconds up to 60 minutes.",Materials Science
"Ion migration in halide perovskites is a key factor limiting the operational stability of solar cells due to formation of halogen ion enriched domains and accumulation layers. The present work demonstrates the manifestation of ion migration in two ways via Hoke and Schottky effects. Both effects are induced by external exposure but have its peculiar way of solar cell performance degradation. We demonstrate the effects of ion migration on the device performance by measuring time dependent short-circuit current and different impedance characteristics that allow to see how charge-carrier separation property degrades. The Schottky effect leads to the rapid decrease of charge-carrier separation characteristic of solar cell while Hoke effect leads to the slow defect accumulation in the perovskite layer leading to the enhanced Shockley-Read-Hall recombination. Separation of these two effects can be realized by simple increase of transport layer thickness. A thick transport layer blocks losses of charge-carrier selectivity in a solar cell and leads to an enormous increase of T80 time, from 15 seconds up to 60 minutes. [SEP] [HINT] perovskite -> Materials Science (Syns: ) | transport -> Materials Science (Syns: transferral, enthral, shipping) | defect -> Materials Science (Syns: mar, shortcoming, fault)",Materials Science
"Medical image labels are often organized by taxonomies (e.g., organ - tissue - subtype), yet standard self-supervised learning (SSL) ignores this structure. We present a hierarchy-preserving contrastive framework that makes the label tree a first-class training signal and an evaluation target. Our approach introduces two plug-in objectives: Hierarchy-Weighted Contrastive (HWC), which scales positive/negative pair strengths by shared ancestors to promote within-parent coherence, and Level-Aware Margin (LAM), a prototype margin that separates ancestor groups across levels. The formulation is geometry-agnostic and applies to Euclidean and hyperbolic embeddings without architectural changes. Across several benchmarks, including breast histopathology, the proposed objectives consistently improve representation quality over strong SSL baselines while better respecting the taxonomy. We evaluate with metrics tailored to hierarchy faithfulness: HF1 (hierarchical F1), H-Acc (tree-distance-weighted accuracy), and parent-distance violation rate. We also report top-1 accuracy for completeness. Ablations show that HWC and LAM are effective even without curvature, and combining them yields the most taxonomy-aligned representations. Taken together, these results provide a simple, general recipe for learning medical image representations that respect the label tree and advance both performance and interpretability in hierarchy-rich domains.",Bioinformatics
"Medical image labels are often organized by taxonomies (e.g., organ - tissue - subtype), yet standard self-supervised learning (SSL) ignores this structure. We present a hierarchy-preserving contrastive framework that makes the label tree a first-class training signal and an evaluation target. Our approach introduces two plug-in objectives: Hierarchy-Weighted Contrastive (HWC), which scales positive/negative pair strengths by shared ancestors to promote within-parent coherence, and Level-Aware Margin (LAM), a prototype margin that separates ancestor groups across levels. The formulation is geometry-agnostic and applies to Euclidean and hyperbolic embeddings without architectural changes. Across several benchmarks, including breast histopathology, the proposed objectives consistently improve representation quality over strong SSL baselines while better respecting the taxonomy. We evaluate with metrics tailored to hierarchy faithfulness: HF1 (hierarchical F1), H-Acc (tree-distance-weighted accuracy), and parent-distance violation rate. We also report top-1 accuracy for completeness. Ablations show that HWC and LAM are effective even without curvature, and combining them yields the most taxonomy-aligned representations. Taken together, these results provide a simple, general recipe for learning medical image representations that respect the label tree and advance both performance and interpretability in hierarchy-rich domains. [SEP] [HINT] tissue -> Bioinformatics (Syns: tissue paper, weave) | learning -> Bioinformatics (Syns: take, teach, acquire) | quality -> Bioinformatics (Syns: lineament, tone, calibre)",Bioinformatics
"Data-driven discovery of model equations is a powerful approach for understanding the behavior of dynamical systems in many scientific fields. In particular, the ability to learn mathematical models from data would benefit systems biology, where the complex nature of these systems often makes a bottom up approach to modeling unfeasible. In recent years, sparse estimation techniques have gained prominence in system identification, primarily using parametric paradigms to efficiently capture system dynamics with minimal model complexity. In particular, the Sindy algorithm has successfully used sparsity to estimate nonlinear systems by extracting from a library of functions only a few key terms needed to capture the dynamics of these systems. However, parametric models often fall short in accurately representing certain nonlinearities inherent in complex systems. To address this limitation, we introduce a novel framework that integrates sparse parametric estimation with nonparametric techniques. It captures nonlinearities that Sindy cannot describe without requiring a priori information about their functional form. That is, without expanding the library of functions to include the one that is trying to be discovered. We illustrate our approach on several examples related to estimation of complex biological phenomena.",Bioinformatics
"Data-driven discovery of model equations is a powerful approach for understanding the behavior of dynamical systems in many scientific fields. In particular, the ability to learn mathematical models from data would benefit systems biology, where the complex nature of these systems often makes a bottom up approach to modeling unfeasible. In recent years, sparse estimation techniques have gained prominence in system identification, primarily using parametric paradigms to efficiently capture system dynamics with minimal model complexity. In particular, the Sindy algorithm has successfully used sparsity to estimate nonlinear systems by extracting from a library of functions only a few key terms needed to capture the dynamics of these systems. However, parametric models often fall short in accurately representing certain nonlinearities inherent in complex systems. To address this limitation, we introduce a novel framework that integrates sparse parametric estimation with nonparametric techniques. It captures nonlinearities that Sindy cannot describe without requiring a priori information about their functional form. That is, without expanding the library of functions to include the one that is trying to be discovered. We illustrate our approach on several examples related to estimation of complex biological phenomena. [SEP] [HINT] used -> Bioinformatics (Syns: utilize, ill-used, apply) | understanding -> Neuroscience (Syns: savvy, intellect, sympathy) | functional -> Neuroscience (Syns: working, usable, running)",Bioinformatics
"Chromatin sensitive partial wave spectroscopic (csPWS) microscopy enables label free detection of nanoscale chromatin packing alterations that occur before visible cellular transformation. However, manual nuclear segmentation limits population scale analysis needed for biomarker discovery in early cancer detection. The lack of annotated csPWS imaging data prevents direct use of standard deep learning methods. We present CFU Net, a hierarchical segmentation architecture trained with a three stage curriculum on synthetic multimodal data. CFU Net achieves near perfect performance on held out synthetic test data that represent diverse spectroscopic imaging conditions without manual annotations (Dice 0.9879, IoU 0.9895). Our approach uses physics based rendering that incorporates empirically supported chromatin packing statistics, Mie scattering models, and modality specific noise, combined with a curriculum that progresses from adversarial RGB pretraining to spectroscopic fine tuning and histology validation. CFU Net integrates five architectural elements (ConvNeXt backbone, Feature Pyramid Network, UNet plus plus dense connections, dual attention, and deep supervision) that together improve Dice over a baseline UNet by 8.3 percent. We demonstrate deployment ready INT8 quantization with 74.9 percent compression and 0.15 second inference, giving a 240 times throughput gain over manual analysis. Applied to more than ten thousand automatically segmented nuclei from synthetic test data, the pipeline extracts chromatin biomarkers that distinguish normal from pre cancerous tissue with large effect sizes (Cohens d between 1.31 and 2.98), reaching 94 percent classification accuracy. This work provides a general framework for synthetic to real transfer learning in specialized microscopy and open resources for community validation on clinical specimens.",Bioinformatics
"Chromatin sensitive partial wave spectroscopic (csPWS) microscopy enables label free detection of nanoscale chromatin packing alterations that occur before visible cellular transformation. However, manual nuclear segmentation limits population scale analysis needed for biomarker discovery in early cancer detection. The lack of annotated csPWS imaging data prevents direct use of standard deep learning methods. We present CFU Net, a hierarchical segmentation architecture trained with a three stage curriculum on synthetic multimodal data. CFU Net achieves near perfect performance on held out synthetic test data that represent diverse spectroscopic imaging conditions without manual annotations (Dice 0.9879, IoU 0.9895). Our approach uses physics based rendering that incorporates empirically supported chromatin packing statistics, Mie scattering models, and modality specific noise, combined with a curriculum that progresses from adversarial RGB pretraining to spectroscopic fine tuning and histology validation. CFU Net integrates five architectural elements (ConvNeXt backbone, Feature Pyramid Network, UNet plus plus dense connections, dual attention, and deep supervision) that together improve Dice over a baseline UNet by 8.3 percent. We demonstrate deployment ready INT8 quantization with 74.9 percent compression and 0.15 second inference, giving a 240 times throughput gain over manual analysis. Applied to more than ten thousand automatically segmented nuclei from synthetic test data, the pipeline extracts chromatin biomarkers that distinguish normal from pre cancerous tissue with large effect sizes (Cohens d between 1.31 and 2.98), reaching 94 percent classification accuracy. This work provides a general framework for synthetic to real transfer learning in specialized microscopy and open resources for community validation on clinical specimens. [SEP] [HINT] tissue -> Bioinformatics (Syns: tissue paper, weave) | based -> Bioinformatics (Syns: ground, free-base, base) | clinical -> Bioinformatics (Syns: )",Bioinformatics
"We derive the irreversibility condition in fracture for the inverse-deformation approach using the second law of thermodynamics. We consider the problem of brittle failure in an elastic bar previously solved in (Rosakis et al 2021). Despite the presence of a non-zero interfacial/surface energy, the third derivative of the inverse-deformation map is discontinuous at the crack faces. This is due to the presence of the inequality constraint ensuring the inverse strain is nonnegative and the orientation of matter is preserved. A change in the material location of a crack results in negative entropy production, violating the second law. Consequently, such changes are disallowed giving the irreversibility condition. The inequality constraint and the irreversibility condition limit the space of admissible variations. We prove necessary and sufficient conditions for local stability that incorporate these restrictions. Their numerical implementation shows that all broken equilibria found in (Rosakis et al 2021) are locally stable.",Materials Science
"We derive the irreversibility condition in fracture for the inverse-deformation approach using the second law of thermodynamics. We consider the problem of brittle failure in an elastic bar previously solved in (Rosakis et al 2021). Despite the presence of a non-zero interfacial/surface energy, the third derivative of the inverse-deformation map is discontinuous at the crack faces. This is due to the presence of the inequality constraint ensuring the inverse strain is nonnegative and the orientation of matter is preserved. A change in the material location of a crack results in negative entropy production, violating the second law. Consequently, such changes are disallowed giving the irreversibility condition. The inequality constraint and the irreversibility condition limit the space of admissible variations. We prove necessary and sufficient conditions for local stability that incorporate these restrictions. Their numerical implementation shows that all broken equilibria found in (Rosakis et al 2021) are locally stable. [SEP] [HINT] space -> Neuroscience (Syns: distance, place, outer space) | results -> Bioinformatics (Syns: final result, consequence, resultant role) | using -> Bioinformatics (Syns: utilize, exploitation, apply)",Materials Science
"While neural-based models have led to significant advancements in audio feature extraction, the interpretability of the learned representations remains a critical challenge. To address this, disentanglement techniques have been integrated into discrete neural audio codecs to impose structure on the extracted tokens. However, these approaches often exhibit strong dependencies on specific datasets or task formulations. In this work, we propose a disentangled neural audio codec that leverages spectral decomposition of time-domain signals to enhance representation interpretability. Experimental evaluations demonstrate that our method surpasses a state-of-the-art baseline in both reconstruction fidelity and perceptual quality.",Neuroscience
"While neural-based models have led to significant advancements in audio feature extraction, the interpretability of the learned representations remains a critical challenge. To address this, disentanglement techniques have been integrated into discrete neural audio codecs to impose structure on the extracted tokens. However, these approaches often exhibit strong dependencies on specific datasets or task formulations. In this work, we propose a disentangled neural audio codec that leverages spectral decomposition of time-domain signals to enhance representation interpretability. Experimental evaluations demonstrate that our method surpasses a state-of-the-art baseline in both reconstruction fidelity and perceptual quality. [SEP] [HINT] task -> Neuroscience (Syns: tax, project, chore) | structure -> Bioinformatics (Syns: social system, complex body part, social structure) | datasets -> Bioinformatics (Syns: )",Neuroscience
"To solve a new task from minimal experience, it is essential to effectively reuse knowledge from previous tasks, a problem known as meta-learning. Compositional solutions, where common elements of computation are flexibly recombined into new configurations, are particularly well-suited for meta-learning. Here, we propose a compositional meta-learning model that explicitly represents tasks as structured combinations of reusable computations. We achieve this by learning a generative model that captures the underlying components and their statistics shared across a family of tasks. This approach transforms learning a new task into a probabilistic inference problem, which allows for finding solutions without parameter updates through highly constrained hypothesis testing. Our model successfully recovers ground truth components and statistics in rule learning and motor learning tasks. We then demonstrate its ability to quickly infer new solutions from just single examples. Together, our framework joins the expressivity of neural networks with the data-efficiency of probabilistic inference to achieve rapid compositional meta-learning.",Neuroscience
"To solve a new task from minimal experience, it is essential to effectively reuse knowledge from previous tasks, a problem known as meta-learning. Compositional solutions, where common elements of computation are flexibly recombined into new configurations, are particularly well-suited for meta-learning. Here, we propose a compositional meta-learning model that explicitly represents tasks as structured combinations of reusable computations. We achieve this by learning a generative model that captures the underlying components and their statistics shared across a family of tasks. This approach transforms learning a new task into a probabilistic inference problem, which allows for finding solutions without parameter updates through highly constrained hypothesis testing. Our model successfully recovers ground truth components and statistics in rule learning and motor learning tasks. We then demonstrate its ability to quickly infer new solutions from just single examples. Together, our framework joins the expressivity of neural networks with the data-efficiency of probabilistic inference to achieve rapid compositional meta-learning. [SEP] [HINT] task -> Neuroscience (Syns: tax, project, chore) | tasks -> Neuroscience (Syns: tax, task, project) | learning -> Bioinformatics (Syns: take, teach, acquire)",Neuroscience
"We offer a comment on the Centaur (Binz et al., 2025) transformer-based model of human behavior. In particular, Centaur was cast as a path towards unified theories of cognition. We offer a counter claim with supporting argument: Centaur is a path divergent from unified theories of cognition, one that moves towards a unified model of behavior sans cognition.",Neuroscience
"We offer a comment on the Centaur (Binz et al., 2025) transformer-based model of human behavior. In particular, Centaur was cast as a path towards unified theories of cognition. We offer a counter claim with supporting argument: Centaur is a path divergent from unified theories of cognition, one that moves towards a unified model of behavior sans cognition. [SEP] [HINT] human -> Neuroscience (Syns: human being, man, homo) | model -> Bioinformatics (Syns: exemplary, framework, modelling)",Neuroscience
"Accurately modeling the relationship between perturbations, transcriptional responses, and phenotypic changes is essential for building an AI Virtual Cell (AIVC). However, existing methods typically constrained to modeling direct associations, such as Perturbation $\rightarrow$ RNA or Perturbation $\rightarrow$ Morphology, overlook the crucial causal link from RNA to morphology. To bridge this gap, we propose TRIDENT, a cascade generative framework that synthesizes realistic cellular morphology by conditioning on both the perturbation and the corresponding gene expression profile. To train and evaluate this task, we construct MorphoGene, a new dataset pairing L1000 gene expression with Cell Painting images for 98 compounds. TRIDENT significantly outperforms state-of-the-art approaches, achieving up to 7-fold improvement with strong generalization to unseen compounds. In a case study on docetaxel, we validate that RNA-guided synthesis accurately produces the corresponding phenotype. An ablation study further confirms that this RNA conditioning is essential for the model's high fidelity. By explicitly modeling transcriptome-phenome mapping, TRIDENT provides a powerful in silico tool and moves us closer to a predictive virtual cell.",Bioinformatics
"Accurately modeling the relationship between perturbations, transcriptional responses, and phenotypic changes is essential for building an AI Virtual Cell (AIVC). However, existing methods typically constrained to modeling direct associations, such as Perturbation $\rightarrow$ RNA or Perturbation $\rightarrow$ Morphology, overlook the crucial causal link from RNA to morphology. To bridge this gap, we propose TRIDENT, a cascade generative framework that synthesizes realistic cellular morphology by conditioning on both the perturbation and the corresponding gene expression profile. To train and evaluate this task, we construct MorphoGene, a new dataset pairing L1000 gene expression with Cell Painting images for 98 compounds. TRIDENT significantly outperforms state-of-the-art approaches, achieving up to 7-fold improvement with strong generalization to unseen compounds. In a case study on docetaxel, we validate that RNA-guided synthesis accurately produces the corresponding phenotype. An ablation study further confirms that this RNA conditioning is essential for the model's high fidelity. By explicitly modeling transcriptome-phenome mapping, TRIDENT provides a powerful in silico tool and moves us closer to a predictive virtual cell. [SEP] [HINT] framework -> Bioinformatics (Syns: theoretical account, model, fabric) | existing -> Bioinformatics (Syns: subsist, existent, survive) | ai -> Bioinformatics (Syns: artificial insemination, Army Intelligence, Bradypus tridactylus)",Bioinformatics
"We present a method for converting 24 channels of psychophysiologic time series data collected from individual participants via electroencephalogram (EEG), electrocardiogram (ECG), electrodermal activity (EDA), respiration rate (RR) into trackable three dimensional (3D) coordinates sufficient to estimate participation in specific task and cognitive states.",Neuroscience
"We present a method for converting 24 channels of psychophysiologic time series data collected from individual participants via electroencephalogram (EEG), electrocardiogram (ECG), electrodermal activity (EDA), respiration rate (RR) into trackable three dimensional (3D) coordinates sufficient to estimate participation in specific task and cognitive states. [SEP] [HINT] task -> Neuroscience (Syns: tax, project, chore) | dimensional -> Materials Science (Syns: ) | data -> Bioinformatics (Syns: data point, information, datum)",Neuroscience
"Designing protein sequences that fold into a target three-dimensional structure, known as the inverse folding problem, is central to protein engineering but remains challenging due to the vast sequence space and the importance of local structural constraints. Existing deep learning approaches achieve strong recovery rates, yet they lack explicit mechanisms to reuse fine-grained structure-sequence patterns that are conserved across natural proteins. We present PRISM, a multimodal retrieval-augmented generation framework for inverse folding that retrieves fine-grained representations of potential motifs from known proteins and integrates them with a hybrid self-cross attention decoder. PRISM is formulated as a latent-variable probabilistic model and implemented with an efficient approximation, combining theoretical grounding with practical scalability. Across five benchmarks (CATH-4.2, TS50, TS500, CAMEO 2022, and the PDB date split), PRISM establishes new state of the art in both perplexity and amino acid recovery, while also improving foldability metrics (RMSD, TM-score, pLDDT), demonstrating that fine-grained multimodal retrieval is a powerful and efficient paradigm for protein sequence design.",Bioinformatics
"Designing protein sequences that fold into a target three-dimensional structure, known as the inverse folding problem, is central to protein engineering but remains challenging due to the vast sequence space and the importance of local structural constraints. Existing deep learning approaches achieve strong recovery rates, yet they lack explicit mechanisms to reuse fine-grained structure-sequence patterns that are conserved across natural proteins. We present PRISM, a multimodal retrieval-augmented generation framework for inverse folding that retrieves fine-grained representations of potential motifs from known proteins and integrates them with a hybrid self-cross attention decoder. PRISM is formulated as a latent-variable probabilistic model and implemented with an efficient approximation, combining theoretical grounding with practical scalability. Across five benchmarks (CATH-4.2, TS50, TS500, CAMEO 2022, and the PDB date split), PRISM establishes new state of the art in both perplexity and amino acid recovery, while also improving foldability metrics (RMSD, TM-score, pLDDT), demonstrating that fine-grained multimodal retrieval is a powerful and efficient paradigm for protein sequence design. [SEP] [HINT] learning -> Bioinformatics (Syns: take, teach, acquire) | space -> Neuroscience (Syns: distance, place, outer space) | framework -> Bioinformatics (Syns: theoretical account, model, fabric)",Bioinformatics
"Altermagnets, characterized by spin-split bands without net magnetization, have recently emerged as a promising platform for spintronics. However, their microscopic mechanisms remain elusive, often relying on abstract group theory. In this work, we present an intuitive and pedagogical framework to understand the origin of spin splitting in altermagnets. We identify two essential ingredients: (1) alternating spin-polarized wavefunction localization on sublattices, and (2) broken translational symmetry caused by distortions in non-magnetic ion cages. We discuss a minimal model Hamiltonian based on an atomic exchange-driven spin splitting and anisotropic hopping that captures these effects and reproduces the hallmark features of altermagnetic band structures, including nodal spin degeneracies and large spin splittings. Our model is further validated by ab initio calculations on MnF2. By demystifying the microscopic origins of altermagnetism, our work bridges symmetry analysis and material realizations, shedding light on practical designs of altermagnetic spintronic devices.",Materials Science
"Altermagnets, characterized by spin-split bands without net magnetization, have recently emerged as a promising platform for spintronics. However, their microscopic mechanisms remain elusive, often relying on abstract group theory. In this work, we present an intuitive and pedagogical framework to understand the origin of spin splitting in altermagnets. We identify two essential ingredients: (1) alternating spin-polarized wavefunction localization on sublattices, and (2) broken translational symmetry caused by distortions in non-magnetic ion cages. We discuss a minimal model Hamiltonian based on an atomic exchange-driven spin splitting and anisotropic hopping that captures these effects and reproduces the hallmark features of altermagnetic band structures, including nodal spin degeneracies and large spin splittings. Our model is further validated by ab initio calculations on MnF2. By demystifying the microscopic origins of altermagnetism, our work bridges symmetry analysis and material realizations, shedding light on practical designs of altermagnetic spintronic devices. [SEP] [HINT] based -> Bioinformatics (Syns: ground, free-base, base) | spin -> Materials Science (Syns: twisting, whirl, tailspin) | features -> Bioinformatics (Syns: characteristic, lineament, feature of speech)",Materials Science
"In this work, the effects of dopamine neurotransmitter within the Cortico-Striatal-Thalamo-Cortical (CSTC) loop have been investigated. Simulations confirmed dopamine facilitates movement via thalamic disinhibition. Analysis of its impact on the signal-to-noise ratio (SNR) revealed a complex, region-specific outcome: SNR increased in some regions (e.g., D2 Striatum: 3.41 dB to 6.25 dB), decreased in others (e.g., Thalamus VL: 6.24 dB to 3.93 dB), and remained stable elsewhere (e.g., M1: 3.16 dB to 3.13 dB). This heterogeneity stems from dopamine increasing the excitability of D1-receptor-expressing neurons, which amplifies channel conductance noise and reduces SNR in specific circuits. Thus, dopamine acts not as a uniform signal enhancer, but as a complex modulator that critically balances facilitation and noise within the CSTC loop.",Neuroscience
"In this work, the effects of dopamine neurotransmitter within the Cortico-Striatal-Thalamo-Cortical (CSTC) loop have been investigated. Simulations confirmed dopamine facilitates movement via thalamic disinhibition. Analysis of its impact on the signal-to-noise ratio (SNR) revealed a complex, region-specific outcome: SNR increased in some regions (e.g., D2 Striatum: 3.41 dB to 6.25 dB), decreased in others (e.g., Thalamus VL: 6.24 dB to 3.93 dB), and remained stable elsewhere (e.g., M1: 3.16 dB to 3.13 dB). This heterogeneity stems from dopamine increasing the excitability of D1-receptor-expressing neurons, which amplifies channel conductance noise and reduces SNR in specific circuits. Thus, dopamine acts not as a uniform signal enhancer, but as a complex modulator that critically balances facilitation and noise within the CSTC loop. [SEP] [HINT] complex -> Bioinformatics (Syns: building complex, coordination compound, composite) | specific -> Bioinformatics (Syns: particular) | analysis -> Bioinformatics (Syns: psychoanalysis, depth psychology, analytic thinking)",Neuroscience
"A new component for the accurate simulation of neutron scattering from magnetic excitations has been developed for the neutron ray-tracing software McStas. The component SpinWave_BCO simulates inelastic neutron scattering from ferro-, antiferro-, and altermagnetic excitations in a body-centered orthorhombic crystal structure, where the dispersion relation and scattered neutron intensities are derived using linear spin wave theory.   Data from a simulated Triple-Axis Spectrometer with an extremely high resolution have been verified by direct comparison with theory and by comparison to data simulated using the package SpinW. The component serves as a proof-of-concept for the implementation of a more general linear spin wave component in McStas.",Materials Science
"A new component for the accurate simulation of neutron scattering from magnetic excitations has been developed for the neutron ray-tracing software McStas. The component SpinWave_BCO simulates inelastic neutron scattering from ferro-, antiferro-, and altermagnetic excitations in a body-centered orthorhombic crystal structure, where the dispersion relation and scattered neutron intensities are derived using linear spin wave theory.   Data from a simulated Triple-Axis Spectrometer with an extremely high resolution have been verified by direct comparison with theory and by comparison to data simulated using the package SpinW. The component serves as a proof-of-concept for the implementation of a more general linear spin wave component in McStas. [SEP] [HINT] data -> Bioinformatics (Syns: data point, information, datum) | crystal -> Materials Science (Syns: crystallization, quartz, lechatelierite) | spin -> Materials Science (Syns: twisting, whirl, tailspin)",Materials Science
"This study introduces a Holographic Agglutination Assay for quantifying levels of the immunoglobulin protein IgA in biological samples. This is the first example of a label-free and bead-free assay that quantifies protein agglutinates by direct detection using Total Holographic Characterization. A proof-of-concept assay for human serum immunoglobulins is demonstrated using Jacalin, the galactose-specific plant lectin, to induce selective agglutination.   By analyzing the size, refractive index, and number of particles in an assay sample, we obtain a reproducible and quantitative measurement of galactosylated immunoglobulins in a given sample. The assay is calibrated for a physiologically relevant reference interval of IgA concentrations in a 10x diluted emulated biological sample from low (80 mg/dL, 5 μM) to high (320 mg/dL, 20 μM) levels. The assay clearly distinguishes samples containing IgA from samples containing IgG.   More broadly, this study introduces a platform for creating lectin-mediated Holographic Agglutination Assays to monitor levels of immunoglobulins in biological samples. The ability to quantify immunoglobulin levels efficiently in clinical samples is likely to be valuable for diagnostics and will provide a basis for assaying other proteins that can be induced to agglutinate.",Bioinformatics
"This study introduces a Holographic Agglutination Assay for quantifying levels of the immunoglobulin protein IgA in biological samples. This is the first example of a label-free and bead-free assay that quantifies protein agglutinates by direct detection using Total Holographic Characterization. A proof-of-concept assay for human serum immunoglobulins is demonstrated using Jacalin, the galactose-specific plant lectin, to induce selective agglutination.   By analyzing the size, refractive index, and number of particles in an assay sample, we obtain a reproducible and quantitative measurement of galactosylated immunoglobulins in a given sample. The assay is calibrated for a physiologically relevant reference interval of IgA concentrations in a 10x diluted emulated biological sample from low (80 mg/dL, 5 μM) to high (320 mg/dL, 20 μM) levels. The assay clearly distinguishes samples containing IgA from samples containing IgG.   More broadly, this study introduces a platform for creating lectin-mediated Holographic Agglutination Assays to monitor levels of immunoglobulins in biological samples. The ability to quantify immunoglobulin levels efficiently in clinical samples is likely to be valuable for diagnostics and will provide a basis for assaying other proteins that can be induced to agglutinate. [SEP] [HINT] low -> Materials Science (Syns: low-spirited, scurvy, depressed) | clinical -> Bioinformatics (Syns: ) | human -> Neuroscience (Syns: human being, man, homo)",Bioinformatics
"Background: Clinical trials are designed to prove the efficacy of an intervention by means of model-based approaches involving parametric hypothesis testing. Issues arise when no effect is observed in the study population. Indeed, an effect may be present in a subgroup and the statistical test cannot detect it. To investigate this possibility, we proposed to change the paradigm to a data-driven approach. We selected exploratory methods to provide another perspective on the data and to identify particular homogeneous subgroups of subjects within which an effect might be detected. In the setting of prevention trials, the endpoint is a trajectory of repeated measures. In the settings of prevention trials, the endpoint is a trajectory of repeated measures, which requires the use of methods that can take data autocorrelation into account. The primary aim of this work was to explore the applicability of different methods for clustering and classifying trajectories. Methods: The Multidomain Alzheimer Preventive Trial (MAPT) was a three-year randomized controlled trial with four parallel arms (NCT00672685). The primary outcome was a composite Z-score combining four cognitive tests. The data were analyzed by quadratic mixed effects model. This study was inconclusive. Exploratory analysis is therefore relevant to investigate the use of data-driven methods for trajectory classification. The methods used were unsupervised: k-means for longitudinal data, Hierarchical Cluster Analysis (HCA), graphic semiology, and supervised analysis with dichotomous classification according to responder status. Results: Using k-means for longitudinal data, three groups were obtained and one of these groups showed cognitive decline over the three years of follow-up. This method could be applied directly to the primary outcome, the composite Z-score with repeated observations over time. With the two others unsupervised methods, we were unable to process longitudinal data directly. It was therefore necessary to choose an indicator of change in trajectories and to consider the rate of change between two measurements. For the HCA method, Ward's aggregation was performed. The Euclidean distance and rates of change were applied for the graphic semiology method. Lastly, as there were no objective criteria to define responder status, we defined our responders based on clinical criteria. Discussion: In the princeps study, the prevention trial was found to be inconclusive, likely due to the heterogeneity of the population, which may have masked a treatment effect later identified in a refined subgroup of high Beta Amyloid subjects. So, we have adopted an alternative unsupervised approach to subject stratification based on their trajectories. We could then identify patterns of similar trajectories of cognitive decline and also highlight the potential problem of a large heterogeneity of the profiles, maybe due to the final endpoint considered.",Neuroscience
"Background: Clinical trials are designed to prove the efficacy of an intervention by means of model-based approaches involving parametric hypothesis testing. Issues arise when no effect is observed in the study population. Indeed, an effect may be present in a subgroup and the statistical test cannot detect it. To investigate this possibility, we proposed to change the paradigm to a data-driven approach. We selected exploratory methods to provide another perspective on the data and to identify particular homogeneous subgroups of subjects within which an effect might be detected. In the setting of prevention trials, the endpoint is a trajectory of repeated measures. In the settings of prevention trials, the endpoint is a trajectory of repeated measures, which requires the use of methods that can take data autocorrelation into account. The primary aim of this work was to explore the applicability of different methods for clustering and classifying trajectories. Methods: The Multidomain Alzheimer Preventive Trial (MAPT) was a three-year randomized controlled trial with four parallel arms (NCT00672685). The primary outcome was a composite Z-score combining four cognitive tests. The data were analyzed by quadratic mixed effects model. This study was inconclusive. Exploratory analysis is therefore relevant to investigate the use of data-driven methods for trajectory classification. The methods used were unsupervised: k-means for longitudinal data, Hierarchical Cluster Analysis (HCA), graphic semiology, and supervised analysis with dichotomous classification according to responder status. Results: Using k-means for longitudinal data, three groups were obtained and one of these groups showed cognitive decline over the three years of follow-up. This method could be applied directly to the primary outcome, the composite Z-score with repeated observations over time. With the two others unsupervised methods, we were unable to process longitudinal data directly. It was therefore necessary to choose an indicator of change in trajectories and to consider the rate of change between two measurements. For the HCA method, Ward's aggregation was performed. The Euclidean distance and rates of change were applied for the graphic semiology method. Lastly, as there were no objective criteria to define responder status, we defined our responders based on clinical criteria. Discussion: In the princeps study, the prevention trial was found to be inconclusive, likely due to the heterogeneity of the population, which may have masked a treatment effect later identified in a refined subgroup of high Beta Amyloid subjects. So, we have adopted an alternative unsupervised approach to subject stratification based on their trajectories. We could then identify patterns of similar trajectories of cognitive decline and also highlight the potential problem of a large heterogeneity of the profiles, maybe due to the final endpoint considered. [SEP] [HINT] used -> Bioinformatics (Syns: utilize, ill-used, apply) | based -> Bioinformatics (Syns: ground, free-base, base) | clinical -> Bioinformatics (Syns: )",Neuroscience
"Electroencephalography (EEG) is widely used to study human brain dynamics, yet its quantitative information capacity remains unclear. Here, we combine information theory and synthetic forward modeling to estimate the mutual information between latent cortical sources and EEG recordings. Using Gaussian-channel theory and empirical simulations, we find that scalp EEG conveys only tens of bits per sample about low-dimensional neural activity. Information saturates with approximately 64-128 electrodes and scales logarithmically with signal-to-noise ratio (SNR). Linear decoders capture nearly all variance that is linearly recoverable, but the mutual information they recover remains far below the analytic channel capacity, indicating that measurement physics - not algorithmic complexity - is the dominant limitation. These results outline the intrinsic ceiling on how much structure about brain state or thought content can be inferred from EEG.",Neuroscience
"Electroencephalography (EEG) is widely used to study human brain dynamics, yet its quantitative information capacity remains unclear. Here, we combine information theory and synthetic forward modeling to estimate the mutual information between latent cortical sources and EEG recordings. Using Gaussian-channel theory and empirical simulations, we find that scalp EEG conveys only tens of bits per sample about low-dimensional neural activity. Information saturates with approximately 64-128 electrodes and scales logarithmically with signal-to-noise ratio (SNR). Linear decoders capture nearly all variance that is linearly recoverable, but the mutual information they recover remains far below the analytic channel capacity, indicating that measurement physics - not algorithmic complexity - is the dominant limitation. These results outline the intrinsic ceiling on how much structure about brain state or thought content can be inferred from EEG. [SEP] [HINT] used -> Bioinformatics (Syns: utilize, ill-used, apply) | cortical -> Neuroscience (Syns: ) | structure -> Bioinformatics (Syns: social system, complex body part, social structure)",Neuroscience
"Several electrochemical and electrical energy storage devices are reported every day, with the claim of outperforming the established ones. The use of newer materials and recent advanced techniques to synthesize and/or assemble them into a device leads to improved performance. Cyclic stability of a device is the most effective way of assessing the performance of the device. A wide variety of parameters can influence the cyclic stability of a cell, and there is no single fundamental parameter that reliably captures or assesses its overall performance. Therefore, we developed a multi-dimensional assessment framework that could account for various parameters like various types of materials used, selected fabrication techniques, current density, operating voltage window, temperature, environment, and other conditions, and can effectively rank cell performance based on essential assessment metrics like specific capacity and energy density that are substantial for a well-founded comparison.   The framework is designed with 45+ fields that capture various details related to i) materials used to fabricate cells, ii) processing techniques associated with electrode preparation and cell assembly, iii) cell information like weights and volumes, iv) electrochemical testing parameters, and v) cyclic charge-discharge performance details of a cell. The framework also accommodates charge-discharge gravimetric specific capacity, which is believed to be a key asset in accurately extracting lots of useful information, such as specific capacity, energy density, quantum efficiency, and other efficiencies. A distinctive feature of the framework is its ability to store data from both experimental and theoretical/computational sources (such as DFT and ML predictions) and facilitate effective comparison between them.",Materials Science
"Several electrochemical and electrical energy storage devices are reported every day, with the claim of outperforming the established ones. The use of newer materials and recent advanced techniques to synthesize and/or assemble them into a device leads to improved performance. Cyclic stability of a device is the most effective way of assessing the performance of the device. A wide variety of parameters can influence the cyclic stability of a cell, and there is no single fundamental parameter that reliably captures or assesses its overall performance. Therefore, we developed a multi-dimensional assessment framework that could account for various parameters like various types of materials used, selected fabrication techniques, current density, operating voltage window, temperature, environment, and other conditions, and can effectively rank cell performance based on essential assessment metrics like specific capacity and energy density that are substantial for a well-founded comparison.   The framework is designed with 45+ fields that capture various details related to i) materials used to fabricate cells, ii) processing techniques associated with electrode preparation and cell assembly, iii) cell information like weights and volumes, iv) electrochemical testing parameters, and v) cyclic charge-discharge performance details of a cell. The framework also accommodates charge-discharge gravimetric specific capacity, which is believed to be a key asset in accurately extracting lots of useful information, such as specific capacity, energy density, quantum efficiency, and other efficiencies. A distinctive feature of the framework is its ability to store data from both experimental and theoretical/computational sources (such as DFT and ML predictions) and facilitate effective comparison between them. [SEP] [HINT] used -> Bioinformatics (Syns: utilize, ill-used, apply) | based -> Bioinformatics (Syns: ground, free-base, base) | dft -> Materials Science (Syns: )",Materials Science
"Reliable measurement of glenoid bone loss is essential for operative planning in shoulder instability, but current manual and semi-automated methods are time-consuming and often subject to interreader variability. We developed and validated a fully automated deep learning pipeline for measuring glenoid bone loss on three-dimensional computed tomography (CT) scans using a linear-based, en-face view, best-circle method. Shoulder CT images of 91 patients (average age, 40 years; range, 14-89 years; 65 men) were retrospectively collected along with manual labels including glenoid segmentation, landmarks, and bone loss measurements. The multi-stage algorithm has three main stages: (1) segmentation, where we developed a U-Net to automatically segment the glenoid and humerus; (2) anatomical landmark detection, where a second network predicts glenoid rim points; and (3) geometric fitting, where we applied principal component analysis (PCA), projection, and circle fitting to compute the percentage of bone loss. The automated measurements showed strong agreement with consensus readings and exceeded surgeon-to-surgeon consistency (intraclass correlation coefficient (ICC) 0.84 vs 0.78), including in low- and high-bone-loss subgroups (ICC 0.71 vs 0.63 and 0.83 vs 0.21, respectively; P < 0.001). For classifying patients into low, medium, and high bone-loss categories, the pipeline achieved a recall of 0.714 for low and 0.857 for high severity, with no low cases misclassified as high or vice versa. These results suggest that our method is a time-efficient and clinically reliable tool for preoperative planning in shoulder instability and for screening patients with substantial glenoid bone loss. Code and dataset are available at https://github.com/Edenliu1/Auto-Glenoid-Measurement-DL-Pipeline.",Bioinformatics
"Reliable measurement of glenoid bone loss is essential for operative planning in shoulder instability, but current manual and semi-automated methods are time-consuming and often subject to interreader variability. We developed and validated a fully automated deep learning pipeline for measuring glenoid bone loss on three-dimensional computed tomography (CT) scans using a linear-based, en-face view, best-circle method. Shoulder CT images of 91 patients (average age, 40 years; range, 14-89 years; 65 men) were retrospectively collected along with manual labels including glenoid segmentation, landmarks, and bone loss measurements. The multi-stage algorithm has three main stages: (1) segmentation, where we developed a U-Net to automatically segment the glenoid and humerus; (2) anatomical landmark detection, where a second network predicts glenoid rim points; and (3) geometric fitting, where we applied principal component analysis (PCA), projection, and circle fitting to compute the percentage of bone loss. The automated measurements showed strong agreement with consensus readings and exceeded surgeon-to-surgeon consistency (intraclass correlation coefficient (ICC) 0.84 vs 0.78), including in low- and high-bone-loss subgroups (ICC 0.71 vs 0.63 and 0.83 vs 0.21, respectively; P < 0.001). For classifying patients into low, medium, and high bone-loss categories, the pipeline achieved a recall of 0.714 for low and 0.857 for high severity, with no low cases misclassified as high or vice versa. These results suggest that our method is a time-efficient and clinically reliable tool for preoperative planning in shoulder instability and for screening patients with substantial glenoid bone loss. Code and dataset are available at https://github.com/Edenliu1/Auto-Glenoid-Measurement-DL-Pipeline. [SEP] [HINT] low -> Materials Science (Syns: low-spirited, scurvy, depressed) | learning -> Bioinformatics (Syns: take, teach, acquire) | results -> Bioinformatics (Syns: final result, consequence, resultant role)",Bioinformatics
"Accurate bone strength prediction is essential for assessing fracture risk, particularly in aging populations and individuals with osteoporosis. Bone imaging has evolved from X-rays and DXA to clinical computed tomography (CT), and now to advanced modalities such as high-resolution peripheral quantitative CT and synchrotron radiation CT, which offer unprecedented resolution of bone microarchitecture. However, analytical methods have not kept pace with these imaging advances. This study applied topological data analysis (TDA) to extract biomechanically relevant features from high-resolution bone images, offering a new framework for bone strength prediction. We extracted topological features, specifically those derived from persistent homology, and combined them with standard bone morphometric descriptors to train machine learning models for apparent strength prediction. Models based solely on topological features outperformed those using traditional morphometrics, highlighting TDA's ability to capture biomechanically relevant structure. In particular, internal voids, often dismissed as imaging noise, proved to be the most predictive. While limited by dataset size and class imbalance, these results suggest that TDA offers a promising approach for advancing osteoporosis risk assessment.",Bioinformatics
"Accurate bone strength prediction is essential for assessing fracture risk, particularly in aging populations and individuals with osteoporosis. Bone imaging has evolved from X-rays and DXA to clinical computed tomography (CT), and now to advanced modalities such as high-resolution peripheral quantitative CT and synchrotron radiation CT, which offer unprecedented resolution of bone microarchitecture. However, analytical methods have not kept pace with these imaging advances. This study applied topological data analysis (TDA) to extract biomechanically relevant features from high-resolution bone images, offering a new framework for bone strength prediction. We extracted topological features, specifically those derived from persistent homology, and combined them with standard bone morphometric descriptors to train machine learning models for apparent strength prediction. Models based solely on topological features outperformed those using traditional morphometrics, highlighting TDA's ability to capture biomechanically relevant structure. In particular, internal voids, often dismissed as imaging noise, proved to be the most predictive. While limited by dataset size and class imbalance, these results suggest that TDA offers a promising approach for advancing osteoporosis risk assessment. [SEP] [HINT] based -> Bioinformatics (Syns: ground, free-base, base) | clinical -> Bioinformatics (Syns: ) | features -> Bioinformatics (Syns: characteristic, lineament, feature of speech)",Bioinformatics
"Background: Identifying new indications for approved drugs is a complex and time-consuming process that requires extensive knowledge of pharmacology, clinical data, and advanced computational methods. Recently, deep learning (DL) methods have shown their capability for the accurate prediction of drug repositioning. However, implementing DL-based modeling requires in-depth domain knowledge and proficient programming skills. Results: In this application, we introduce DeepDR, the first integrated platform that combines a variety of established DL-based models for disease- and target-specific drug repositioning tasks. DeepDR leverages invaluable experience to recommend candidate drugs, which covers more than 15 networks and a comprehensive knowledge graph that includes 5.9 million edges across 107 types of relationships connecting drugs, diseases, proteins/genes, pathways, and expression from six existing databases and a large scientific corpus of 24 million PubMed publications. Additionally, the recommended results include detailed descriptions of the recommended drugs and visualize key patterns with interpretability through a knowledge graph. Conclusion: DeepDR is free and open to all users without the requirement of registration. We believe it can provide an easy-to-use, systematic, highly accurate, and computationally automated platform for both experimental and computational scientists.",Bioinformatics
"Background: Identifying new indications for approved drugs is a complex and time-consuming process that requires extensive knowledge of pharmacology, clinical data, and advanced computational methods. Recently, deep learning (DL) methods have shown their capability for the accurate prediction of drug repositioning. However, implementing DL-based modeling requires in-depth domain knowledge and proficient programming skills. Results: In this application, we introduce DeepDR, the first integrated platform that combines a variety of established DL-based models for disease- and target-specific drug repositioning tasks. DeepDR leverages invaluable experience to recommend candidate drugs, which covers more than 15 networks and a comprehensive knowledge graph that includes 5.9 million edges across 107 types of relationships connecting drugs, diseases, proteins/genes, pathways, and expression from six existing databases and a large scientific corpus of 24 million PubMed publications. Additionally, the recommended results include detailed descriptions of the recommended drugs and visualize key patterns with interpretability through a knowledge graph. Conclusion: DeepDR is free and open to all users without the requirement of registration. We believe it can provide an easy-to-use, systematic, highly accurate, and computationally automated platform for both experimental and computational scientists. [SEP] [HINT] clinical -> Bioinformatics (Syns: ) | computational -> Neuroscience (Syns: ) | learning -> Bioinformatics (Syns: take, teach, acquire)",Bioinformatics
"Decoded Neurofeedback (DecNef) is a flourishing non-invasive approach to brain modulation with wide-ranging applications in neuromedicine and cognitive neuroscience. However, progress in DecNef research remains constrained by subject-dependent learning variability, reliance on indirect measures to quantify progress, and the high cost and time demands of experimentation.   We present DecNefLab, a modular and interpretable simulation framework that formalizes DecNef as a machine learning problem. Beyond providing a virtual laboratory, DecNefLab enables researchers to model, analyze and understand neurofeedback dynamics. Using latent variable generative models as simulated participants, DecNefLab allows direct observation of internal cognitive states and systematic evaluation of how different protocol designs and subject characteristics influence learning.   We demonstrate how this approach can (i) reproduce empirical phenomena of DecNef learning, (ii) identify conditions under which DecNef feedback fails to induce learning, and (iii) guide the design of more robust and reliable DecNef protocols in silico before human implementation.   In summary, DecNefLab bridges computational modeling and cognitive neuroscience, offering a principled foundation for methodological innovation, robust protocol design, and ultimately, a deeper understanding of DecNef-based brain modulation.",Neuroscience
"Decoded Neurofeedback (DecNef) is a flourishing non-invasive approach to brain modulation with wide-ranging applications in neuromedicine and cognitive neuroscience. However, progress in DecNef research remains constrained by subject-dependent learning variability, reliance on indirect measures to quantify progress, and the high cost and time demands of experimentation.   We present DecNefLab, a modular and interpretable simulation framework that formalizes DecNef as a machine learning problem. Beyond providing a virtual laboratory, DecNefLab enables researchers to model, analyze and understand neurofeedback dynamics. Using latent variable generative models as simulated participants, DecNefLab allows direct observation of internal cognitive states and systematic evaluation of how different protocol designs and subject characteristics influence learning.   We demonstrate how this approach can (i) reproduce empirical phenomena of DecNef learning, (ii) identify conditions under which DecNef feedback fails to induce learning, and (iii) guide the design of more robust and reliable DecNef protocols in silico before human implementation.   In summary, DecNefLab bridges computational modeling and cognitive neuroscience, offering a principled foundation for methodological innovation, robust protocol design, and ultimately, a deeper understanding of DecNef-based brain modulation. [SEP] [HINT] computational -> Neuroscience (Syns: ) | understanding -> Neuroscience (Syns: savvy, intellect, sympathy) | learning -> Bioinformatics (Syns: take, teach, acquire)",Neuroscience
"The use of coarse demographic adjustments in clinical equations has been increasingly scrutinized. In particular, adjustments for race have sparked significant debate with several medical professional societies recommending race-neutral equations in recent years. However, current approaches to remove race from clinical equations do not address the underlying causes of observed differences. Here, we present ARC (Approach for identifying pRoxies of demographic Correction), a framework to identify explanatory factors of group-level differences, which may inform the development of more accurate and precise clinical equations. We apply ARC to spirometry tests across two observational cohorts, CDC NHANES and UK Biobank, comprising 159,893 participants. Cross-sectional sociodemographic or exposure measures did not explain differences in reference lung function across race groups beyond those already explained by age, sex, and height. By contrast, sitting height accounted for up to 26% of the remaining differences in lung volumes between healthy Black and White adults. We then demonstrate how pulmonary function test (PFT) reference equations can incorporate these factors in a new set of equations called $ARC_{PFT}$, surpassing the predictive performance of the race-neutral GLI-Global equation recommended by major pulmonary societies. When compared to GLI-Global, inclusion of sitting height and waist circumference in $ARC_{PFT}$ decreased mean absolute error by 13% among Black participants in the UK Biobank and by 24% in NHANES. $ARC_{PFT}$ also had reduced vulnerability to domain shift compared to race-based methods, with mean absolute error 19.3% and 35.6% lower than race-stratified models in out-of-sample Asian and Hispanic populations, respectively. This approach provides a path for understanding the proxies of imprecise demographic adjustments and developing personalized clinical equations.",Bioinformatics
"The use of coarse demographic adjustments in clinical equations has been increasingly scrutinized. In particular, adjustments for race have sparked significant debate with several medical professional societies recommending race-neutral equations in recent years. However, current approaches to remove race from clinical equations do not address the underlying causes of observed differences. Here, we present ARC (Approach for identifying pRoxies of demographic Correction), a framework to identify explanatory factors of group-level differences, which may inform the development of more accurate and precise clinical equations. We apply ARC to spirometry tests across two observational cohorts, CDC NHANES and UK Biobank, comprising 159,893 participants. Cross-sectional sociodemographic or exposure measures did not explain differences in reference lung function across race groups beyond those already explained by age, sex, and height. By contrast, sitting height accounted for up to 26% of the remaining differences in lung volumes between healthy Black and White adults. We then demonstrate how pulmonary function test (PFT) reference equations can incorporate these factors in a new set of equations called $ARC_{PFT}$, surpassing the predictive performance of the race-neutral GLI-Global equation recommended by major pulmonary societies. When compared to GLI-Global, inclusion of sitting height and waist circumference in $ARC_{PFT}$ decreased mean absolute error by 13% among Black participants in the UK Biobank and by 24% in NHANES. $ARC_{PFT}$ also had reduced vulnerability to domain shift compared to race-based methods, with mean absolute error 19.3% and 35.6% lower than race-stratified models in out-of-sample Asian and Hispanic populations, respectively. This approach provides a path for understanding the proxies of imprecise demographic adjustments and developing personalized clinical equations. [SEP] [HINT] clinical -> Bioinformatics (Syns: ) | understanding -> Neuroscience (Syns: savvy, intellect, sympathy) | performance -> Bioinformatics (Syns: functioning, operation, carrying out)",Bioinformatics
"Digital assays represent a shift from traditional diagnostics and enable the precise detection of low-abundance analytes, critical for early disease diagnosis and personalized medicine, through discrete counting of biomolecular reporters. Within this paradigm, we present a particle counting algorithm for nanoparticle based imaging assays, formulated as a multiple-hypothesis statistical test under an explicit image-formation model and evaluated using a penalized likelihood rule. In contrast to thresholding or machine learning methods, this approach requires no training data or empirical parameter tuning, and its outputs remain interpretable through direct links to imaging physics and statistical decision theory.   Through numerical simulations we demonstrate robust count accuracy across weak signals, variable backgrounds, magnification changes and moderate PSF mismatch. Particle resolvability tests further reveal characteristic error modes, including under-counting at very small separations and localized over-counting near the resolution limit. Practically, we also confirm the algorithm's utility, through application to experimental dark-field images comprising a nanoparticle-based assay for detection of DNA biomarkers derived from SARS-CoV-2. Statistically significant differences in particle count distributions are observed between control and positive samples. Full count statistics obtained further exhibit consistent over-dispersion, and provide insight into non-specific and target-induced particle aggregation. These results establish our method as a reliable framework for nanoparticle-based detection assays in digital molecular diagnostics.",Bioinformatics
"Digital assays represent a shift from traditional diagnostics and enable the precise detection of low-abundance analytes, critical for early disease diagnosis and personalized medicine, through discrete counting of biomolecular reporters. Within this paradigm, we present a particle counting algorithm for nanoparticle based imaging assays, formulated as a multiple-hypothesis statistical test under an explicit image-formation model and evaluated using a penalized likelihood rule. In contrast to thresholding or machine learning methods, this approach requires no training data or empirical parameter tuning, and its outputs remain interpretable through direct links to imaging physics and statistical decision theory.   Through numerical simulations we demonstrate robust count accuracy across weak signals, variable backgrounds, magnification changes and moderate PSF mismatch. Particle resolvability tests further reveal characteristic error modes, including under-counting at very small separations and localized over-counting near the resolution limit. Practically, we also confirm the algorithm's utility, through application to experimental dark-field images comprising a nanoparticle-based assay for detection of DNA biomarkers derived from SARS-CoV-2. Statistically significant differences in particle count distributions are observed between control and positive samples. Full count statistics obtained further exhibit consistent over-dispersion, and provide insight into non-specific and target-induced particle aggregation. These results establish our method as a reliable framework for nanoparticle-based detection assays in digital molecular diagnostics. [SEP] [HINT] based -> Bioinformatics (Syns: ground, free-base, base) | learning -> Bioinformatics (Syns: take, teach, acquire) | molecular -> Bioinformatics (Syns: )",Bioinformatics
"Phylogenetic inference, the task of reconstructing how related sequences evolved from common ancestors, is a central objective in evolutionary genomics. The current state-of-the-art methods exploit probabilistic models of sequence evolution along phylogenetic trees, by searching for the tree maximizing the likelihood of observed sequences, or by estimating the posterior of the tree given the sequences in a Bayesian framework. Both approaches typically require to compute likelihoods, which is only feasible under simplifying assumptions such as independence of the evolution at the different positions of the sequence, and even then remains a costly operation. Here we present the first likelihood-free inference method for posterior distributions over phylogenies. It exploits a novel expressive encoding for pairs of sequences, and a parameterized probability distribution factorized over a succession of subtree merges. The resulting network provides accurate estimates of the posterior distribution outperforming both state-of-the-art maximum likelihood methods and a previous likelihood-free method for point estimation. It opens the way to fast and accurate phylogenetic inference under models of sequence evolution beyond those amenable to current likelihood-based inference methods.",Bioinformatics
"Phylogenetic inference, the task of reconstructing how related sequences evolved from common ancestors, is a central objective in evolutionary genomics. The current state-of-the-art methods exploit probabilistic models of sequence evolution along phylogenetic trees, by searching for the tree maximizing the likelihood of observed sequences, or by estimating the posterior of the tree given the sequences in a Bayesian framework. Both approaches typically require to compute likelihoods, which is only feasible under simplifying assumptions such as independence of the evolution at the different positions of the sequence, and even then remains a costly operation. Here we present the first likelihood-free inference method for posterior distributions over phylogenies. It exploits a novel expressive encoding for pairs of sequences, and a parameterized probability distribution factorized over a succession of subtree merges. The resulting network provides accurate estimates of the posterior distribution outperforming both state-of-the-art maximum likelihood methods and a previous likelihood-free method for point estimation. It opens the way to fast and accurate phylogenetic inference under models of sequence evolution beyond those amenable to current likelihood-based inference methods. [SEP] [HINT] task -> Neuroscience (Syns: tax, project, chore) | different -> Neuroscience (Syns: unlike, dissimilar) | method -> Bioinformatics (Syns: method acting)",Bioinformatics
"Precise, generalizable subject-agnostic seizure prediction (SASP) remains a fundamental challenge due to the intrinsic complexity and significant spectral variability of electrophysiological signals across individuals and recording modalities. We propose FAPEX, a novel architecture that introduces a learnable fractional neural frame operator (FrNFO) for adaptive time-frequency decomposition. Unlike conventional models that exhibit spectral bias toward low frequencies, our FrNFO employs fractional-order convolutions to capture both high and low-frequency dynamics, achieving approximately 10% improvement in F1-score and sensitivity over state-of-the-art baselines. The FrNFO enables the extraction of instantaneous phase and amplitude representations that are particularly informative for preictal biomarker discovery and enhance out-of-distribution generalization. FAPEX further integrates structural state-space modeling and channelwise attention, allowing it to handle heterogeneous electrode montages. Evaluated across 12 benchmarks spanning species (human, rat, dog, macaque) and modalities (Scalp-EEG, SEEG, ECoG, LFP), FAPEX consistently outperforms 23 supervised and 10 self-supervised baselines under nested cross-validation, with gains of up to 15% in sensitivity on complex cross-domain scenarios. It further demonstrates superior performance in several external validation cohorts. To our knowledge, these establish FAPEX as the first epilepsy model to show consistent superiority in SASP, offering a promising solution for discovering epileptic biomarker evidence supporting the existence of a distinct and identifiable preictal state and clinical translation.",Neuroscience
"Precise, generalizable subject-agnostic seizure prediction (SASP) remains a fundamental challenge due to the intrinsic complexity and significant spectral variability of electrophysiological signals across individuals and recording modalities. We propose FAPEX, a novel architecture that introduces a learnable fractional neural frame operator (FrNFO) for adaptive time-frequency decomposition. Unlike conventional models that exhibit spectral bias toward low frequencies, our FrNFO employs fractional-order convolutions to capture both high and low-frequency dynamics, achieving approximately 10% improvement in F1-score and sensitivity over state-of-the-art baselines. The FrNFO enables the extraction of instantaneous phase and amplitude representations that are particularly informative for preictal biomarker discovery and enhance out-of-distribution generalization. FAPEX further integrates structural state-space modeling and channelwise attention, allowing it to handle heterogeneous electrode montages. Evaluated across 12 benchmarks spanning species (human, rat, dog, macaque) and modalities (Scalp-EEG, SEEG, ECoG, LFP), FAPEX consistently outperforms 23 supervised and 10 self-supervised baselines under nested cross-validation, with gains of up to 15% in sensitivity on complex cross-domain scenarios. It further demonstrates superior performance in several external validation cohorts. To our knowledge, these establish FAPEX as the first epilepsy model to show consistent superiority in SASP, offering a promising solution for discovering epileptic biomarker evidence supporting the existence of a distinct and identifiable preictal state and clinical translation. [SEP] [HINT] low -> Materials Science (Syns: low-spirited, scurvy, depressed) | clinical -> Bioinformatics (Syns: ) | complex -> Bioinformatics (Syns: building complex, coordination compound, composite)",Neuroscience
"T cell receptor (TCR) recognition of peptide-MHC (pMHC) complexes is a central component of adaptive immunity, with implications for vaccine design, cancer immunotherapy, and autoimmune disease. While recent advances in machine learning have improved prediction of TCR-pMHC binding, the most effective approaches are black-box transformer models that cannot provide a rationale for predictions. Post-hoc explanation methods can provide insight with respect to the input but do not explicitly model biochemical mechanisms (e.g. known binding regions), as in TCR-pMHC binding. ``Explain-by-design'' models (i.e., with architectural components that can be examined directly after training) have been explored in other domains, but have not been used for TCR-pMHC binding. We propose explainable model layers (TCR-EML) that can be incorporated into protein-language model backbones for TCR-pMHC modeling. Our approach uses prototype layers for amino acid residue contacts drawn from known TCR-pMHC binding mechanisms, enabling high-quality explanations for predicted TCR-pMHC binding. Experiments of our proposed method on large-scale datasets demonstrate competitive predictive accuracy and generalization, and evaluation on the TCR-XAI benchmark demonstrates improved explainability compared with existing approaches.",Bioinformatics
"T cell receptor (TCR) recognition of peptide-MHC (pMHC) complexes is a central component of adaptive immunity, with implications for vaccine design, cancer immunotherapy, and autoimmune disease. While recent advances in machine learning have improved prediction of TCR-pMHC binding, the most effective approaches are black-box transformer models that cannot provide a rationale for predictions. Post-hoc explanation methods can provide insight with respect to the input but do not explicitly model biochemical mechanisms (e.g. known binding regions), as in TCR-pMHC binding. ``Explain-by-design'' models (i.e., with architectural components that can be examined directly after training) have been explored in other domains, but have not been used for TCR-pMHC binding. We propose explainable model layers (TCR-EML) that can be incorporated into protein-language model backbones for TCR-pMHC modeling. Our approach uses prototype layers for amino acid residue contacts drawn from known TCR-pMHC binding mechanisms, enabling high-quality explanations for predicted TCR-pMHC binding. Experiments of our proposed method on large-scale datasets demonstrate competitive predictive accuracy and generalization, and evaluation on the TCR-XAI benchmark demonstrates improved explainability compared with existing approaches. [SEP] [HINT] used -> Bioinformatics (Syns: utilize, ill-used, apply) | learning -> Bioinformatics (Syns: take, teach, acquire) | datasets -> Bioinformatics (Syns: )",Bioinformatics
"Entropy production is arguably the most universally applicable measure of non-equilibrium behavior, particularly for systems coupled to a heat bath. This setting encompasses driven soft matter as well as biomolecular, biochemical, and biophysical systems. Despite its central role, direct measurements of entropy production remain challenging - especially in small systems dominated by fluctuations. The main difficulty arises because not all degrees of freedom contributing to entropy production are experimentally accessible. A key question, therefore, is how to infer entropy production from coarse-grained observations, such as time series of experimentally measurable variables. Over the past decade, stochastic thermodynamics has provided several inequalities that yield model-free lower bounds on entropy production from such coarse-grained data. The major approaches rely on observations of coarse-grained states, fluctuating currents or ticks, correlation functions of coarse-grained observables, and waiting-time distributions between so-called Markovian events, which correspond to transitions between mesoscopic states. Here, we systematically review these techniques valid under the sole assumption of a Markovian, i.e., memoryless, dynamics on an underlying, not necessarily observable, network of states or following a possibly high-dimensional Langevin equation. We discuss in detail the large class of non-equilibrium steady states and highlight extensions of these methods to time-dependent and relaxing systems. While our focus is on mean entropy production, we also summarize recent progress in quantifying entropy production along individual coarse-grained trajectories.",Bioinformatics
"Entropy production is arguably the most universally applicable measure of non-equilibrium behavior, particularly for systems coupled to a heat bath. This setting encompasses driven soft matter as well as biomolecular, biochemical, and biophysical systems. Despite its central role, direct measurements of entropy production remain challenging - especially in small systems dominated by fluctuations. The main difficulty arises because not all degrees of freedom contributing to entropy production are experimentally accessible. A key question, therefore, is how to infer entropy production from coarse-grained observations, such as time series of experimentally measurable variables. Over the past decade, stochastic thermodynamics has provided several inequalities that yield model-free lower bounds on entropy production from such coarse-grained data. The major approaches rely on observations of coarse-grained states, fluctuating currents or ticks, correlation functions of coarse-grained observables, and waiting-time distributions between so-called Markovian events, which correspond to transitions between mesoscopic states. Here, we systematically review these techniques valid under the sole assumption of a Markovian, i.e., memoryless, dynamics on an underlying, not necessarily observable, network of states or following a possibly high-dimensional Langevin equation. We discuss in detail the large class of non-equilibrium steady states and highlight extensions of these methods to time-dependent and relaxing systems. While our focus is on mean entropy production, we also summarize recent progress in quantifying entropy production along individual coarse-grained trajectories. [SEP] [HINT] systems -> Bioinformatics (Syns: organization, organisation, system) | dynamics -> Bioinformatics (Syns: kinetics, dynamic, moral force) | states -> Materials Science (Syns: put forward, province, say)",Bioinformatics
"We propose an altermagnet-topological insulator bilayer as a platform to engineer Berry phase driven spin-charge responses using an interfacial buffer layer. Using a momentum-space lattice model and linear-response theory, we investigate a $d$-wave altermagnet coupled to a topological insulator and highlight the crucial role of spin-flip tunneling in shaping its electronic and transport properties. Interfacial hybridization strongly modifies the band structure, leading to anisotropic Rashba-Edelstein and Hall responses. The spin-flip component of the coupling induces an inverse $d$-wave spin texture in the altermagnetic bands, signaling the onset of an altermagnetic topological phase. This coupling also renders the Rashba-Edelstein effect strongly in-plane anisotropic, enhancing the transverse response relative to ferromagnetic or antiferromagnetic analogues. These results establish interfacial spin-flip tunneling as a practical control knob for direction-sensitive, stray-field-free spin-charge conversion in correlated topological heterostructures.",Materials Science
"We propose an altermagnet-topological insulator bilayer as a platform to engineer Berry phase driven spin-charge responses using an interfacial buffer layer. Using a momentum-space lattice model and linear-response theory, we investigate a $d$-wave altermagnet coupled to a topological insulator and highlight the crucial role of spin-flip tunneling in shaping its electronic and transport properties. Interfacial hybridization strongly modifies the band structure, leading to anisotropic Rashba-Edelstein and Hall responses. The spin-flip component of the coupling induces an inverse $d$-wave spin texture in the altermagnetic bands, signaling the onset of an altermagnetic topological phase. This coupling also renders the Rashba-Edelstein effect strongly in-plane anisotropic, enhancing the transverse response relative to ferromagnetic or antiferromagnetic analogues. These results establish interfacial spin-flip tunneling as a practical control knob for direction-sensitive, stray-field-free spin-charge conversion in correlated topological heterostructures. [SEP] [HINT] spin -> Materials Science (Syns: twisting, whirl, tailspin) | transport -> Materials Science (Syns: transferral, enthral, shipping) | electronic -> Materials Science (Syns: )",Materials Science
"Breast cancer is the most diagnosed cancer in women, with HER2 status critically guiding treatment decisions. Noninvasive prediction of HER2 status from dynamic contrast-enhanced MRI (DCE-MRI) could streamline diagnostics and reduce reliance on biopsy. However, preprocessing high-dynamic-range DCE-MRI into standardized 8-bit RGB format for pretrained neural networks is nontrivial, and normalization strategy significantly affects model performance. We benchmarked intensity normalization strategies using a Triple-Head Dual-Attention ResNet that processes RGB-fused temporal sequences from three DCE phases. Trained on a multicenter cohort (n=1,149) from the I-SPY trials and externally validated on BreastDCEDL_AMBL (n=43 lesions), our model outperformed transformer-based architectures, achieving 0.75 accuracy and 0.74 AUC on I-SPY test data. N4 bias field correction slightly degraded performance. Without fine-tuning, external validation yielded 0.66 AUC, demonstrating cross-institutional generalizability. These findings highlight the effectiveness of dual-attention mechanisms in capturing transferable spatiotemporal features for HER2 stratification, advancing reproducible deep learning biomarkers in breast cancer imaging.",Bioinformatics
"Breast cancer is the most diagnosed cancer in women, with HER2 status critically guiding treatment decisions. Noninvasive prediction of HER2 status from dynamic contrast-enhanced MRI (DCE-MRI) could streamline diagnostics and reduce reliance on biopsy. However, preprocessing high-dynamic-range DCE-MRI into standardized 8-bit RGB format for pretrained neural networks is nontrivial, and normalization strategy significantly affects model performance. We benchmarked intensity normalization strategies using a Triple-Head Dual-Attention ResNet that processes RGB-fused temporal sequences from three DCE phases. Trained on a multicenter cohort (n=1,149) from the I-SPY trials and externally validated on BreastDCEDL_AMBL (n=43 lesions), our model outperformed transformer-based architectures, achieving 0.75 accuracy and 0.74 AUC on I-SPY test data. N4 bias field correction slightly degraded performance. Without fine-tuning, external validation yielded 0.66 AUC, demonstrating cross-institutional generalizability. These findings highlight the effectiveness of dual-attention mechanisms in capturing transferable spatiotemporal features for HER2 stratification, advancing reproducible deep learning biomarkers in breast cancer imaging. [SEP] [HINT] field -> Materials Science (Syns: field of honor, line of business, orbit) | features -> Bioinformatics (Syns: characteristic, lineament, feature of speech) | learning -> Bioinformatics (Syns: take, teach, acquire)",Bioinformatics
"Objective: To develop an explainable multimodal large language model (MM-LLM) that (1) screens optic nerve head (ONH) OCT circle scans for quality and (2) generates structured clinical reports that include glaucoma diagnosis and sector-wise retinal nerve fiber layer (RNFL) thinning assessments. Design: Retrospective cohort study of 1,310 subjects contributing 43,849 Spectralis ONH OCT circle scans (1,331 glaucomatous and 867 healthy eyes) from the DIGS and ADAGES cohorts. Methods: A MM-LLM (Llama 3.2 Vision-Instruct model) was fine-tuned to generate clinical descriptions of OCT imaging data. Training data included paired OCT images and automatically generated, structured clinical reports that described global and sectoral RNFL thinning. Poor-quality scans were labeled as unusable and paired with a fixed refusal statement. The model was evaluated on a held-out test set for three tasks: quality assessment, glaucoma detection, and RNFL thinning classification across seven anatomical sectors. Evaluation metrics included accuracy, sensitivity, specificity, precision, and F1-score. Model description quality was also evaluated using standard text evaluation metrics. Results: The model achieved 0.90 accuracy and 0.98 specificity for quality triage. For glaucoma detection, accuracy was 0.86 (sensitivity 0.91, specificity 0.73, F1-score 0.91). RNFL thinning prediction accuracy ranged from 0.83 to 0.94, with highest performance in global and temporal sectors. Text generation scores showed strong alignment with reference reports (BLEU: 0.82; ROUGE-1: 0.94; ROUGE-2: 0.87; ROUGE-L: 0.92; BERTScore-F1: 0.99). Conclusions: The fine-tuned MM-LLM generated accurate clinical descriptions based on OCT imaging. The model achieved high accuracy in identifying image quality issues and detecting glaucoma. The model also provided sectoral descriptions of RNFL thinning to help support clinical OCT evaluation.",Bioinformatics
"Objective: To develop an explainable multimodal large language model (MM-LLM) that (1) screens optic nerve head (ONH) OCT circle scans for quality and (2) generates structured clinical reports that include glaucoma diagnosis and sector-wise retinal nerve fiber layer (RNFL) thinning assessments. Design: Retrospective cohort study of 1,310 subjects contributing 43,849 Spectralis ONH OCT circle scans (1,331 glaucomatous and 867 healthy eyes) from the DIGS and ADAGES cohorts. Methods: A MM-LLM (Llama 3.2 Vision-Instruct model) was fine-tuned to generate clinical descriptions of OCT imaging data. Training data included paired OCT images and automatically generated, structured clinical reports that described global and sectoral RNFL thinning. Poor-quality scans were labeled as unusable and paired with a fixed refusal statement. The model was evaluated on a held-out test set for three tasks: quality assessment, glaucoma detection, and RNFL thinning classification across seven anatomical sectors. Evaluation metrics included accuracy, sensitivity, specificity, precision, and F1-score. Model description quality was also evaluated using standard text evaluation metrics. Results: The model achieved 0.90 accuracy and 0.98 specificity for quality triage. For glaucoma detection, accuracy was 0.86 (sensitivity 0.91, specificity 0.73, F1-score 0.91). RNFL thinning prediction accuracy ranged from 0.83 to 0.94, with highest performance in global and temporal sectors. Text generation scores showed strong alignment with reference reports (BLEU: 0.82; ROUGE-1: 0.94; ROUGE-2: 0.87; ROUGE-L: 0.92; BERTScore-F1: 0.99). Conclusions: The fine-tuned MM-LLM generated accurate clinical descriptions based on OCT imaging. The model achieved high accuracy in identifying image quality issues and detecting glaucoma. The model also provided sectoral descriptions of RNFL thinning to help support clinical OCT evaluation. [SEP] [HINT] based -> Bioinformatics (Syns: ground, free-base, base) | clinical -> Bioinformatics (Syns: ) | language -> Neuroscience (Syns: linguistic process, linguistic communication, spoken communication)",Bioinformatics
"Organisms adapt to volatile environments by integrating sensory information with internal memory, yet their information processing is constrained by resource limitations. Such limitations can fundamentally alter optimal estimation strategies in biological systems. For example, recent experiments suggest that organisms exhibit nonmonotonic phase transitions between memoryless and memory-based estimation strategies depending on sensory reliability. However, an analytical understanding of these resource-induced phase transitions is still missing. This Letter presents an analytical characterization of resource-induced phase transitions in optimal estimation strategies. Our result identifies the conditions under which resource limitations alter estimation strategies and analytically reveals the mechanism underlying the emergence of discontinuous, nonmonotonic, and scaling behaviors. These results provide a theoretical foundation for understanding how limited resources shape information processing in biological systems.",Neuroscience
"Organisms adapt to volatile environments by integrating sensory information with internal memory, yet their information processing is constrained by resource limitations. Such limitations can fundamentally alter optimal estimation strategies in biological systems. For example, recent experiments suggest that organisms exhibit nonmonotonic phase transitions between memoryless and memory-based estimation strategies depending on sensory reliability. However, an analytical understanding of these resource-induced phase transitions is still missing. This Letter presents an analytical characterization of resource-induced phase transitions in optimal estimation strategies. Our result identifies the conditions under which resource limitations alter estimation strategies and analytically reveals the mechanism underlying the emergence of discontinuous, nonmonotonic, and scaling behaviors. These results provide a theoretical foundation for understanding how limited resources shape information processing in biological systems. [SEP] [HINT] understanding -> Neuroscience (Syns: savvy, intellect, sympathy) | information -> Bioinformatics (Syns: entropy, data, info) | processing -> Neuroscience (Syns: work, process, march)",Neuroscience
"A key question for adapting modern deep learning architectures to functional MRI (fMRI) is how to represent the data for model input. To bridge the modality gap between fMRI and natural images, we transform the 4D volumetric fMRI data into videos of 2D fMRI activity flat maps. We train Vision Transformers on 2.3K hours of fMRI flat map videos from the Human Connectome Project using the spatiotemporal masked autoencoder (MAE) framework. We observe that masked fMRI modeling performance improves with dataset size according to a strict power scaling law. Downstream classification benchmarks show that our model learns rich representations supporting both fine-grained state decoding across subjects, as well as subject-specific trait decoding across changes in brain state. This work is part of an ongoing open science project to build foundation models for fMRI data. Our code and datasets are available at https://github.com/MedARC-AI/fmri-fm.",Neuroscience
"A key question for adapting modern deep learning architectures to functional MRI (fMRI) is how to represent the data for model input. To bridge the modality gap between fMRI and natural images, we transform the 4D volumetric fMRI data into videos of 2D fMRI activity flat maps. We train Vision Transformers on 2.3K hours of fMRI flat map videos from the Human Connectome Project using the spatiotemporal masked autoencoder (MAE) framework. We observe that masked fMRI modeling performance improves with dataset size according to a strict power scaling law. Downstream classification benchmarks show that our model learns rich representations supporting both fine-grained state decoding across subjects, as well as subject-specific trait decoding across changes in brain state. This work is part of an ongoing open science project to build foundation models for fMRI data. Our code and datasets are available at https://github.com/MedARC-AI/fmri-fm. [SEP] [HINT] decoding -> Neuroscience (Syns: decrypt, decipherment, decryption) | learning -> Bioinformatics (Syns: take, teach, acquire) | functional -> Neuroscience (Syns: working, usable, running)",Neuroscience
"Inferring synaptic connectivity from neural population activity is a fundamental challenge in computational neuroscience, complicated by partial observability and mismatches between inference models and true circuit dynamics. In this study, we propose a graph-based neural inference model that simultaneously predicts neural activity and infers latent connectivity by modeling neurons as interacting nodes in a graph. The architecture features two distinct modules: one for learning structural connectivity and another for predicting future spiking activity via a graph neural network (GNN). Our model accommodates unobserved neurons through auxiliary nodes, allowing for inference in partially observed circuits. We evaluate this approach using synthetic data generated from ring attractor network models and real spike recordings from head direction cells in mice. Across a wide range of conditions, including varying recurrent connectivity, external inputs, and incomplete observations, our model reliably resolves spurious correlations and recovers accurate weight profiles. When applied to real data, the inferred connectivity aligns with theoretical predictions of continuous attractor models. These results highlight the potential of GNN-based models to infer latent neural circuitry through self-supervised structure learning, while leveraging the spike prediction task to flexibly link connectivity and dynamics across both simulated and biological neural systems.",Neuroscience
"Inferring synaptic connectivity from neural population activity is a fundamental challenge in computational neuroscience, complicated by partial observability and mismatches between inference models and true circuit dynamics. In this study, we propose a graph-based neural inference model that simultaneously predicts neural activity and infers latent connectivity by modeling neurons as interacting nodes in a graph. The architecture features two distinct modules: one for learning structural connectivity and another for predicting future spiking activity via a graph neural network (GNN). Our model accommodates unobserved neurons through auxiliary nodes, allowing for inference in partially observed circuits. We evaluate this approach using synthetic data generated from ring attractor network models and real spike recordings from head direction cells in mice. Across a wide range of conditions, including varying recurrent connectivity, external inputs, and incomplete observations, our model reliably resolves spurious correlations and recovers accurate weight profiles. When applied to real data, the inferred connectivity aligns with theoretical predictions of continuous attractor models. These results highlight the potential of GNN-based models to infer latent neural circuitry through self-supervised structure learning, while leveraging the spike prediction task to flexibly link connectivity and dynamics across both simulated and biological neural systems. [SEP] [HINT] task -> Neuroscience (Syns: tax, project, chore) | connectivity -> Neuroscience (Syns: ) | computational -> Neuroscience (Syns: )",Neuroscience
"Precise modeling and understanding of heat transport in the superionic phase are of great interest. Although simulations combining Green-Kubo (GK) molecular dynamics with machine-learned potentials (MLPs) stand as a promising approach, substantial challenges remain due to the crucial impact of atomic diffusion. Here, we first show that the thermal conductivity ($κ$) of superionic materials calculated via conventional GK integral of the energy flux varies notably with the MLP model. Subsequently, we highlight that reliable, model-independent $κ$ values can be obtained by applying Onsager's reciprocal relations to correctly capture the coupled heat and mass transport. Remarkably, an anomalously invariant $κ$ is observed over a wide temperature range, distinct from the characteristic trends in traditional crystals and glasses. Finally, we illustrate that conventional $κ$ decompositions into kinetic, potential, and cross terms suffer from ambiguities in the physical interpretation, despite their mathematical rigor.",Materials Science
"Precise modeling and understanding of heat transport in the superionic phase are of great interest. Although simulations combining Green-Kubo (GK) molecular dynamics with machine-learned potentials (MLPs) stand as a promising approach, substantial challenges remain due to the crucial impact of atomic diffusion. Here, we first show that the thermal conductivity ($κ$) of superionic materials calculated via conventional GK integral of the energy flux varies notably with the MLP model. Subsequently, we highlight that reliable, model-independent $κ$ values can be obtained by applying Onsager's reciprocal relations to correctly capture the coupled heat and mass transport. Remarkably, an anomalously invariant $κ$ is observed over a wide temperature range, distinct from the characteristic trends in traditional crystals and glasses. Finally, we illustrate that conventional $κ$ decompositions into kinetic, potential, and cross terms suffer from ambiguities in the physical interpretation, despite their mathematical rigor. [SEP] [HINT] understanding -> Neuroscience (Syns: savvy, intellect, sympathy) | transport -> Materials Science (Syns: transferral, enthral, shipping) | molecular -> Bioinformatics (Syns: )",Materials Science
"The development of next-generation electrochemical energy storage requires devices that combine the high energy density of batteries with the power capability and long cycle life of supercapacitors. However, the interfacial phenomena governing performance in these systems remain poorly unified. The solid-electrolyte interphase (SEI), a nanoscale film formed by electrolyte decomposition, is well studied in batteries but its counterpart in supercapacitors has received limited systematic investigation despite growing experimental evidence. This review argues that SEI formation is a universal electrochemical process that occurs whenever electrode potentials drive electron transfer into electrolyte orbitals beyond their stability limits, independent of whether charge storage is Faradaic or non-Faradaic. Differences between battery SEIs and supercapacitor interphases arise mainly from operating conditions, not fundamental chemistry. Engineered interphases created through electrolyte additives, protective coatings, or surface functionalization suppress leakage currents, improve capacitance retention, and enable stable high-voltage operation. By identifying shared mechanisms and establishing transferable design rules, this unified framework provides a foundation for predictive interphase engineering that supports long-lived, high-performance energy-storage technologies.",Materials Science
"The development of next-generation electrochemical energy storage requires devices that combine the high energy density of batteries with the power capability and long cycle life of supercapacitors. However, the interfacial phenomena governing performance in these systems remain poorly unified. The solid-electrolyte interphase (SEI), a nanoscale film formed by electrolyte decomposition, is well studied in batteries but its counterpart in supercapacitors has received limited systematic investigation despite growing experimental evidence. This review argues that SEI formation is a universal electrochemical process that occurs whenever electrode potentials drive electron transfer into electrolyte orbitals beyond their stability limits, independent of whether charge storage is Faradaic or non-Faradaic. Differences between battery SEIs and supercapacitor interphases arise mainly from operating conditions, not fundamental chemistry. Engineered interphases created through electrolyte additives, protective coatings, or surface functionalization suppress leakage currents, improve capacitance retention, and enable stable high-voltage operation. By identifying shared mechanisms and establishing transferable design rules, this unified framework provides a foundation for predictive interphase engineering that supports long-lived, high-performance energy-storage technologies. [SEP] [HINT] charge -> Materials Science (Syns: tear, bearing, burster) | electron -> Materials Science (Syns: negatron) | performance -> Bioinformatics (Syns: functioning, operation, carrying out)",Materials Science
"The 1mm roundworm C. elegans is a model organism used in many sub-areas of biology to investigate different types of biological processes. In order to complement the n-vivo analysis with computer-based investigations, several methods have been proposed to simulate the worm behaviour. These methods extract discrete behavioural units from the flow of the worm movements using different types of tracking techniques. Nevertheless, these techniques require a clear view of the entire worm body, which is not always achievable. For example, this happens in high density worm conditions, which are particularly informative to understand the influence of the social context on the single worm behaviour. In this paper, we illustrate and evaluate a method to extract behavioural units from recordings of C. elegans movements which do not necessarily require a clear view of the entire worm body. Moreover, the behavioural units are defined by an unsupervised automatic pipeline which frees the process from predefined assumptions that inevitably bias the behavioural analysis. The behavioural units resulting from the automatic method are interpreted by comparing them with hand-designed behavioural units. The effectiveness of the automatic method is evaluated by measuring the extent to which the movement of a simulated worm, with an agent-based model, matches the movement of a natural worm. Our results indicate that spatio-temporal locomotory patterns emerge even from single point worm tracking. Moreover, we show that such patterns represent a fundamental aspect of the behavioural classification process.",Bioinformatics
"The 1mm roundworm C. elegans is a model organism used in many sub-areas of biology to investigate different types of biological processes. In order to complement the n-vivo analysis with computer-based investigations, several methods have been proposed to simulate the worm behaviour. These methods extract discrete behavioural units from the flow of the worm movements using different types of tracking techniques. Nevertheless, these techniques require a clear view of the entire worm body, which is not always achievable. For example, this happens in high density worm conditions, which are particularly informative to understand the influence of the social context on the single worm behaviour. In this paper, we illustrate and evaluate a method to extract behavioural units from recordings of C. elegans movements which do not necessarily require a clear view of the entire worm body. Moreover, the behavioural units are defined by an unsupervised automatic pipeline which frees the process from predefined assumptions that inevitably bias the behavioural analysis. The behavioural units resulting from the automatic method are interpreted by comparing them with hand-designed behavioural units. The effectiveness of the automatic method is evaluated by measuring the extent to which the movement of a simulated worm, with an agent-based model, matches the movement of a natural worm. Our results indicate that spatio-temporal locomotory patterns emerge even from single point worm tracking. Moreover, we show that such patterns represent a fundamental aspect of the behavioural classification process. [SEP] [HINT] used -> Bioinformatics (Syns: utilize, ill-used, apply) | order -> Materials Science (Syns: enjoin, dictate, social club) | results -> Bioinformatics (Syns: final result, consequence, resultant role)",Bioinformatics
"Two-dimensional transition metal dichalcogenide (TMD) semiconductors exhibit a wide range of novel phenomena at millielectronvolt (terahertz-frequency) energy scales, including superconducting and correlation-induced insulating gaps that are frequently accompanied by symmetry breaking. However, due to the subwavelength dimensions and the often low conductivities of these systems, their intrinsic THz plasmons and meV-scale excitation gaps are difficult to access experimentally. Here we report an optical readout method that can image propagating THz-frequency collective modes in real time. The method relies on a strong coupling between the optical polarons of monolayer TMD semiconductors and the local THz fields in a waveguide, which enables us to image THz plasmons with micron scale spatial resolution and determine their propagation group velocities. Moreover, at finite magnetic fields, we observe coherent cyclotron oscillations resulting from Landau level repopulation induced by the THz field. Our findings provide a new near-field platform for probing collective excitations in strongly correlated two-dimensional semiconductors and enable ""all-photonic"" TMD-based architectures for time-domain THz plasmonics and optoelectronics.",Materials Science
"Two-dimensional transition metal dichalcogenide (TMD) semiconductors exhibit a wide range of novel phenomena at millielectronvolt (terahertz-frequency) energy scales, including superconducting and correlation-induced insulating gaps that are frequently accompanied by symmetry breaking. However, due to the subwavelength dimensions and the often low conductivities of these systems, their intrinsic THz plasmons and meV-scale excitation gaps are difficult to access experimentally. Here we report an optical readout method that can image propagating THz-frequency collective modes in real time. The method relies on a strong coupling between the optical polarons of monolayer TMD semiconductors and the local THz fields in a waveguide, which enables us to image THz plasmons with micron scale spatial resolution and determine their propagation group velocities. Moreover, at finite magnetic fields, we observe coherent cyclotron oscillations resulting from Landau level repopulation induced by the THz field. Our findings provide a new near-field platform for probing collective excitations in strongly correlated two-dimensional semiconductors and enable ""all-photonic"" TMD-based architectures for time-domain THz plasmonics and optoelectronics. [SEP] [HINT] transition -> Materials Science (Syns: passage, modulation, changeover) | low -> Materials Science (Syns: low-spirited, scurvy, depressed) | including -> Bioinformatics (Syns: admit, include, let in)",Materials Science
"Emergency departments worldwide face rising patient volumes, workforce shortages, and variability in triage decisions that threaten the delivery of timely and accurate care. Current triage methods rely primarily on vital signs, routine laboratory values, and clinicians' judgment, which, while effective, often miss emerging biological signals that could improve risk prediction for infection typing or antibiotic administration in acute conditions. To address this challenge, we introduce TriAgent, a large language model (LLM)-based multi-agent framework that couples automated biomarker discovery with deep research for literature-grounded validation and novelty assessment. TriAgent employs a supervisor research agent to generate research topics and delegate targeted queries to specialized sub-agents for evidence retrieval from various data sources. Findings are synthesized to classify biomarkers as either grounded in existing knowledge or flagged as novel candidates, offering transparent justification and highlighting unexplored pathways in acute care risk stratification. Unlike prior frameworks limited to existing routine clinical biomarkers, TriAgent aims to deliver an end-to-end framework from data analysis to literature grounding to improve transparency, explainability and expand the frontier of potentially actionable clinical biomarkers. Given a user's clinical query and quantitative triage data, TriAgent achieved a topic adherence F1 score of 55.7 +/- 5.0%, surpassing the CoT-ReAct agent by over 10%, and a faithfulness score of 0.42 +/- 0.39, exceeding all baselines by more than 50%. Across experiments, TriAgent consistently outperformed state-of-the-art LLM-based agentic frameworks in biomarker justification and literature-grounded novelty assessment. We share our repo: https://github.com/CellFace/TriAgent.",Bioinformatics
"Emergency departments worldwide face rising patient volumes, workforce shortages, and variability in triage decisions that threaten the delivery of timely and accurate care. Current triage methods rely primarily on vital signs, routine laboratory values, and clinicians' judgment, which, while effective, often miss emerging biological signals that could improve risk prediction for infection typing or antibiotic administration in acute conditions. To address this challenge, we introduce TriAgent, a large language model (LLM)-based multi-agent framework that couples automated biomarker discovery with deep research for literature-grounded validation and novelty assessment. TriAgent employs a supervisor research agent to generate research topics and delegate targeted queries to specialized sub-agents for evidence retrieval from various data sources. Findings are synthesized to classify biomarkers as either grounded in existing knowledge or flagged as novel candidates, offering transparent justification and highlighting unexplored pathways in acute care risk stratification. Unlike prior frameworks limited to existing routine clinical biomarkers, TriAgent aims to deliver an end-to-end framework from data analysis to literature grounding to improve transparency, explainability and expand the frontier of potentially actionable clinical biomarkers. Given a user's clinical query and quantitative triage data, TriAgent achieved a topic adherence F1 score of 55.7 +/- 5.0%, surpassing the CoT-ReAct agent by over 10%, and a faithfulness score of 0.42 +/- 0.39, exceeding all baselines by more than 50%. Across experiments, TriAgent consistently outperformed state-of-the-art LLM-based agentic frameworks in biomarker justification and literature-grounded novelty assessment. We share our repo: https://github.com/CellFace/TriAgent. [SEP] [HINT] clinical -> Bioinformatics (Syns: ) | language -> Neuroscience (Syns: linguistic process, linguistic communication, spoken communication) | framework -> Bioinformatics (Syns: theoretical account, model, fabric)",Bioinformatics
"Protein inverse folding, the design of an amino acid sequence based on a target 3D structure, is a fundamental problem of computational protein engineering. Existing methods either generate sequences without leveraging external knowledge or relying on protein language models (PLMs). The former omits the evolutionary information stored in protein databases, while the latter is parameter-inefficient and inflexible to adapt to ever-growing protein data. To overcome the above drawbacks, in this paper we propose a novel method, called retrieval-augmented denoising diffusion (RadDiff), for protein inverse folding. Given the target protein backbone, RadDiff uses a hierarchical search strategy to efficiently retrieve structurally similar proteins from large protein databases. The retrieved structures are then aligned residue-by-residue to the target to construct a position-specific amino acid profile, which serves as an evolutionary-informed prior that conditions the denoising process. A lightweight integration module is further designed to incorporate this prior effectively. Experimental results on the CATH, PDB, and TS50 datasets show that RadDiff consistently outperforms existing methods, improving sequence recovery rate by up to 19%. Experimental results also demonstrate that RadDiff generates highly foldable sequences and scales effectively with database size.",Bioinformatics
"Protein inverse folding, the design of an amino acid sequence based on a target 3D structure, is a fundamental problem of computational protein engineering. Existing methods either generate sequences without leveraging external knowledge or relying on protein language models (PLMs). The former omits the evolutionary information stored in protein databases, while the latter is parameter-inefficient and inflexible to adapt to ever-growing protein data. To overcome the above drawbacks, in this paper we propose a novel method, called retrieval-augmented denoising diffusion (RadDiff), for protein inverse folding. Given the target protein backbone, RadDiff uses a hierarchical search strategy to efficiently retrieve structurally similar proteins from large protein databases. The retrieved structures are then aligned residue-by-residue to the target to construct a position-specific amino acid profile, which serves as an evolutionary-informed prior that conditions the denoising process. A lightweight integration module is further designed to incorporate this prior effectively. Experimental results on the CATH, PDB, and TS50 datasets show that RadDiff consistently outperforms existing methods, improving sequence recovery rate by up to 19%. Experimental results also demonstrate that RadDiff generates highly foldable sequences and scales effectively with database size. [SEP] [HINT] based -> Bioinformatics (Syns: ground, free-base, base) | language -> Neuroscience (Syns: linguistic process, linguistic communication, spoken communication) | computational -> Neuroscience (Syns: )",Bioinformatics
"We present Brain Harmony (BrainHarmonix), the first multimodal brain foundation model that unifies structural morphology and functional dynamics into compact 1D token representations. The model was pretrained on two of the largest neuroimaging datasets to date, encompassing 64,594 T1-weighted structural MRI 3D volumes (~ 14 million images) and 70,933 functional MRI (fMRI) time series. BrainHarmonix is grounded in two foundational neuroscience principles: structure complements function - structural and functional modalities offer distinct yet synergistic insights into brain organization; function follows structure - brain functional dynamics are shaped by cortical morphology. The modular pretraining process involves single-modality training with geometric pre-alignment followed by modality fusion through shared brain hub tokens. Notably, our dynamics encoder uniquely handles fMRI time series with heterogeneous repetition times (TRs), addressing a major limitation in existing models. BrainHarmonix is also the first to deeply compress high-dimensional neuroimaging signals into unified, continuous 1D tokens, forming a compact latent space of the human brain. BrainHarmonix achieves strong generalization across diverse downstream tasks, including neurodevelopmental and neurodegenerative disorder classification and cognition prediction - consistently outperforming previous approaches. Our models - pretrained on 8 H100 GPUs - aim to catalyze a new era of AI-driven neuroscience powered by large-scale multimodal neuroimaging.",Neuroscience
"We present Brain Harmony (BrainHarmonix), the first multimodal brain foundation model that unifies structural morphology and functional dynamics into compact 1D token representations. The model was pretrained on two of the largest neuroimaging datasets to date, encompassing 64,594 T1-weighted structural MRI 3D volumes (~ 14 million images) and 70,933 functional MRI (fMRI) time series. BrainHarmonix is grounded in two foundational neuroscience principles: structure complements function - structural and functional modalities offer distinct yet synergistic insights into brain organization; function follows structure - brain functional dynamics are shaped by cortical morphology. The modular pretraining process involves single-modality training with geometric pre-alignment followed by modality fusion through shared brain hub tokens. Notably, our dynamics encoder uniquely handles fMRI time series with heterogeneous repetition times (TRs), addressing a major limitation in existing models. BrainHarmonix is also the first to deeply compress high-dimensional neuroimaging signals into unified, continuous 1D tokens, forming a compact latent space of the human brain. BrainHarmonix achieves strong generalization across diverse downstream tasks, including neurodevelopmental and neurodegenerative disorder classification and cognition prediction - consistently outperforming previous approaches. Our models - pretrained on 8 H100 GPUs - aim to catalyze a new era of AI-driven neuroscience powered by large-scale multimodal neuroimaging. [SEP] [HINT] cortical -> Neuroscience (Syns: ) | space -> Neuroscience (Syns: distance, place, outer space) | functional -> Neuroscience (Syns: working, usable, running)",Neuroscience
"Designing mRNA sequences is a major challenge in developing next-generation therapeutics, since it involves exploring a vast space of possible nucleotide combinations while optimizing sequence properties like stability, translation efficiency, and protein expression. While Generative Flow Networks are promising for this task, their training is hindered by sparse, long-horizon rewards and multi-objective trade-offs. We propose Curriculum-Augmented GFlowNets (CAGFN), which integrate curriculum learning with multi-objective GFlowNets to generate de novo mRNA sequences. CAGFN integrates a length-based curriculum that progressively adapts the maximum sequence length guiding exploration from easier to harder subproblems. We also provide a new mRNA design environment for GFlowNets which, given a target protein sequence and a combination of biological objectives, allows for the training of models that generate plausible mRNA candidates. This provides a biologically motivated setting for applying and advancing GFlowNets in therapeutic sequence design. On different mRNA design tasks, CAGFN improves Pareto performance and biological plausibility, while maintaining diversity. Moreover, CAGFN reaches higher-quality solutions faster than a GFlowNet trained with random sequence sampling (no curriculum), and enables generalization to out-of-distribution sequences.",Bioinformatics
"Designing mRNA sequences is a major challenge in developing next-generation therapeutics, since it involves exploring a vast space of possible nucleotide combinations while optimizing sequence properties like stability, translation efficiency, and protein expression. While Generative Flow Networks are promising for this task, their training is hindered by sparse, long-horizon rewards and multi-objective trade-offs. We propose Curriculum-Augmented GFlowNets (CAGFN), which integrate curriculum learning with multi-objective GFlowNets to generate de novo mRNA sequences. CAGFN integrates a length-based curriculum that progressively adapts the maximum sequence length guiding exploration from easier to harder subproblems. We also provide a new mRNA design environment for GFlowNets which, given a target protein sequence and a combination of biological objectives, allows for the training of models that generate plausible mRNA candidates. This provides a biologically motivated setting for applying and advancing GFlowNets in therapeutic sequence design. On different mRNA design tasks, CAGFN improves Pareto performance and biological plausibility, while maintaining diversity. Moreover, CAGFN reaches higher-quality solutions faster than a GFlowNet trained with random sequence sampling (no curriculum), and enables generalization to out-of-distribution sequences. [SEP] [HINT] learning -> Bioinformatics (Syns: take, teach, acquire) | networks -> Neuroscience (Syns: network, meshwork, electronic network) | space -> Neuroscience (Syns: distance, place, outer space)",Bioinformatics
"While recent sound event detection (SED) systems can identify baleen whale calls in marine audio, challenges related to false positive and minority-class detection persist. We propose the boundary proposal network (BPN), which extends an existing lightweight SED system. The BPN is inspired by work in image object detection and aims to reduce the number of false positive detections. It achieves this by using intermediate latent representations computed within the backbone classification model to gate the final output. When added to an existing SED system, the BPN achieves a 16.8 % absolute increase in precision, as well as 21.3 % and 9.4 % improvements in the F1-score for minority-class d-calls and bp-calls, respectively. We further consider two approaches to the selection of post-processing hyperparameters: a forward-search and a backward-search. By separately optimising event-level and frame-level hyperparameters, these two approaches lead to considerable performance improvements over parameters selected using empirical methods. The complete WhaleVAD-BPN system achieves a cross-validated development F1-score of 0.475, which is a 9.8 % absolute improvement over the baseline.",Bioinformatics
"While recent sound event detection (SED) systems can identify baleen whale calls in marine audio, challenges related to false positive and minority-class detection persist. We propose the boundary proposal network (BPN), which extends an existing lightweight SED system. The BPN is inspired by work in image object detection and aims to reduce the number of false positive detections. It achieves this by using intermediate latent representations computed within the backbone classification model to gate the final output. When added to an existing SED system, the BPN achieves a 16.8 % absolute increase in precision, as well as 21.3 % and 9.4 % improvements in the F1-score for minority-class d-calls and bp-calls, respectively. We further consider two approaches to the selection of post-processing hyperparameters: a forward-search and a backward-search. By separately optimising event-level and frame-level hyperparameters, these two approaches lead to considerable performance improvements over parameters selected using empirical methods. The complete WhaleVAD-BPN system achieves a cross-validated development F1-score of 0.475, which is a 9.8 % absolute improvement over the baseline. [SEP] [HINT] work -> Bioinformatics (Syns: work out, process, bring) | performance -> Bioinformatics (Syns: functioning, operation, carrying out) | systems -> Bioinformatics (Syns: organization, organisation, system)",Bioinformatics
"The application of spectral-shifting films in greenhouses to shift green light to red light has shown variable growth responses across crop species. However, the yield enhancement of crops under altered light quality is related to the collective effects of the specific biophysical characteristics of each species. Considering only one attribute of a crop has limitations in understanding the relationship between sunlight quality adjustments and crop growth performance. Therefore, this study aims to comprehensively link multiple plant phenotypic traits and daily light integral considering the physiological responses of crops to their growth outcomes under SF using artificial intelligence. Between 2021 and 2024, various leafy, fruiting, and root crops were grown in greenhouses covered with either PEF or SF, and leaf reflectance, leaf mass per area, chlorophyll content, daily light integral, and light saturation point were measured from the plants cultivated in each condition. 210 data points were collected, but there was insufficient data to train deep learning models, so a variational autoencoder was used for data augmentation. Most crop yields showed an average increase of 22.5% under SF. These data were used to train several models, including logistic regression, decision tree, random forest, XGBoost, and feedforward neural network (FFNN), aiming to binary classify whether there was a significant effect on yield with SF application. The FFNN achieved a high classification accuracy of 91.4% on a test dataset that was not used for training. This study provide insight into the complex interactions between leaf phenotypic and photosynthetic traits, environmental conditions, and solar spectral components by improving the ability to predict solar spectral shift effects using SF.",Bioinformatics
"The application of spectral-shifting films in greenhouses to shift green light to red light has shown variable growth responses across crop species. However, the yield enhancement of crops under altered light quality is related to the collective effects of the specific biophysical characteristics of each species. Considering only one attribute of a crop has limitations in understanding the relationship between sunlight quality adjustments and crop growth performance. Therefore, this study aims to comprehensively link multiple plant phenotypic traits and daily light integral considering the physiological responses of crops to their growth outcomes under SF using artificial intelligence. Between 2021 and 2024, various leafy, fruiting, and root crops were grown in greenhouses covered with either PEF or SF, and leaf reflectance, leaf mass per area, chlorophyll content, daily light integral, and light saturation point were measured from the plants cultivated in each condition. 210 data points were collected, but there was insufficient data to train deep learning models, so a variational autoencoder was used for data augmentation. Most crop yields showed an average increase of 22.5% under SF. These data were used to train several models, including logistic regression, decision tree, random forest, XGBoost, and feedforward neural network (FFNN), aiming to binary classify whether there was a significant effect on yield with SF application. The FFNN achieved a high classification accuracy of 91.4% on a test dataset that was not used for training. This study provide insight into the complex interactions between leaf phenotypic and photosynthetic traits, environmental conditions, and solar spectral components by improving the ability to predict solar spectral shift effects using SF. [SEP] [HINT] used -> Bioinformatics (Syns: utilize, ill-used, apply) | understanding -> Neuroscience (Syns: savvy, intellect, sympathy) | learning -> Bioinformatics (Syns: take, teach, acquire)",Bioinformatics
"We present an approach for first principles investigations on the spin driven electric polarization in type II multiferroics. We propose a   parametrization of the polarization with the parameters calculated   using the Korringa-Kohn-Rostoker Green function (KKR-GF) formalism. Within this approach the induced electric polarization of a unit cell is represented in terms of three-site parameters. Those antisymmetric with respect to spin permutation are seen as an ab-initio based counter-part to the phenomenological parameters used within the inverse-Dzyaloshinskii-Moriya-interaction (DMI) model. Due to their relativistic origin, these parameters are responsible for the electric polarization induced in the presence of a non-collinear spin alignment in materials with a centrosymmetric crystal structure. Beyond to this, our approach gives direct access to the element- or site-resolved electric polarization. To demonstrate the capability of the approach, we consider several examples of the so-called type II multiferroics, for which the magneto-electric effect is observed either as a consequence of an applied magnetic field (we use Cr$_2$O$_3$ as a prototype), or as a result of a phase transition to a spin-spiral magnetic state, as for instance in MnI$_2$, CuCrO$_2$ and AgCrO$_2$.",Materials Science
"We present an approach for first principles investigations on the spin driven electric polarization in type II multiferroics. We propose a   parametrization of the polarization with the parameters calculated   using the Korringa-Kohn-Rostoker Green function (KKR-GF) formalism. Within this approach the induced electric polarization of a unit cell is represented in terms of three-site parameters. Those antisymmetric with respect to spin permutation are seen as an ab-initio based counter-part to the phenomenological parameters used within the inverse-Dzyaloshinskii-Moriya-interaction (DMI) model. Due to their relativistic origin, these parameters are responsible for the electric polarization induced in the presence of a non-collinear spin alignment in materials with a centrosymmetric crystal structure. Beyond to this, our approach gives direct access to the element- or site-resolved electric polarization. To demonstrate the capability of the approach, we consider several examples of the so-called type II multiferroics, for which the magneto-electric effect is observed either as a consequence of an applied magnetic field (we use Cr$_2$O$_3$ as a prototype), or as a result of a phase transition to a spin-spiral magnetic state, as for instance in MnI$_2$, CuCrO$_2$ and AgCrO$_2$. [SEP] [HINT] used -> Bioinformatics (Syns: utilize, ill-used, apply) | field -> Materials Science (Syns: field of honor, line of business, orbit) | transition -> Materials Science (Syns: passage, modulation, changeover)",Materials Science
"Animals use past experiences to adapt future behavior. To enable this rapid learning, vertebrates and invertebrates have evolved analogous neural structures like the vertebrate cerebellum or insect mushroom body. A defining feature of these circuits is a large expansion layer, which re-codes sensory inputs to improve pattern separation, a prerequisite to learn non-overlapping associations between relevant sensorimotor inputs and adaptive changes in behavior. However, classical models of associative learning treat expansion layers as static, assuming that associations are learned through plasticity at the output synapses. Here, we review emerging evidence that also highlights the importance of plasticity within the expansion layer for associative learning. Because the underlying plasticity mechanisms and principles of this representation learning are only emerging, we systematically compare experimental data from two well-studied circuits for expansion coding -- the cerebellum granule layer and the mushroom body calyx. The data indicate remarkably similar interneuron circuits, dendritic morphology and plasticity mechanisms between both systems that hint at more general principles for representation learning. Moreover, the data show strong overlap with recent theoretical advances that consider interneuron circuits and dendritic computations for representation learning. However, they also hint at an interesting interaction of stimulus-induced, non-associative and reinforced, associative mechanisms of plasticity that is not well understood in current theories of representation learning. Therefore, studying expansion layer plasticity will be important to elucidate the mechanisms and full potential of representation learning for behavioral adaptation.",Neuroscience
"Animals use past experiences to adapt future behavior. To enable this rapid learning, vertebrates and invertebrates have evolved analogous neural structures like the vertebrate cerebellum or insect mushroom body. A defining feature of these circuits is a large expansion layer, which re-codes sensory inputs to improve pattern separation, a prerequisite to learn non-overlapping associations between relevant sensorimotor inputs and adaptive changes in behavior. However, classical models of associative learning treat expansion layers as static, assuming that associations are learned through plasticity at the output synapses. Here, we review emerging evidence that also highlights the importance of plasticity within the expansion layer for associative learning. Because the underlying plasticity mechanisms and principles of this representation learning are only emerging, we systematically compare experimental data from two well-studied circuits for expansion coding -- the cerebellum granule layer and the mushroom body calyx. The data indicate remarkably similar interneuron circuits, dendritic morphology and plasticity mechanisms between both systems that hint at more general principles for representation learning. Moreover, the data show strong overlap with recent theoretical advances that consider interneuron circuits and dendritic computations for representation learning. However, they also hint at an interesting interaction of stimulus-induced, non-associative and reinforced, associative mechanisms of plasticity that is not well understood in current theories of representation learning. Therefore, studying expansion layer plasticity will be important to elucidate the mechanisms and full potential of representation learning for behavioral adaptation. [SEP] [HINT] learning -> Bioinformatics (Syns: take, teach, acquire) | systems -> Bioinformatics (Syns: organization, organisation, system) | potential -> Bioinformatics (Syns: voltage, potential difference, electric potential)",Neuroscience
"First-principles DFT calculations on the hydrides Ca2NiH6, Sr2NiH6, and Ba2NiH6 reveal key thermodynamic properties. These compounds exhibit increasing entropy and heat capacity with temperature, and are thermodynamically stable at elevated temperatures due to negative free energies. The kinetics of hydrogen storage is influenced by entropy changes during hydrogen adsorption and desorption. Optically, Ba2NiH6 shows a high refractive index at low energies. Mechanical assessments indicate Sr2NiH6 is incompressible with moderate malleability, Ca2NiH6 has the highest resistance to deformation, while Ba2NiH6 is most compressible. Formation energies and hydrogen storage capacities (4.005 wt% for Ca2NiH6, 2.548 wt% for Sr2NiH6, and 1.750 wt% for Ba2NiH6) highlight Ca2NiH6 as the most promising candidate for hydrogen storage technology.",Materials Science
"First-principles DFT calculations on the hydrides Ca2NiH6, Sr2NiH6, and Ba2NiH6 reveal key thermodynamic properties. These compounds exhibit increasing entropy and heat capacity with temperature, and are thermodynamically stable at elevated temperatures due to negative free energies. The kinetics of hydrogen storage is influenced by entropy changes during hydrogen adsorption and desorption. Optically, Ba2NiH6 shows a high refractive index at low energies. Mechanical assessments indicate Sr2NiH6 is incompressible with moderate malleability, Ca2NiH6 has the highest resistance to deformation, while Ba2NiH6 is most compressible. Formation energies and hydrogen storage capacities (4.005 wt% for Ca2NiH6, 2.548 wt% for Sr2NiH6, and 1.750 wt% for Ba2NiH6) highlight Ca2NiH6 as the most promising candidate for hydrogen storage technology. [SEP] [HINT] dft -> Materials Science (Syns: ) | low -> Materials Science (Syns: low-spirited, scurvy, depressed) | calculations -> Materials Science (Syns: computation, deliberation, reckoning)",Materials Science
"Selecting an effective docking algorithm is highly context-dependent, and no single method performs reliably across structural, chemical, or protocol regimes. We introduce MolAS, a lightweight algorithm selection system that predicts per-algorithm performance from pretrained protein-ligand embeddings using attentional pooling and a shallow residual decoder. With only hundreds to a few thousand labelled complexes, MolAS achieves up to 15% absolute improvement over the single-best solver (SBS) and closes 17-66% of the Virtual Best Solver (VBS)-SBS gap across five diverse docking benchmarks. Analyses of reliability, embedding geometry, and solver-selection patterns show that MolAS succeeds when the oracle landscape exhibits low entropy and separable solver behaviour, but collapses under protocol-induced hierarchy shifts. These findings indicate that the main barrier to robust docking AS is not representational capacity but instability in solver rankings across pose-generation regimes, positioning MolAS as both a practical in-domain selector and a diagnostic tool for assessing when AS is feasible.",Bioinformatics
"Selecting an effective docking algorithm is highly context-dependent, and no single method performs reliably across structural, chemical, or protocol regimes. We introduce MolAS, a lightweight algorithm selection system that predicts per-algorithm performance from pretrained protein-ligand embeddings using attentional pooling and a shallow residual decoder. With only hundreds to a few thousand labelled complexes, MolAS achieves up to 15% absolute improvement over the single-best solver (SBS) and closes 17-66% of the Virtual Best Solver (VBS)-SBS gap across five diverse docking benchmarks. Analyses of reliability, embedding geometry, and solver-selection patterns show that MolAS succeeds when the oracle landscape exhibits low entropy and separable solver behaviour, but collapses under protocol-induced hierarchy shifts. These findings indicate that the main barrier to robust docking AS is not representational capacity but instability in solver rankings across pose-generation regimes, positioning MolAS as both a practical in-domain selector and a diagnostic tool for assessing when AS is feasible. [SEP] [HINT] low -> Materials Science (Syns: low-spirited, scurvy, depressed) | performance -> Bioinformatics (Syns: functioning, operation, carrying out) | using -> Bioinformatics (Syns: utilize, exploitation, apply)",Bioinformatics
"Background: Metabolic Dysfunction-Associated Steatotic Liver Disease (MASLD) affects ~33% of U.S. adults and is the most common chronic liver disease. Although often asymptomatic, progression can lead to cirrhosis. Early detection is important, as lifestyle interventions can prevent disease progression. We developed a fair, rigorous, and reproducible MASLD prediction model and compared it to prior methods using a large electronic health record database.   Methods: We evaluated LASSO logistic regression, random forest, XGBoost, and a neural network for MASLD prediction using clinical feature subsets, including the top 10 SHAP-ranked features. To reduce disparities in true positive rates across racial and ethnic subgroups, we applied an equal opportunity postprocessing method.   Results: This study included 59,492 patients in the training data, 24,198 in the validating data, and 25,188 in the testing data. The LASSO logistic regression model with the top 10 features was selected for its interpretability and comparable performance. Before fairness adjustment, the model achieved AUROC of 0.84, accuracy of 78%, sensitivity of 72%, specificity of 79%, and F1-score of 0.617. After equal opportunity postprocessing, accuracy modestly increased to 81% and specificity to 94%, while sensitivity decreased to 41% and F1-score to 0.515, reflecting the fairness trade-off.   Conclusions: We developed the MASER prediction model (MASLD Static EHR Risk Prediction), a LASSO logistic regression model which achieved competitive performance for MASLD prediction (AUROC 0.836, accuracy 77.6%), comparable to previously reported ensemble and tree-based models. Overall, this approach demonstrates that interpretable models can achieve a balance of predictive performance and fairness in diverse patient populations.",Bioinformatics
"Background: Metabolic Dysfunction-Associated Steatotic Liver Disease (MASLD) affects ~33% of U.S. adults and is the most common chronic liver disease. Although often asymptomatic, progression can lead to cirrhosis. Early detection is important, as lifestyle interventions can prevent disease progression. We developed a fair, rigorous, and reproducible MASLD prediction model and compared it to prior methods using a large electronic health record database.   Methods: We evaluated LASSO logistic regression, random forest, XGBoost, and a neural network for MASLD prediction using clinical feature subsets, including the top 10 SHAP-ranked features. To reduce disparities in true positive rates across racial and ethnic subgroups, we applied an equal opportunity postprocessing method.   Results: This study included 59,492 patients in the training data, 24,198 in the validating data, and 25,188 in the testing data. The LASSO logistic regression model with the top 10 features was selected for its interpretability and comparable performance. Before fairness adjustment, the model achieved AUROC of 0.84, accuracy of 78%, sensitivity of 72%, specificity of 79%, and F1-score of 0.617. After equal opportunity postprocessing, accuracy modestly increased to 81% and specificity to 94%, while sensitivity decreased to 41% and F1-score to 0.515, reflecting the fairness trade-off.   Conclusions: We developed the MASER prediction model (MASLD Static EHR Risk Prediction), a LASSO logistic regression model which achieved competitive performance for MASLD prediction (AUROC 0.836, accuracy 77.6%), comparable to previously reported ensemble and tree-based models. Overall, this approach demonstrates that interpretable models can achieve a balance of predictive performance and fairness in diverse patient populations. [SEP] [HINT] clinical -> Bioinformatics (Syns: ) | features -> Bioinformatics (Syns: characteristic, lineament, feature of speech) | electronic -> Materials Science (Syns: )",Bioinformatics
"Multimodal Large Language Models (MLLMs) have demonstrated extraordinary progress in bridging textual and visual inputs. However, MLLMs still face challenges in situated physical and social interactions in sensorally rich, multimodal and real-world settings where the embodied experience of the living organism is essential. We posit that next frontiers for MLLM development require incorporating both internal and external embodiment -- modeling not only external interactions with the world, but also internal states and drives. Here, we describe mechanisms of internal and external embodiment in humans and relate these to current advances in MLLMs in early stages of aligning to human representations. Our dual-embodied framework proposes to model interactions between these forms of embodiment in MLLMs to bridge the gap between multimodal data and world experience.",Neuroscience
"Multimodal Large Language Models (MLLMs) have demonstrated extraordinary progress in bridging textual and visual inputs. However, MLLMs still face challenges in situated physical and social interactions in sensorally rich, multimodal and real-world settings where the embodied experience of the living organism is essential. We posit that next frontiers for MLLM development require incorporating both internal and external embodiment -- modeling not only external interactions with the world, but also internal states and drives. Here, we describe mechanisms of internal and external embodiment in humans and relate these to current advances in MLLMs in early stages of aligning to human representations. Our dual-embodied framework proposes to model interactions between these forms of embodiment in MLLMs to bridge the gap between multimodal data and world experience. [SEP] [HINT] language -> Neuroscience (Syns: linguistic process, linguistic communication, spoken communication) | human -> Neuroscience (Syns: human being, man, homo) | visual -> Neuroscience (Syns: optical, ocular, optic)",Neuroscience
"Adaptive material systems that autonomously respond to external stimuli are crucial for advancing next-generation smart devices. Biological systems achieve autonomous behavior by utilizing chemical energy from out-of-equilibrium reactions to power life-like functions without requiring external energy inputs. Although responsive hydrogels with embedded enzymatic reactions offer a promising platform for implementing adaptive behavior in synthetic systems, previous studies have focused on controlling the supramolecular self-assembly of responsive building blocks rather than modulating network crosslinking. Here, we demonstrate direct enzymatic modulation of crosslinking density in a double-network hydrogel to achieve autonomous self-stiffening in response to a chemical stimulus. Our adaptive system embeds glucose oxidase within a polyacrylamide-alginate double-network hydrogel containing Ca(EDTA)2- complexes that render the crosslinked alginate network pH-responsive through a competitive calcium binding mechanism. Chemical waves emerging from enzymatic reaction activation propagate at speeds ranging from 15 to 44 um/min, driving spatiotemporal mechanical transitions that increase material stiffness by up to 2.1-fold. By integrating signal sensing and chemomechanical transduction within this responsive hydrogel, we realized adaptive behavior that autonomously converts localized chemical inputs into system-wide mechanical outputs. This positions our adaptive hydrogels as promising model systems to guide the design of intelligent materials for soft robotics and biomedical devices.",Materials Science
"Adaptive material systems that autonomously respond to external stimuli are crucial for advancing next-generation smart devices. Biological systems achieve autonomous behavior by utilizing chemical energy from out-of-equilibrium reactions to power life-like functions without requiring external energy inputs. Although responsive hydrogels with embedded enzymatic reactions offer a promising platform for implementing adaptive behavior in synthetic systems, previous studies have focused on controlling the supramolecular self-assembly of responsive building blocks rather than modulating network crosslinking. Here, we demonstrate direct enzymatic modulation of crosslinking density in a double-network hydrogel to achieve autonomous self-stiffening in response to a chemical stimulus. Our adaptive system embeds glucose oxidase within a polyacrylamide-alginate double-network hydrogel containing Ca(EDTA)2- complexes that render the crosslinked alginate network pH-responsive through a competitive calcium binding mechanism. Chemical waves emerging from enzymatic reaction activation propagate at speeds ranging from 15 to 44 um/min, driving spatiotemporal mechanical transitions that increase material stiffness by up to 2.1-fold. By integrating signal sensing and chemomechanical transduction within this responsive hydrogel, we realized adaptive behavior that autonomously converts localized chemical inputs into system-wide mechanical outputs. This positions our adaptive hydrogels as promising model systems to guide the design of intelligent materials for soft robotics and biomedical devices. [SEP] [HINT] systems -> Bioinformatics (Syns: organization, organisation, system) | materials -> Materials Science (Syns: stuff, cloth, material) | material -> Materials Science (Syns: stuff, cloth, real)",Materials Science
"Human Immunodeficiency Virus (HIV) has posed a major global health challenge for decades, and forecasting HIV diagnoses continues to be a critical area of research. However, capturing the complex spatial and temporal dependencies of HIV transmission remains challenging. Conventional Message Passing Neural Network (MPNN) models rely on a fixed binary adjacency matrix that only encodes geographic adjacency, which is unable to represent interactions between non-contiguous counties. Our study proposes a deep learning architecture Mobility-Aware Transformer-Message Passing Neural Network (MAT-MPNN) framework to predict county-level HIV diagnosis rates across California, Florida, and the New England region. The model combines temporal features extracted by a Transformer encoder with spatial relationships captured through a Mobility Graph Generator (MGG). The MGG improves conventional adjacency matrices by combining geographic and demographic information. Compared with the best-performing hybrid baseline, the Transformer MPNN model, MAT-MPNN reduced the Mean Squared Prediction Error (MSPE) by 27.9% in Florida, 39.1% in California, and 12.5% in New England, and improved the Predictive Model Choice Criterion (PMCC) by 7.7%, 3.5%, and 3.9%, respectively. MAT-MPNN also achieved better results than the Spatially Varying Auto-Regressive (SVAR) model in Florida and New England, with comparable performance in California. These results demonstrate that applying mobility-aware dynamic spatial structures substantially enhances predictive accuracy and calibration in spatiotemporal epidemiological prediction.",Bioinformatics
"Human Immunodeficiency Virus (HIV) has posed a major global health challenge for decades, and forecasting HIV diagnoses continues to be a critical area of research. However, capturing the complex spatial and temporal dependencies of HIV transmission remains challenging. Conventional Message Passing Neural Network (MPNN) models rely on a fixed binary adjacency matrix that only encodes geographic adjacency, which is unable to represent interactions between non-contiguous counties. Our study proposes a deep learning architecture Mobility-Aware Transformer-Message Passing Neural Network (MAT-MPNN) framework to predict county-level HIV diagnosis rates across California, Florida, and the New England region. The model combines temporal features extracted by a Transformer encoder with spatial relationships captured through a Mobility Graph Generator (MGG). The MGG improves conventional adjacency matrices by combining geographic and demographic information. Compared with the best-performing hybrid baseline, the Transformer MPNN model, MAT-MPNN reduced the Mean Squared Prediction Error (MSPE) by 27.9% in Florida, 39.1% in California, and 12.5% in New England, and improved the Predictive Model Choice Criterion (PMCC) by 7.7%, 3.5%, and 3.9%, respectively. MAT-MPNN also achieved better results than the Spatially Varying Auto-Regressive (SVAR) model in Florida and New England, with comparable performance in California. These results demonstrate that applying mobility-aware dynamic spatial structures substantially enhances predictive accuracy and calibration in spatiotemporal epidemiological prediction. [SEP] [HINT] features -> Bioinformatics (Syns: characteristic, lineament, feature of speech) | learning -> Bioinformatics (Syns: take, teach, acquire) | complex -> Bioinformatics (Syns: building complex, coordination compound, composite)",Bioinformatics
"The realization of extreme optical anisotropy is foundational to nanoscale light manipulation. Van der Waals (vdW) crystal MoOCl2 has emerged as a promising candidate for this quest, hosting hyperbolic plasmon polaritons in the visible and near-infrared wavelengths. However, the fundamental anisotropic dielectric tensor governing this behavior has remained elusive. Here, we resolve this problem by providing the first experimental determination of the full dielectric tensor of hyperbolic vdW MoOCl2. Via spectroscopic ellipsometry, Mueller matrix, and reflectance measurements, we quantify the material's optical duality: a metallic optical response (ε_1 < 0) along the crystallographic a-axis and a dielectric response (ε_1 > 0) along the orthogonal directions. This dichotomy drives an epsilon-near-zero (ENZ) condition at \approx 512 nm and results in giant in-plane birefringence of δn \approx 2.2 for MoOCl2. As a result, our work provides the critical missing experimental parameters for MoOCl2, establishing it as a benchmark hyperbolic and ENZ material.",Materials Science
"The realization of extreme optical anisotropy is foundational to nanoscale light manipulation. Van der Waals (vdW) crystal MoOCl2 has emerged as a promising candidate for this quest, hosting hyperbolic plasmon polaritons in the visible and near-infrared wavelengths. However, the fundamental anisotropic dielectric tensor governing this behavior has remained elusive. Here, we resolve this problem by providing the first experimental determination of the full dielectric tensor of hyperbolic vdW MoOCl2. Via spectroscopic ellipsometry, Mueller matrix, and reflectance measurements, we quantify the material's optical duality: a metallic optical response (ε_1 < 0) along the crystallographic a-axis and a dielectric response (ε_1 > 0) along the orthogonal directions. This dichotomy drives an epsilon-near-zero (ENZ) condition at \approx 512 nm and results in giant in-plane birefringence of δn \approx 2.2 for MoOCl2. As a result, our work provides the critical missing experimental parameters for MoOCl2, establishing it as a benchmark hyperbolic and ENZ material. [SEP] [HINT] work -> Bioinformatics (Syns: work out, process, bring) | results -> Bioinformatics (Syns: final result, consequence, resultant role) | crystal -> Materials Science (Syns: crystallization, quartz, lechatelierite)",Materials Science
"Transition metal dichalcogenides (TMDs) host multiple competing structural and electronic phases, making them an ideal platform for constructing polytype heterostructures with emergent quantum properties. However, controlling phase transitions to form diverse heterostructures inside a single crystal remains challenging. Here, we realize vertical/lateral polytype heterostructures in a hole-doped Mott insulator via thermal-annealing-induced structural transitions. Raman spectroscopy, atomic force microscopy (AFM) and scanning Kelvin probe force microscopy (SKPM) confirm the coexistence of T-H polytype heterostructures. Atomic-scale scanning tunneling microscopy/spectroscopy (STM/STS) measurements reveal the transparent effect in 1H/1T vertical heterostructures, where the charge density wave (CDW) of the underlying 1T-layer superposes on the top 1H-layer under positive bias. By systematically comparing 1T/1H and 1T/1T interfaces, we demonstrate that the metallic 1H-layer imposes a Coulomb screening effect on the 1T-layer, suppressing the formation of CDW domain walls and forming more ordered electronic states. These results clarify the interfacial coupling between distinct quantum many-body phases and establish a controllable pathway for constructing two-dimensional polytype heterostructures with tunable electronic properties.",Materials Science
"Transition metal dichalcogenides (TMDs) host multiple competing structural and electronic phases, making them an ideal platform for constructing polytype heterostructures with emergent quantum properties. However, controlling phase transitions to form diverse heterostructures inside a single crystal remains challenging. Here, we realize vertical/lateral polytype heterostructures in a hole-doped Mott insulator via thermal-annealing-induced structural transitions. Raman spectroscopy, atomic force microscopy (AFM) and scanning Kelvin probe force microscopy (SKPM) confirm the coexistence of T-H polytype heterostructures. Atomic-scale scanning tunneling microscopy/spectroscopy (STM/STS) measurements reveal the transparent effect in 1H/1T vertical heterostructures, where the charge density wave (CDW) of the underlying 1T-layer superposes on the top 1H-layer under positive bias. By systematically comparing 1T/1H and 1T/1T interfaces, we demonstrate that the metallic 1H-layer imposes a Coulomb screening effect on the 1T-layer, suppressing the formation of CDW domain walls and forming more ordered electronic states. These results clarify the interfacial coupling between distinct quantum many-body phases and establish a controllable pathway for constructing two-dimensional polytype heterostructures with tunable electronic properties. [SEP] [HINT] transition -> Materials Science (Syns: passage, modulation, changeover) | charge -> Materials Science (Syns: tear, bearing, burster) | electronic -> Materials Science (Syns: )",Materials Science
"Quantifying the irreversibility and dissipation of non-equilibrium processes is crucial to understanding their behavior, assessing their possible capabilities, and characterizing their efficiency. We introduce a physical quantity that quantifies the irreversibility of stochastic Langevin systems from the observation of individual molecules' displacements. Categorizing these displacements into a few groups based on their initial and final position allows us to measure irreversibility precisely without the need to know the forces and magnitude of the fluctuations acting on the system. Our model-free estimate of irreversibility is related to entropy production by a conditional fluctuation theorem and provides a lower bound to the average entropy production. We validate the method on single-molecule force spectroscopy experiments of proteins subject to force ramps. We show that irreversibility is sensitive to detailed features of the energy landscape underlying the protein folding dynamics and suggest how our methods can be employed to unveil key properties of protein folding processes.",Bioinformatics
"Quantifying the irreversibility and dissipation of non-equilibrium processes is crucial to understanding their behavior, assessing their possible capabilities, and characterizing their efficiency. We introduce a physical quantity that quantifies the irreversibility of stochastic Langevin systems from the observation of individual molecules' displacements. Categorizing these displacements into a few groups based on their initial and final position allows us to measure irreversibility precisely without the need to know the forces and magnitude of the fluctuations acting on the system. Our model-free estimate of irreversibility is related to entropy production by a conditional fluctuation theorem and provides a lower bound to the average entropy production. We validate the method on single-molecule force spectroscopy experiments of proteins subject to force ramps. We show that irreversibility is sensitive to detailed features of the energy landscape underlying the protein folding dynamics and suggest how our methods can be employed to unveil key properties of protein folding processes. [SEP] [HINT] based -> Bioinformatics (Syns: ground, free-base, base) | features -> Bioinformatics (Syns: characteristic, lineament, feature of speech) | understanding -> Neuroscience (Syns: savvy, intellect, sympathy)",Bioinformatics
"This study explores the impact of an optimized amorphous silicon (a-Si) buffer layer on AlxIn1-xN-on-Si(100) heterojunction solar cells, with Al content varying from 0% (InN) to 55%. The buffer layer improves the structural quality of the AlInN layer, as evidenced by reduced full width at half maximum values in X-ray diffraction rocking curves around the AlInN (0002) peak. Atomic force microscopy reveals that the buffer layer does not alter surface roughness. The effectiveness of the a-Si buffer is demonstrated by an enhancement of the conversion efficiency under AM1.5G illumination from 3.3 % to 3.9 % for devices with 35 % Al. Looking at the effect of the Al content in devices with the a-Si buffer, the device with 22% Al shows the best photovoltaic performance, with a conversion efficiency of 4.1 % and a VOC of 0.42 V, JSC of 15.4 mA/cm2, and FF of 63.3%. However, performance declines for Al contents above 36% due to increased resistivity and reduced carrier concentration. These findings highlight the critical role of the novel a-Si buffer layer developed by RF-sputtering and the Al content in optimizing AlInN/Si heterojunction solar cell performance.",Materials Science
"This study explores the impact of an optimized amorphous silicon (a-Si) buffer layer on AlxIn1-xN-on-Si(100) heterojunction solar cells, with Al content varying from 0% (InN) to 55%. The buffer layer improves the structural quality of the AlInN layer, as evidenced by reduced full width at half maximum values in X-ray diffraction rocking curves around the AlInN (0002) peak. Atomic force microscopy reveals that the buffer layer does not alter surface roughness. The effectiveness of the a-Si buffer is demonstrated by an enhancement of the conversion efficiency under AM1.5G illumination from 3.3 % to 3.9 % for devices with 35 % Al. Looking at the effect of the Al content in devices with the a-Si buffer, the device with 22% Al shows the best photovoltaic performance, with a conversion efficiency of 4.1 % and a VOC of 0.42 V, JSC of 15.4 mA/cm2, and FF of 63.3%. However, performance declines for Al contents above 36% due to increased resistivity and reduced carrier concentration. These findings highlight the critical role of the novel a-Si buffer layer developed by RF-sputtering and the Al content in optimizing AlInN/Si heterojunction solar cell performance. [SEP] [HINT] quality -> Bioinformatics (Syns: lineament, tone, calibre) | performance -> Bioinformatics (Syns: functioning, operation, carrying out) | structural -> Materials Science (Syns: geomorphologic, morphologic, morphological)",Materials Science
"In single-cell perturbation prediction, a central task is to forecast the effects of perturbing a gene unseen in the training data. The efficacy of such predictions depends on two factors: (1) the similarity of the target gene to those covered in the training data, which informs model (epistemic) uncertainty, and (2) the quality of the corresponding training data, which reflects data (aleatoric) uncertainty. Both factors are critical for determining the reliability of a prediction, particularly as gene perturbation is an inherently stochastic biochemical process. In this paper, we propose PRESCRIBE (PREdicting Single-Cell Response wIth Bayesian Estimation), a multivariate deep evidential regression framework designed to measure both sources of uncertainty jointly. Our analysis demonstrates that PRESCRIBE effectively estimates a confidence score for each prediction, which strongly correlates with its empirical accuracy. This capability enables the filtering of untrustworthy results, and in our experiments, it achieves steady accuracy improvements of over 3% compared to comparable baselines.",Bioinformatics
"In single-cell perturbation prediction, a central task is to forecast the effects of perturbing a gene unseen in the training data. The efficacy of such predictions depends on two factors: (1) the similarity of the target gene to those covered in the training data, which informs model (epistemic) uncertainty, and (2) the quality of the corresponding training data, which reflects data (aleatoric) uncertainty. Both factors are critical for determining the reliability of a prediction, particularly as gene perturbation is an inherently stochastic biochemical process. In this paper, we propose PRESCRIBE (PREdicting Single-Cell Response wIth Bayesian Estimation), a multivariate deep evidential regression framework designed to measure both sources of uncertainty jointly. Our analysis demonstrates that PRESCRIBE effectively estimates a confidence score for each prediction, which strongly correlates with its empirical accuracy. This capability enables the filtering of untrustworthy results, and in our experiments, it achieves steady accuracy improvements of over 3% compared to comparable baselines. [SEP] [HINT] task -> Neuroscience (Syns: tax, project, chore) | quality -> Bioinformatics (Syns: lineament, tone, calibre) | framework -> Bioinformatics (Syns: theoretical account, model, fabric)",Bioinformatics
"As COVID-19 transitions into an endemic disease that remains constantly present in the population at a stable level, monitoring its prevalence without invasive measures becomes increasingly important. In this paper, we present a deep neural network estimator for the COVID-19 daily case count based on wastewater surveillance data and other confounding factors. This work builds upon the study by Jiang, Kolozsvary, and Li (2024), which connects the COVID-19 case counts with testing data collected early in the pandemic. Using the COVID-19 testing data and the wastewater surveillance data during the period when both data were highly reliable, one can train an artificial neural network that learns the nonlinear relation between the COVID-19 daily case count and the wastewater viral RNA concentration. From a machine learning perspective, the main challenge lies in addressing temporal feature reliability, as the training data has different reliability over different time periods.",Bioinformatics
"As COVID-19 transitions into an endemic disease that remains constantly present in the population at a stable level, monitoring its prevalence without invasive measures becomes increasingly important. In this paper, we present a deep neural network estimator for the COVID-19 daily case count based on wastewater surveillance data and other confounding factors. This work builds upon the study by Jiang, Kolozsvary, and Li (2024), which connects the COVID-19 case counts with testing data collected early in the pandemic. Using the COVID-19 testing data and the wastewater surveillance data during the period when both data were highly reliable, one can train an artificial neural network that learns the nonlinear relation between the COVID-19 daily case count and the wastewater viral RNA concentration. From a machine learning perspective, the main challenge lies in addressing temporal feature reliability, as the training data has different reliability over different time periods. [SEP] [HINT] based -> Bioinformatics (Syns: ground, free-base, base) | learning -> Bioinformatics (Syns: take, teach, acquire) | work -> Bioinformatics (Syns: work out, process, bring)",Bioinformatics
"Higher-order information theory has become a rapidly growing toolkit in computational neuroscience, motivated by the idea that multivariate dependencies can reveal aspects of neural computation and communication that are invisible to pairwise analyses. Yet functional interpretations of synergy and redundancy often outpace principled arguments for how statistical quantities map onto mechanistic cognitive processes. Here we review the main families of higher-order measures with the explicit goal of translating mathematical properties into defensible mechanistic inferences. First, we systematize Shannon-based multivariate metrics and demonstrate that higher-order dependence is parsimoniously characterized by two largely independent axes: interaction strength and redundancy-synergy balance. We argue that balanced layering of synergistic integration and redundant broadcasting optimizes multiscale complexity, formalizing a computation-communication tradeoff. We then examine the partial information decomposition and outline pragmatic considerations for its deployment in neural data. Equipped with the relevant mathematical essentials, we connect redundancy-synergy balance to cognitive function by progressively embedding their mathematical properties in real-world constraints, starting with small synthetic systems before gradually building up to neuroimaging. We close by identifying key future directions for mechanistic insight: cross-scale bridging, intervention-based validation, and thermodynamically grounded unification of information dynamics.",Neuroscience
"Higher-order information theory has become a rapidly growing toolkit in computational neuroscience, motivated by the idea that multivariate dependencies can reveal aspects of neural computation and communication that are invisible to pairwise analyses. Yet functional interpretations of synergy and redundancy often outpace principled arguments for how statistical quantities map onto mechanistic cognitive processes. Here we review the main families of higher-order measures with the explicit goal of translating mathematical properties into defensible mechanistic inferences. First, we systematize Shannon-based multivariate metrics and demonstrate that higher-order dependence is parsimoniously characterized by two largely independent axes: interaction strength and redundancy-synergy balance. We argue that balanced layering of synergistic integration and redundant broadcasting optimizes multiscale complexity, formalizing a computation-communication tradeoff. We then examine the partial information decomposition and outline pragmatic considerations for its deployment in neural data. Equipped with the relevant mathematical essentials, we connect redundancy-synergy balance to cognitive function by progressively embedding their mathematical properties in real-world constraints, starting with small synthetic systems before gradually building up to neuroimaging. We close by identifying key future directions for mechanistic insight: cross-scale bridging, intervention-based validation, and thermodynamically grounded unification of information dynamics. [SEP] [HINT] computational -> Neuroscience (Syns: ) | functional -> Neuroscience (Syns: working, usable, running) | information -> Bioinformatics (Syns: entropy, data, info)",Neuroscience
"Cells achieve size homeostasis by regulating their division timing based on their size, added size, and cell cycle time. Previous research under steady-state conditions demonstrated the robustness of these mechanisms. However, their dynamic responses in fluctuating environments, such as nutrient depletion due to population growth, remain challenging to fully characterize. Currently, advances in single-cell microscopy have revealed various cellular division strategies whose underlying molecular mechanisms are complex and not always available. This study introduces a novel approach to model cell size dynamics using a piecewise deterministic Markov chain framework, where cell division events are modeled as stochastic jumps determined by a division propensity dependent on both current cell size and added size since birth. We propose a three-parameter characterization for the division process: scale (target added size at division), shape (division stochasticity), and division strategy (relevance of cell size, added size, or cell cycle duration). We derive analytical formulas for the probability of division, and with this probability, we develop a maximum likelihood estimation (MLE) framework. We implement a systematic investigation of the accuracy of inference as a function of sample size. The model's performance is studied across various scenarios, including those exhibiting dynamical changes in one or more parameters, suggesting its broad applicability for analyzing new experimental data on cell size regulation in dynamic environments.",Bioinformatics
"Cells achieve size homeostasis by regulating their division timing based on their size, added size, and cell cycle time. Previous research under steady-state conditions demonstrated the robustness of these mechanisms. However, their dynamic responses in fluctuating environments, such as nutrient depletion due to population growth, remain challenging to fully characterize. Currently, advances in single-cell microscopy have revealed various cellular division strategies whose underlying molecular mechanisms are complex and not always available. This study introduces a novel approach to model cell size dynamics using a piecewise deterministic Markov chain framework, where cell division events are modeled as stochastic jumps determined by a division propensity dependent on both current cell size and added size since birth. We propose a three-parameter characterization for the division process: scale (target added size at division), shape (division stochasticity), and division strategy (relevance of cell size, added size, or cell cycle duration). We derive analytical formulas for the probability of division, and with this probability, we develop a maximum likelihood estimation (MLE) framework. We implement a systematic investigation of the accuracy of inference as a function of sample size. The model's performance is studied across various scenarios, including those exhibiting dynamical changes in one or more parameters, suggesting its broad applicability for analyzing new experimental data on cell size regulation in dynamic environments. [SEP] [HINT] based -> Bioinformatics (Syns: ground, free-base, base) | complex -> Bioinformatics (Syns: building complex, coordination compound, composite) | molecular -> Bioinformatics (Syns: )",Bioinformatics
"Mixtures of linear dynamical systems (MoLDS) provide a path to model time-series data that exhibit diverse temporal dynamics across trajectories. However, its application remains challenging in complex and noisy settings, limiting its effectiveness for neural data analysis. Tensor-based moment methods can provide global identifiability guarantees for MoLDS, but their performance degrades under noise and complexity. Commonly used expectation-maximization (EM) methods offer flexibility in fitting latent models but are highly sensitive to initialization and prone to poor local minima. Here, we propose a tensor-based method that provides identifiability guarantees for learning MoLDS, which is followed by EM updates to combine the strengths of both approaches. The novelty in our approach lies in the construction of moment tensors using the input-output data to recover globally consistent estimates of mixture weights and system parameters. These estimates can then be refined through a Kalman EM algorithm, with closed-form updates for all LDS parameters. We validate our framework on synthetic benchmarks and real-world datasets. On synthetic data, the proposed Tensor-EM method achieves more reliable recovery and improved robustness compared to either pure tensor or randomly initialized EM methods. We then analyze neural recordings from the primate somatosensory cortex while a non-human primate performs reaches in different directions. Our method successfully models and clusters different conditions as separate subsystems, consistent with supervised single-LDS fits for each condition. Finally, we apply this approach to another neural dataset where monkeys perform a sequential reaching task. These results demonstrate that MoLDS provides an effective framework for modeling complex neural data, and that Tensor-EM is a reliable approach to MoLDS learning for these applications.",Neuroscience
"Mixtures of linear dynamical systems (MoLDS) provide a path to model time-series data that exhibit diverse temporal dynamics across trajectories. However, its application remains challenging in complex and noisy settings, limiting its effectiveness for neural data analysis. Tensor-based moment methods can provide global identifiability guarantees for MoLDS, but their performance degrades under noise and complexity. Commonly used expectation-maximization (EM) methods offer flexibility in fitting latent models but are highly sensitive to initialization and prone to poor local minima. Here, we propose a tensor-based method that provides identifiability guarantees for learning MoLDS, which is followed by EM updates to combine the strengths of both approaches. The novelty in our approach lies in the construction of moment tensors using the input-output data to recover globally consistent estimates of mixture weights and system parameters. These estimates can then be refined through a Kalman EM algorithm, with closed-form updates for all LDS parameters. We validate our framework on synthetic benchmarks and real-world datasets. On synthetic data, the proposed Tensor-EM method achieves more reliable recovery and improved robustness compared to either pure tensor or randomly initialized EM methods. We then analyze neural recordings from the primate somatosensory cortex while a non-human primate performs reaches in different directions. Our method successfully models and clusters different conditions as separate subsystems, consistent with supervised single-LDS fits for each condition. Finally, we apply this approach to another neural dataset where monkeys perform a sequential reaching task. These results demonstrate that MoLDS provides an effective framework for modeling complex neural data, and that Tensor-EM is a reliable approach to MoLDS learning for these applications. [SEP] [HINT] used -> Bioinformatics (Syns: utilize, ill-used, apply) | learning -> Bioinformatics (Syns: take, teach, acquire) | complex -> Bioinformatics (Syns: building complex, coordination compound, composite)",Neuroscience
"Weakly electric fish, like Gnathonemus petersii, use a remarkable electrical modality for active sensing and communication, but studying their rich electrosensing and electrocommunication behavior and associated neural activity in naturalistic settings remains experimentally challenging. Here, we present a novel biologically-inspired computational framework to study these behaviors, where recurrent neural network (RNN) based artificial agents trained via multi-agent reinforcement learning (MARL) learn to modulate their electric organ discharges (EODs) and movement patterns to collectively forage in virtual environments. Trained agents demonstrate several emergent features consistent with real fish collectives, including heavy tailed EOD interval distributions, environmental context dependent shifts in EOD interval distributions, and social interaction patterns like freeloading, where agents reduce their EOD rates while benefiting from neighboring agents' active sensing. A minimal two-fish assay further isolates the role of electro-communication, showing that access to conspecific EODs and relative dominance jointly shape foraging success. Notably, these behaviors emerge through evolution-inspired rewards for individual fitness and emergent inter-agent interactions, rather than through rewarding agents explicitly for social interactions. Our work has broad implications for the neuroethology of weakly electric fish, as well as other social, communicating animals in which extensive recordings from multiple individuals, and thus traditional data-driven modeling, are infeasible.",Neuroscience
"Weakly electric fish, like Gnathonemus petersii, use a remarkable electrical modality for active sensing and communication, but studying their rich electrosensing and electrocommunication behavior and associated neural activity in naturalistic settings remains experimentally challenging. Here, we present a novel biologically-inspired computational framework to study these behaviors, where recurrent neural network (RNN) based artificial agents trained via multi-agent reinforcement learning (MARL) learn to modulate their electric organ discharges (EODs) and movement patterns to collectively forage in virtual environments. Trained agents demonstrate several emergent features consistent with real fish collectives, including heavy tailed EOD interval distributions, environmental context dependent shifts in EOD interval distributions, and social interaction patterns like freeloading, where agents reduce their EOD rates while benefiting from neighboring agents' active sensing. A minimal two-fish assay further isolates the role of electro-communication, showing that access to conspecific EODs and relative dominance jointly shape foraging success. Notably, these behaviors emerge through evolution-inspired rewards for individual fitness and emergent inter-agent interactions, rather than through rewarding agents explicitly for social interactions. Our work has broad implications for the neuroethology of weakly electric fish, as well as other social, communicating animals in which extensive recordings from multiple individuals, and thus traditional data-driven modeling, are infeasible. [SEP] [HINT] based -> Bioinformatics (Syns: ground, free-base, base) | computational -> Neuroscience (Syns: ) | features -> Bioinformatics (Syns: characteristic, lineament, feature of speech)",Neuroscience
"It is known that listeners lose the ability to discriminate the direction of motion of a revolving sound (clockwise vs. counterclockwise) beyond a critical velocity (""the upper limit""), primarily due to degraded front-back discrimination. Little is known about how this ability is affected by simultaneously present distractor sounds, despite the real-life importance of tracking moving sounds in the presence of distractors. We hypothesized that the presence of a static distractor sound would impair the perception of moving target sounds and reduce the upper limit, and show that this is indeed the case. A distractor on the right was as effective as a distractor at the front in reducing the upper limit despite the importance of resolving front-back confusions. By manipulating the spectral content of both the target and distractor, we found that the upper limit was reduced if and only if the distractor spectrally overlaps with the target in the frequency range relevant for front/back discrimination; energetic masking thus explains the upper limit reduction by the distractor. We did not find any evidence for informational masking by the distractor. Our findings form the first steps towards a better understanding of the tracking of multiple sounds in the presence of distractors.",Neuroscience
"It is known that listeners lose the ability to discriminate the direction of motion of a revolving sound (clockwise vs. counterclockwise) beyond a critical velocity (""the upper limit""), primarily due to degraded front-back discrimination. Little is known about how this ability is affected by simultaneously present distractor sounds, despite the real-life importance of tracking moving sounds in the presence of distractors. We hypothesized that the presence of a static distractor sound would impair the perception of moving target sounds and reduce the upper limit, and show that this is indeed the case. A distractor on the right was as effective as a distractor at the front in reducing the upper limit despite the importance of resolving front-back confusions. By manipulating the spectral content of both the target and distractor, we found that the upper limit was reduced if and only if the distractor spectrally overlaps with the target in the frequency range relevant for front/back discrimination; energetic masking thus explains the upper limit reduction by the distractor. We did not find any evidence for informational masking by the distractor. Our findings form the first steps towards a better understanding of the tracking of multiple sounds in the presence of distractors. [SEP] [HINT] understanding -> Neuroscience (Syns: savvy, intellect, sympathy) | findings -> Neuroscience (Syns: determination, finding) | present -> Bioinformatics (Syns: deliver, exhibit, confront)",Neuroscience
"A computational framework is presented for the sampling of the energy surface of magnetic systems via the systematic identification of first-order saddle points that determine connectivity of metastable states and define the mechanisms of transitions between them. The framework combines four stages: first, the symmetry of a given minimum-energy configuration is identified and used to define subsystems whose eigenmodes provide relevant deformation directions; the subsystem eigenmodes are then used to guide the system toward the vicinity of different saddle points surrounding the energy minimum; next, the geodesic minimum mode following method is employed to efficiently converge onto the saddle points; and finally, the identified saddle points are embedded into the state network. Applied to metastable textures in two-dimensional chiral magnets described by a lattice Hamiltonian, the method reveals a hierarchy of transition mechanisms governing the nucleation, annihilation, and rearrangement of the fundamental components of localized magnetic textures. The identified saddle points enable the construction of the network of metastable states, where saddle points define the connectivity between them, providing a comprehensive map of accessible transitions and their associated energy barriers. Transitions corresponding to both homotopies that preserve the topological charge and transformations that change it are identified. By scaling the interaction parameters, the distinct behavior of these two classes is obtained as the continuum limit is approached. Finally, it is shown that textures with the same topological charge are not always connected by a homotopy corresponding to a minimum-energy path: in specific parameter regimes, the total topological charge necessarily increases and then decreases (or vice versa) during the transition, returning to its initial value at the final state.",Materials Science
"A computational framework is presented for the sampling of the energy surface of magnetic systems via the systematic identification of first-order saddle points that determine connectivity of metastable states and define the mechanisms of transitions between them. The framework combines four stages: first, the symmetry of a given minimum-energy configuration is identified and used to define subsystems whose eigenmodes provide relevant deformation directions; the subsystem eigenmodes are then used to guide the system toward the vicinity of different saddle points surrounding the energy minimum; next, the geodesic minimum mode following method is employed to efficiently converge onto the saddle points; and finally, the identified saddle points are embedded into the state network. Applied to metastable textures in two-dimensional chiral magnets described by a lattice Hamiltonian, the method reveals a hierarchy of transition mechanisms governing the nucleation, annihilation, and rearrangement of the fundamental components of localized magnetic textures. The identified saddle points enable the construction of the network of metastable states, where saddle points define the connectivity between them, providing a comprehensive map of accessible transitions and their associated energy barriers. Transitions corresponding to both homotopies that preserve the topological charge and transformations that change it are identified. By scaling the interaction parameters, the distinct behavior of these two classes is obtained as the continuum limit is approached. Finally, it is shown that textures with the same topological charge are not always connected by a homotopy corresponding to a minimum-energy path: in specific parameter regimes, the total topological charge necessarily increases and then decreases (or vice versa) during the transition, returning to its initial value at the final state. [SEP] [HINT] used -> Bioinformatics (Syns: utilize, ill-used, apply) | transition -> Materials Science (Syns: passage, modulation, changeover) | connectivity -> Neuroscience (Syns: )",Materials Science
"Harvesting low-grade heat to electricity is attractive for powering wearable electronic devices. Here, we demonstrate nW-scale thermoelectric power generation in devices from thin film assemblies of microwave-synthesized p-Sb2Te3 nanoplates and n-Ag2Te nanowires on polyvinylidene fluoride membranes. While microwave cycling is crucial for Ag2Te nanocrystal shaping, Sb2Te3 formation is sensitive to precursors and surfactant concentrations. Introducing S doping in Sb2Te3 in the 1 - 1.5 atomic percent range via thioglycolic acid during synthesis yields an up to eightfold higher power-factor, due to a fivefold increase in electrical conductivity and 25% increase in Seebeck coefficient. Our microfilm devices generate up to 33.6 mV from 5 deg C to 50 deg C thermal gradients, with 120 nW maximum power output at Delta T 30 deg C, which is sixtyfold higher than Sb2Te3 paper devices. Mechanical bending can increase device resistance by up to 125% due to diminished inter-nanostructure electronic transport. These findings provide insights for integrating synthesis, morphology engineering and device design for next-generation wearable thermoelectric systems.",Materials Science
"Harvesting low-grade heat to electricity is attractive for powering wearable electronic devices. Here, we demonstrate nW-scale thermoelectric power generation in devices from thin film assemblies of microwave-synthesized p-Sb2Te3 nanoplates and n-Ag2Te nanowires on polyvinylidene fluoride membranes. While microwave cycling is crucial for Ag2Te nanocrystal shaping, Sb2Te3 formation is sensitive to precursors and surfactant concentrations. Introducing S doping in Sb2Te3 in the 1 - 1.5 atomic percent range via thioglycolic acid during synthesis yields an up to eightfold higher power-factor, due to a fivefold increase in electrical conductivity and 25% increase in Seebeck coefficient. Our microfilm devices generate up to 33.6 mV from 5 deg C to 50 deg C thermal gradients, with 120 nW maximum power output at Delta T 30 deg C, which is sixtyfold higher than Sb2Te3 paper devices. Mechanical bending can increase device resistance by up to 125% due to diminished inter-nanostructure electronic transport. These findings provide insights for integrating synthesis, morphology engineering and device design for next-generation wearable thermoelectric systems. [SEP] [HINT] electronic -> Materials Science (Syns: ) | thermal -> Materials Science (Syns: thermic, caloric) | demonstrate -> Bioinformatics (Syns: evidence, march, prove)",Materials Science
"Cr$_{1+δ}$Te$_2$, a two-dimensional van der Waals ferromagnet, displays a contested magnetic structure, poised between collinear and non-collinear spin configurations. In this work, we investigate the magnetic structure of Cr$_{1.33}$Te$_2$ at the microscopic level by combining single-crystal neutron diffraction, X-ray absorption spectroscopy, and first-principles calculations. Neutron diffraction measurements reveal a distinct collinear spin alignment, whereas spectroscopic analyses reveal inherent structural vacancies at both Cr and Te sites. These vacancies lead to local symmetry breaking that elevates the orbital degeneracy of the Cr 3$d$ states, as demonstrated by our first-principles analysis. The resulting modification of magnetocrystalline anisotropy emerges as the key mechanism stabilising the collinear magnetic ground state over the non-collinear one in the presence of vacancies. Our findings uncover a vacancy-driven route to control spin anisotropy and magnetic ordering in layered ferromagnets, offering new insights into the design of tunable 2D magnetic materials.",Materials Science
"Cr$_{1+δ}$Te$_2$, a two-dimensional van der Waals ferromagnet, displays a contested magnetic structure, poised between collinear and non-collinear spin configurations. In this work, we investigate the magnetic structure of Cr$_{1.33}$Te$_2$ at the microscopic level by combining single-crystal neutron diffraction, X-ray absorption spectroscopy, and first-principles calculations. Neutron diffraction measurements reveal a distinct collinear spin alignment, whereas spectroscopic analyses reveal inherent structural vacancies at both Cr and Te sites. These vacancies lead to local symmetry breaking that elevates the orbital degeneracy of the Cr 3$d$ states, as demonstrated by our first-principles analysis. The resulting modification of magnetocrystalline anisotropy emerges as the key mechanism stabilising the collinear magnetic ground state over the non-collinear one in the presence of vacancies. Our findings uncover a vacancy-driven route to control spin anisotropy and magnetic ordering in layered ferromagnets, offering new insights into the design of tunable 2D magnetic materials. [SEP] [HINT] spin -> Materials Science (Syns: twisting, whirl, tailspin) | structure -> Bioinformatics (Syns: social system, complex body part, social structure) | structural -> Materials Science (Syns: geomorphologic, morphologic, morphological)",Materials Science
"An electric bias can shift the Fermi level along the Dirac cone of a topological insulator and modify its charge transport, but tuning the electronic states and spin-orbit interaction (SOI) without destroying the surface topology is challenging. Here, we show that thin film Bi2Se3/n-p (p-n) molecular diodes form ordered interfaces where charge transfer and orbital re-hybridisation result in a decrease (increase) of the carrier density and improved mobility. In Bi2Se3 the spin-orbit lifetime, t_so, is 0.13 ps, which is comparable to the strongest spin-orbit materials. This lifetime drops further to 0.06 ps (0.09 ps) with the addition of p-n (n-p) molecular diodes, at the limit of measurable values. This strengthened spin-orbit interaction occurs even though molecules are made of light elements and increase the mean free path of the charge carriers by almost 50%, indicating changes to the Berry curvature and/or Rashba splitting around the hybridisation points. Raman spectroscopy gives evidence that the coupling effect may be controlled by optical irradiation, opening a pathway towards the design of heavy-light element hybrids with optically tunable quantum transport.",Materials Science
"An electric bias can shift the Fermi level along the Dirac cone of a topological insulator and modify its charge transport, but tuning the electronic states and spin-orbit interaction (SOI) without destroying the surface topology is challenging. Here, we show that thin film Bi2Se3/n-p (p-n) molecular diodes form ordered interfaces where charge transfer and orbital re-hybridisation result in a decrease (increase) of the carrier density and improved mobility. In Bi2Se3 the spin-orbit lifetime, t_so, is 0.13 ps, which is comparable to the strongest spin-orbit materials. This lifetime drops further to 0.06 ps (0.09 ps) with the addition of p-n (n-p) molecular diodes, at the limit of measurable values. This strengthened spin-orbit interaction occurs even though molecules are made of light elements and increase the mean free path of the charge carriers by almost 50%, indicating changes to the Berry curvature and/or Rashba splitting around the hybridisation points. Raman spectroscopy gives evidence that the coupling effect may be controlled by optical irradiation, opening a pathway towards the design of heavy-light element hybrids with optically tunable quantum transport. [SEP] [HINT] charge -> Materials Science (Syns: tear, bearing, burster) | electronic -> Materials Science (Syns: ) | molecular -> Bioinformatics (Syns: )",Materials Science
"High-dimensional tissue imaging generates highly complex 3D data containing multiple biomarkers, making it challenging to identify biologically relevant regions without an expert user specifying manual labels for regions of interest. We introduce an approach to automatically identifying regions of interest (ROIs) in the 3D microscopy data. Our approach is based on a novel self-supervised multi-layer graph attention network (SSGAT), coupled with a React interactive interface wrapped around Vitessce. SSGAT employs an adversarial self-supervised learning objective to identify meaningful immune microenvironments through marker interactions. Our method reveals complex spatial bioreactions that can be visually assessed to assess their distribution across tissue. Index Terms: Biomedical visualization, graph attention networks,self-supervised learning, spatial interaction analysis.",Bioinformatics
"High-dimensional tissue imaging generates highly complex 3D data containing multiple biomarkers, making it challenging to identify biologically relevant regions without an expert user specifying manual labels for regions of interest. We introduce an approach to automatically identifying regions of interest (ROIs) in the 3D microscopy data. Our approach is based on a novel self-supervised multi-layer graph attention network (SSGAT), coupled with a React interactive interface wrapped around Vitessce. SSGAT employs an adversarial self-supervised learning objective to identify meaningful immune microenvironments through marker interactions. Our method reveals complex spatial bioreactions that can be visually assessed to assess their distribution across tissue. Index Terms: Biomedical visualization, graph attention networks,self-supervised learning, spatial interaction analysis. [SEP] [HINT] tissue -> Bioinformatics (Syns: tissue paper, weave) | based -> Bioinformatics (Syns: ground, free-base, base) | learning -> Bioinformatics (Syns: take, teach, acquire)",Bioinformatics
"Chronic upper extremity (UE) impairment is common after stroke. This study evaluated Boost, a novel wheelchair-mounted rehabilitation device designed to assist individuals in UE motor recovery during inpatient rehabilitation. Thirty-five stroke inpatients were randomized to perform additional UE exercises alongside standard therapy, using either Boost or a therapist-customized booklet for self-practice. Outcomes included the UE Fugl-Meyer (UEFM) Exam, Box and Block Test, Motor Activity Log, Modified Ashworth Scale, shoulder subluxation, and shoulder pain. At baseline, mean days post-stroke were 11.9$\pm$4.6 and 13.1$\pm$5.9, and UEFM scores were 20.5$\pm$10.1 and 21.0$\pm$13.5. Intervention durations averaged 11.9$\pm$4.0 and 17.2$\pm$8.8 days, respectively. Participants in the Boost group completed 3,359$\pm$3,137 additional arm movements. No significant between-group differences were found at the three-month follow-up. However, the Boost group showed a trend toward greater UEFM improvement immediately post-intervention (11.8 vs. 6.9 points, p=0.06). Importantly, UEFM gains were predicted by the number of Boost exercises performed (p=0.02, R-square=0.34). Subgroup analysis revealed that patients with less severe impairment (baseline UEFM >21) achieved significantly greater UEFM improvements at discharge with Boost compared to controls (15.8 vs. 7.8 points, p=0.01). These findings demonstrate the feasibility of achieving thousands of additional UE practice movements while seated in a wheelchair without direct supervision during subacute rehabilitation. The added movement practice was well tolerated and may offer short-term impairment-reduction benefits, particularly in those with less severe impairment. Larger trials are needed to confirm efficacy, establish optimal dosage, and determine long-term clinical and functional benefits of Boost-assisted therapy.",Neuroscience
"Chronic upper extremity (UE) impairment is common after stroke. This study evaluated Boost, a novel wheelchair-mounted rehabilitation device designed to assist individuals in UE motor recovery during inpatient rehabilitation. Thirty-five stroke inpatients were randomized to perform additional UE exercises alongside standard therapy, using either Boost or a therapist-customized booklet for self-practice. Outcomes included the UE Fugl-Meyer (UEFM) Exam, Box and Block Test, Motor Activity Log, Modified Ashworth Scale, shoulder subluxation, and shoulder pain. At baseline, mean days post-stroke were 11.9$\pm$4.6 and 13.1$\pm$5.9, and UEFM scores were 20.5$\pm$10.1 and 21.0$\pm$13.5. Intervention durations averaged 11.9$\pm$4.0 and 17.2$\pm$8.8 days, respectively. Participants in the Boost group completed 3,359$\pm$3,137 additional arm movements. No significant between-group differences were found at the three-month follow-up. However, the Boost group showed a trend toward greater UEFM improvement immediately post-intervention (11.8 vs. 6.9 points, p=0.06). Importantly, UEFM gains were predicted by the number of Boost exercises performed (p=0.02, R-square=0.34). Subgroup analysis revealed that patients with less severe impairment (baseline UEFM >21) achieved significantly greater UEFM improvements at discharge with Boost compared to controls (15.8 vs. 7.8 points, p=0.01). These findings demonstrate the feasibility of achieving thousands of additional UE practice movements while seated in a wheelchair without direct supervision during subacute rehabilitation. The added movement practice was well tolerated and may offer short-term impairment-reduction benefits, particularly in those with less severe impairment. Larger trials are needed to confirm efficacy, establish optimal dosage, and determine long-term clinical and functional benefits of Boost-assisted therapy. [SEP] [HINT] clinical -> Bioinformatics (Syns: ) | functional -> Neuroscience (Syns: working, usable, running) | using -> Bioinformatics (Syns: utilize, exploitation, apply)",Neuroscience
"Optical microscopy is one of the most widely used techniques in research studies for life sciences and biomedicine. These applications require reliable experimental pipelines to extract valuable knowledge from the measured samples and must be supported by image quality assessment (IQA) to ensure correct processing and analysis of the image data. IQA methods are implemented with variable complexity. However, while most quality metrics have a straightforward implementation, they might be time consuming and computationally expensive when evaluating a large dataset. In addition, quality metrics are often designed for well-defined image features and may be unstable for images out of the ideal domain. To overcome these limitations, recent works have proposed deep learning-based IQA methods, which can provide superior performance, increased generalizability and fast prediction. Our method, named $\mathrmμ$DeepIQA, is inspired by previous studies and applies a deep convolutional neural network designed for IQA on natural images to optical microscopy measurements. We retrained the same architecture to predict individual quality metrics and global quality scores for optical microscopy data. The resulting models provide fast and stable predictions of image quality by generalizing quality estimation even outside the ideal range of standard methods. In addition, $\mathrmμ$DeepIQA provides patch-wise prediction of image quality and can be used to visualize spatially varying quality in a single image. Our study demonstrates that optical microscopy-based studies can benefit from the generalizability of deep learning models due to their stable performance in the presence of outliers, the ability to assess small image patches, and rapid predictions.",Bioinformatics
"Optical microscopy is one of the most widely used techniques in research studies for life sciences and biomedicine. These applications require reliable experimental pipelines to extract valuable knowledge from the measured samples and must be supported by image quality assessment (IQA) to ensure correct processing and analysis of the image data. IQA methods are implemented with variable complexity. However, while most quality metrics have a straightforward implementation, they might be time consuming and computationally expensive when evaluating a large dataset. In addition, quality metrics are often designed for well-defined image features and may be unstable for images out of the ideal domain. To overcome these limitations, recent works have proposed deep learning-based IQA methods, which can provide superior performance, increased generalizability and fast prediction. Our method, named $\mathrmμ$DeepIQA, is inspired by previous studies and applies a deep convolutional neural network designed for IQA on natural images to optical microscopy measurements. We retrained the same architecture to predict individual quality metrics and global quality scores for optical microscopy data. The resulting models provide fast and stable predictions of image quality by generalizing quality estimation even outside the ideal range of standard methods. In addition, $\mathrmμ$DeepIQA provides patch-wise prediction of image quality and can be used to visualize spatially varying quality in a single image. Our study demonstrates that optical microscopy-based studies can benefit from the generalizability of deep learning models due to their stable performance in the presence of outliers, the ability to assess small image patches, and rapid predictions. [SEP] [HINT] used -> Bioinformatics (Syns: utilize, ill-used, apply) | features -> Bioinformatics (Syns: characteristic, lineament, feature of speech) | learning -> Bioinformatics (Syns: take, teach, acquire)",Bioinformatics
"We report in-situ synthesis of iron oxide particles inside silicon nitride nanopores via a chemical reaction, monitored by current readout. Nanopores were formed by electroporation on glass chips (diameters from 1.7 to 11.3 nm), transmission electron microscopy (TEM) drilling (diameters from 6.5 to 64.6 nm), or hydrofluoric acid (HF) etching (diameters from 12.6 to 36.2 nm) in 5 to 20 nm thick membranes. Nanopores seal on timescales from ~1 ms to ~3.6 s, across a range of sizes and concentrations. We show single and ~5-pore arrays, as fabricated, after sealing, and after cleaning and pore recovery. These results are independent of fabrication method. Energy dispersive X-ray spectroscopy (EDS), aberration-corrected scanning TEM (AC-STEM), and powder X-ray diffraction (XRD) verify the synthesis of mixed magnetite and maghemite iron oxide. This work advances nanoparticle-nanopore chips for applications in biosensing, plasmonics and photonics when position and size control is required.",Materials Science
"We report in-situ synthesis of iron oxide particles inside silicon nitride nanopores via a chemical reaction, monitored by current readout. Nanopores were formed by electroporation on glass chips (diameters from 1.7 to 11.3 nm), transmission electron microscopy (TEM) drilling (diameters from 6.5 to 64.6 nm), or hydrofluoric acid (HF) etching (diameters from 12.6 to 36.2 nm) in 5 to 20 nm thick membranes. Nanopores seal on timescales from ~1 ms to ~3.6 s, across a range of sizes and concentrations. We show single and ~5-pore arrays, as fabricated, after sealing, and after cleaning and pore recovery. These results are independent of fabrication method. Energy dispersive X-ray spectroscopy (EDS), aberration-corrected scanning TEM (AC-STEM), and powder X-ray diffraction (XRD) verify the synthesis of mixed magnetite and maghemite iron oxide. This work advances nanoparticle-nanopore chips for applications in biosensing, plasmonics and photonics when position and size control is required. [SEP] [HINT] electron -> Materials Science (Syns: negatron) | work -> Bioinformatics (Syns: work out, process, bring) | results -> Bioinformatics (Syns: final result, consequence, resultant role)",Materials Science
"The slime mould Physarum polycephalum displays adaptive transport dynamics and network formation that have inspired its use as a model of biological computation. We develop a Lagrangian formulation of Physarum's adaptive dynamics on predefined graphs, showing that steady states arise as extrema of a least-action functional balancing metabolic dissipation and transport efficiency. The organism's apparent ability to find optimal paths between nutrient sources and sinks emerges from minimizing global energy dissipation under predefined boundary conditions that specify the problem to be solved. Applied to ring, tree, and lattice geometries, the framework accurately reproduces the optimal conductance and flux configurations observed experimentally. These results show that Physarum's problem-solving on constrained topologies follows a physics-based variational principle, revealing least-action dynamics as the foundation of its adaptive organization.",Neuroscience
"The slime mould Physarum polycephalum displays adaptive transport dynamics and network formation that have inspired its use as a model of biological computation. We develop a Lagrangian formulation of Physarum's adaptive dynamics on predefined graphs, showing that steady states arise as extrema of a least-action functional balancing metabolic dissipation and transport efficiency. The organism's apparent ability to find optimal paths between nutrient sources and sinks emerges from minimizing global energy dissipation under predefined boundary conditions that specify the problem to be solved. Applied to ring, tree, and lattice geometries, the framework accurately reproduces the optimal conductance and flux configurations observed experimentally. These results show that Physarum's problem-solving on constrained topologies follows a physics-based variational principle, revealing least-action dynamics as the foundation of its adaptive organization. [SEP] [HINT] transport -> Materials Science (Syns: transferral, enthral, shipping) | functional -> Neuroscience (Syns: working, usable, running) | results -> Bioinformatics (Syns: final result, consequence, resultant role)",Neuroscience
"Colorectal cancer (CRC) is highly heterogeneous, with five-year survival rates dropping from $\sim$90% in localized disease to $\sim$15% with distant metastases. Disease progression is shaped not only by tumor-intrinsic alterations but also by the reorganization of the tumor microenvironment (TME). Metabolic, compositional, and spatial changes contribute to this progression, but considered individually they lack context and often fail as therapeutic targets. Understanding their coordination could reveal processes to alter the disease course. Here, we combined multiplexed ion beam imaging (MIBI) with machine learning to profile metabolic, functional and spatial states of 522 colorectal lesions with single-cell resolution. We observed recurrent stage-specific remodeling marked by a lymphoid-to-myeloid shift, stromal-cancer cooperation, and malignant metabolic shifts. Spatial organization of epithelial, stromal, and immune compartments provided stronger stratification of disease stage than tumor-intrinsic changes or bulk immune infiltration alone. To systematically model these coordinated changes, we condensed multimodal features into 10 latent factors of TME organization. These factors tracked disease progression, were conserved across cohorts, and revealed frequent multicellular metabolic niches and distinct, non-exclusive TME trajectories. Our framework MuVIcell exposes the elements that together drive CRC progression by grouping co-occurring changes across cell types and feature classes into coordinated multicellular programs. This creates a rational basis to therapeutically target TME reorganization. Importantly, the framework is scalable and flexible, offering a resource for studying multicellular organization in other solid tumors.",Bioinformatics
"Colorectal cancer (CRC) is highly heterogeneous, with five-year survival rates dropping from $\sim$90% in localized disease to $\sim$15% with distant metastases. Disease progression is shaped not only by tumor-intrinsic alterations but also by the reorganization of the tumor microenvironment (TME). Metabolic, compositional, and spatial changes contribute to this progression, but considered individually they lack context and often fail as therapeutic targets. Understanding their coordination could reveal processes to alter the disease course. Here, we combined multiplexed ion beam imaging (MIBI) with machine learning to profile metabolic, functional and spatial states of 522 colorectal lesions with single-cell resolution. We observed recurrent stage-specific remodeling marked by a lymphoid-to-myeloid shift, stromal-cancer cooperation, and malignant metabolic shifts. Spatial organization of epithelial, stromal, and immune compartments provided stronger stratification of disease stage than tumor-intrinsic changes or bulk immune infiltration alone. To systematically model these coordinated changes, we condensed multimodal features into 10 latent factors of TME organization. These factors tracked disease progression, were conserved across cohorts, and revealed frequent multicellular metabolic niches and distinct, non-exclusive TME trajectories. Our framework MuVIcell exposes the elements that together drive CRC progression by grouping co-occurring changes across cell types and feature classes into coordinated multicellular programs. This creates a rational basis to therapeutically target TME reorganization. Importantly, the framework is scalable and flexible, offering a resource for studying multicellular organization in other solid tumors. [SEP] [HINT] features -> Bioinformatics (Syns: characteristic, lineament, feature of speech) | understanding -> Neuroscience (Syns: savvy, intellect, sympathy) | learning -> Bioinformatics (Syns: take, teach, acquire)",Bioinformatics
"A topological interlocking assembly is an arrangement of blocks, where all blocks are kinematically constrained by their neighboring blocks and a fixed frame. This concept has been known for a long time, attracting recent interest due to its advantageous mechanical properties, such as reusability, redundancy and limited crack propagation. New mathematical methods enable the generation of vast numbers of new topologically interlocking blocks. A natural next question is the quantification of the mechanical performance of these new blocks. We conduct a numerical study of topological interlocking assemblies whose blocks are constructed based on the hexagonal grid. By varying a design parameter used in the generation of these blocks, we study its influence on the structural performance of the entire assembly. The results improve our understanding of the link between the block parameters and the mechanical performance. This enhances the ability to custom design blocks for certain mechanical requirements of the topological interlocking assemblies.",Materials Science
"A topological interlocking assembly is an arrangement of blocks, where all blocks are kinematically constrained by their neighboring blocks and a fixed frame. This concept has been known for a long time, attracting recent interest due to its advantageous mechanical properties, such as reusability, redundancy and limited crack propagation. New mathematical methods enable the generation of vast numbers of new topologically interlocking blocks. A natural next question is the quantification of the mechanical performance of these new blocks. We conduct a numerical study of topological interlocking assemblies whose blocks are constructed based on the hexagonal grid. By varying a design parameter used in the generation of these blocks, we study its influence on the structural performance of the entire assembly. The results improve our understanding of the link between the block parameters and the mechanical performance. This enhances the ability to custom design blocks for certain mechanical requirements of the topological interlocking assemblies. [SEP] [HINT] used -> Bioinformatics (Syns: utilize, ill-used, apply) | based -> Bioinformatics (Syns: ground, free-base, base) | understanding -> Neuroscience (Syns: savvy, intellect, sympathy)",Materials Science
"For many taxonomic groups, online biodiversity portals used by naturalists and citizen scientists constitute the primary source of distributional information. Over the last decade, site-occupancy models have been advanced as a promising framework to analyse such loosely structured, opportunistically collected datasets. Current approaches often ignore important aspects of the detection process and do not fully capitalise on the information present in these datasets, leaving opportunities for fine-grained spatiotemporal backcasting untouched. We propose a flexible Bayesian spatiotemporal site-occupancy model that aims to mimic the data-generating process that underlies common citizen science datasets sourced from public biodiversity portals, and yields rich biological output. We illustrate the use of the model to a dataset containing over 3M butterfly records in Belgium, collected through the citizen science data portal Observations.be. We show that the proposed approach enables retrospective predictions on the occupancy of species through time and space at high resolution, as well as inference on inter-annual distributional trends, range dynamics, habitat preferences, phenological patterns, detection patterns and observer heterogeneity. The proposed model can be used to increase the value of opportunistically collected data by naturalists and citizen scientists, and can aid the understanding of spatiotemporal dynamics of species for which rigorously collected data are absent or too costly to collect.",Bioinformatics
"For many taxonomic groups, online biodiversity portals used by naturalists and citizen scientists constitute the primary source of distributional information. Over the last decade, site-occupancy models have been advanced as a promising framework to analyse such loosely structured, opportunistically collected datasets. Current approaches often ignore important aspects of the detection process and do not fully capitalise on the information present in these datasets, leaving opportunities for fine-grained spatiotemporal backcasting untouched. We propose a flexible Bayesian spatiotemporal site-occupancy model that aims to mimic the data-generating process that underlies common citizen science datasets sourced from public biodiversity portals, and yields rich biological output. We illustrate the use of the model to a dataset containing over 3M butterfly records in Belgium, collected through the citizen science data portal Observations.be. We show that the proposed approach enables retrospective predictions on the occupancy of species through time and space at high resolution, as well as inference on inter-annual distributional trends, range dynamics, habitat preferences, phenological patterns, detection patterns and observer heterogeneity. The proposed model can be used to increase the value of opportunistically collected data by naturalists and citizen scientists, and can aid the understanding of spatiotemporal dynamics of species for which rigorously collected data are absent or too costly to collect. [SEP] [HINT] used -> Bioinformatics (Syns: utilize, ill-used, apply) | understanding -> Neuroscience (Syns: savvy, intellect, sympathy) | space -> Neuroscience (Syns: distance, place, outer space)",Bioinformatics
"This study introduces a WaveNet-based deep learning model designed to automate the classification of EEG signals into physiological, pathological, artifact, and noise categories. Traditional methods for EEG signal classification, which rely on expert visual review, are becoming increasingly impractical due to the growing complexity and volume of EEG recordings. Leveraging a publicly available annotated dataset from Mayo Clinic and St. Anne's University Hospital, the WaveNet model was trained, validated, and tested on 209,232 samples with a 70/20/10 percent split. The model achieved a classification accuracy exceeding previous CNN and LSTM-based approaches, and was benchmarked against a Temporal Convolutional Network (TCN) baseline. Notably, the model distinguishes noise and artifacts with high precision, although it reveals a modest but explainable degree of misclassification between physiological and pathological signals, reflecting inherent clinical overlap. WaveNet's architecture, originally developed for raw audio synthesis, is well suited for EEG data due to its use of dilated causal convolutions and residual connections, enabling it to capture both fine-grained and long-range temporal dependencies. The research also details the preprocessing pipeline, including dynamic dataset partitioning and normalization steps that support model generalization.",Neuroscience
"This study introduces a WaveNet-based deep learning model designed to automate the classification of EEG signals into physiological, pathological, artifact, and noise categories. Traditional methods for EEG signal classification, which rely on expert visual review, are becoming increasingly impractical due to the growing complexity and volume of EEG recordings. Leveraging a publicly available annotated dataset from Mayo Clinic and St. Anne's University Hospital, the WaveNet model was trained, validated, and tested on 209,232 samples with a 70/20/10 percent split. The model achieved a classification accuracy exceeding previous CNN and LSTM-based approaches, and was benchmarked against a Temporal Convolutional Network (TCN) baseline. Notably, the model distinguishes noise and artifacts with high precision, although it reveals a modest but explainable degree of misclassification between physiological and pathological signals, reflecting inherent clinical overlap. WaveNet's architecture, originally developed for raw audio synthesis, is well suited for EEG data due to its use of dilated causal convolutions and residual connections, enabling it to capture both fine-grained and long-range temporal dependencies. The research also details the preprocessing pipeline, including dynamic dataset partitioning and normalization steps that support model generalization. [SEP] [HINT] clinical -> Bioinformatics (Syns: ) | learning -> Bioinformatics (Syns: take, teach, acquire) | including -> Bioinformatics (Syns: admit, include, let in)",Neuroscience
"A sensor-fused wearable assistance prototype for upper-limb function (triceps brachii and extensor pollicis brevis) is presented. The device integrates surface electromyography (sEMG), an inertial measurement unit (IMU), and flex/force sensors on an M5StickC plus an ESP32-S3 compute hub. Signals are band-pass and notch filtered; features (RMS, MAV, zero-crossings, and 4-12 Hz tremor-band power) are computed in 250 ms windows and fed to an INT8 TensorFlow Lite Micro model. Control commands are bounded by a control-barrier-function safety envelope and delivered within game-based tasks with lightweight personalization. In a pilot technical feasibility evaluation with healthy volunteers (n = 12) performing three ADL-oriented tasks, tremor prominence decreased (Delta TI = -0.092, 95% CI [-0.102, -0.079]), range of motion increased (+12.65%, 95% CI [+8.43, +13.89]), repetitions rose (+2.99 min^-1, 95% CI [+2.61, +3.35]), and the EMG median-frequency slope became less negative (Delta = +0.100 Hz/min, 95% CI [+0.083, +0.127]). The sensing-to-assist loop ran at 100 Hz with 8.7 ms median on-device latency, 100% session completion, and 0 device-related adverse events. These results demonstrate technical feasibility of embedded, sensor-fused assistance for upper-limb function; formal patient studies under IRB oversight are planned.",Neuroscience
"A sensor-fused wearable assistance prototype for upper-limb function (triceps brachii and extensor pollicis brevis) is presented. The device integrates surface electromyography (sEMG), an inertial measurement unit (IMU), and flex/force sensors on an M5StickC plus an ESP32-S3 compute hub. Signals are band-pass and notch filtered; features (RMS, MAV, zero-crossings, and 4-12 Hz tremor-band power) are computed in 250 ms windows and fed to an INT8 TensorFlow Lite Micro model. Control commands are bounded by a control-barrier-function safety envelope and delivered within game-based tasks with lightweight personalization. In a pilot technical feasibility evaluation with healthy volunteers (n = 12) performing three ADL-oriented tasks, tremor prominence decreased (Delta TI = -0.092, 95% CI [-0.102, -0.079]), range of motion increased (+12.65%, 95% CI [+8.43, +13.89]), repetitions rose (+2.99 min^-1, 95% CI [+2.61, +3.35]), and the EMG median-frequency slope became less negative (Delta = +0.100 Hz/min, 95% CI [+0.083, +0.127]). The sensing-to-assist loop ran at 100 Hz with 8.7 ms median on-device latency, 100% session completion, and 0 device-related adverse events. These results demonstrate technical feasibility of embedded, sensor-fused assistance for upper-limb function; formal patient studies under IRB oversight are planned. [SEP] [HINT] tasks -> Neuroscience (Syns: tax, task, project) | features -> Bioinformatics (Syns: characteristic, lineament, feature of speech) | results -> Bioinformatics (Syns: final result, consequence, resultant role)",Neuroscience
"Scenes are complex, yet structured collections of parts, including objects and surfaces, that exhibit spatial and semantic relations to one another. An effective visual system therefore needs unified scene representations that relate scene parts to their location and their co-occurrence. We hypothesize that this structure can be learned self-supervised from natural experience by exploiting the temporal regularities of active vision: each fixation reveals a locally-detailed glimpse that is statistically related to the previous one via co-occurrence and saccade-conditioned spatial regularities. We instantiate this idea with Glimpse Prediction Networks (GPNs) -- recurrent models trained to predict the feature embedding of the next glimpse along human-like scanpaths over natural scenes. GPNs successfully learn co-occurrence structure and, when given relative saccade location vectors, show sensitivity to spatial arrangement. Furthermore, recurrent variants of GPNs were able to integrate information across glimpses into a unified scene representation. Notably, these scene representations align strongly with human fMRI responses during natural-scene viewing across mid/high-level visual cortex. Critically, GPNs outperform architecture- and dataset-matched controls trained with explicit semantic objectives, and match or exceed strong modern vision baselines, leaving little unique variance for those alternatives. These results establish next-glimpse prediction during active vision as a biologically plausible, self-supervised route to brain-aligned scene representations learned from natural visual experience.",Neuroscience
"Scenes are complex, yet structured collections of parts, including objects and surfaces, that exhibit spatial and semantic relations to one another. An effective visual system therefore needs unified scene representations that relate scene parts to their location and their co-occurrence. We hypothesize that this structure can be learned self-supervised from natural experience by exploiting the temporal regularities of active vision: each fixation reveals a locally-detailed glimpse that is statistically related to the previous one via co-occurrence and saccade-conditioned spatial regularities. We instantiate this idea with Glimpse Prediction Networks (GPNs) -- recurrent models trained to predict the feature embedding of the next glimpse along human-like scanpaths over natural scenes. GPNs successfully learn co-occurrence structure and, when given relative saccade location vectors, show sensitivity to spatial arrangement. Furthermore, recurrent variants of GPNs were able to integrate information across glimpses into a unified scene representation. Notably, these scene representations align strongly with human fMRI responses during natural-scene viewing across mid/high-level visual cortex. Critically, GPNs outperform architecture- and dataset-matched controls trained with explicit semantic objectives, and match or exceed strong modern vision baselines, leaving little unique variance for those alternatives. These results establish next-glimpse prediction during active vision as a biologically plausible, self-supervised route to brain-aligned scene representations learned from natural visual experience. [SEP] [HINT] networks -> Neuroscience (Syns: network, meshwork, electronic network) | structure -> Bioinformatics (Syns: social system, complex body part, social structure) | information -> Bioinformatics (Syns: entropy, data, info)",Neuroscience
"Cryo-electron tomography (cryo-ET) enables structural characterization of biomolecules under near-native conditions. Existing approaches for interpreting the resulting three-dimensional volumes are computationally expensive and have difficulty interpreting density associated with small proteins/complexes. To explore alternate approaches for identifying proteins in cryo-ET data we pursued a Graph Network and topologically invariant approach. Here, we report on a fast algorithm that distinguishes volumes containing protein density from noise by searching for nuances of evolutionarily conversed motifs and the geometrical characteristics of protein structure. GRIP-Tomo 2.0 is a machine-learning pipeline that extracts interpretable topological features of protein structures within noisy experimental backgrounds. Compared to version 1.0, the new pipeline includes three upgrades that significantly improve performance including synthetic tomogram generation simulating realistic noise, graph-based persistent feature extraction as protein fingerprints, and high-performance computing acceleration. GRIP-Tomo 2.0 achieves over 90% accuracy in distinguishing proteins from noise for synthetic datasets and over 80% accuracy for real datasets, which represents a foundational step toward advancing cryo-ET workflows and empowering automated detection of both small and large proteins for visual proteomics.",Bioinformatics
"Cryo-electron tomography (cryo-ET) enables structural characterization of biomolecules under near-native conditions. Existing approaches for interpreting the resulting three-dimensional volumes are computationally expensive and have difficulty interpreting density associated with small proteins/complexes. To explore alternate approaches for identifying proteins in cryo-ET data we pursued a Graph Network and topologically invariant approach. Here, we report on a fast algorithm that distinguishes volumes containing protein density from noise by searching for nuances of evolutionarily conversed motifs and the geometrical characteristics of protein structure. GRIP-Tomo 2.0 is a machine-learning pipeline that extracts interpretable topological features of protein structures within noisy experimental backgrounds. Compared to version 1.0, the new pipeline includes three upgrades that significantly improve performance including synthetic tomogram generation simulating realistic noise, graph-based persistent feature extraction as protein fingerprints, and high-performance computing acceleration. GRIP-Tomo 2.0 achieves over 90% accuracy in distinguishing proteins from noise for synthetic datasets and over 80% accuracy for real datasets, which represents a foundational step toward advancing cryo-ET workflows and empowering automated detection of both small and large proteins for visual proteomics. [SEP] [HINT] features -> Bioinformatics (Syns: characteristic, lineament, feature of speech) | datasets -> Bioinformatics (Syns: ) | performance -> Bioinformatics (Syns: functioning, operation, carrying out)",Bioinformatics
"Virtually every biological rate changes with temperature, but the mechanisms underlying these responses differ between different processes. Here, we bring together the main theoretical approaches used to describe temperature-rate relationships, ranging from empirical curve shapes to reaction-level kinetics and network-based dynamical frameworks. These models highlight how temperature influences not only the speed of elementary reactions, but also the behavior that emerges when many reactions interact through regulation, feedback, or stochastic transitions. By outlining the assumptions and implications of each perspective, we aim to clarify how different modeling strategies connect molecular processes to physiological temperature response curves and to point toward integrative frameworks that can better explain the diversity of biological thermal responses.",Bioinformatics
"Virtually every biological rate changes with temperature, but the mechanisms underlying these responses differ between different processes. Here, we bring together the main theoretical approaches used to describe temperature-rate relationships, ranging from empirical curve shapes to reaction-level kinetics and network-based dynamical frameworks. These models highlight how temperature influences not only the speed of elementary reactions, but also the behavior that emerges when many reactions interact through regulation, feedback, or stochastic transitions. By outlining the assumptions and implications of each perspective, we aim to clarify how different modeling strategies connect molecular processes to physiological temperature response curves and to point toward integrative frameworks that can better explain the diversity of biological thermal responses. [SEP] [HINT] used -> Bioinformatics (Syns: utilize, ill-used, apply) | molecular -> Bioinformatics (Syns: ) | different -> Neuroscience (Syns: unlike, dissimilar)",Bioinformatics
"We present a lateral ventricular brain-computer interface (LV-BCI) that deploys an expandable, flexible electrode into the lateral ventricle through a minimally invasive external ventricular drainage pathway. Inspired by the framework of traditional Chinese lanterns, the electrode expands uniformly within the ventricle and conforms to the ependymal wall. Compared with conventional subdural ECoG electrodes, the LV-BCI shows superior signal stability and immunocompatibility. Resting-state spectral analyses revealed a maximum effective bandwidth comparable to subdural ECoG. In evoked potential tests, the LV-BCI maintained a consistently higher signal-to-noise ratio over 112 days without the decline typically associated with scarring or other immune responses. Immunohistochemistry showed only a transient, early microglial activation after implantation, returning to control levels and remaining stable through 168 days. We further designed an ""action-memory T-maze"" task and developed a microstate sequence classifier (MSSC) to predict rats' turn decisions. The LV-BCI achieved prediction accuracy up to 98%, significantly outperforming subdural ECoG, indicating enhanced access to decision-related information from deep structures such as the hippocampus. These results establish the lateral ventricle as a viable route for neural signal acquisition. Using a lantern-inspired flexible electrode, we achieve long-term stable recordings and robust memory decision decoding from within the ventricular system, opening new directions for BCI technology and systems neuroscience.",Neuroscience
"We present a lateral ventricular brain-computer interface (LV-BCI) that deploys an expandable, flexible electrode into the lateral ventricle through a minimally invasive external ventricular drainage pathway. Inspired by the framework of traditional Chinese lanterns, the electrode expands uniformly within the ventricle and conforms to the ependymal wall. Compared with conventional subdural ECoG electrodes, the LV-BCI shows superior signal stability and immunocompatibility. Resting-state spectral analyses revealed a maximum effective bandwidth comparable to subdural ECoG. In evoked potential tests, the LV-BCI maintained a consistently higher signal-to-noise ratio over 112 days without the decline typically associated with scarring or other immune responses. Immunohistochemistry showed only a transient, early microglial activation after implantation, returning to control levels and remaining stable through 168 days. We further designed an ""action-memory T-maze"" task and developed a microstate sequence classifier (MSSC) to predict rats' turn decisions. The LV-BCI achieved prediction accuracy up to 98%, significantly outperforming subdural ECoG, indicating enhanced access to decision-related information from deep structures such as the hippocampus. These results establish the lateral ventricle as a viable route for neural signal acquisition. Using a lantern-inspired flexible electrode, we achieve long-term stable recordings and robust memory decision decoding from within the ventricular system, opening new directions for BCI technology and systems neuroscience. [SEP] [HINT] task -> Neuroscience (Syns: tax, project, chore) | decoding -> Neuroscience (Syns: decrypt, decipherment, decryption) | information -> Bioinformatics (Syns: entropy, data, info)",Neuroscience
"Nanopore sequencing technologies continue to advance rapidly, offering critical benefits such as real-time analysis, the ability to sequence extremely long DNA fragments (up to millions of bases in a single read), and the option to selectively stop sequencing a molecule before completion. Traditionally, the raw electrical signals generated during sequencing are converted into DNA sequences through a process called basecalling, which typically relies on large neural network models. Raw signal analysis has emerged as a promising alternative to these resource-intensive approaches. While attempts have been made to benchmark conventional basecalling methods, existing evaluation frameworks 1) overlook raw signal analysis techniques, 2) lack the flexibility to accommodate new raw signal analysis tools easily, and 3) fail to include the latest improvements in nanopore datasets. Our goal is to provide an extensible benchmarking framework that enables designing and comparing new methods for raw signal analysis. To this end, we introduce RawBench, the first flexible framework for evaluating raw nanopore signal analysis techniques. RawBench provides modular evaluation of three core pipeline components: 1) reference genome encoding (using different pore models), 2) signal encoding (through various segmentation methods), and 3) representation matching (via different data structures). We extensively evaluate raw signal analysis techniques in terms of 1) quality and performance for read mapping, 2) quality and performance for read classification, and 3) quality of raw signal analysis-assisted basecalling. Our evaluations show that raw signal analysis can achieve competitive quality while significantly reducing resource requirements, particularly in settings where real-time processing or edge deployment is necessary.",Bioinformatics
"Nanopore sequencing technologies continue to advance rapidly, offering critical benefits such as real-time analysis, the ability to sequence extremely long DNA fragments (up to millions of bases in a single read), and the option to selectively stop sequencing a molecule before completion. Traditionally, the raw electrical signals generated during sequencing are converted into DNA sequences through a process called basecalling, which typically relies on large neural network models. Raw signal analysis has emerged as a promising alternative to these resource-intensive approaches. While attempts have been made to benchmark conventional basecalling methods, existing evaluation frameworks 1) overlook raw signal analysis techniques, 2) lack the flexibility to accommodate new raw signal analysis tools easily, and 3) fail to include the latest improvements in nanopore datasets. Our goal is to provide an extensible benchmarking framework that enables designing and comparing new methods for raw signal analysis. To this end, we introduce RawBench, the first flexible framework for evaluating raw nanopore signal analysis techniques. RawBench provides modular evaluation of three core pipeline components: 1) reference genome encoding (using different pore models), 2) signal encoding (through various segmentation methods), and 3) representation matching (via different data structures). We extensively evaluate raw signal analysis techniques in terms of 1) quality and performance for read mapping, 2) quality and performance for read classification, and 3) quality of raw signal analysis-assisted basecalling. Our evaluations show that raw signal analysis can achieve competitive quality while significantly reducing resource requirements, particularly in settings where real-time processing or edge deployment is necessary. [SEP] [HINT] quality -> Bioinformatics (Syns: lineament, tone, calibre) | processing -> Neuroscience (Syns: work, process, march) | performance -> Bioinformatics (Syns: functioning, operation, carrying out)",Bioinformatics
"This work draws on the conjecture that fingerprints of stochastic event sequences can be retrieved from electroencephalographic data (EEG) recorded during a behavioral task. To test this, we used the Goalkeeper Game (game.numec.prp.usp.br). Acting as a goalkeeper, the participant predicted each kick in a probabilistic sequence while EEG activity was recorded. At each trial, driven by a context tree, the kicker chose one of three options: left, center, or right. The goalkeeper then predicted the next kick by pressing a button. Tree estimation was performed by applying the Context Algorithm to EEG segments locked to the button press (-300 to 0 ms). We calculated the distance between the penalty taker's tree and the trees retrieved per participant and electrode. This metric was then correlated with the goalkeeper's success rates. We observed a clear reduction in the overall distance distribution over time for a subset of electrodes, indicating that EEG dependencies become more congruent with the penalty taker's tree as the goalkeeper learns the sequence. This distance is inversely proportional to the goalkeepers' success rates, indicating a clear relationship between performance and the neural signatures associated with the sequence structure.",Neuroscience
"This work draws on the conjecture that fingerprints of stochastic event sequences can be retrieved from electroencephalographic data (EEG) recorded during a behavioral task. To test this, we used the Goalkeeper Game (game.numec.prp.usp.br). Acting as a goalkeeper, the participant predicted each kick in a probabilistic sequence while EEG activity was recorded. At each trial, driven by a context tree, the kicker chose one of three options: left, center, or right. The goalkeeper then predicted the next kick by pressing a button. Tree estimation was performed by applying the Context Algorithm to EEG segments locked to the button press (-300 to 0 ms). We calculated the distance between the penalty taker's tree and the trees retrieved per participant and electrode. This metric was then correlated with the goalkeeper's success rates. We observed a clear reduction in the overall distance distribution over time for a subset of electrodes, indicating that EEG dependencies become more congruent with the penalty taker's tree as the goalkeeper learns the sequence. This distance is inversely proportional to the goalkeepers' success rates, indicating a clear relationship between performance and the neural signatures associated with the sequence structure. [SEP] [HINT] used -> Bioinformatics (Syns: utilize, ill-used, apply) | work -> Bioinformatics (Syns: work out, process, bring) | performance -> Bioinformatics (Syns: functioning, operation, carrying out)",Neuroscience
"Social communication fundamentally involves at least two interacting brains, creating a unique modeling problem. We present the first application of Contrastive Embedding for Behavioral and Neural Analysis (CEBRA) to dyadic EEG hyperscanning data, extending modeling paradigms to interpersonal neural dynamics. Using structured social interactions between participants, we demonstrate that CEBRA can learn meaningful representations of joint neural activity that captures individual roles (speaker-listener) and other behavioral metrics. Our approach to characterizing interactions, as opposed to individual neural responses to stimuli, addresses the key principles of foundational model development: scalability and cross-subject generalization, opening new directions for representation learning in social neuroscience and clinical applications.",Neuroscience
"Social communication fundamentally involves at least two interacting brains, creating a unique modeling problem. We present the first application of Contrastive Embedding for Behavioral and Neural Analysis (CEBRA) to dyadic EEG hyperscanning data, extending modeling paradigms to interpersonal neural dynamics. Using structured social interactions between participants, we demonstrate that CEBRA can learn meaningful representations of joint neural activity that captures individual roles (speaker-listener) and other behavioral metrics. Our approach to characterizing interactions, as opposed to individual neural responses to stimuli, addresses the key principles of foundational model development: scalability and cross-subject generalization, opening new directions for representation learning in social neuroscience and clinical applications. [SEP] [HINT] clinical -> Bioinformatics (Syns: ) | learning -> Bioinformatics (Syns: take, teach, acquire) | neuroscience -> Neuroscience (Syns: )",Neuroscience
"In the human brain, the allowed patterns of activity are constrained by the correlations between brain regions. Yet it remains unclear which correlations -- and how many -- are needed to predict large-scale neural activity. Here, we present an information-theoretic framework to identify the most important correlations, which provide the most accurate predictions of neural states. Applying our framework to cortical activity in humans, we discover that the vast majority of variance in activity is explained by a small number of correlations. This means that the brain is highly compressible: only a sparse network of correlations is needed to predict large-scale activity. We find that this compressibility is strikingly consistent across different individuals and cognitive tasks, and that, counterintuitively, the most important correlations are not necessarily the strongest. Together, these results suggest that nearly all correlations are not needed to predict neural activity, and we provide the tools to uncover the key correlations that are.",Neuroscience
"In the human brain, the allowed patterns of activity are constrained by the correlations between brain regions. Yet it remains unclear which correlations -- and how many -- are needed to predict large-scale neural activity. Here, we present an information-theoretic framework to identify the most important correlations, which provide the most accurate predictions of neural states. Applying our framework to cortical activity in humans, we discover that the vast majority of variance in activity is explained by a small number of correlations. This means that the brain is highly compressible: only a sparse network of correlations is needed to predict large-scale activity. We find that this compressibility is strikingly consistent across different individuals and cognitive tasks, and that, counterintuitively, the most important correlations are not necessarily the strongest. Together, these results suggest that nearly all correlations are not needed to predict neural activity, and we provide the tools to uncover the key correlations that are. [SEP] [HINT] cortical -> Neuroscience (Syns: ) | results -> Bioinformatics (Syns: final result, consequence, resultant role) | human -> Neuroscience (Syns: human being, man, homo)",Neuroscience
"Integrating semiconducting and magnetic materials could combine transistor-like operation with nonvolatility and enable architectures such as logic-in-memory. Here, we employ correlated electrical transport and scanning nitrogen-vacancy (NV) center magnetic imaging to elucidate a spin transistor concept that amalgamates both vertical and lateral transport in a 2D antiferromagnetic semiconductor, distinct from purely vertical tunneling devices. Our device, based on a monolayer-bilayer junction in CrSBr, displays giant, gate-tunable magnetoresistance driven by the dual action of electrostatic doping on space-charge-limited lateral conduction and interlayer exchange coupling. Moreover, we visualize a field-trainable, layer-sharing effect that selects between coherent or domain-wall reversal at the spin-flip transition, enabling multilevel, memristive conductance states. These findings open opportunities for 2D magnetic semiconductors to address limitations in contemporary computing.",Materials Science
"Integrating semiconducting and magnetic materials could combine transistor-like operation with nonvolatility and enable architectures such as logic-in-memory. Here, we employ correlated electrical transport and scanning nitrogen-vacancy (NV) center magnetic imaging to elucidate a spin transistor concept that amalgamates both vertical and lateral transport in a 2D antiferromagnetic semiconductor, distinct from purely vertical tunneling devices. Our device, based on a monolayer-bilayer junction in CrSBr, displays giant, gate-tunable magnetoresistance driven by the dual action of electrostatic doping on space-charge-limited lateral conduction and interlayer exchange coupling. Moreover, we visualize a field-trainable, layer-sharing effect that selects between coherent or domain-wall reversal at the spin-flip transition, enabling multilevel, memristive conductance states. These findings open opportunities for 2D magnetic semiconductors to address limitations in contemporary computing. [SEP] [HINT] based -> Bioinformatics (Syns: ground, free-base, base) | spin -> Materials Science (Syns: twisting, whirl, tailspin) | transport -> Materials Science (Syns: transferral, enthral, shipping)",Materials Science
"Topological quasiparticles, such as merons and bimerons, are characterized by non-trivial textures that exhibit remarkably robust transport against deformation, offering significant potential for information processing. While these phenomena have been explored in various systems, acoustic realizations remain challenging. Here, we report that acoustic meron topological textures were successfully realized using designed Archimedeanlike square spiral metastructures via the excitation of spoof surface acoustic waves (SSAWs). By applying mirror-symmetric combinatorial operations to the unit structures, we further construct composite chiral metastructures that enable both one-dimensional and two-dimensional stable transport of acoustic bimerons. It is further revealed that bimeron transport originates from the locked opposite phase differences of SSAWs, induced by the handedness of the cavity resonant modes. The intrinsic robustness of the meron textures against structural defects is confirmed through the calculation of their topological charge. Our findings establish stable acoustic bimeron transport as a topologically resilient foundation for future acoustic information processing and storage technologies.",Materials Science
"Topological quasiparticles, such as merons and bimerons, are characterized by non-trivial textures that exhibit remarkably robust transport against deformation, offering significant potential for information processing. While these phenomena have been explored in various systems, acoustic realizations remain challenging. Here, we report that acoustic meron topological textures were successfully realized using designed Archimedeanlike square spiral metastructures via the excitation of spoof surface acoustic waves (SSAWs). By applying mirror-symmetric combinatorial operations to the unit structures, we further construct composite chiral metastructures that enable both one-dimensional and two-dimensional stable transport of acoustic bimerons. It is further revealed that bimeron transport originates from the locked opposite phase differences of SSAWs, induced by the handedness of the cavity resonant modes. The intrinsic robustness of the meron textures against structural defects is confirmed through the calculation of their topological charge. Our findings establish stable acoustic bimeron transport as a topologically resilient foundation for future acoustic information processing and storage technologies. [SEP] [HINT] transport -> Materials Science (Syns: transferral, enthral, shipping) | information -> Bioinformatics (Syns: entropy, data, info) | processing -> Neuroscience (Syns: work, process, march)",Materials Science
"Automated semantic segmentation of whole-slide images (WSIs) stained with hematoxylin and eosin (H&E) is essential for large-scale artificial intelligence-based biomarker analysis in breast cancer. However, existing public datasets for breast cancer segmentation lack the morphological diversity needed to support model generalizability and robust biomarker validation across heterogeneous patient cohorts. We introduce BrEast cancEr hisTopathoLogy sEgmentation (BEETLE), a dataset for multiclass semantic segmentation of H&E-stained breast cancer WSIs. It consists of 587 biopsies and resections from three collaborating clinical centers and two public datasets, digitized using seven scanners, and covers all molecular subtypes and histological grades. Using diverse annotation strategies, we collected annotations across four classes - invasive epithelium, non-invasive epithelium, necrosis, and other - with particular focus on morphologies underrepresented in existing datasets, such as ductal carcinoma in situ and dispersed lobular tumor cells. The dataset's diversity and relevance to the rapidly growing field of automated biomarker quantification in breast cancer ensure its high potential for reuse. Finally, we provide a well-curated, multicentric external evaluation set to enable standardized benchmarking of breast cancer segmentation models.",Bioinformatics
"Automated semantic segmentation of whole-slide images (WSIs) stained with hematoxylin and eosin (H&E) is essential for large-scale artificial intelligence-based biomarker analysis in breast cancer. However, existing public datasets for breast cancer segmentation lack the morphological diversity needed to support model generalizability and robust biomarker validation across heterogeneous patient cohorts. We introduce BrEast cancEr hisTopathoLogy sEgmentation (BEETLE), a dataset for multiclass semantic segmentation of H&E-stained breast cancer WSIs. It consists of 587 biopsies and resections from three collaborating clinical centers and two public datasets, digitized using seven scanners, and covers all molecular subtypes and histological grades. Using diverse annotation strategies, we collected annotations across four classes - invasive epithelium, non-invasive epithelium, necrosis, and other - with particular focus on morphologies underrepresented in existing datasets, such as ductal carcinoma in situ and dispersed lobular tumor cells. The dataset's diversity and relevance to the rapidly growing field of automated biomarker quantification in breast cancer ensure its high potential for reuse. Finally, we provide a well-curated, multicentric external evaluation set to enable standardized benchmarking of breast cancer segmentation models. [SEP] [HINT] field -> Materials Science (Syns: field of honor, line of business, orbit) | clinical -> Bioinformatics (Syns: ) | molecular -> Bioinformatics (Syns: )",Bioinformatics
"Dimensionality reduction is critical across various domains of science including neuroscience. Probabilistic Principal Component Analysis (PPCA) is a prominent dimensionality reduction method that provides a probabilistic approach unlike the deterministic approach of PCA and serves as a connection between PCA and Factor Analysis (FA). Despite their power, PPCA and its extensions are mainly based on linear models and can only describe the data in a Euclidean coordinate system. However, in many neuroscience applications, data may be distributed around a nonlinear geometry (i.e., manifold) rather than lying in the Euclidean space. We develop Probabilistic Geometric Principal Component Analysis (PGPCA) for such datasets as a new dimensionality reduction algorithm that can explicitly incorporate knowledge about a given nonlinear manifold that is first fitted from these data. Further, we show how in addition to the Euclidean coordinate system, a geometric coordinate system can be derived for the manifold to capture the deviations of data from the manifold and noise. We also derive a data-driven EM algorithm for learning the PGPCA model parameters. As such, PGPCA generalizes PPCA to better describe data distributions by incorporating a nonlinear manifold geometry. In simulations and brain data analyses, we show that PGPCA can effectively model the data distribution around various given manifolds and outperforms PPCA for such data. Moreover, PGPCA provides the capability to test whether the new geometric coordinate system better describes the data than the Euclidean one. Finally, PGPCA can perform dimensionality reduction and learn the data distribution both around and on the manifold. These capabilities make PGPCA valuable for enhancing the efficacy of dimensionality reduction for analysis of high-dimensional data that exhibit noise and are distributed around a nonlinear manifold.",Neuroscience
"Dimensionality reduction is critical across various domains of science including neuroscience. Probabilistic Principal Component Analysis (PPCA) is a prominent dimensionality reduction method that provides a probabilistic approach unlike the deterministic approach of PCA and serves as a connection between PCA and Factor Analysis (FA). Despite their power, PPCA and its extensions are mainly based on linear models and can only describe the data in a Euclidean coordinate system. However, in many neuroscience applications, data may be distributed around a nonlinear geometry (i.e., manifold) rather than lying in the Euclidean space. We develop Probabilistic Geometric Principal Component Analysis (PGPCA) for such datasets as a new dimensionality reduction algorithm that can explicitly incorporate knowledge about a given nonlinear manifold that is first fitted from these data. Further, we show how in addition to the Euclidean coordinate system, a geometric coordinate system can be derived for the manifold to capture the deviations of data from the manifold and noise. We also derive a data-driven EM algorithm for learning the PGPCA model parameters. As such, PGPCA generalizes PPCA to better describe data distributions by incorporating a nonlinear manifold geometry. In simulations and brain data analyses, we show that PGPCA can effectively model the data distribution around various given manifolds and outperforms PPCA for such data. Moreover, PGPCA provides the capability to test whether the new geometric coordinate system better describes the data than the Euclidean one. Finally, PGPCA can perform dimensionality reduction and learn the data distribution both around and on the manifold. These capabilities make PGPCA valuable for enhancing the efficacy of dimensionality reduction for analysis of high-dimensional data that exhibit noise and are distributed around a nonlinear manifold. [SEP] [HINT] based -> Bioinformatics (Syns: ground, free-base, base) | learning -> Bioinformatics (Syns: take, teach, acquire) | datasets -> Bioinformatics (Syns: )",Neuroscience
"Brain decoding is a key neuroscience field that reconstructs the visual stimuli from brain activity with fMRI, which helps illuminate how the brain represents the world. fMRI-to-image reconstruction has achieved impressive progress by leveraging diffusion models. However, brain signals infused with prior knowledge and associations exhibit a significant information asymmetry when compared to raw visual features, still posing challenges for decoding fMRI representations under the supervision of images. Consequently, the reconstructed images often lack fine-grained visual fidelity, such as missing attributes and distorted spatial relationships. To tackle this challenge, we propose BrainCognizer, a novel brain decoding model inspired by human visual cognition, which explores multi-level semantics and correlations without fine-tuning of generative models. Specifically, BrainCognizer introduces two modules: the Cognitive Integration Module which incorporates prior human knowledge to extract hierarchical region semantics; and the Cognitive Correlation Module which captures contextual semantic relationships across regions. Incorporating these two modules enhances intra-region semantic consistency and maintains inter-region contextual associations, thereby facilitating fine-grained brain decoding. Moreover, we quantitatively interpret our components from a neuroscience perspective and analyze the associations between different visual patterns and brain functions. Extensive quantitative and qualitative experiments demonstrate that BrainCognizer outperforms state-of-the-art approaches on multiple evaluation metrics.",Neuroscience
"Brain decoding is a key neuroscience field that reconstructs the visual stimuli from brain activity with fMRI, which helps illuminate how the brain represents the world. fMRI-to-image reconstruction has achieved impressive progress by leveraging diffusion models. However, brain signals infused with prior knowledge and associations exhibit a significant information asymmetry when compared to raw visual features, still posing challenges for decoding fMRI representations under the supervision of images. Consequently, the reconstructed images often lack fine-grained visual fidelity, such as missing attributes and distorted spatial relationships. To tackle this challenge, we propose BrainCognizer, a novel brain decoding model inspired by human visual cognition, which explores multi-level semantics and correlations without fine-tuning of generative models. Specifically, BrainCognizer introduces two modules: the Cognitive Integration Module which incorporates prior human knowledge to extract hierarchical region semantics; and the Cognitive Correlation Module which captures contextual semantic relationships across regions. Incorporating these two modules enhances intra-region semantic consistency and maintains inter-region contextual associations, thereby facilitating fine-grained brain decoding. Moreover, we quantitatively interpret our components from a neuroscience perspective and analyze the associations between different visual patterns and brain functions. Extensive quantitative and qualitative experiments demonstrate that BrainCognizer outperforms state-of-the-art approaches on multiple evaluation metrics. [SEP] [HINT] field -> Materials Science (Syns: field of honor, line of business, orbit) | decoding -> Neuroscience (Syns: decrypt, decipherment, decryption) | information -> Bioinformatics (Syns: entropy, data, info)",Neuroscience
"Building on evidence of structural parallels between brain networks and the cosmic web [1], we apply AI-based geometric analysis to cultured neuronal networks. Isolated neurons self-organize into dendritic lattices shaped by reproducible wiring rules. These lattices show non-random features-frequent dendritic convergence, hub nodes, small-world connectivity, and large voids. Synaptic contacts cluster and strengthen at hubs. Strikingly, these properties mirror the cosmic web: dendritic branches resemble cosmic filaments and synapses map to galaxies. Quantitative metrics align across systems, suggesting shared underlying geometric principles. We invite cross-disciplinary collaboration to interrogate and extend these parallels.",Neuroscience
"Building on evidence of structural parallels between brain networks and the cosmic web [1], we apply AI-based geometric analysis to cultured neuronal networks. Isolated neurons self-organize into dendritic lattices shaped by reproducible wiring rules. These lattices show non-random features-frequent dendritic convergence, hub nodes, small-world connectivity, and large voids. Synaptic contacts cluster and strengthen at hubs. Strikingly, these properties mirror the cosmic web: dendritic branches resemble cosmic filaments and synapses map to galaxies. Quantitative metrics align across systems, suggesting shared underlying geometric principles. We invite cross-disciplinary collaboration to interrogate and extend these parallels. [SEP] [HINT] large -> Bioinformatics (Syns: prominent, great, tumid) | networks -> Neuroscience (Syns: network, meshwork, electronic network) | neurons -> Neuroscience (Syns: neuron, nerve cell)",Neuroscience
"Solving crystal structures from powder X-ray diffraction (XRD) is a central challenge in materials characterization. In this work, we study the powder XRD-to-structure mapping using gradient descent optimization, with the goal of recovering the correct structure from moderately distorted initial states based solely on XRD similarity. We show that commonly used XRD similarity metrics result in a highly non-convex landscape, complicating direct optimization. Constraining the optimization to the ground-truth crystal family significantly improves recovery, yielding higher match rates and increased mutual information and correlation scores between structural similarity and XRD similarity. Nevertheless, the landscape may remain non-convex along certain symmetry axes. These findings suggest that symmetry-aware inductive biases could play a meaningful role in helping learning models navigate the inverse mapping from diffraction to structure.",Materials Science
"Solving crystal structures from powder X-ray diffraction (XRD) is a central challenge in materials characterization. In this work, we study the powder XRD-to-structure mapping using gradient descent optimization, with the goal of recovering the correct structure from moderately distorted initial states based solely on XRD similarity. We show that commonly used XRD similarity metrics result in a highly non-convex landscape, complicating direct optimization. Constraining the optimization to the ground-truth crystal family significantly improves recovery, yielding higher match rates and increased mutual information and correlation scores between structural similarity and XRD similarity. Nevertheless, the landscape may remain non-convex along certain symmetry axes. These findings suggest that symmetry-aware inductive biases could play a meaningful role in helping learning models navigate the inverse mapping from diffraction to structure. [SEP] [HINT] used -> Bioinformatics (Syns: utilize, ill-used, apply) | based -> Bioinformatics (Syns: ground, free-base, base) | learning -> Bioinformatics (Syns: take, teach, acquire)",Materials Science
"Brain-computer interface (BCI) speech decoding has emerged as a promising tool for assisting individuals with speech impairments. In this context, the integration of electroencephalography (EEG) and electromyography (EMG) signals offers strong potential for enhancing decoding performance. Mandarin tone classification presents particular challenges, as tonal variations convey distinct meanings even when phonemes remain identical. In this study, we propose a novel cross-subject multimodal BCI decoding framework that fuses EEG and EMG signals to classify four Mandarin tones under both audible and silent speech conditions. Inspired by the cooperative mechanisms of neural and muscular systems in speech production, our neural decoding architecture combines spatial-temporal feature extraction branches with a cross-attention fusion mechanism, enabling informative interaction between modalities. We further incorporate domain-adversarial training to improve cross-subject generalization. We collected 4,800 EEG trials and 4,800 EMG trials from 10 participants using only twenty EEG and five EMG channels, demonstrating the feasibility of minimal-channel decoding. Despite employing lightweight modules, our model outperforms state-of-the-art baselines across all conditions, achieving average classification accuracies of 87.83% for audible speech and 88.08% for silent speech. In cross-subject evaluations, it still maintains strong performance with accuracies of 83.27% and 85.10% for audible and silent speech, respectively. We further conduct ablation studies to validate the effectiveness of each component. Our findings suggest that tone-level decoding with minimal EEG-EMG channels is feasible and potentially generalizable across subjects, contributing to the development of practical BCI applications.",Neuroscience
"Brain-computer interface (BCI) speech decoding has emerged as a promising tool for assisting individuals with speech impairments. In this context, the integration of electroencephalography (EEG) and electromyography (EMG) signals offers strong potential for enhancing decoding performance. Mandarin tone classification presents particular challenges, as tonal variations convey distinct meanings even when phonemes remain identical. In this study, we propose a novel cross-subject multimodal BCI decoding framework that fuses EEG and EMG signals to classify four Mandarin tones under both audible and silent speech conditions. Inspired by the cooperative mechanisms of neural and muscular systems in speech production, our neural decoding architecture combines spatial-temporal feature extraction branches with a cross-attention fusion mechanism, enabling informative interaction between modalities. We further incorporate domain-adversarial training to improve cross-subject generalization. We collected 4,800 EEG trials and 4,800 EMG trials from 10 participants using only twenty EEG and five EMG channels, demonstrating the feasibility of minimal-channel decoding. Despite employing lightweight modules, our model outperforms state-of-the-art baselines across all conditions, achieving average classification accuracies of 87.83% for audible speech and 88.08% for silent speech. In cross-subject evaluations, it still maintains strong performance with accuracies of 83.27% and 85.10% for audible and silent speech, respectively. We further conduct ablation studies to validate the effectiveness of each component. Our findings suggest that tone-level decoding with minimal EEG-EMG channels is feasible and potentially generalizable across subjects, contributing to the development of practical BCI applications. [SEP] [HINT] decoding -> Neuroscience (Syns: decrypt, decipherment, decryption) | performance -> Bioinformatics (Syns: functioning, operation, carrying out) | systems -> Bioinformatics (Syns: organization, organisation, system)",Neuroscience
"Nuclear fusion requires overcoming or traversing a repulsive Coulomb barrier of hundreds of kiloelectronvolts, rendering the probability of fusion at sub-keV energies vanishingly small. Yet in condensed matter, the electronic and structural environment of reacting nuclei can profoundly alter fusion rates. Here we demonstrate that deuterium-deuterium fusion within metallic foils exhibits a pronounced enhancement and reaction yield plateau below energies of 2.5 keV- contrary to the expected exponential suppression with decreasing energy. Using a dual-chamber platform that combines electrochemical deuterium loading with ion-beam bombardment, we show that fusion yields in palladium and titanium hydrides are enhanced by over 10^18 compared to theoretical bare-nucleus fusion rates. These results demonstrate that access to low-energy fusion processes can be governed by materials degrees of freedom. This materials-driven fusion regime establishes a reproducible, tunable framework for studying and ultimately engineering nuclear reactions in solids. While the reaction rates reported here are low, these insights into materials-modulated fusion processes offer a potential foundation for understanding how condensed-matter environments could influence future fusion-energy concepts.",Materials Science
"Nuclear fusion requires overcoming or traversing a repulsive Coulomb barrier of hundreds of kiloelectronvolts, rendering the probability of fusion at sub-keV energies vanishingly small. Yet in condensed matter, the electronic and structural environment of reacting nuclei can profoundly alter fusion rates. Here we demonstrate that deuterium-deuterium fusion within metallic foils exhibits a pronounced enhancement and reaction yield plateau below energies of 2.5 keV- contrary to the expected exponential suppression with decreasing energy. Using a dual-chamber platform that combines electrochemical deuterium loading with ion-beam bombardment, we show that fusion yields in palladium and titanium hydrides are enhanced by over 10^18 compared to theoretical bare-nucleus fusion rates. These results demonstrate that access to low-energy fusion processes can be governed by materials degrees of freedom. This materials-driven fusion regime establishes a reproducible, tunable framework for studying and ultimately engineering nuclear reactions in solids. While the reaction rates reported here are low, these insights into materials-modulated fusion processes offer a potential foundation for understanding how condensed-matter environments could influence future fusion-energy concepts. [SEP] [HINT] understanding -> Neuroscience (Syns: savvy, intellect, sympathy) | electronic -> Materials Science (Syns: ) | results -> Bioinformatics (Syns: final result, consequence, resultant role)",Materials Science
"Direction-dependent charge transport and optical responses are characteristic of van der Waals (vdW) materials with strong in-plane anisotropy. While transition-metal trichalcogenides (TMTCs) exemplify this behavior, heavier analogs remain largely unexplored. In this study we examine USe$_3$ as an anisotropic vdW material and a heavier analog of the well-studied TMTCs. We reveal strong in-plane anisotropy using polarization-resolved Raman spectroscopy, investigate strain-induced shifts of phonon modes, and quantify direction-dependent charge-carrier mobility through transport measurements on field-effect devices. First-principles calculations based on density-functional theory corroborate our findings, providing a theoretical basis for our experimental observations. Casting USe$_3$ as an actinide analog of a TMTC establishes a platform for exploring low-dimensional semiconductors that combine strong in-plane anisotropy with f-electron physics.",Materials Science
"Direction-dependent charge transport and optical responses are characteristic of van der Waals (vdW) materials with strong in-plane anisotropy. While transition-metal trichalcogenides (TMTCs) exemplify this behavior, heavier analogs remain largely unexplored. In this study we examine USe$_3$ as an anisotropic vdW material and a heavier analog of the well-studied TMTCs. We reveal strong in-plane anisotropy using polarization-resolved Raman spectroscopy, investigate strain-induced shifts of phonon modes, and quantify direction-dependent charge-carrier mobility through transport measurements on field-effect devices. First-principles calculations based on density-functional theory corroborate our findings, providing a theoretical basis for our experimental observations. Casting USe$_3$ as an actinide analog of a TMTC establishes a platform for exploring low-dimensional semiconductors that combine strong in-plane anisotropy with f-electron physics. [SEP] [HINT] phonon -> Materials Science (Syns: ) | based -> Bioinformatics (Syns: ground, free-base, base) | transport -> Materials Science (Syns: transferral, enthral, shipping)",Materials Science
"Correlated motions of proteins underpin many physiological mechanisms, such as substrate binding, signal transduction, enzymatic activity and allostery. These motions arise from low frequency collective movements of biomolecules and have mostly been studied using molecular dynamics simulations. Here, we present the effects of two different empirical energy force fields used for molecular dynamics simulations on correlated motions -- the non-polarizable CHARMM 36m additive force field and the polarizable Drude-2019 force field. The study was conducted on two proteins, ubiquitin - a small protein with a well-described dynamic - and the nuclear receptor protein PPAR___. The ligand binding domain of PPAR___ was of particular interest since its function is to regulate transcription through ligand and coregulator protein binding. It has been previously shown that a dynamical network of correlated motions ensures the transmission of information related to PPAR___ ligand binding. We present the results of classical MD simulations where we analyze the results in terms of residue fluctuations, residue correlation maps, community network analysis and hydrophobic cluster analysis. We find that RMS fluctuations tend to be greater and correlated motions are less intense with Drude-2019 force field than with the non-polarizable all atom additive force field. Analysis of large hydrophobic clusters in the respective proteins show a greater loss of native contacts in the simulations using the Drude-2019 force field than in the simulations using the all atom force additive force field. Our results provide the first quantification of the impact of using a polarizable force field in computational studies that focus on correlated motions.",Bioinformatics
"Correlated motions of proteins underpin many physiological mechanisms, such as substrate binding, signal transduction, enzymatic activity and allostery. These motions arise from low frequency collective movements of biomolecules and have mostly been studied using molecular dynamics simulations. Here, we present the effects of two different empirical energy force fields used for molecular dynamics simulations on correlated motions -- the non-polarizable CHARMM 36m additive force field and the polarizable Drude-2019 force field. The study was conducted on two proteins, ubiquitin - a small protein with a well-described dynamic - and the nuclear receptor protein PPAR___. The ligand binding domain of PPAR___ was of particular interest since its function is to regulate transcription through ligand and coregulator protein binding. It has been previously shown that a dynamical network of correlated motions ensures the transmission of information related to PPAR___ ligand binding. We present the results of classical MD simulations where we analyze the results in terms of residue fluctuations, residue correlation maps, community network analysis and hydrophobic cluster analysis. We find that RMS fluctuations tend to be greater and correlated motions are less intense with Drude-2019 force field than with the non-polarizable all atom additive force field. Analysis of large hydrophobic clusters in the respective proteins show a greater loss of native contacts in the simulations using the Drude-2019 force field than in the simulations using the all atom force additive force field. Our results provide the first quantification of the impact of using a polarizable force field in computational studies that focus on correlated motions. [SEP] [HINT] used -> Bioinformatics (Syns: utilize, ill-used, apply) | field -> Materials Science (Syns: field of honor, line of business, orbit) | low -> Materials Science (Syns: low-spirited, scurvy, depressed)",Bioinformatics
"In this work, we examine the conditions for the emergence of chimera-like states in Ising systems. We study an Ising chain with periodic boundaries in contact with a thermal bath at temperature T, that induces stochastic changes in spin variables. To capture the non-locality needed for chimera formation, we introduce a model setup with non-local diffusion of spin values through the whole system. More precisely, diffusion is modeled through spin-exchange interactions between units up to a distance R, using Kawasaki dynamics. This setup mimics, e.g., neural media, as the brain, in the presence of electrical (diffusive) interactions. We explored the influence of such non-local dynamics on the emergence of complex spatiotemporal synchronization patterns of activity. Depending on system parameters we report here for the first time chimera-like states in the Ising model, characterized by relatively stable moving domains of spins with different local magnetization. We analyzed the system at T=0, both analytically and via simulations and computed the system's phase diagram, revealing rich behavior: regions with only chimeras, coexistence of chimeras and stable domains, and metastable chimeras that decay into uniform stable domains. This study offers fundamental insights into how coherent and incoherent synchronization patterns can arise in complex networked systems as it is, e.g., the brain.",Neuroscience
"In this work, we examine the conditions for the emergence of chimera-like states in Ising systems. We study an Ising chain with periodic boundaries in contact with a thermal bath at temperature T, that induces stochastic changes in spin variables. To capture the non-locality needed for chimera formation, we introduce a model setup with non-local diffusion of spin values through the whole system. More precisely, diffusion is modeled through spin-exchange interactions between units up to a distance R, using Kawasaki dynamics. This setup mimics, e.g., neural media, as the brain, in the presence of electrical (diffusive) interactions. We explored the influence of such non-local dynamics on the emergence of complex spatiotemporal synchronization patterns of activity. Depending on system parameters we report here for the first time chimera-like states in the Ising model, characterized by relatively stable moving domains of spins with different local magnetization. We analyzed the system at T=0, both analytically and via simulations and computed the system's phase diagram, revealing rich behavior: regions with only chimeras, coexistence of chimeras and stable domains, and metastable chimeras that decay into uniform stable domains. This study offers fundamental insights into how coherent and incoherent synchronization patterns can arise in complex networked systems as it is, e.g., the brain. [SEP] [HINT] spin -> Materials Science (Syns: twisting, whirl, tailspin) | complex -> Bioinformatics (Syns: building complex, coordination compound, composite) | systems -> Bioinformatics (Syns: organization, organisation, system)",Neuroscience
"To study how the human brain works, we need to explore the organization of the cerebral cortex and its detailed cellular architecture. We introduce CytoNet, a foundation model that encodes high-resolution microscopic image patches of the cerebral cortex into highly expressive feature representations, enabling comprehensive brain analyses. CytoNet employs self-supervised learning using spatial proximity as a powerful training signal, without requiring manual labelling. The resulting features are anatomically sound and biologically relevant. They encode general aspects of cortical architecture and unique brain-specific traits. We demonstrate top-tier performance in tasks such as cortical area classification, cortical layer segmentation, cell morphology estimation, and unsupervised brain region mapping. As a foundation model, CytoNet offers a consistent framework for studying cortical microarchitecture, supporting analyses of its relationship with other structural and functional brain features, and paving the way for diverse neuroscientific investigations.",Neuroscience
"To study how the human brain works, we need to explore the organization of the cerebral cortex and its detailed cellular architecture. We introduce CytoNet, a foundation model that encodes high-resolution microscopic image patches of the cerebral cortex into highly expressive feature representations, enabling comprehensive brain analyses. CytoNet employs self-supervised learning using spatial proximity as a powerful training signal, without requiring manual labelling. The resulting features are anatomically sound and biologically relevant. They encode general aspects of cortical architecture and unique brain-specific traits. We demonstrate top-tier performance in tasks such as cortical area classification, cortical layer segmentation, cell morphology estimation, and unsupervised brain region mapping. As a foundation model, CytoNet offers a consistent framework for studying cortical microarchitecture, supporting analyses of its relationship with other structural and functional brain features, and paving the way for diverse neuroscientific investigations. [SEP] [HINT] tasks -> Neuroscience (Syns: tax, task, project) | features -> Bioinformatics (Syns: characteristic, lineament, feature of speech) | learning -> Bioinformatics (Syns: take, teach, acquire)",Neuroscience
"AlphaFold has transformed protein structure prediction, but emerging applications such as virtual ligand screening, proteome-wide folding, and de novo binder design demand predictions at a massive scale, where runtime and memory costs become prohibitive. A major bottleneck lies in the Pairformer backbone of AlphaFold3-style models, which relies on computationally expensive triangular primitives-especially triangle attention-for pairwise reasoning. We introduce Pairmixer, a streamlined alternative that eliminates triangle attention while preserving higher-order geometric reasoning capabilities that are critical for structure prediction. Pairmixer substantially improves computational efficiency, matching state-of-the-art structure predictors across folding and docking benchmarks, delivering up to 4x faster inference on long sequences while reducing training cost by 34%. Its efficiency alleviates the computational burden of downstream applications such as modeling large protein complexes, high-throughput ligand and binder screening, and hallucination-based design. Within BoltzDesign, for example, Pairmixer delivers over 2x faster sampling and scales to sequences ~30% longer than the memory limits of Pairformer. Code is available at https://github.com/genesistherapeutics/pairmixer.",Bioinformatics
"AlphaFold has transformed protein structure prediction, but emerging applications such as virtual ligand screening, proteome-wide folding, and de novo binder design demand predictions at a massive scale, where runtime and memory costs become prohibitive. A major bottleneck lies in the Pairformer backbone of AlphaFold3-style models, which relies on computationally expensive triangular primitives-especially triangle attention-for pairwise reasoning. We introduce Pairmixer, a streamlined alternative that eliminates triangle attention while preserving higher-order geometric reasoning capabilities that are critical for structure prediction. Pairmixer substantially improves computational efficiency, matching state-of-the-art structure predictors across folding and docking benchmarks, delivering up to 4x faster inference on long sequences while reducing training cost by 34%. Its efficiency alleviates the computational burden of downstream applications such as modeling large protein complexes, high-throughput ligand and binder screening, and hallucination-based design. Within BoltzDesign, for example, Pairmixer delivers over 2x faster sampling and scales to sequences ~30% longer than the memory limits of Pairformer. Code is available at https://github.com/genesistherapeutics/pairmixer. [SEP] [HINT] computational -> Neuroscience (Syns: ) | structure -> Bioinformatics (Syns: social system, complex body part, social structure) | protein -> Bioinformatics (Syns: )",Bioinformatics
"We present Materium: an autoregressive transformer for generating crystal structures that converts 3D material representations into token sequences. These sequences include elements with oxidation states, fractional coordinates and lattice parameters. Unlike diffusion approaches, which refine atomic positions iteratively through many denoising steps, Materium places atoms at precise fractional coordinates, enabling fast, scalable generation. With this design, the model can be trained in a few hours on a single GPU and generate samples much faster on GPUs and CPUs than diffusion-based approaches. The model was trained and evaluated using multiple properties as conditions, including fundamental properties, such as density and space group, as well as more practical targets, such as band gap and magnetic density. In both single and combined conditions, the model performs consistently well, producing candidates that align with the requested inputs.",Materials Science
"We present Materium: an autoregressive transformer for generating crystal structures that converts 3D material representations into token sequences. These sequences include elements with oxidation states, fractional coordinates and lattice parameters. Unlike diffusion approaches, which refine atomic positions iteratively through many denoising steps, Materium places atoms at precise fractional coordinates, enabling fast, scalable generation. With this design, the model can be trained in a few hours on a single GPU and generate samples much faster on GPUs and CPUs than diffusion-based approaches. The model was trained and evaluated using multiple properties as conditions, including fundamental properties, such as density and space group, as well as more practical targets, such as band gap and magnetic density. In both single and combined conditions, the model performs consistently well, producing candidates that align with the requested inputs. [SEP] [HINT] space -> Neuroscience (Syns: distance, place, outer space) | including -> Bioinformatics (Syns: admit, include, let in) | crystal -> Materials Science (Syns: crystallization, quartz, lechatelierite)",Materials Science
"Erbium-based materials have long been recognized for their important telecom-band applications, yet their widespread adoption in integrated optoelectronics has been hindered by two fundamental limitations: the difficulty in achieving high erbium density without concentration quenching which leads to small optical gain in doped materials, and the difficulty in fabricating a practical device with single crystal nanowires that demonstrated high optical gain previously1,2. Here, we overcome these limitations by synthesizing 2D single crystal ErOCl that has an Er density of 1.75*1022 cm-3. The high-quality single crystal material significantly reduces the density-related quenching effect that dominates in randomly doped materials with high Er concentration. This results in a record optical gain coefficient over 1500 dB/cm at 1536 nm band, at least larger by an order of magnitude than the previous gain record in Er materials. Leveraging this exceptional gain medium, we demonstrate room-temperature continuous-wave lasing operation by integrating with a photonic crystal microcavity, achieving a record-low threshold of 7 μW with the most compact size of any Er-based lasers. Furthermore, the unique Stark splitting characteristics of ErOCl provide optical gain in three wavelength bands and lead to lasing in these wavelengths by engineering the cavity. This is the first time that optical gain has been shown in three different wavelength bands in Er materials, together with the smallest size of laser cavity, could have many important applications in on-chip sensing and optical communication.",Materials Science
"Erbium-based materials have long been recognized for their important telecom-band applications, yet their widespread adoption in integrated optoelectronics has been hindered by two fundamental limitations: the difficulty in achieving high erbium density without concentration quenching which leads to small optical gain in doped materials, and the difficulty in fabricating a practical device with single crystal nanowires that demonstrated high optical gain previously1,2. Here, we overcome these limitations by synthesizing 2D single crystal ErOCl that has an Er density of 1.75*1022 cm-3. The high-quality single crystal material significantly reduces the density-related quenching effect that dominates in randomly doped materials with high Er concentration. This results in a record optical gain coefficient over 1500 dB/cm at 1536 nm band, at least larger by an order of magnitude than the previous gain record in Er materials. Leveraging this exceptional gain medium, we demonstrate room-temperature continuous-wave lasing operation by integrating with a photonic crystal microcavity, achieving a record-low threshold of 7 μW with the most compact size of any Er-based lasers. Furthermore, the unique Stark splitting characteristics of ErOCl provide optical gain in three wavelength bands and lead to lasing in these wavelengths by engineering the cavity. This is the first time that optical gain has been shown in three different wavelength bands in Er materials, together with the smallest size of laser cavity, could have many important applications in on-chip sensing and optical communication. [SEP] [HINT] order -> Materials Science (Syns: enjoin, dictate, social club) | results -> Bioinformatics (Syns: final result, consequence, resultant role) | different -> Neuroscience (Syns: unlike, dissimilar)",Materials Science
"Understanding the interplay between charge order and lattice instability in quantum materials remains a central challenge, as their coexistence often obscures causal relationships. This work introduces $\mathrm{C}_6\mathrm{Li}$ as a novel platform to investigate charge order mediated by two distinct mechanisms. We show that the hybridization between carbon $π$ and lithium $s$ orbitals generates an effective long-range hopping within Li-centered hexagons. This hopping drives a Kekulé bond order, whose structure varies with charge density and the sign of the hopping. This bond order induces a Kekulé lattice distortion via electron-phonon coupling. In the limit where lithium atoms are distant from the graphene layer, a Fermi surface nesting-driven Kekulé bond order emerges, stabilized by the electron-phonon interaction. Our results establish $\mathrm{C}_6\mathrm{Li}$ as a tunable platform for elucidating the causal hierarchy between electronic and structural orders in quantum materials.",Materials Science
"Understanding the interplay between charge order and lattice instability in quantum materials remains a central challenge, as their coexistence often obscures causal relationships. This work introduces $\mathrm{C}_6\mathrm{Li}$ as a novel platform to investigate charge order mediated by two distinct mechanisms. We show that the hybridization between carbon $π$ and lithium $s$ orbitals generates an effective long-range hopping within Li-centered hexagons. This hopping drives a Kekulé bond order, whose structure varies with charge density and the sign of the hopping. This bond order induces a Kekulé lattice distortion via electron-phonon coupling. In the limit where lithium atoms are distant from the graphene layer, a Fermi surface nesting-driven Kekulé bond order emerges, stabilized by the electron-phonon interaction. Our results establish $\mathrm{C}_6\mathrm{Li}$ as a tunable platform for elucidating the causal hierarchy between electronic and structural orders in quantum materials. [SEP] [HINT] understanding -> Neuroscience (Syns: savvy, intellect, sympathy) | charge -> Materials Science (Syns: tear, bearing, burster) | electronic -> Materials Science (Syns: )",Materials Science
"Matrix-Assisted Laser Desorption/Ionization Time-of-Flight Mass Spectrometry (MALDI-TOF MS) has become a cornerstone technology in clinical microbiology, enabling rapid and accurate microbial identification. However, the development of data-driven diagnostic models remains limited by the lack of sufficiently large, balanced, and standardized spectral datasets. This study investigates the use of deep generative models to synthesize realistic MALDI-TOF MS spectra, aiming to overcome data scarcity and support the development of robust machine learning tools in microbiology.   We adapt and evaluate three generative models, Variational Autoencoders (MALDIVAEs), Generative Adversarial Networks (MALDIGANs), and Denoising Diffusion Probabilistic Model (MALDIffusion), for the conditional generation of microbial spectra guided by species labels. Generation is conditioned on species labels, and spectral fidelity and diversity are assessed using diverse metrics.   Our experiments show that synthetic data generated by MALDIVAE, MALDIGAN, and MALDIffusion are statistically and diagnostically comparable to real measurements, enabling classifiers trained exclusively on synthetic samples to reach performance levels similar to those trained on real data. While all models faithfully reproduce the peak structure and variability of MALDI-TOF spectra, MALDIffusion obtains this fidelity at a substantially higher computational cost, and MALDIGAN shows competitive but slightly less stable behaviour. In contrast, MALDIVAE offers the most favorable balance between realism, stability, and efficiency. Furthermore, augmenting minority species with synthetic spectra markedly improves classification accuracy, effectively mitigating class imbalance and domain mismatch without compromising the authenticity of the generated data.",Bioinformatics
"Matrix-Assisted Laser Desorption/Ionization Time-of-Flight Mass Spectrometry (MALDI-TOF MS) has become a cornerstone technology in clinical microbiology, enabling rapid and accurate microbial identification. However, the development of data-driven diagnostic models remains limited by the lack of sufficiently large, balanced, and standardized spectral datasets. This study investigates the use of deep generative models to synthesize realistic MALDI-TOF MS spectra, aiming to overcome data scarcity and support the development of robust machine learning tools in microbiology.   We adapt and evaluate three generative models, Variational Autoencoders (MALDIVAEs), Generative Adversarial Networks (MALDIGANs), and Denoising Diffusion Probabilistic Model (MALDIffusion), for the conditional generation of microbial spectra guided by species labels. Generation is conditioned on species labels, and spectral fidelity and diversity are assessed using diverse metrics.   Our experiments show that synthetic data generated by MALDIVAE, MALDIGAN, and MALDIffusion are statistically and diagnostically comparable to real measurements, enabling classifiers trained exclusively on synthetic samples to reach performance levels similar to those trained on real data. While all models faithfully reproduce the peak structure and variability of MALDI-TOF spectra, MALDIffusion obtains this fidelity at a substantially higher computational cost, and MALDIGAN shows competitive but slightly less stable behaviour. In contrast, MALDIVAE offers the most favorable balance between realism, stability, and efficiency. Furthermore, augmenting minority species with synthetic spectra markedly improves classification accuracy, effectively mitigating class imbalance and domain mismatch without compromising the authenticity of the generated data. [SEP] [HINT] clinical -> Bioinformatics (Syns: ) | computational -> Neuroscience (Syns: ) | learning -> Bioinformatics (Syns: take, teach, acquire)",Bioinformatics
"Soft X-ray angle resolved photoemission spectroscopy (SX-ARPES) is one of the most powerful spectroscopic techniques to visualize the three-dimensional bulk electronic structure in reciprocal lattice space. Compared with ARPES employing low-energy photon sources, the time burden imposed by a lower photoelectron yield, stemming from the photoionization cross-section, has been a persistent technical challenge. To address this challenge, we have developed a noise removal system by using the deep prior-based method and integrated it into the micro focused SX-ARPES (μSX-ARPES) system at BL25SU in SPring-8. Our implemented system effectively eliminates the grid and spike noise typically present in ARPES data acquired using the voltage Fixed-mode, within about 30 seconds. We demonstrate, through the μSX-ARPES measurements on a single crystal of CeRu2Si2, that data with sufficient statistical accuracy can be obtained in approximately 40 seconds. In addition, we present the potential of high signal-to-noise ratio ARPES measurement, achieving an energy resolution of 51.6 meV at an excitation energy of 708 eV in μSX-ARPES measurements on polycrystalline gold. Our developed system successfully reduces the time burden in SX-ARPES and paves the way for advancements in lower photoelectron yield measurements, such as those requiring higher energy resolution and three-dimensional nonequilibrium measurements.",Materials Science
"Soft X-ray angle resolved photoemission spectroscopy (SX-ARPES) is one of the most powerful spectroscopic techniques to visualize the three-dimensional bulk electronic structure in reciprocal lattice space. Compared with ARPES employing low-energy photon sources, the time burden imposed by a lower photoelectron yield, stemming from the photoionization cross-section, has been a persistent technical challenge. To address this challenge, we have developed a noise removal system by using the deep prior-based method and integrated it into the micro focused SX-ARPES (μSX-ARPES) system at BL25SU in SPring-8. Our implemented system effectively eliminates the grid and spike noise typically present in ARPES data acquired using the voltage Fixed-mode, within about 30 seconds. We demonstrate, through the μSX-ARPES measurements on a single crystal of CeRu2Si2, that data with sufficient statistical accuracy can be obtained in approximately 40 seconds. In addition, we present the potential of high signal-to-noise ratio ARPES measurement, achieving an energy resolution of 51.6 meV at an excitation energy of 708 eV in μSX-ARPES measurements on polycrystalline gold. Our developed system successfully reduces the time burden in SX-ARPES and paves the way for advancements in lower photoelectron yield measurements, such as those requiring higher energy resolution and three-dimensional nonequilibrium measurements. [SEP] [HINT] electronic -> Materials Science (Syns: ) | structure -> Bioinformatics (Syns: social system, complex body part, social structure) | crystal -> Materials Science (Syns: crystallization, quartz, lechatelierite)",Materials Science
"This work presents the development and evaluation of an NLP-enabled probabilistic classifier designed to estimate the probability of technical and regulatory success (pTRS) for clinical trials in the field of neuroscience. While pharmaceutical R&D is plagued by high attrition rates and enormous costs, particularly within neuroscience, where success rates are below 10%, timely identification of promising programs can streamline resource allocation and reduce financial risk. Leveraging data from the ClinicalTrials.gov database and success labels from the recently developed Clinical Trial Outcome dataset, the classifier extracts text-based clinical trial features using statistical NLP techniques. These features were integrated into several non-LLM frameworks (logistic regression, gradient boosting, and random forest) to generate calibrated probability scores. Model performance was assessed on a retrospective dataset of 101,145 completed clinical trials spanning 1976-2024, achieving an overall ROC-AUC of 0.64. An LLM-based predictive model was then built using BioBERT, a domain-specific language representation encoder. The BioBERT-based model achieved an overall ROC-AUC of 0.74 and a Brier Score of 0.185, indicating its predictions had, on average, 40% less squared error than would be observed using industry benchmarks. The BioBERT-based model also made trial outcome predictions that were superior to benchmark values 70% of the time overall. By integrating NLP-driven insights into drug development decision-making, this work aims to enhance strategic planning and optimize investment allocation in neuroscience programs.",Bioinformatics
"This work presents the development and evaluation of an NLP-enabled probabilistic classifier designed to estimate the probability of technical and regulatory success (pTRS) for clinical trials in the field of neuroscience. While pharmaceutical R&D is plagued by high attrition rates and enormous costs, particularly within neuroscience, where success rates are below 10%, timely identification of promising programs can streamline resource allocation and reduce financial risk. Leveraging data from the ClinicalTrials.gov database and success labels from the recently developed Clinical Trial Outcome dataset, the classifier extracts text-based clinical trial features using statistical NLP techniques. These features were integrated into several non-LLM frameworks (logistic regression, gradient boosting, and random forest) to generate calibrated probability scores. Model performance was assessed on a retrospective dataset of 101,145 completed clinical trials spanning 1976-2024, achieving an overall ROC-AUC of 0.64. An LLM-based predictive model was then built using BioBERT, a domain-specific language representation encoder. The BioBERT-based model achieved an overall ROC-AUC of 0.74 and a Brier Score of 0.185, indicating its predictions had, on average, 40% less squared error than would be observed using industry benchmarks. The BioBERT-based model also made trial outcome predictions that were superior to benchmark values 70% of the time overall. By integrating NLP-driven insights into drug development decision-making, this work aims to enhance strategic planning and optimize investment allocation in neuroscience programs. [SEP] [HINT] field -> Materials Science (Syns: field of honor, line of business, orbit) | clinical -> Bioinformatics (Syns: ) | language -> Neuroscience (Syns: linguistic process, linguistic communication, spoken communication)",Bioinformatics
"Motivation: Parameter estimation is a cornerstone of data-driven modeling in systems biology. Yet, constructing such problems in a reproducible and accessible manner remains challenging. The PEtab format has established itself as a powerful community standard to encode parameter estimation problems, promoting interoperability and reusability. However, its reliance on multiple interlinked files - often edited manually - can introduce inconsistencies, and new users often struggle to navigate them. Here, we present PEtab-GUI, an open-source Python application designed to streamline the creation, editing, and validation of PEtab problems through an intuitive graphical user interface. PEtab-GUI integrates all PEtab components, including SBML models and tabular files, into a single environment with live error-checking and customizable defaults. Interactive visualization and simulation capabilities enable users to inspect the relationship between the model and the data. PEtab-GUI lowers the barrier to entry for specifying standardized parameter estimation problems, making dynamic modeling more accessible, especially in educational and interdisciplinary settings.   Availability and Implementation: PEtab-GUI is implemented in Python, open-source under a 3-Clause BSD license. The code, designed to be modular and extensible, is hosted on https://github.com/PEtab-dev/PEtab-GUI and can be installed from PyPI.   Key words: Parameter Estimation, Python, Graphical User Interface, Systems Biology",Bioinformatics
"Motivation: Parameter estimation is a cornerstone of data-driven modeling in systems biology. Yet, constructing such problems in a reproducible and accessible manner remains challenging. The PEtab format has established itself as a powerful community standard to encode parameter estimation problems, promoting interoperability and reusability. However, its reliance on multiple interlinked files - often edited manually - can introduce inconsistencies, and new users often struggle to navigate them. Here, we present PEtab-GUI, an open-source Python application designed to streamline the creation, editing, and validation of PEtab problems through an intuitive graphical user interface. PEtab-GUI integrates all PEtab components, including SBML models and tabular files, into a single environment with live error-checking and customizable defaults. Interactive visualization and simulation capabilities enable users to inspect the relationship between the model and the data. PEtab-GUI lowers the barrier to entry for specifying standardized parameter estimation problems, making dynamic modeling more accessible, especially in educational and interdisciplinary settings.   Availability and Implementation: PEtab-GUI is implemented in Python, open-source under a 3-Clause BSD license. The code, designed to be modular and extensible, is hosted on https://github.com/PEtab-dev/PEtab-GUI and can be installed from PyPI.   Key words: Parameter Estimation, Python, Graphical User Interface, Systems Biology [SEP] [HINT] systems -> Bioinformatics (Syns: organization, organisation, system) | including -> Bioinformatics (Syns: admit, include, let in) | models -> Bioinformatics (Syns: framework, modelling, good example)",Bioinformatics
"Neurons, as eukaryotic cells, have powerful internal computation capabilities. One neuron can have many distinct states, and brains can use this capability. Processes of neuron growth and maintenance use chemical signalling between cell bodies and synapses, ferrying chemical messengers over microtubules and actin fibres within cells. These processes are computations which, while slower than neural electrical signalling, could allow any neuron to change its state over intervals of seconds or minutes. Based on its state, a single neuron can selectively de-activate some of its synapses, sculpting a dynamic neural net from the static neural connections of the brain. Without this dynamic selection, the static neural networks in brains are too amorphous and dilute to do the computations of neural cognitive models. The use of multi-state neurons in animal brains is illustrated in hierarchical Bayesian object recognition. Multi-state neurons may support a design which is more efficient than two-state neurons, and scales better as object complexity increases. Brains could have evolved to use multi-state neurons. Multi-state neurons could be used in artificial neural networks, to use a kind of non-Hebbian learning which is faster and more focused and controllable than traditional neural net learning. This possibility has not yet been explored in computational models.",Neuroscience
"Neurons, as eukaryotic cells, have powerful internal computation capabilities. One neuron can have many distinct states, and brains can use this capability. Processes of neuron growth and maintenance use chemical signalling between cell bodies and synapses, ferrying chemical messengers over microtubules and actin fibres within cells. These processes are computations which, while slower than neural electrical signalling, could allow any neuron to change its state over intervals of seconds or minutes. Based on its state, a single neuron can selectively de-activate some of its synapses, sculpting a dynamic neural net from the static neural connections of the brain. Without this dynamic selection, the static neural networks in brains are too amorphous and dilute to do the computations of neural cognitive models. The use of multi-state neurons in animal brains is illustrated in hierarchical Bayesian object recognition. Multi-state neurons may support a design which is more efficient than two-state neurons, and scales better as object complexity increases. Brains could have evolved to use multi-state neurons. Multi-state neurons could be used in artificial neural networks, to use a kind of non-Hebbian learning which is faster and more focused and controllable than traditional neural net learning. This possibility has not yet been explored in computational models. [SEP] [HINT] used -> Bioinformatics (Syns: utilize, ill-used, apply) | based -> Bioinformatics (Syns: ground, free-base, base) | computational -> Neuroscience (Syns: )",Neuroscience
"Given a sequence $s_1$ of $n$ letters drawn i.i.d. from an alphabet of size $σ$ and a mutated substring $s_2$ of length $m < n$, we often want to recover the mutation history that generated $s_2$ from $s_1$. Modern sequence aligners are widely used for this task, and many employ the seed-chain-extend heuristic with $k$-mer seeds. Previously, Shaw and Yu showed that optimal linear-gap cost chaining can produce a chain with $1 - O\left(\frac{1}{\sqrt{m}}\right)$ recoverability, the proportion of the mutation history that is recovered, in $O\left(mn^{2.43θ} \log n\right)$ expected time, where $θ< 0.206$ is the mutation rate under a substitution-only channel and $s_1$ is assumed to be uniformly random. However, a gap remains between theory and practice, since real genomic data includes insertions and deletions (indels), and yet seed-chain-extend remains effective. In this paper, we generalize those prior results by introducing mathematical machinery to deal with the two new obstacles introduced by indel channels: the dependence of neighboring anchors and the presence of anchors that are only partially correct. We are thus able   to prove that the expected recoverability of an optimal chain is $\ge 1 - O\Bigl(\frac{1}{\sqrt{m}}\Bigr)$ and the expected runtime is $O(mn^{3.15 \cdot θ_T}\log n)$, when the total mutation rate given by the sum of the substitution, insertion, and deletion mutation rates ($θ_T = θ_i + θ_d + θ_s$) is less than $0.159$.",Bioinformatics
"Given a sequence $s_1$ of $n$ letters drawn i.i.d. from an alphabet of size $σ$ and a mutated substring $s_2$ of length $m < n$, we often want to recover the mutation history that generated $s_2$ from $s_1$. Modern sequence aligners are widely used for this task, and many employ the seed-chain-extend heuristic with $k$-mer seeds. Previously, Shaw and Yu showed that optimal linear-gap cost chaining can produce a chain with $1 - O\left(\frac{1}{\sqrt{m}}\right)$ recoverability, the proportion of the mutation history that is recovered, in $O\left(mn^{2.43θ} \log n\right)$ expected time, where $θ< 0.206$ is the mutation rate under a substitution-only channel and $s_1$ is assumed to be uniformly random. However, a gap remains between theory and practice, since real genomic data includes insertions and deletions (indels), and yet seed-chain-extend remains effective. In this paper, we generalize those prior results by introducing mathematical machinery to deal with the two new obstacles introduced by indel channels: the dependence of neighboring anchors and the presence of anchors that are only partially correct. We are thus able   to prove that the expected recoverability of an optimal chain is $\ge 1 - O\Bigl(\frac{1}{\sqrt{m}}\Bigr)$ and the expected runtime is $O(mn^{3.15 \cdot θ_T}\log n)$, when the total mutation rate given by the sum of the substitution, insertion, and deletion mutation rates ($θ_T = θ_i + θ_d + θ_s$) is less than $0.159$. [SEP] [HINT] used -> Bioinformatics (Syns: utilize, ill-used, apply) | results -> Bioinformatics (Syns: final result, consequence, resultant role) | theory -> Materials Science (Syns: possibility, hypothesis)",Bioinformatics
"Long-term time-lapse imaging of biological samples requires correcting for focal drift, which would otherwise gradually push the sample out of focus. We present a software-based method that eliminates this time-dependent blur using only a motorized Z-drive, with no additional hardware. The method relies on imaging marks made on the side of the coverslip opposite to the sample. We provide a Beanshell script implementation, evaluate its performance across multiple objectives, and benchmark it against a hardware autofocus system, finding comparable results. Finally, we demonstrate its effectiveness in live imaging of growing bacterial colonies.",Bioinformatics
"Long-term time-lapse imaging of biological samples requires correcting for focal drift, which would otherwise gradually push the sample out of focus. We present a software-based method that eliminates this time-dependent blur using only a motorized Z-drive, with no additional hardware. The method relies on imaging marks made on the side of the coverslip opposite to the sample. We provide a Beanshell script implementation, evaluate its performance across multiple objectives, and benchmark it against a hardware autofocus system, finding comparable results. Finally, we demonstrate its effectiveness in live imaging of growing bacterial colonies. [SEP] [HINT] imaging -> Bioinformatics (Syns: imagery, imagination, visualise) | demonstrate -> Bioinformatics (Syns: evidence, march, prove) | performance -> Bioinformatics (Syns: functioning, operation, carrying out)",Bioinformatics
"Protein structure prediction has advanced significantly with the introduction of AlphaFold3, a diffusion-based model capable of predicting complex biomolecular interactions across proteins, nucleic acids, small molecules, and ions. While AlphaFold3 demonstrates high accuracy in folded proteins, its performance on intrinsically disordered proteins (IDPs), which comprise 30 to 40 percent of the human proteome and play critical roles in transcription, signaling, and disease, remains less explored. This study evaluated AlphaFold3's predictions of IDPs with a focus on intrinsically disordered regions (IDRs) using 72 proteins curated from the DisProt database. Predictions were generated across multiple random seeds and ensemble outputs, and residue-level pLDDT scores were compared with experimental disorder annotations. Our analysis reveals that 32 percent of residues are misaligned with DisProt, with percent representing hallucinations where AlphaFold3 incorrectly predicts order in disordered regions or vice versa. Additionally, 10 percent of residues exhibited context-driven misalignment, suggesting that AlphaFold3 implicitly incorporates stable structural assumptions. Importantly, 18 percent of residues associated with biological processes showed hallucinations, raising concerns about downstream implications in drug discovery and disease research. These findings highlight the limitations of AlphaFold3 in modeling IDRs, the need for refined hallucination metrics beyond the pLDDT, and the importance of integrating experimental disorder data to improve prediction reliability.",Bioinformatics
"Protein structure prediction has advanced significantly with the introduction of AlphaFold3, a diffusion-based model capable of predicting complex biomolecular interactions across proteins, nucleic acids, small molecules, and ions. While AlphaFold3 demonstrates high accuracy in folded proteins, its performance on intrinsically disordered proteins (IDPs), which comprise 30 to 40 percent of the human proteome and play critical roles in transcription, signaling, and disease, remains less explored. This study evaluated AlphaFold3's predictions of IDPs with a focus on intrinsically disordered regions (IDRs) using 72 proteins curated from the DisProt database. Predictions were generated across multiple random seeds and ensemble outputs, and residue-level pLDDT scores were compared with experimental disorder annotations. Our analysis reveals that 32 percent of residues are misaligned with DisProt, with percent representing hallucinations where AlphaFold3 incorrectly predicts order in disordered regions or vice versa. Additionally, 10 percent of residues exhibited context-driven misalignment, suggesting that AlphaFold3 implicitly incorporates stable structural assumptions. Importantly, 18 percent of residues associated with biological processes showed hallucinations, raising concerns about downstream implications in drug discovery and disease research. These findings highlight the limitations of AlphaFold3 in modeling IDRs, the need for refined hallucination metrics beyond the pLDDT, and the importance of integrating experimental disorder data to improve prediction reliability. [SEP] [HINT] structure -> Bioinformatics (Syns: social system, complex body part, social structure) | complex -> Bioinformatics (Syns: building complex, coordination compound, composite) | order -> Materials Science (Syns: enjoin, dictate, social club)",Bioinformatics
"Tracking cells in time-lapse videos is an essential technique for monitoring cell population dynamics at a single-cell level. Current methods for cell tracking are developed on videos with mostly single, constant signals and do not detect pivotal events such as cell death. Here, we present TransientTrack, a deep learning-based framework for cell tracking in multi-channel microscopy video data with transient fluorescent signals that fluctuate over time following processes such as the circadian rhythm of cells. By identifying key cellular events - mitosis (cell division) and apoptosis (cell death) our method allows us to build complete trajectories, including cell lineage information. TransientTrack is lightweight and performs matching on cell detection embeddings directly, without the need for quantification of tracking-specific cell features. Furthermore, our approach integrates Transformer Networks, multi-stage matching using all detection boxes, and the interpolation of missing tracklets with the Kalman Filter. This unified framework achieves strong performance across diverse conditions, effectively tracking cells and capturing cell division and death. We demonstrate the use of TransientTrack in an analysis of the efficacy of a chemotherapeutic drug at a single-cell level. The proposed framework could further advance quantitative studies of cancer cell dynamics, enabling detailed characterization of treatment response and resistance mechanisms. The code is available at https://github.com/bozeklab/TransientTrack.",Bioinformatics
"Tracking cells in time-lapse videos is an essential technique for monitoring cell population dynamics at a single-cell level. Current methods for cell tracking are developed on videos with mostly single, constant signals and do not detect pivotal events such as cell death. Here, we present TransientTrack, a deep learning-based framework for cell tracking in multi-channel microscopy video data with transient fluorescent signals that fluctuate over time following processes such as the circadian rhythm of cells. By identifying key cellular events - mitosis (cell division) and apoptosis (cell death) our method allows us to build complete trajectories, including cell lineage information. TransientTrack is lightweight and performs matching on cell detection embeddings directly, without the need for quantification of tracking-specific cell features. Furthermore, our approach integrates Transformer Networks, multi-stage matching using all detection boxes, and the interpolation of missing tracklets with the Kalman Filter. This unified framework achieves strong performance across diverse conditions, effectively tracking cells and capturing cell division and death. We demonstrate the use of TransientTrack in an analysis of the efficacy of a chemotherapeutic drug at a single-cell level. The proposed framework could further advance quantitative studies of cancer cell dynamics, enabling detailed characterization of treatment response and resistance mechanisms. The code is available at https://github.com/bozeklab/TransientTrack. [SEP] [HINT] performance -> Bioinformatics (Syns: functioning, operation, carrying out) | including -> Bioinformatics (Syns: admit, include, let in) | framework -> Bioinformatics (Syns: theoretical account, model, fabric)",Bioinformatics
"Application of electroencephalography (EEG) in educational research has grown substantially, yet a comprehensive integration of methodological frameworks, educational constructs, computational methods, and research gaps remains limited. This study applies a Bibliometric-enhanced Systematic Literature Review (BenSLR) to provide a systematic overview of EEG in education. Literature was extracted from Scopus, screened, and analyzed, with keyword co-occurrence evaluated using VOSviewer and emerging trends visualized through an Enhanced Strategic Diagram via BiblioPlot. Key findings include engagement, attention, and learning style as prominent constructs, with machine learning and deep learning frequently employed for modeling complex cognitive states. EEG signal processing, feature extraction, and assessment of cognitive and affective states were recurrent across studies. Innovative interventions such as virtual reality and neurofeedback demonstrate EEG's role in supporting adaptive and individualized learning experiences. Challenges remain in linking neural markers with observable learning behaviors, extending measurements beyond attention and working memory, and enhancing predictive model generalizability. The study demonstrates BenSLR's potential to integrate qualitative and quantitative perspectives and offers a transferable approach for other research areas to develop methodologies and evidence-based educational interventions.",Neuroscience
"Application of electroencephalography (EEG) in educational research has grown substantially, yet a comprehensive integration of methodological frameworks, educational constructs, computational methods, and research gaps remains limited. This study applies a Bibliometric-enhanced Systematic Literature Review (BenSLR) to provide a systematic overview of EEG in education. Literature was extracted from Scopus, screened, and analyzed, with keyword co-occurrence evaluated using VOSviewer and emerging trends visualized through an Enhanced Strategic Diagram via BiblioPlot. Key findings include engagement, attention, and learning style as prominent constructs, with machine learning and deep learning frequently employed for modeling complex cognitive states. EEG signal processing, feature extraction, and assessment of cognitive and affective states were recurrent across studies. Innovative interventions such as virtual reality and neurofeedback demonstrate EEG's role in supporting adaptive and individualized learning experiences. Challenges remain in linking neural markers with observable learning behaviors, extending measurements beyond attention and working memory, and enhancing predictive model generalizability. The study demonstrates BenSLR's potential to integrate qualitative and quantitative perspectives and offers a transferable approach for other research areas to develop methodologies and evidence-based educational interventions. [SEP] [HINT] computational -> Neuroscience (Syns: ) | learning -> Bioinformatics (Syns: take, teach, acquire) | complex -> Bioinformatics (Syns: building complex, coordination compound, composite)",Neuroscience
"Neuroeconomics promises to ground welfare analysis in neural and computational evidence about how people value outcomes, learn from experience and exercise self-control. At the same time, policy and commercial actors increasingly invoke neural data to justify paternalistic regulation, ""brain-based"" interventions and new welfare measures. This paper asks under what conditions neural data can legitimately inform welfare judgements for policy rather than merely describing behaviour. I develop a non-empirical, model-based framework that links three levels: neural signals, computational decision models and normative welfare criteria. Within an actor-critic reinforcement-learning model, I formalise the inference path from neural activity to latent values and prediction errors and then to welfare claims. I show that neural evidence constrains welfare judgements only when the neural-computational mapping is well validated, the decision model identifies ""true"" interests versus context-dependent mistakes, and the welfare criterion is explicitly specified and defended. Applying the framework to addiction, neuromarketing and environmental policy, I derive a Neuroeconomic Welfare Inference Checklist for regulators and for designers of NeuroAI systems. The analysis treats brains and artificial agents as value-learning systems while showing that internal reward signals, whether biological or artificial, are computational quantities and cannot be treated as welfare measures without an explicit normative model.",Neuroscience
"Neuroeconomics promises to ground welfare analysis in neural and computational evidence about how people value outcomes, learn from experience and exercise self-control. At the same time, policy and commercial actors increasingly invoke neural data to justify paternalistic regulation, ""brain-based"" interventions and new welfare measures. This paper asks under what conditions neural data can legitimately inform welfare judgements for policy rather than merely describing behaviour. I develop a non-empirical, model-based framework that links three levels: neural signals, computational decision models and normative welfare criteria. Within an actor-critic reinforcement-learning model, I formalise the inference path from neural activity to latent values and prediction errors and then to welfare claims. I show that neural evidence constrains welfare judgements only when the neural-computational mapping is well validated, the decision model identifies ""true"" interests versus context-dependent mistakes, and the welfare criterion is explicitly specified and defended. Applying the framework to addiction, neuromarketing and environmental policy, I derive a Neuroeconomic Welfare Inference Checklist for regulators and for designers of NeuroAI systems. The analysis treats brains and artificial agents as value-learning systems while showing that internal reward signals, whether biological or artificial, are computational quantities and cannot be treated as welfare measures without an explicit normative model. [SEP] [HINT] computational -> Neuroscience (Syns: ) | systems -> Bioinformatics (Syns: organization, organisation, system) | framework -> Bioinformatics (Syns: theoretical account, model, fabric)",Neuroscience
"Hidden Markov models (HMMs) have been used increasingly to understand how movement patterns of animals arise from behavioural states. An animal is assumed to transition between behavioural states through time, as described by transition probabilities. Within each state, the movement typically follows a discrete-time random walk, where steps between successive observed locations are described in terms of step lengths (related to speed) and turning angles (related to tortuosity). HMMs are discrete-time models, and most of their outputs strongly depend on the temporal resolution of data. We compile known theoretical results about scale dependence in Markov chains and correlated random walks, which are the most common components of HMMs for animal movement. We also illustrate this phenomenon using simulations covering a wide range of biological scenarios. The scale dependence affects not only all model parameters, i.e., the transition probabilities and the movement parameters within each behavioural state, but also the overall classification of movement patterns into states. This highlights the importance of carefully considering the time resolution when drawing conclusions from the results of analysis. In addition, scale dependence generally precludes the analysis of tracking data collected at irregular time intervals, and the comparison (or combination) of data sets with different sampling rates. HMMs remain a valuable tool to answer questions about animal movement and behaviour, as long as these limitations are well understood.",Bioinformatics
"Hidden Markov models (HMMs) have been used increasingly to understand how movement patterns of animals arise from behavioural states. An animal is assumed to transition between behavioural states through time, as described by transition probabilities. Within each state, the movement typically follows a discrete-time random walk, where steps between successive observed locations are described in terms of step lengths (related to speed) and turning angles (related to tortuosity). HMMs are discrete-time models, and most of their outputs strongly depend on the temporal resolution of data. We compile known theoretical results about scale dependence in Markov chains and correlated random walks, which are the most common components of HMMs for animal movement. We also illustrate this phenomenon using simulations covering a wide range of biological scenarios. The scale dependence affects not only all model parameters, i.e., the transition probabilities and the movement parameters within each behavioural state, but also the overall classification of movement patterns into states. This highlights the importance of carefully considering the time resolution when drawing conclusions from the results of analysis. In addition, scale dependence generally precludes the analysis of tracking data collected at irregular time intervals, and the comparison (or combination) of data sets with different sampling rates. HMMs remain a valuable tool to answer questions about animal movement and behaviour, as long as these limitations are well understood. [SEP] [HINT] used -> Bioinformatics (Syns: utilize, ill-used, apply) | transition -> Materials Science (Syns: passage, modulation, changeover) | results -> Bioinformatics (Syns: final result, consequence, resultant role)",Bioinformatics
"The integration of artificial intelligence (AI) in early-stage drug discovery offers unprecedented opportunities for exploring chemical space and accelerating hit-to-lead optimization. However, docking optimization in generative approaches is computationally expensive and may lead to inaccurate results. Here, we present a novel generative framework that balances pharmacophore similarity to reference compounds with structural diversity from active molecules. The framework allows users to provide custom reference sets, including FDA-approved drugs or clinical candidates, and guides the \textit{de novo} generation of potential therapeutics. We demonstrate its applicability through a case study targeting estrogen receptor modulators and antagonists for breast cancer. The generated compounds maintain high pharmacophoric fidelity to known active molecules while introducing substantial structural novelty, suggesting strong potential for functional innovation and patentability. Comprehensive evaluation of the generated molecules against common drug-like properties confirms the robustness and pharmaceutical relevance of the approach.",Bioinformatics
"The integration of artificial intelligence (AI) in early-stage drug discovery offers unprecedented opportunities for exploring chemical space and accelerating hit-to-lead optimization. However, docking optimization in generative approaches is computationally expensive and may lead to inaccurate results. Here, we present a novel generative framework that balances pharmacophore similarity to reference compounds with structural diversity from active molecules. The framework allows users to provide custom reference sets, including FDA-approved drugs or clinical candidates, and guides the \textit{de novo} generation of potential therapeutics. We demonstrate its applicability through a case study targeting estrogen receptor modulators and antagonists for breast cancer. The generated compounds maintain high pharmacophoric fidelity to known active molecules while introducing substantial structural novelty, suggesting strong potential for functional innovation and patentability. Comprehensive evaluation of the generated molecules against common drug-like properties confirms the robustness and pharmaceutical relevance of the approach. [SEP] [HINT] clinical -> Bioinformatics (Syns: ) | space -> Neuroscience (Syns: distance, place, outer space) | functional -> Neuroscience (Syns: working, usable, running)",Bioinformatics
"Electron tomography is a powerful tool for understanding the morphology of materials in three dimensions, but conventional reconstruction algorithms typically suffer from missing-wedge artifacts and data misalignment imposed by experimental constraints. Recently proposed supervised machine-learning-enabled reconstruction methods to address these challenges rely on training data and are therefore difficult to generalize across materials systems. We propose a fully self-supervised implicit neural representation (INR) approach using a neural network as a regularizer. Our approach enables fast inline alignment through pose optimization, missing wedge inpainting, and denoising of low dose datasets via model regularization using only a single dataset. We apply our method to simulated and experimental data and show that it produces high-quality tomograms from diverse and information limited datasets. Our results show that INR-based self-supervised reconstructions offer high fidelity reconstructions with minimal user input and preprocessing, and can be readily applied to a wide variety of materials samples and experimental parameters.",Materials Science
"Electron tomography is a powerful tool for understanding the morphology of materials in three dimensions, but conventional reconstruction algorithms typically suffer from missing-wedge artifacts and data misalignment imposed by experimental constraints. Recently proposed supervised machine-learning-enabled reconstruction methods to address these challenges rely on training data and are therefore difficult to generalize across materials systems. We propose a fully self-supervised implicit neural representation (INR) approach using a neural network as a regularizer. Our approach enables fast inline alignment through pose optimization, missing wedge inpainting, and denoising of low dose datasets via model regularization using only a single dataset. We apply our method to simulated and experimental data and show that it produces high-quality tomograms from diverse and information limited datasets. Our results show that INR-based self-supervised reconstructions offer high fidelity reconstructions with minimal user input and preprocessing, and can be readily applied to a wide variety of materials samples and experimental parameters. [SEP] [HINT] low -> Materials Science (Syns: low-spirited, scurvy, depressed) | understanding -> Neuroscience (Syns: savvy, intellect, sympathy) | information -> Bioinformatics (Syns: entropy, data, info)",Materials Science
"This study presents a comprehensive computational investigation of the vibration density of states (VDOS) of a silica nanopore, systematically evaluating a range of force fields against inelastic neutron scattering results. We analyze the influence of temperature, crustal structure, and surface-adsorbed water molecules on the nanopore's structural and dynamic properties. We performed classical molecular dynamics simulations of nanopore and bulk silica, and used density functional theory (DFT) calculations for bulk silica for comparison. The resulting VDOS shows relatively good agreement with DFT and experimental data. The temperature has a relatively low effect on the dry nanopore. The inclusion of H2O molecules significantly affects the VDOS. The low-energy modes are dominated by H2O VDOS and increase with loading. This work is an essential step towards characterizing silica nanopores via molecular dynamics and provides a valuable reference for experimental comparison with X-ray and neutron scattering VDOS results.",Materials Science
"This study presents a comprehensive computational investigation of the vibration density of states (VDOS) of a silica nanopore, systematically evaluating a range of force fields against inelastic neutron scattering results. We analyze the influence of temperature, crustal structure, and surface-adsorbed water molecules on the nanopore's structural and dynamic properties. We performed classical molecular dynamics simulations of nanopore and bulk silica, and used density functional theory (DFT) calculations for bulk silica for comparison. The resulting VDOS shows relatively good agreement with DFT and experimental data. The temperature has a relatively low effect on the dry nanopore. The inclusion of H2O molecules significantly affects the VDOS. The low-energy modes are dominated by H2O VDOS and increase with loading. This work is an essential step towards characterizing silica nanopores via molecular dynamics and provides a valuable reference for experimental comparison with X-ray and neutron scattering VDOS results. [SEP] [HINT] used -> Bioinformatics (Syns: utilize, ill-used, apply) | dft -> Materials Science (Syns: ) | low -> Materials Science (Syns: low-spirited, scurvy, depressed)",Materials Science
"This paper introduces variational representational similarity analysis RSA (vRSA) for electromagnetic recordings of neural responses (e.g., EEG, MEG, ECoG or LFP). Variational RSA is a Bayesian approach for testing whether the similarity of stimuli or experimental conditions is expressed in univariate or multivariate neural recordings. Extending an approach previously introduced in the context of functional MRI, vRSA decomposes the condition-by-condition data covariance matrix into hypothesised effects and observation noise, thereby casting RSA as a covariance component estimation problem. In this context, peristimulus time may be treated as an experimental factor, enabling one to test for the probability that different experimental effects are expressed in data at different times. Variational Bayesian methods are used for model estimation and model comparison, which confer a number of advantages over classical approaches, including statistically efficient hypothesis testing, quantification of uncertainty using Bayesian credible intervals and computational efficiency. After introducing the theory, we provide a worked example using openly available EEG data. Software functions implementing vRSA for the SPM software package accompany this paper, together with exemplar analysis scripts.",Neuroscience
"This paper introduces variational representational similarity analysis RSA (vRSA) for electromagnetic recordings of neural responses (e.g., EEG, MEG, ECoG or LFP). Variational RSA is a Bayesian approach for testing whether the similarity of stimuli or experimental conditions is expressed in univariate or multivariate neural recordings. Extending an approach previously introduced in the context of functional MRI, vRSA decomposes the condition-by-condition data covariance matrix into hypothesised effects and observation noise, thereby casting RSA as a covariance component estimation problem. In this context, peristimulus time may be treated as an experimental factor, enabling one to test for the probability that different experimental effects are expressed in data at different times. Variational Bayesian methods are used for model estimation and model comparison, which confer a number of advantages over classical approaches, including statistically efficient hypothesis testing, quantification of uncertainty using Bayesian credible intervals and computational efficiency. After introducing the theory, we provide a worked example using openly available EEG data. Software functions implementing vRSA for the SPM software package accompany this paper, together with exemplar analysis scripts. [SEP] [HINT] used -> Bioinformatics (Syns: utilize, ill-used, apply) | computational -> Neuroscience (Syns: ) | functional -> Neuroscience (Syns: working, usable, running)",Neuroscience
"Interband effects such as coherence/tunneling have recently been shown to give an important contribution to the charge and heat transport properties under certain conditions. These can be captured by adding corrective terms to the semiclassical Boltzmann transport equation. In recent derivations of this type of transport equations that are based on the density matrix formalism, there remain, however, certain omissions. These derivations also rely on a particular type of relaxation time approximation and a band-diagonal form of the interaction self-energies. In this work we derive the interband terms of the electronic Boltzmann transport equation starting from the Keldysh formulation of the quantum kinetic equation and considering the band non-diagonality of the electron-impurity and electron-phonon self-energies. We introduce a minimally modified Kadanoff-Baym Ansatz, and find a quantum-corrected, matrix Boltzmann transport equation that is well beyond the current state of the art theory. We show that the occupations and coherences are interdependent, and that the kinetic corrections due to the included interactions cannot, in general, be ignored. This work clarifies the various approximations that must be introduced in an ab initio derivation of Boltzmann-like equations and finds a new matrix Boltzmann transport equation that is suitable for parameters-free numerical implementations.",Materials Science
"Interband effects such as coherence/tunneling have recently been shown to give an important contribution to the charge and heat transport properties under certain conditions. These can be captured by adding corrective terms to the semiclassical Boltzmann transport equation. In recent derivations of this type of transport equations that are based on the density matrix formalism, there remain, however, certain omissions. These derivations also rely on a particular type of relaxation time approximation and a band-diagonal form of the interaction self-energies. In this work we derive the interband terms of the electronic Boltzmann transport equation starting from the Keldysh formulation of the quantum kinetic equation and considering the band non-diagonality of the electron-impurity and electron-phonon self-energies. We introduce a minimally modified Kadanoff-Baym Ansatz, and find a quantum-corrected, matrix Boltzmann transport equation that is well beyond the current state of the art theory. We show that the occupations and coherences are interdependent, and that the kinetic corrections due to the included interactions cannot, in general, be ignored. This work clarifies the various approximations that must be introduced in an ab initio derivation of Boltzmann-like equations and finds a new matrix Boltzmann transport equation that is suitable for parameters-free numerical implementations. [SEP] [HINT] based -> Bioinformatics (Syns: ground, free-base, base) | transport -> Materials Science (Syns: transferral, enthral, shipping) | charge -> Materials Science (Syns: tear, bearing, burster)",Materials Science
"Maintaining comfortable temperatures for buildings, humans, and devices consumes a substantial portion of global energy, underscoring the urgent need for energy-efficient thermoregulation technologies. Dynamic radiative thermal emitters that can switch between passive cooling and heating modes offer a promising solution, but most existing devices exhibit broadband optical responses, resulting in unwanted parasitic heat exchange and limited performance. Here, we introduce an elegant strategy that uses a dielectric cap to transform broadband metal-insulator transition (MIT) materials into spectrally selective dynamic emitters. This design creates a highly tunable Fabry-Perot cavity, enabling a tailored thermal emission spectrum by engineering the reflected-wave phase profile. Our Fresnel-formalism-based phasor diagram analysis reveals two key routes for realizing high spectral selectivity: a high-index dielectric cap and a low-loss metallic MIT state, which are further validated by Bayesian optimization. Following this principle, we demonstrated a wide-angle spectrally-selective thermoregulator operating in the atmospheric transparency window (8-13 um), where the thermal emittance can be electrically tuned from about 0.2 to 0.9 through reversible copper electrodeposition on a germanium cavity. Furthermore, this strategy can be extended to multispectral electrochromic windows, enabling switching between solar heating and spectrally-selective radiative cooling. Our work establishes a versatile and generalizable paradigm for spectral engineering of dynamic thermal emitters, opening opportunities in energy-efficient buildings, wearable thermal comfort, spacecraft thermoregulation, and multispectral camouflage.",Materials Science
"Maintaining comfortable temperatures for buildings, humans, and devices consumes a substantial portion of global energy, underscoring the urgent need for energy-efficient thermoregulation technologies. Dynamic radiative thermal emitters that can switch between passive cooling and heating modes offer a promising solution, but most existing devices exhibit broadband optical responses, resulting in unwanted parasitic heat exchange and limited performance. Here, we introduce an elegant strategy that uses a dielectric cap to transform broadband metal-insulator transition (MIT) materials into spectrally selective dynamic emitters. This design creates a highly tunable Fabry-Perot cavity, enabling a tailored thermal emission spectrum by engineering the reflected-wave phase profile. Our Fresnel-formalism-based phasor diagram analysis reveals two key routes for realizing high spectral selectivity: a high-index dielectric cap and a low-loss metallic MIT state, which are further validated by Bayesian optimization. Following this principle, we demonstrated a wide-angle spectrally-selective thermoregulator operating in the atmospheric transparency window (8-13 um), where the thermal emittance can be electrically tuned from about 0.2 to 0.9 through reversible copper electrodeposition on a germanium cavity. Furthermore, this strategy can be extended to multispectral electrochromic windows, enabling switching between solar heating and spectrally-selective radiative cooling. Our work establishes a versatile and generalizable paradigm for spectral engineering of dynamic thermal emitters, opening opportunities in energy-efficient buildings, wearable thermal comfort, spacecraft thermoregulation, and multispectral camouflage. [SEP] [HINT] transition -> Materials Science (Syns: passage, modulation, changeover) | work -> Bioinformatics (Syns: work out, process, bring) | existing -> Bioinformatics (Syns: subsist, existent, survive)",Materials Science
"An Ag-doped CuO-AgCl-g-C3N4 heterostructure has been designed to achieve rapid Methylene Blue (MB) degradation through a synergistic photo-Fenton mechanism driven by low-power UV illumination. The composite integrates narrow-bandgap CuO, plasmonic Ag/AgCl, and visible-responsive g-C3N4 into a dual Z-scheme configuration that promotes efficient interfacial charge transfer while preserving strong redox potentials. Diffuse reflectance UV-Vis spectra ascertained the bandgap positions of the composite corresponding to those of its constituents: 2.9 eV (g-C3N4) and 1.42 eV (Ag-doped CuO-AgCl), indicating enhanced absorption and efficient charge carrier generation. BET analysis confirmed the presence of mesoporosity and revealed an effective surface area, ensuring the availability of abundant adsorption and reaction sites. A commercial 11 W UV irradiation was used for the photocatalytic test. Almost complete degradation of MB occurred within 10 min, following pseudo-first-order kinetics with a high apparent rate constant of 0.45/min. The remarkable activity arises from the synergistic interplay of Fenton-like redox cycling and efficient photoinduced charge carrier generation and separation. In addition, it has been demonstrated that intentionally incorporated AgCl plays an active role as a plasmonic-semiconducting interface, strengthening charge separation and catalyst stability under neutral conditions, rather than acting as a passive chloride byproduct. Overall, by linking defect engineering, heterojunction design, and photo-Fenton synergy, this study establishes a low-power, catalytic platform offering a viable pathway towards sustainable dye wastewater remediation.",Materials Science
"An Ag-doped CuO-AgCl-g-C3N4 heterostructure has been designed to achieve rapid Methylene Blue (MB) degradation through a synergistic photo-Fenton mechanism driven by low-power UV illumination. The composite integrates narrow-bandgap CuO, plasmonic Ag/AgCl, and visible-responsive g-C3N4 into a dual Z-scheme configuration that promotes efficient interfacial charge transfer while preserving strong redox potentials. Diffuse reflectance UV-Vis spectra ascertained the bandgap positions of the composite corresponding to those of its constituents: 2.9 eV (g-C3N4) and 1.42 eV (Ag-doped CuO-AgCl), indicating enhanced absorption and efficient charge carrier generation. BET analysis confirmed the presence of mesoporosity and revealed an effective surface area, ensuring the availability of abundant adsorption and reaction sites. A commercial 11 W UV irradiation was used for the photocatalytic test. Almost complete degradation of MB occurred within 10 min, following pseudo-first-order kinetics with a high apparent rate constant of 0.45/min. The remarkable activity arises from the synergistic interplay of Fenton-like redox cycling and efficient photoinduced charge carrier generation and separation. In addition, it has been demonstrated that intentionally incorporated AgCl plays an active role as a plasmonic-semiconducting interface, strengthening charge separation and catalyst stability under neutral conditions, rather than acting as a passive chloride byproduct. Overall, by linking defect engineering, heterojunction design, and photo-Fenton synergy, this study establishes a low-power, catalytic platform offering a viable pathway towards sustainable dye wastewater remediation. [SEP] [HINT] used -> Bioinformatics (Syns: utilize, ill-used, apply) | charge -> Materials Science (Syns: tear, bearing, burster) | defect -> Materials Science (Syns: mar, shortcoming, fault)",Materials Science
"The past few years have seen the development of ``universal'' machine-learning interatomic potentials (uMLIPs) capable of approximating the ground-state potential energy surface across a wide range of chemical structures and compositions with reasonable accuracy. While these models differ in the architecture and the dataset used, they share the ability to compress a staggering amount of chemical information into descriptive latent features. Herein, we systematically analyze what the different uMLIPs have learned by quantitatively assessing the relative information content of their latent features with feature reconstruction errors as metrics, and observing how the trends are affected by the choice of training set and training protocol. We find that the uMLIPs encode chemical space in significantly distinct ways, with substantial cross-model feature reconstruction errors. When variants of the same model architecture are considered, trends become dependent on the dataset, target, and training protocol of choice. We also observe that fine-tuning of a uMLIP retains a strong pre-training bias in the latent features. Finally, we discuss how atom-level features, which are directly output by MLIPs, can be compressed into global structure-level features via concatenation of progressive cumulants, each adding significantly new information about the variability across the atomic environments within a given system.",Materials Science
"The past few years have seen the development of ``universal'' machine-learning interatomic potentials (uMLIPs) capable of approximating the ground-state potential energy surface across a wide range of chemical structures and compositions with reasonable accuracy. While these models differ in the architecture and the dataset used, they share the ability to compress a staggering amount of chemical information into descriptive latent features. Herein, we systematically analyze what the different uMLIPs have learned by quantitatively assessing the relative information content of their latent features with feature reconstruction errors as metrics, and observing how the trends are affected by the choice of training set and training protocol. We find that the uMLIPs encode chemical space in significantly distinct ways, with substantial cross-model feature reconstruction errors. When variants of the same model architecture are considered, trends become dependent on the dataset, target, and training protocol of choice. We also observe that fine-tuning of a uMLIP retains a strong pre-training bias in the latent features. Finally, we discuss how atom-level features, which are directly output by MLIPs, can be compressed into global structure-level features via concatenation of progressive cumulants, each adding significantly new information about the variability across the atomic environments within a given system. [SEP] [HINT] features -> Bioinformatics (Syns: characteristic, lineament, feature of speech) | space -> Neuroscience (Syns: distance, place, outer space) | information -> Bioinformatics (Syns: entropy, data, info)",Materials Science
"Freestanding thin films, a class of low-dimensional materials capable of maintaining structural integrity without substrates, have emerged as a forefront research focus. Their unique advantages-circumventing substrate clamping, liberating intrinsic material properties, and enabling cross-platform heterogeneous integration-underpin this prominence. This review systematically summarizes core fabrication techniques, including physical delamination (e.g., laser lift-off, mechanical exfoliation) and chemical etching, alongside associated transfer strategies. It further explores the induced strain modulation mechanisms, extreme mechanical properties and interface decoupling effects enabled by these films. Representative case studies demonstrate breakthrough applications in flexible/ultrathin electronics, ultrahigh-sensitivity sensors and the exploration of novel quantum states. Critical challenges regarding scalable fabrication, precise interface control, and long-term stability are analyzed, concluding with prospects for emerging applications in bio-inspired intelligent devices, quantum precision sensing, and brain-inspired neural networks.",Materials Science
"Freestanding thin films, a class of low-dimensional materials capable of maintaining structural integrity without substrates, have emerged as a forefront research focus. Their unique advantages-circumventing substrate clamping, liberating intrinsic material properties, and enabling cross-platform heterogeneous integration-underpin this prominence. This review systematically summarizes core fabrication techniques, including physical delamination (e.g., laser lift-off, mechanical exfoliation) and chemical etching, alongside associated transfer strategies. It further explores the induced strain modulation mechanisms, extreme mechanical properties and interface decoupling effects enabled by these films. Representative case studies demonstrate breakthrough applications in flexible/ultrathin electronics, ultrahigh-sensitivity sensors and the exploration of novel quantum states. Critical challenges regarding scalable fabrication, precise interface control, and long-term stability are analyzed, concluding with prospects for emerging applications in bio-inspired intelligent devices, quantum precision sensing, and brain-inspired neural networks. [SEP] [HINT] including -> Bioinformatics (Syns: admit, include, let in) | strain -> Materials Science (Syns: air, stock, form) | materials -> Materials Science (Syns: stuff, cloth, material)",Materials Science
"Two-dimensional carbon nitride materials have been the center of attention for their diverse usage in energy harvesting, environmental remediation and nanoelectronic applications. A broad range of utilities with decent synthetic plausibility have made this family a sweet spot to dive into, whereas the underlying analytical aspects are yet to have prominence. Recently, using the machinaries of first principles, we reported a family of six different structures C3NX with a unique dumbbell-shaped morphology, functionalizing the recently synthesized monolayer of C3N. Here we have critically explored the non-trivial topological phases of the semimetallic Dumbbell C3NX sheets and nanoribbons. Spin-orbit coupling induced gap across the Fermi level, its subsequent tuning via an external electric field, portrayal of band inversion from the Berry curvature distribution and the evaluation of topological index using the Wannier charge center (WCC) firmly establishes the traces of topological footprint. The real space decimation scheme and Green function technique evaluate the underlying spectral information with corresponding transport characteristics. Fascinating features of these quasi-1D systems are observed utilizing the Su-Schrieffer-Heeger (SSH) model where different twisted phases reveal distinct topological signatures even in a low atomic mass system like DB C4N.",Materials Science
"Two-dimensional carbon nitride materials have been the center of attention for their diverse usage in energy harvesting, environmental remediation and nanoelectronic applications. A broad range of utilities with decent synthetic plausibility have made this family a sweet spot to dive into, whereas the underlying analytical aspects are yet to have prominence. Recently, using the machinaries of first principles, we reported a family of six different structures C3NX with a unique dumbbell-shaped morphology, functionalizing the recently synthesized monolayer of C3N. Here we have critically explored the non-trivial topological phases of the semimetallic Dumbbell C3NX sheets and nanoribbons. Spin-orbit coupling induced gap across the Fermi level, its subsequent tuning via an external electric field, portrayal of band inversion from the Berry curvature distribution and the evaluation of topological index using the Wannier charge center (WCC) firmly establishes the traces of topological footprint. The real space decimation scheme and Green function technique evaluate the underlying spectral information with corresponding transport characteristics. Fascinating features of these quasi-1D systems are observed utilizing the Su-Schrieffer-Heeger (SSH) model where different twisted phases reveal distinct topological signatures even in a low atomic mass system like DB C4N. [SEP] [HINT] low -> Materials Science (Syns: low-spirited, scurvy, depressed) | features -> Bioinformatics (Syns: characteristic, lineament, feature of speech) | transport -> Materials Science (Syns: transferral, enthral, shipping)",Materials Science
"The selection of appropriate medical imaging procedures is a critical and complex clinical decision, guided by extensive evidence-based standards such as the ACR Appropriateness Criteria (ACR-AC). However, the underutilization of these guidelines, stemming from the difficulty of mapping unstructured patient narratives to structured criteria, contributes to suboptimal patient outcomes and increased healthcare costs. To bridge this gap, we introduce a multi-agent cognitive architecture that automates the translation of free-text clinical scenarios into specific, guideline-adherent imaging recommendations. Our system leverages a novel, domain-adapted dense retrieval model, ColBERT, fine-tuned on a synthetically generated dataset of 8,840 clinical scenario-recommendation pairs to achieve highly accurate information retrieval from the ACR-AC knowledge base. This retriever identifies candidate guidelines with a 93.9% top-10 recall, which are then processed by a sequence of LLM-based agents for selection and evidence-based synthesis. We evaluate our architecture using GPT-4.1 and MedGemma agents, demonstrating a state-of-the-art exact match accuracy of 81%, meaning that in 81% of test cases the predicted procedure set was identical to the guideline's reference set, and an F1-score of 0.879. This represents a 67-percentage-point absolute improvement in accuracy over a strong standalone GPT-4.1 baseline, underscoring the contribution that our architecture makes to a frontier model. These results were obtained on a challenging test set with substantial lexical divergence from the source guidelines. Our code is available at https://anonymous.4open.science/r/demo-iclr-B567/",Bioinformatics
"The selection of appropriate medical imaging procedures is a critical and complex clinical decision, guided by extensive evidence-based standards such as the ACR Appropriateness Criteria (ACR-AC). However, the underutilization of these guidelines, stemming from the difficulty of mapping unstructured patient narratives to structured criteria, contributes to suboptimal patient outcomes and increased healthcare costs. To bridge this gap, we introduce a multi-agent cognitive architecture that automates the translation of free-text clinical scenarios into specific, guideline-adherent imaging recommendations. Our system leverages a novel, domain-adapted dense retrieval model, ColBERT, fine-tuned on a synthetically generated dataset of 8,840 clinical scenario-recommendation pairs to achieve highly accurate information retrieval from the ACR-AC knowledge base. This retriever identifies candidate guidelines with a 93.9% top-10 recall, which are then processed by a sequence of LLM-based agents for selection and evidence-based synthesis. We evaluate our architecture using GPT-4.1 and MedGemma agents, demonstrating a state-of-the-art exact match accuracy of 81%, meaning that in 81% of test cases the predicted procedure set was identical to the guideline's reference set, and an F1-score of 0.879. This represents a 67-percentage-point absolute improvement in accuracy over a strong standalone GPT-4.1 baseline, underscoring the contribution that our architecture makes to a frontier model. These results were obtained on a challenging test set with substantial lexical divergence from the source guidelines. Our code is available at https://anonymous.4open.science/r/demo-iclr-B567/ [SEP] [HINT] clinical -> Bioinformatics (Syns: ) | information -> Bioinformatics (Syns: entropy, data, info) | complex -> Bioinformatics (Syns: building complex, coordination compound, composite)",Bioinformatics
"The interplay between real and reciprocal space topology yields intrinsically linked transport phenomena in magnetic Weyl systems, wherein the broken time-reversal symmetry, strong Dzyaloshinskii-Moriya interaction, and pronounced uniaxial anisotropy stabilize the momentum-space Berry-curvature monopoles (Weyl nodes) and real-space chiral spin textures. We present a combined first-principles and experimental study of epitaxial Fe5Si3 thin films, establishing them as a magnetic Weyl nodal-line material. First-principles Density Functional Theory (DFT) calculations unambiguously reveal that Fe5Si3 hosts a topologically nontrivial electronic structure containing six pairs of Weyl nodes at or near the Fermi level, accompanied by pronounced Berry curvature at high-symmetry points of the Brillouin Zone. High-quality epitaxial films exhibit robust ferromagnetism with a Curie temperature of ~370 K and strong magneto crystalline anisotropy. The magneto transport measurements on epitaxial films reveal the corresponding Berry curvature-driven responses, including a significantly large intrinsic anomalous Hall conductivity of 504 S/cm and a high anomalous Hall angle of 5.5%, which is in good agreement with DFT calculations. A negative and non-saturating longitudinal magnetoresistance is observed, consistent with a chiral-anomaly contribution from Weyl fermions near the Fermi level (EF). Furthermore, a substantial topological Hall resistivity of 1.6 μΩ cm robust across a wide temperature range, indicating the possibility of robust chiral spin textures in the thin-film geometry. These combined theoretical and experimental results establish Fe5Si3 as a unique, low-cost, centrosymmetric magnetic Weyl nodal-line material, providing a versatile platform for exploring coupled real and reciprocal space topologies in topological spintronic applications.",Materials Science
"The interplay between real and reciprocal space topology yields intrinsically linked transport phenomena in magnetic Weyl systems, wherein the broken time-reversal symmetry, strong Dzyaloshinskii-Moriya interaction, and pronounced uniaxial anisotropy stabilize the momentum-space Berry-curvature monopoles (Weyl nodes) and real-space chiral spin textures. We present a combined first-principles and experimental study of epitaxial Fe5Si3 thin films, establishing them as a magnetic Weyl nodal-line material. First-principles Density Functional Theory (DFT) calculations unambiguously reveal that Fe5Si3 hosts a topologically nontrivial electronic structure containing six pairs of Weyl nodes at or near the Fermi level, accompanied by pronounced Berry curvature at high-symmetry points of the Brillouin Zone. High-quality epitaxial films exhibit robust ferromagnetism with a Curie temperature of ~370 K and strong magneto crystalline anisotropy. The magneto transport measurements on epitaxial films reveal the corresponding Berry curvature-driven responses, including a significantly large intrinsic anomalous Hall conductivity of 504 S/cm and a high anomalous Hall angle of 5.5%, which is in good agreement with DFT calculations. A negative and non-saturating longitudinal magnetoresistance is observed, consistent with a chiral-anomaly contribution from Weyl fermions near the Fermi level (EF). Furthermore, a substantial topological Hall resistivity of 1.6 μΩ cm robust across a wide temperature range, indicating the possibility of robust chiral spin textures in the thin-film geometry. These combined theoretical and experimental results establish Fe5Si3 as a unique, low-cost, centrosymmetric magnetic Weyl nodal-line material, providing a versatile platform for exploring coupled real and reciprocal space topologies in topological spintronic applications. [SEP] [HINT] dft -> Materials Science (Syns: ) | spin -> Materials Science (Syns: twisting, whirl, tailspin) | transport -> Materials Science (Syns: transferral, enthral, shipping)",Materials Science
"The human visual system exhibits non-uniform spatial resolution across the visual field, which is characterized by the cortical magnification factor (CMF) that reflects its anatomical basis. However, current approaches for quantifying CMF using retinotopic maps derived from BOLD functional magnetic resonance imaging (fMRI) are limited by the inherent low signal-to-noise ratio of fMRI data and inaccuracies in the topological relationships of the retinotopic maps. In this study, we introduced a new pipeline to quantify planar CMF from retinotopic maps generated from the population receptive field (pRF) model. The pipeline projected the 3D pRF solutions onto a 2D planar disk, using optimal transport (OT) to preserve local cortical surface areas, and applied topological smoothing to ensure that the resulting retinotopic maps maintain their topology. We then estimated 2D CMF maps from the projected retinotopic maps on the planar disk using the 1-ring patch method. Applying this pipeline to the Human Connectome Project (HCP) 7T dataset, we revealed previously unobserved CMF patterns across the visual field and demonstrated individual differences among the 181 subjects. The pipeline was further validated on the New York University (NYU) 3T dataset, showing reliable and repeatable results. Our study provided new analytical methods and offered novel insights into visual processing.",Neuroscience
"The human visual system exhibits non-uniform spatial resolution across the visual field, which is characterized by the cortical magnification factor (CMF) that reflects its anatomical basis. However, current approaches for quantifying CMF using retinotopic maps derived from BOLD functional magnetic resonance imaging (fMRI) are limited by the inherent low signal-to-noise ratio of fMRI data and inaccuracies in the topological relationships of the retinotopic maps. In this study, we introduced a new pipeline to quantify planar CMF from retinotopic maps generated from the population receptive field (pRF) model. The pipeline projected the 3D pRF solutions onto a 2D planar disk, using optimal transport (OT) to preserve local cortical surface areas, and applied topological smoothing to ensure that the resulting retinotopic maps maintain their topology. We then estimated 2D CMF maps from the projected retinotopic maps on the planar disk using the 1-ring patch method. Applying this pipeline to the Human Connectome Project (HCP) 7T dataset, we revealed previously unobserved CMF patterns across the visual field and demonstrated individual differences among the 181 subjects. The pipeline was further validated on the New York University (NYU) 3T dataset, showing reliable and repeatable results. Our study provided new analytical methods and offered novel insights into visual processing. [SEP] [HINT] field -> Materials Science (Syns: field of honor, line of business, orbit) | low -> Materials Science (Syns: low-spirited, scurvy, depressed) | cortical -> Neuroscience (Syns: )",Neuroscience
"Despite many years of research, the quest to identify neural correlates of perceptual consciousness (NCC) remains unresolved. One major obstacle lies in methodological limitations: most studies rely on non-invasive neural measures with limited spatial or temporal resolution making it difficult to disentangle proper NCCs from concurrent cognitive processes. Additionally, the relatively low sensitivity of non-invasive neural measures limits the interpretation of null findings in studies targeting proper NCCs. In this review, we discuss how human intracranial recordings can advance the search for NCCs, by offering high spatiotemporal resolution, improved signal sensitivity, and broad cortical and subcortical coverage. We review studies that have examined NCCs at the level of single neurons and populations of neurons, and evaluate their implications on the debates between cognitive and sensory theories of consciousness. Finally, we highlight the limits of current intracranial human recordings and propose future directions based on emerging technologies and novel experimental paradigms.",Neuroscience
"Despite many years of research, the quest to identify neural correlates of perceptual consciousness (NCC) remains unresolved. One major obstacle lies in methodological limitations: most studies rely on non-invasive neural measures with limited spatial or temporal resolution making it difficult to disentangle proper NCCs from concurrent cognitive processes. Additionally, the relatively low sensitivity of non-invasive neural measures limits the interpretation of null findings in studies targeting proper NCCs. In this review, we discuss how human intracranial recordings can advance the search for NCCs, by offering high spatiotemporal resolution, improved signal sensitivity, and broad cortical and subcortical coverage. We review studies that have examined NCCs at the level of single neurons and populations of neurons, and evaluate their implications on the debates between cognitive and sensory theories of consciousness. Finally, we highlight the limits of current intracranial human recordings and propose future directions based on emerging technologies and novel experimental paradigms. [SEP] [HINT] low -> Materials Science (Syns: low-spirited, scurvy, depressed) | based -> Bioinformatics (Syns: ground, free-base, base) | cortical -> Neuroscience (Syns: )",Neuroscience
We report proof-of-concept measurements of the magnetocaloric effect (MCE) in ultrahigh magnetic fields up to 120 T for the classical spin-ice compound Ho$_{2}$Ti$_{2}$O$_{7}$. Radio-frequency resistivity measurements using an Au$_{16}$Ge$_{84}$ thin-film thermometer enable us to detect a rapid change in the sample temperature associated with a crystal-field level crossing in the high-field region in addition to a giant MCE at low fields. We discuss a possible delay in the temperature response and outline prospects for more precise MCE measurements in destructive pulsed fields.,Materials Science
"We report proof-of-concept measurements of the magnetocaloric effect (MCE) in ultrahigh magnetic fields up to 120 T for the classical spin-ice compound Ho$_{2}$Ti$_{2}$O$_{7}$. Radio-frequency resistivity measurements using an Au$_{16}$Ge$_{84}$ thin-film thermometer enable us to detect a rapid change in the sample temperature associated with a crystal-field level crossing in the high-field region in addition to a giant MCE at low fields. We discuss a possible delay in the temperature response and outline prospects for more precise MCE measurements in destructive pulsed fields. [SEP] [HINT] measurements -> Materials Science (Syns: mensuration, measure, measurement) | temperature -> Materials Science (Syns: ) | level -> Bioinformatics (Syns: level off, raze, layer)",Materials Science
"We introduce EEG Autoclean Vision Language AI (ICVision) a first-of-its-kind system that emulates expert-level EEG ICA component classification through AI-agent vision and natural language reasoning. Unlike conventional classifiers such as ICLabel, which rely on handcrafted features, ICVision directly interprets ICA dashboard visualizations topography, time series, power spectra, and ERP plots, using a multimodal large language model (GPT-4 Vision). This allows the AI to see and explain EEG components the way trained neurologists do, making it the first scientific implementation of AI-agent visual cognition in neurophysiology. ICVision classifies each component into one of six canonical categories (brain, eye, heart, muscle, channel noise, and other noise), returning both a confidence score and a human-like explanation. Evaluated on 3,168 ICA components from 124 EEG datasets, ICVision achieved k = 0.677 agreement with expert consensus, surpassing MNE ICLabel, while also preserving clinically relevant brain signals in ambiguous cases. Over 97% of its outputs were rated as interpretable and actionable by expert reviewers. As a core module of the open-source EEG Autoclean platform, ICVision signals a paradigm shift in scientific AI, where models do not just classify, but see, reason, and communicate. It opens the door to globally scalable, explainable, and reproducible EEG workflows, marking the emergence of AI agents capable of expert-level visual decision-making in brain science and beyond.",Bioinformatics
"We introduce EEG Autoclean Vision Language AI (ICVision) a first-of-its-kind system that emulates expert-level EEG ICA component classification through AI-agent vision and natural language reasoning. Unlike conventional classifiers such as ICLabel, which rely on handcrafted features, ICVision directly interprets ICA dashboard visualizations topography, time series, power spectra, and ERP plots, using a multimodal large language model (GPT-4 Vision). This allows the AI to see and explain EEG components the way trained neurologists do, making it the first scientific implementation of AI-agent visual cognition in neurophysiology. ICVision classifies each component into one of six canonical categories (brain, eye, heart, muscle, channel noise, and other noise), returning both a confidence score and a human-like explanation. Evaluated on 3,168 ICA components from 124 EEG datasets, ICVision achieved k = 0.677 agreement with expert consensus, surpassing MNE ICLabel, while also preserving clinically relevant brain signals in ambiguous cases. Over 97% of its outputs were rated as interpretable and actionable by expert reviewers. As a core module of the open-source EEG Autoclean platform, ICVision signals a paradigm shift in scientific AI, where models do not just classify, but see, reason, and communicate. It opens the door to globally scalable, explainable, and reproducible EEG workflows, marking the emergence of AI agents capable of expert-level visual decision-making in brain science and beyond. [SEP] [HINT] language -> Neuroscience (Syns: linguistic process, linguistic communication, spoken communication) | visual -> Neuroscience (Syns: optical, ocular, optic) | using -> Bioinformatics (Syns: utilize, exploitation, apply)",Bioinformatics
"Brains learn to represent information from a large set of stimuli, typically by weak supervision. Unsupervised learning is therefore a natural approach for exploring the design of biological neural networks and their computations. Accordingly, redundancy reduction has been suggested as a prominent design principle of neural encoding, but its ``mechanistic'' biological implementation is unclear. Analogously, unsupervised training of artificial neural networks yields internal representations that allow for accurate stimulus classification or decoding, but typically rely on biologically-implausible implementations. We suggest that interactions between parallel subnetworks in the brain may underlie such learning: we present a model of representation learning by ensembles of neural networks, where each network learns to encode stimuli into an abstract representation space by cross-supervising interactions with other networks, for inputs they receive simultaneously or in close temporal proximity. Aiming for biological plausibility, each network has a small ``receptive field'', thus receiving a fixed part of the external input, and the networks do not share weights. We find that for different types of network architectures, and for both visual or neuronal stimuli, these cross-supervising networks learn semantic representations that are easily decodable and that decoding accuracy is comparable to supervised networks -- both at the level of single networks and the ensemble. We further show that performance is optimal for small receptive fields, and that sparse connectivity between networks is nearly as accurate as all-to-all interactions, with far fewer computations. We thus suggest a sparsely interacting collective of cross-supervising networks as an algorithmic framework for representational learning and collective computation in the brain.",Neuroscience
"Brains learn to represent information from a large set of stimuli, typically by weak supervision. Unsupervised learning is therefore a natural approach for exploring the design of biological neural networks and their computations. Accordingly, redundancy reduction has been suggested as a prominent design principle of neural encoding, but its ``mechanistic'' biological implementation is unclear. Analogously, unsupervised training of artificial neural networks yields internal representations that allow for accurate stimulus classification or decoding, but typically rely on biologically-implausible implementations. We suggest that interactions between parallel subnetworks in the brain may underlie such learning: we present a model of representation learning by ensembles of neural networks, where each network learns to encode stimuli into an abstract representation space by cross-supervising interactions with other networks, for inputs they receive simultaneously or in close temporal proximity. Aiming for biological plausibility, each network has a small ``receptive field'', thus receiving a fixed part of the external input, and the networks do not share weights. We find that for different types of network architectures, and for both visual or neuronal stimuli, these cross-supervising networks learn semantic representations that are easily decodable and that decoding accuracy is comparable to supervised networks -- both at the level of single networks and the ensemble. We further show that performance is optimal for small receptive fields, and that sparse connectivity between networks is nearly as accurate as all-to-all interactions, with far fewer computations. We thus suggest a sparsely interacting collective of cross-supervising networks as an algorithmic framework for representational learning and collective computation in the brain. [SEP] [HINT] decoding -> Neuroscience (Syns: decrypt, decipherment, decryption) | connectivity -> Neuroscience (Syns: ) | learning -> Bioinformatics (Syns: take, teach, acquire)",Neuroscience
"Stroke is a leading cause of disability and death worldwide, with ischemic strokes accounting for nearly 80% of cases. Fewer than 5% of patients receive the sole validated pharmacotherapy, intravenous thrombolysis, highlighting the urgent need for novel therapies. Within this landscape, the exploration of natural molecules emerges as a promising avenue, particularly as a means to address limitations associated with conventional drugs. Nutraceuticals, bioactive compounds derived from food sources, offer a compelling prospect for health and wellness. The term nutraceutical reflects their dual potential in nutrition and pharmacotherapy, emphasizing their relevance to both disease prevention and treatment. Interestingly, many were initially recognized as ''natural preconditioners'', substances that prime the body for protection against stress or damage. In fact, numerous nutraceuticals have been shown to activate protective pathways similar to those triggered by preconditioning across various organs. Among nutraceuticals, omega-3 polyunsaturated fatty acids sourced from plants or fish, along with polyphenols, have emerged as particularly promising. Their consumption has been associated with a reduced risk of ischemic stroke, supported by numerous preclinical studies demonstrating their beneficial effects on cellular components within the neurovascular unit. This review explores the shared protective mechanisms of various nutraceuticals against key drivers of ischemic injury, including excitotoxicity, oxidative stress, apoptosis, and inflammation. By delineating these actions, the review highlights the potential of nutraceuticals as brain preconditioners that enhance neuroprotection, thereby mitigating the impact of cerebral ischemia in both preventive and therapeutic contexts.",Neuroscience
"Stroke is a leading cause of disability and death worldwide, with ischemic strokes accounting for nearly 80% of cases. Fewer than 5% of patients receive the sole validated pharmacotherapy, intravenous thrombolysis, highlighting the urgent need for novel therapies. Within this landscape, the exploration of natural molecules emerges as a promising avenue, particularly as a means to address limitations associated with conventional drugs. Nutraceuticals, bioactive compounds derived from food sources, offer a compelling prospect for health and wellness. The term nutraceutical reflects their dual potential in nutrition and pharmacotherapy, emphasizing their relevance to both disease prevention and treatment. Interestingly, many were initially recognized as ''natural preconditioners'', substances that prime the body for protection against stress or damage. In fact, numerous nutraceuticals have been shown to activate protective pathways similar to those triggered by preconditioning across various organs. Among nutraceuticals, omega-3 polyunsaturated fatty acids sourced from plants or fish, along with polyphenols, have emerged as particularly promising. Their consumption has been associated with a reduced risk of ischemic stroke, supported by numerous preclinical studies demonstrating their beneficial effects on cellular components within the neurovascular unit. This review explores the shared protective mechanisms of various nutraceuticals against key drivers of ischemic injury, including excitotoxicity, oxidative stress, apoptosis, and inflammation. By delineating these actions, the review highlights the potential of nutraceuticals as brain preconditioners that enhance neuroprotection, thereby mitigating the impact of cerebral ischemia in both preventive and therapeutic contexts. [SEP] [HINT] including -> Bioinformatics (Syns: admit, include, let in) | potential -> Bioinformatics (Syns: voltage, potential difference, electric potential) | novel -> Bioinformatics (Syns: refreshing, fresh, new)",Neuroscience
"Spatial Transcriptomics (ST) is a technology that measures gene expression profiles within tissue sections while retaining spatial context. It reveals localized gene expression patterns and tissue heterogeneity, both of which are essential for understanding disease etiology. However, its high cost has driven efforts to predict spatial gene expression from whole slide images. Despite recent advancements, current methods still face significant limitations, such as under-exploitation of high-level biological context, over-reliance on exemplar retrievals, and inadequate alignment of heterogeneous modalities. To address these challenges, we propose DKAN, a novel Dual-path Knowledge-Augmented contrastive alignment Network that predicts spatially resolved gene expression by integrating histopathological images and gene expression profiles through a biologically informed approach. Specifically, we introduce an effective gene semantic representation module that leverages the external gene database to provide additional biological insights, thereby enhancing gene expression prediction. Further, we adopt a unified, one-stage contrastive learning paradigm, seamlessly combining contrastive learning and supervised learning to eliminate reliance on exemplars, complemented with an adaptive weighting mechanism. Additionally, we propose a dual-path contrastive alignment module that employs gene semantic features as dynamic cross-modal coordinators to enable effective heterogeneous feature integration. Through extensive experiments across three public ST datasets, DKAN demonstrates superior performance over state-of-the-art models, establishing a new benchmark for spatial gene expression prediction and offering a powerful tool for advancing biological and clinical research.",Bioinformatics
"Spatial Transcriptomics (ST) is a technology that measures gene expression profiles within tissue sections while retaining spatial context. It reveals localized gene expression patterns and tissue heterogeneity, both of which are essential for understanding disease etiology. However, its high cost has driven efforts to predict spatial gene expression from whole slide images. Despite recent advancements, current methods still face significant limitations, such as under-exploitation of high-level biological context, over-reliance on exemplar retrievals, and inadequate alignment of heterogeneous modalities. To address these challenges, we propose DKAN, a novel Dual-path Knowledge-Augmented contrastive alignment Network that predicts spatially resolved gene expression by integrating histopathological images and gene expression profiles through a biologically informed approach. Specifically, we introduce an effective gene semantic representation module that leverages the external gene database to provide additional biological insights, thereby enhancing gene expression prediction. Further, we adopt a unified, one-stage contrastive learning paradigm, seamlessly combining contrastive learning and supervised learning to eliminate reliance on exemplars, complemented with an adaptive weighting mechanism. Additionally, we propose a dual-path contrastive alignment module that employs gene semantic features as dynamic cross-modal coordinators to enable effective heterogeneous feature integration. Through extensive experiments across three public ST datasets, DKAN demonstrates superior performance over state-of-the-art models, establishing a new benchmark for spatial gene expression prediction and offering a powerful tool for advancing biological and clinical research. [SEP] [HINT] tissue -> Bioinformatics (Syns: tissue paper, weave) | clinical -> Bioinformatics (Syns: ) | features -> Bioinformatics (Syns: characteristic, lineament, feature of speech)",Bioinformatics
"Accounting for inter-individual variability in brain function is key to precision medicine. Here, by considering functional inter-individual variability as meaningful data rather than noise, we introduce VarCoNet, an enhanced self-supervised framework for robust functional connectome (FC) extraction from resting-state fMRI (rs-fMRI) data. VarCoNet employs self-supervised contrastive learning to exploit inherent functional inter-individual variability, serving as a brain function encoder that generates FC embeddings readily applicable to downstream tasks even in the absence of labeled data. Contrastive learning is facilitated by a novel augmentation strategy based on segmenting rs-fMRI signals. At its core, VarCoNet integrates a 1D-CNN-Transformer encoder for advanced time-series processing, enhanced with a robust Bayesian hyperparameter optimization. Our VarCoNet framework is evaluated on two downstream tasks: (i) subject fingerprinting, using rs-fMRI data from the Human Connectome Project, and (ii) autism spectrum disorder (ASD) classification, using rs-fMRI data from the ABIDE I and ABIDE II datasets. Using different brain parcellations, our extensive testing against state-of-the-art methods, including 13 deep learning methods, demonstrates VarCoNet's superiority, robustness, interpretability, and generalizability. Overall, VarCoNet provides a versatile and robust framework for FC analysis in rs-fMRI.",Neuroscience
"Accounting for inter-individual variability in brain function is key to precision medicine. Here, by considering functional inter-individual variability as meaningful data rather than noise, we introduce VarCoNet, an enhanced self-supervised framework for robust functional connectome (FC) extraction from resting-state fMRI (rs-fMRI) data. VarCoNet employs self-supervised contrastive learning to exploit inherent functional inter-individual variability, serving as a brain function encoder that generates FC embeddings readily applicable to downstream tasks even in the absence of labeled data. Contrastive learning is facilitated by a novel augmentation strategy based on segmenting rs-fMRI signals. At its core, VarCoNet integrates a 1D-CNN-Transformer encoder for advanced time-series processing, enhanced with a robust Bayesian hyperparameter optimization. Our VarCoNet framework is evaluated on two downstream tasks: (i) subject fingerprinting, using rs-fMRI data from the Human Connectome Project, and (ii) autism spectrum disorder (ASD) classification, using rs-fMRI data from the ABIDE I and ABIDE II datasets. Using different brain parcellations, our extensive testing against state-of-the-art methods, including 13 deep learning methods, demonstrates VarCoNet's superiority, robustness, interpretability, and generalizability. Overall, VarCoNet provides a versatile and robust framework for FC analysis in rs-fMRI. [SEP] [HINT] tasks -> Neuroscience (Syns: tax, task, project) | based -> Bioinformatics (Syns: ground, free-base, base) | learning -> Bioinformatics (Syns: take, teach, acquire)",Neuroscience
"European grapevine (\textit{Vitis vinifera} L.) is a climate-sensitive perennial whose flowering and ripening govern yield and quality. Phenological records from monitoring programs are typically collected at irregular intervals, so true transition dates are interval-censored, and many site-years are right-censored. We develop a reproducible workflow that treats phenology as a time-to-event outcome: Status \& Intensity observations from the USA-NPN are converted to interval bounds, linked to NASA POWER daily weather, and analyzed with parametric accelerated failure time (AFT) models (Weibull and log-logistic). To avoid outcome-dependent bias from aggregating weather up to the event date, antecedent conditions are summarized in fixed pre-season windows and standardized; quality-control filters ensure adequate within-window data coverage. Applied to flowering and ripening of \textit{V.~vinifera}, the framework yields interpretable time-ratio effects and publication-ready tables and figures. Warmer pre-season conditions are associated with earlier ripening, whereas flowering responses are modest and uncertain in these data; precipitation plays, at most, a secondary role. The approach demonstrates how interval-censored survival models with exogenous weather windows can extract robust climate signals from citizen-science phenology while preserving observation uncertainty, and it generalizes readily to other species and networks.",Bioinformatics
"European grapevine (\textit{Vitis vinifera} L.) is a climate-sensitive perennial whose flowering and ripening govern yield and quality. Phenological records from monitoring programs are typically collected at irregular intervals, so true transition dates are interval-censored, and many site-years are right-censored. We develop a reproducible workflow that treats phenology as a time-to-event outcome: Status \& Intensity observations from the USA-NPN are converted to interval bounds, linked to NASA POWER daily weather, and analyzed with parametric accelerated failure time (AFT) models (Weibull and log-logistic). To avoid outcome-dependent bias from aggregating weather up to the event date, antecedent conditions are summarized in fixed pre-season windows and standardized; quality-control filters ensure adequate within-window data coverage. Applied to flowering and ripening of \textit{V.~vinifera}, the framework yields interpretable time-ratio effects and publication-ready tables and figures. Warmer pre-season conditions are associated with earlier ripening, whereas flowering responses are modest and uncertain in these data; precipitation plays, at most, a secondary role. The approach demonstrates how interval-censored survival models with exogenous weather windows can extract robust climate signals from citizen-science phenology while preserving observation uncertainty, and it generalizes readily to other species and networks. [SEP] [HINT] transition -> Materials Science (Syns: passage, modulation, changeover) | framework -> Bioinformatics (Syns: theoretical account, model, fabric) | signals -> Neuroscience (Syns: indicate, signaling, sign)",Bioinformatics
"Biological and artificial learners are inherently exposed to a stream of data and experience throughout their lifetimes and must constantly adapt to, learn from, or selectively ignore the ongoing input. Recent findings reveal that, even when the performance remains stable, the underlying neural representations can change gradually over time, a phenomenon known as representational drift. Studying the different sources of data and noise that may contribute to drift is essential for understanding lifelong learning in neural systems. However, a systematic study of drift across architectures and learning rules, and the connection to task, are missing. Here, in an online learning setup, we characterize drift as a function of data distribution, and specifically show that the learning noise induced by task-irrelevant stimuli, which the agent learns to ignore in a given context, can create long-term drift in the representation of task-relevant stimuli. Using theory and simulations, we demonstrate this phenomenon both in Hebbian-based learning -- Oja's rule and Similarity Matching -- and in stochastic gradient descent applied to autoencoders and a supervised two-layer network. We consistently observe that the drift rate increases with the variance and the dimension of the data in the task-irrelevant subspace. We further show that this yields different qualitative predictions for the geometry and dimension-dependency of drift than those arising from Gaussian synaptic noise. Overall, our study links the structure of stimuli, task, and learning rule to representational drift and could pave the way for using drift as a signal for uncovering underlying computation in the brain.",Neuroscience
"Biological and artificial learners are inherently exposed to a stream of data and experience throughout their lifetimes and must constantly adapt to, learn from, or selectively ignore the ongoing input. Recent findings reveal that, even when the performance remains stable, the underlying neural representations can change gradually over time, a phenomenon known as representational drift. Studying the different sources of data and noise that may contribute to drift is essential for understanding lifelong learning in neural systems. However, a systematic study of drift across architectures and learning rules, and the connection to task, are missing. Here, in an online learning setup, we characterize drift as a function of data distribution, and specifically show that the learning noise induced by task-irrelevant stimuli, which the agent learns to ignore in a given context, can create long-term drift in the representation of task-relevant stimuli. Using theory and simulations, we demonstrate this phenomenon both in Hebbian-based learning -- Oja's rule and Similarity Matching -- and in stochastic gradient descent applied to autoencoders and a supervised two-layer network. We consistently observe that the drift rate increases with the variance and the dimension of the data in the task-irrelevant subspace. We further show that this yields different qualitative predictions for the geometry and dimension-dependency of drift than those arising from Gaussian synaptic noise. Overall, our study links the structure of stimuli, task, and learning rule to representational drift and could pave the way for using drift as a signal for uncovering underlying computation in the brain. [SEP] [HINT] understanding -> Neuroscience (Syns: savvy, intellect, sympathy) | learning -> Bioinformatics (Syns: take, teach, acquire) | structure -> Bioinformatics (Syns: social system, complex body part, social structure)",Neuroscience
"Ohmic contacts to high (>70\%) Al content n-type Al$_x$Ga$_{1-x}$N ultra-wide bandgap semiconductor layers in nitride electronic and photonic devices are typically fabricated by a lift-off process and high temperature ($>700^\circ$C) thermal alloying. These conditions often result in significant structural deformations of the fabricated structures and impose a harsh thermal budget on all other aspects of the device. Here, we report the fabrication of \textit{non-alloyed} \textit{as-deposited} ohmic contacts to 71\% n+AlGaN ($E_\text{g}\sim5.4$~eV) with a free carrier concentration of roughly $7\times 10^{19}$~cm$^{-3}$ and a resistivity of 4 - 5.5 m$Ω$cm (among the lowest reported for Al$_{0.71}$Ga$_{0.29}$N) with linear $I-V$ characteristics and a contact resistivity of $ρ_\text{c}=(4.4\pm1.0)\times10^{-4}$~$Ω$cm$^2$ (measured at zero voltage). Contacts with this quality are formed by two separate fabrication schemes: (i) metal-first patterning, and (ii) lift-off with an oxygen asher descum prior to metal deposition. Given the low threading dislocation density in the single-crystal AlN substrate used for epitaxy, the smooth morphology of the contacted epitaxial surface, and the non-alloyed nature of the contacts, this contact resistivity is attributed purely to thermionic field emission through the metal-semiconductor junction. Contact resistivity extraction at low current injection enables us to model these results using a thermionic field-emission model of contact resistivity, yielding a barrier height for Ti/Al$_{0.71}$Ga$_{0.29}$N of $(0.81\pm0.02)$ eV.",Materials Science
"Ohmic contacts to high (>70\%) Al content n-type Al$_x$Ga$_{1-x}$N ultra-wide bandgap semiconductor layers in nitride electronic and photonic devices are typically fabricated by a lift-off process and high temperature ($>700^\circ$C) thermal alloying. These conditions often result in significant structural deformations of the fabricated structures and impose a harsh thermal budget on all other aspects of the device. Here, we report the fabrication of \textit{non-alloyed} \textit{as-deposited} ohmic contacts to 71\% n+AlGaN ($E_\text{g}\sim5.4$~eV) with a free carrier concentration of roughly $7\times 10^{19}$~cm$^{-3}$ and a resistivity of 4 - 5.5 m$Ω$cm (among the lowest reported for Al$_{0.71}$Ga$_{0.29}$N) with linear $I-V$ characteristics and a contact resistivity of $ρ_\text{c}=(4.4\pm1.0)\times10^{-4}$~$Ω$cm$^2$ (measured at zero voltage). Contacts with this quality are formed by two separate fabrication schemes: (i) metal-first patterning, and (ii) lift-off with an oxygen asher descum prior to metal deposition. Given the low threading dislocation density in the single-crystal AlN substrate used for epitaxy, the smooth morphology of the contacted epitaxial surface, and the non-alloyed nature of the contacts, this contact resistivity is attributed purely to thermionic field emission through the metal-semiconductor junction. Contact resistivity extraction at low current injection enables us to model these results using a thermionic field-emission model of contact resistivity, yielding a barrier height for Ti/Al$_{0.71}$Ga$_{0.29}$N of $(0.81\pm0.02)$ eV. [SEP] [HINT] used -> Bioinformatics (Syns: utilize, ill-used, apply) | field -> Materials Science (Syns: field of honor, line of business, orbit) | low -> Materials Science (Syns: low-spirited, scurvy, depressed)",Materials Science
"Encoding the distance between locations in space is essential for accurate navigation. Grid cells, a functional class of neurons in medial entorhinal cortex, are believed to support this computation. However, existing theories of how populations of grid cells code distance rely on complex coding schemes, with assumptions that may not be met by anatomical constraints. Inspired by recent work finding grid cells to have small, but robust heterogeneity in their grid properties, we hypothesize that distance coding can be achieved by a simple de-correlation of population activity. We develop a mathematical theory for describing this de-correlation in one-dimension, showing that its predictions are consistent with simulations of noisy grid cells. Our simulations highlight a non-intuitive prediction of such a distance by de-correlation framework. Namely, that some further distances are better encoded than some nearer distances. We find evidence of this ""sweet spot"" in previously published rodent behavioral experiments and demonstrate that a decoder which estimates distance from the de-correlation of populations of simulated noisy grid cells leads to a similar pattern of errors. Finally, by simulating noisy grid cells in two-dimensions, we find that there exists a trade-off between the range of distances that can be encoded by de-correlation of population activity and the distinguishability of different distances, which is controlled by the amount of variability in grid properties. We show that the previously observed average amount of grid property variability strikes a balance between the two, enabling the encoding of distances up to several meters. Our work provides new insight on how grid cells can underlie the coding of distance, without the assumptions previously needed, and why grid cells may have small amounts of heterogeneity in their grid properties.",Neuroscience
"Encoding the distance between locations in space is essential for accurate navigation. Grid cells, a functional class of neurons in medial entorhinal cortex, are believed to support this computation. However, existing theories of how populations of grid cells code distance rely on complex coding schemes, with assumptions that may not be met by anatomical constraints. Inspired by recent work finding grid cells to have small, but robust heterogeneity in their grid properties, we hypothesize that distance coding can be achieved by a simple de-correlation of population activity. We develop a mathematical theory for describing this de-correlation in one-dimension, showing that its predictions are consistent with simulations of noisy grid cells. Our simulations highlight a non-intuitive prediction of such a distance by de-correlation framework. Namely, that some further distances are better encoded than some nearer distances. We find evidence of this ""sweet spot"" in previously published rodent behavioral experiments and demonstrate that a decoder which estimates distance from the de-correlation of populations of simulated noisy grid cells leads to a similar pattern of errors. Finally, by simulating noisy grid cells in two-dimensions, we find that there exists a trade-off between the range of distances that can be encoded by de-correlation of population activity and the distinguishability of different distances, which is controlled by the amount of variability in grid properties. We show that the previously observed average amount of grid property variability strikes a balance between the two, enabling the encoding of distances up to several meters. Our work provides new insight on how grid cells can underlie the coding of distance, without the assumptions previously needed, and why grid cells may have small amounts of heterogeneity in their grid properties. [SEP] [HINT] space -> Neuroscience (Syns: distance, place, outer space) | functional -> Neuroscience (Syns: working, usable, running) | complex -> Bioinformatics (Syns: building complex, coordination compound, composite)",Neuroscience
"Vanadium oxide thin films exhibit temperature-driven electronic transitions desirable for sensing and microelectronic applications, yet their performance is often limited by thermal hysteresis. This study demonstrates that electronic stability is governed not simply by roughness or crystallinity but by a unique combination of surface morphological complexity and thermal hysteresis, revealed across films deposited with varying working pressure using Direct Current/Radio Frequency magnetron sputtering. Specifically, the film grown at 15 mTorr shows a distinct convergence of highest morphological vertical complexity and lowest thermal hysteresis, exhibiting nearly reversible transport with activation energies ranging from 0.26 to 0.28 eV and negative temperature coefficients of resistance between -0.0337 and -0.035 K-1. While conventional roughness metrics and mono-fractal parameters do not capture this behavior, multifractal detrended fluctuation analysis uncovers a pronounced peak in multifractality strength, which correlates inversely with thermal hysteresis. This highlights multifractality strength as a predictive descriptor of electronic stability, identifying a multiscale structural signature that enhances stress accommodation during thermal cycling. These results define an optimal deposition window and provide a morphology-guided pathway for developing thermally robust mixed-phase vanadium oxide films.",Materials Science
"Vanadium oxide thin films exhibit temperature-driven electronic transitions desirable for sensing and microelectronic applications, yet their performance is often limited by thermal hysteresis. This study demonstrates that electronic stability is governed not simply by roughness or crystallinity but by a unique combination of surface morphological complexity and thermal hysteresis, revealed across films deposited with varying working pressure using Direct Current/Radio Frequency magnetron sputtering. Specifically, the film grown at 15 mTorr shows a distinct convergence of highest morphological vertical complexity and lowest thermal hysteresis, exhibiting nearly reversible transport with activation energies ranging from 0.26 to 0.28 eV and negative temperature coefficients of resistance between -0.0337 and -0.035 K-1. While conventional roughness metrics and mono-fractal parameters do not capture this behavior, multifractal detrended fluctuation analysis uncovers a pronounced peak in multifractality strength, which correlates inversely with thermal hysteresis. This highlights multifractality strength as a predictive descriptor of electronic stability, identifying a multiscale structural signature that enhances stress accommodation during thermal cycling. These results define an optimal deposition window and provide a morphology-guided pathway for developing thermally robust mixed-phase vanadium oxide films. [SEP] [HINT] transport -> Materials Science (Syns: transferral, enthral, shipping) | electronic -> Materials Science (Syns: ) | performance -> Bioinformatics (Syns: functioning, operation, carrying out)",Materials Science
"This work studies photosensitivity and current-voltage characteristics under illumination of water-soluble eumelanin films based on DHICA tetramers and hybrid eumelanin/porous Si photovoltaic cells aimed at optimizing their characteristics. By using DMSO to dissolve melanin containing protonated carboxyl groups and to remove ammonium cations, it became possible to significantly reduce the ionic component of conductivity, thus improved the electron transport. It was found out that dissolution in DMSO provides a denser π-π stacking of DHICA tetramers, which led to a significant improvement in the photovoltaic cell parameters. In particular, the efficiency increased from 0.023 % to 4.4 % and the series resistance decreased from 119 Ω to 42.6 Ω. Modeling demonstrated that high-temperature annealing, which causes decarboxylation, leads to a structural rearrangement of tetramers from a Christmas tree-like configuration to a ""toothed helix"". At this, one of the planes partially straightens. This emphasizes the critical importance of the morphology of the organic layer for photogeneration of carriers in a heterojunction.",Materials Science
"This work studies photosensitivity and current-voltage characteristics under illumination of water-soluble eumelanin films based on DHICA tetramers and hybrid eumelanin/porous Si photovoltaic cells aimed at optimizing their characteristics. By using DMSO to dissolve melanin containing protonated carboxyl groups and to remove ammonium cations, it became possible to significantly reduce the ionic component of conductivity, thus improved the electron transport. It was found out that dissolution in DMSO provides a denser π-π stacking of DHICA tetramers, which led to a significant improvement in the photovoltaic cell parameters. In particular, the efficiency increased from 0.023 % to 4.4 % and the series resistance decreased from 119 Ω to 42.6 Ω. Modeling demonstrated that high-temperature annealing, which causes decarboxylation, leads to a structural rearrangement of tetramers from a Christmas tree-like configuration to a ""toothed helix"". At this, one of the planes partially straightens. This emphasizes the critical importance of the morphology of the organic layer for photogeneration of carriers in a heterojunction. [SEP] [HINT] based -> Bioinformatics (Syns: ground, free-base, base) | electron -> Materials Science (Syns: negatron) | work -> Bioinformatics (Syns: work out, process, bring)",Materials Science
"Bismuth vanadate (BiVO$_4$) is a key photocatalyst for solar fuel applications, yet fundamental questions remain regarding the nature of photogenerated polaronic states and the lattice dynamics that govern its light-to-chemical pathways. Here, we use femtosecond optical pump-X-ray probe measurements to track the photoinduced electronic and structural dynamics in BiVO$_4$ across multiple length and time scales. Transient X-ray absorption spectroscopy captures sub-picosecond electron localization within VO$_4$ tetrahedra, consistent with small polaron formation, whereas time-resolved X-ray diffraction reveals a slower, multi-picosecond lattice reorganization into a hidden photoexcited state that is structurally distinct from both the monoclinic ground state and the high-temperature tetragonal phase. Supported by density functional theory, we show that hole-lattice interactions dynamically reduce the ground state monoclinic distortion, stabilizing the hidden state. Our results demonstrate that electron- and hole-lattice coupling jointly shape the excited state landscape, with implications for carrier transport, interfacial energetics, and light-to-chemical energy conversion pathways.",Materials Science
"Bismuth vanadate (BiVO$_4$) is a key photocatalyst for solar fuel applications, yet fundamental questions remain regarding the nature of photogenerated polaronic states and the lattice dynamics that govern its light-to-chemical pathways. Here, we use femtosecond optical pump-X-ray probe measurements to track the photoinduced electronic and structural dynamics in BiVO$_4$ across multiple length and time scales. Transient X-ray absorption spectroscopy captures sub-picosecond electron localization within VO$_4$ tetrahedra, consistent with small polaron formation, whereas time-resolved X-ray diffraction reveals a slower, multi-picosecond lattice reorganization into a hidden photoexcited state that is structurally distinct from both the monoclinic ground state and the high-temperature tetragonal phase. Supported by density functional theory, we show that hole-lattice interactions dynamically reduce the ground state monoclinic distortion, stabilizing the hidden state. Our results demonstrate that electron- and hole-lattice coupling jointly shape the excited state landscape, with implications for carrier transport, interfacial energetics, and light-to-chemical energy conversion pathways. [SEP] [HINT] electronic -> Materials Science (Syns: ) | functional -> Neuroscience (Syns: working, usable, running) | electron -> Materials Science (Syns: negatron)",Materials Science
"In Hopfield-type associative memory models, memories are stored in the connectivity matrix and can be retrieved subsequently thanks to the collective dynamics of the network. In these models, the retrieval of a particular memory can be hampered by overlaps between the network state and other memories, termed spurious overlaps since these overlaps collectively introduce noise in the retrieval process. In classic models, spurious overlaps increase the variance of synaptic inputs but do not affect the mean. We show here that in models equipped with a learning rule inferred from neurobiological data, spurious overlaps collectively reduce the mean synaptic inputs to neurons, and that this mean reduction causes in turn an increase in storage capacity through a sparsening of network activity. Our paper demonstrates a link between a specific feature of experimentally inferred plasticity rules and network storage capacity.",Neuroscience
"In Hopfield-type associative memory models, memories are stored in the connectivity matrix and can be retrieved subsequently thanks to the collective dynamics of the network. In these models, the retrieval of a particular memory can be hampered by overlaps between the network state and other memories, termed spurious overlaps since these overlaps collectively introduce noise in the retrieval process. In classic models, spurious overlaps increase the variance of synaptic inputs but do not affect the mean. We show here that in models equipped with a learning rule inferred from neurobiological data, spurious overlaps collectively reduce the mean synaptic inputs to neurons, and that this mean reduction causes in turn an increase in storage capacity through a sparsening of network activity. Our paper demonstrates a link between a specific feature of experimentally inferred plasticity rules and network storage capacity. [SEP] [HINT] connectivity -> Neuroscience (Syns: ) | learning -> Bioinformatics (Syns: take, teach, acquire) | specific -> Bioinformatics (Syns: particular)",Neuroscience
"Rare-disease diagnosis remains one of the most pressing challenges in digital health, hindered by extreme data scarcity, privacy concerns, and the limited resources of edge devices. This paper proposes the Adaptive Federated Few-Shot Rare-Disease Diagnosis (AFFR) framework, which integrates three pillars: (i) few-shot federated optimization with meta-learning to generalize from limited patient samples, (ii) energy-aware client scheduling to mitigate device dropouts and ensure balanced participation, and (iii) secure aggregation with calibrated differential privacy to safeguard sensitive model updates. Unlike prior work that addresses these aspects in isolation, AFFR unifies them into a modular pipeline deployable on real-world clinical networks. Experimental evaluation on simulated rare-disease detection datasets demonstrates up to 10% improvement in accuracy compared with baseline FL, while reducing client dropouts by over 50% without degrading convergence. Furthermore, privacy-utility trade-offs remain within clinically acceptable bounds. These findings highlight AFFR as a practical pathway for equitable and trustworthy federated diagnosis of rare conditions.",Bioinformatics
"Rare-disease diagnosis remains one of the most pressing challenges in digital health, hindered by extreme data scarcity, privacy concerns, and the limited resources of edge devices. This paper proposes the Adaptive Federated Few-Shot Rare-Disease Diagnosis (AFFR) framework, which integrates three pillars: (i) few-shot federated optimization with meta-learning to generalize from limited patient samples, (ii) energy-aware client scheduling to mitigate device dropouts and ensure balanced participation, and (iii) secure aggregation with calibrated differential privacy to safeguard sensitive model updates. Unlike prior work that addresses these aspects in isolation, AFFR unifies them into a modular pipeline deployable on real-world clinical networks. Experimental evaluation on simulated rare-disease detection datasets demonstrates up to 10% improvement in accuracy compared with baseline FL, while reducing client dropouts by over 50% without degrading convergence. Furthermore, privacy-utility trade-offs remain within clinically acceptable bounds. These findings highlight AFFR as a practical pathway for equitable and trustworthy federated diagnosis of rare conditions. [SEP] [HINT] clinical -> Bioinformatics (Syns: ) | work -> Bioinformatics (Syns: work out, process, bring) | datasets -> Bioinformatics (Syns: )",Bioinformatics
"MacroB12 interference presents a significant challenge in the diagnosis of Vitamin B12 status, potentially masking true deficiency. To establish robust predictors and quantify the utility of pre-polyethylene glycol (PEG) B12 levels, we conducted a retrospective analysis of 875 individuals with hypercobalaminaemia (greater than 1000 pg/mL), using multiple imputation to handle missing data. Multivariable regression modelling revealed that MacroB12 positivity (less than 30% PEG recovery) was independently associated with a profile suggestive of autoimmunity, including older age (adjusted odds ratio [aOR] 1.03 per year, P<0.001) and a Rheumatologic/Autoimmune diagnosis (aOR 2.96, P=0.01). We also identified a counterintuitive haematological signature, with higher haemoglobin (aOR 1.14, P=0.02) and Mean Corpuscular Volume (aOR 1.04, P=0.01) predicting MacroB12. Receiver Operating Characteristic (ROC) analysis of pre-PEG B12 concentration yielded only moderate discriminatory power (Area Under the Curve [AUC] = 0.744, 95% CI 0.707-0.782). The optimal threshold of 1584.0 pg/mL (sensitivity 71.3%, specificity 69.7%) serves to stratify clinical suspicion, but its performance confirms that it cannot replace definitive confirmatory testing. Our findings define a clinical and laboratory phenotype for suspected MacroB12 but highlight that confirmatory PEG precipitation remains essential for accurate diagnosis, particularly in older patients and those with autoimmune disease.",Bioinformatics
"MacroB12 interference presents a significant challenge in the diagnosis of Vitamin B12 status, potentially masking true deficiency. To establish robust predictors and quantify the utility of pre-polyethylene glycol (PEG) B12 levels, we conducted a retrospective analysis of 875 individuals with hypercobalaminaemia (greater than 1000 pg/mL), using multiple imputation to handle missing data. Multivariable regression modelling revealed that MacroB12 positivity (less than 30% PEG recovery) was independently associated with a profile suggestive of autoimmunity, including older age (adjusted odds ratio [aOR] 1.03 per year, P<0.001) and a Rheumatologic/Autoimmune diagnosis (aOR 2.96, P=0.01). We also identified a counterintuitive haematological signature, with higher haemoglobin (aOR 1.14, P=0.02) and Mean Corpuscular Volume (aOR 1.04, P=0.01) predicting MacroB12. Receiver Operating Characteristic (ROC) analysis of pre-PEG B12 concentration yielded only moderate discriminatory power (Area Under the Curve [AUC] = 0.744, 95% CI 0.707-0.782). The optimal threshold of 1584.0 pg/mL (sensitivity 71.3%, specificity 69.7%) serves to stratify clinical suspicion, but its performance confirms that it cannot replace definitive confirmatory testing. Our findings define a clinical and laboratory phenotype for suspected MacroB12 but highlight that confirmatory PEG precipitation remains essential for accurate diagnosis, particularly in older patients and those with autoimmune disease. [SEP] [HINT] clinical -> Bioinformatics (Syns: ) | performance -> Bioinformatics (Syns: functioning, operation, carrying out) | including -> Bioinformatics (Syns: admit, include, let in)",Bioinformatics
"Early recurrence (ER) prediction after curative-intent resection remains a critical challenge in the clinical management of hepatocellular carcinoma (HCC). Although contrast-enhanced computed tomography (CT) with full multi-phase acquisition is recommended in clinical guidelines and routinely performed in many tertiary centers, complete phase coverage is not consistently available across all institutions. In practice, single-phase portal venous (PV) scans are often used alone, particularly in settings with limited imaging resources, variations in acquisition protocols, or patient-related factors such as contrast intolerance or motion artifacts. This variability results in a mismatch between idealized model assumptions and the practical constraints of real-world deployment, underscoring the need for methods that can effectively leverage limited multi-phase data. To address this challenge, we propose a Dual-Branch Prototype-guided (DuoProto) framework that enhances ER prediction from single-phase CT by leveraging limited multi-phase data during training. DuoProto employs a dual-branch architecture: the main branch processes single-phase images, while the auxiliary branch utilizes available multi-phase scans to guide representation learning via cross-domain prototype alignment. Structured prototype representations serve as class anchors to improve feature discrimination, and a ranking-based supervision mechanism incorporates clinically relevant recurrence risk factors. Extensive experiments demonstrate that DuoProto outperforms existing methods, particularly under class imbalance and missing-phase conditions. Ablation studies further validate the effectiveness of the dual-branch, prototype-guided design. Our framework aligns with current clinical application needs and provides a general solution for recurrence risk prediction in HCC, supporting more informed decision-making.",Bioinformatics
"Early recurrence (ER) prediction after curative-intent resection remains a critical challenge in the clinical management of hepatocellular carcinoma (HCC). Although contrast-enhanced computed tomography (CT) with full multi-phase acquisition is recommended in clinical guidelines and routinely performed in many tertiary centers, complete phase coverage is not consistently available across all institutions. In practice, single-phase portal venous (PV) scans are often used alone, particularly in settings with limited imaging resources, variations in acquisition protocols, or patient-related factors such as contrast intolerance or motion artifacts. This variability results in a mismatch between idealized model assumptions and the practical constraints of real-world deployment, underscoring the need for methods that can effectively leverage limited multi-phase data. To address this challenge, we propose a Dual-Branch Prototype-guided (DuoProto) framework that enhances ER prediction from single-phase CT by leveraging limited multi-phase data during training. DuoProto employs a dual-branch architecture: the main branch processes single-phase images, while the auxiliary branch utilizes available multi-phase scans to guide representation learning via cross-domain prototype alignment. Structured prototype representations serve as class anchors to improve feature discrimination, and a ranking-based supervision mechanism incorporates clinically relevant recurrence risk factors. Extensive experiments demonstrate that DuoProto outperforms existing methods, particularly under class imbalance and missing-phase conditions. Ablation studies further validate the effectiveness of the dual-branch, prototype-guided design. Our framework aligns with current clinical application needs and provides a general solution for recurrence risk prediction in HCC, supporting more informed decision-making. [SEP] [HINT] used -> Bioinformatics (Syns: utilize, ill-used, apply) | clinical -> Bioinformatics (Syns: ) | learning -> Bioinformatics (Syns: take, teach, acquire)",Bioinformatics
"Nonequilibrium phonon transport driven by nanoscale hotspot heating in silicon device layers governs heat dissipation in advanced microelectronics and underscores the need for a better microscopic understanding of such processes. Yet the origin of the frequently observed logarithmic (ln) dependence of the apparent thermal response on hotspot size in crystalline silicon, and the role of individual phonon modes in this regime, remain unclear. Here, we develop a semianalytical, mode-resolved framework in the spectral phonon mean free path (MFP) domain and validate it against a full-phonon-dispersion Boltzmann transport model for heat removal from a 10 x 10 nm^2 hotspot in a thin Si layer (thicknesses of 41, 78, and 177 nm) representative of a silicon-on-insulator transistor. We show that ln-type quasiballistic scaling arises only for modes that lie on a log-uniform conductivity plateau and are diffusive-side or quasiballistic with respect to the hotspot size, whereas fully ballistic long-MFP modes contribute a saturated, nonlogarithmic background, leading to extremely slow suppression of their heat-carrying capability. The resulting phonon-modal nonlocal spectrum establishes spectral selection rules for ln-regime transport in confined Si and provides a compact basis for incorporating mode-selective quasiballistic corrections into continuum thermal models and for interpreting phonon-resolved thermometry experiments.",Materials Science
"Nonequilibrium phonon transport driven by nanoscale hotspot heating in silicon device layers governs heat dissipation in advanced microelectronics and underscores the need for a better microscopic understanding of such processes. Yet the origin of the frequently observed logarithmic (ln) dependence of the apparent thermal response on hotspot size in crystalline silicon, and the role of individual phonon modes in this regime, remain unclear. Here, we develop a semianalytical, mode-resolved framework in the spectral phonon mean free path (MFP) domain and validate it against a full-phonon-dispersion Boltzmann transport model for heat removal from a 10 x 10 nm^2 hotspot in a thin Si layer (thicknesses of 41, 78, and 177 nm) representative of a silicon-on-insulator transistor. We show that ln-type quasiballistic scaling arises only for modes that lie on a log-uniform conductivity plateau and are diffusive-side or quasiballistic with respect to the hotspot size, whereas fully ballistic long-MFP modes contribute a saturated, nonlogarithmic background, leading to extremely slow suppression of their heat-carrying capability. The resulting phonon-modal nonlocal spectrum establishes spectral selection rules for ln-regime transport in confined Si and provides a compact basis for incorporating mode-selective quasiballistic corrections into continuum thermal models and for interpreting phonon-resolved thermometry experiments. [SEP] [HINT] phonon -> Materials Science (Syns: ) | understanding -> Neuroscience (Syns: savvy, intellect, sympathy) | transport -> Materials Science (Syns: transferral, enthral, shipping)",Materials Science
"Studies of human decision-making demonstrate that environmental regularities, such as natural image statistics or intentionally nonuniform stimulus probabilities, can be exploited to improve efficiency (termed `efficient-coding'). Conversely, from a machine learning perspective, such nonuniform stimulus properties can lead to biased neural networks with poor generalization performance. Understanding how the brain flexibly leverages stimulus bias while maintaining robust generalization could lead to novel architectures that adaptively exploit environmental structure without sacrificing performance on out-of-distribution data. To address this disconnect, we investigated the impact of stimulus regularities in a 3-layer hierarchical continuous-time recurrent neural network (ctRNN) to better understand how artificial networks might exploit statistical regularities to improve efficiency while avoiding undesirable biases. We trained the model to reproduce one of six possible inputs under biased conditions (stimulus 1 more probable than stimuli 2-6) or unbiased conditions (all stimuli equally likely). Across all hidden layers, more information was encoded about high-probability stimuli, consistent with the efficient-coding framework. Importantly, reducing feedback from the final hidden layer of trained models selectively magnified representations of high-probability stimuli, at the expense of low-probability stimuli, across all layers. Together, these results suggest that models exploit nonuniform input statistics to improve efficiency, and that feedback pathways evolve to protect the processing of low-probability stimuli by regulating the impact of biased input statistics.",Neuroscience
"Studies of human decision-making demonstrate that environmental regularities, such as natural image statistics or intentionally nonuniform stimulus probabilities, can be exploited to improve efficiency (termed `efficient-coding'). Conversely, from a machine learning perspective, such nonuniform stimulus properties can lead to biased neural networks with poor generalization performance. Understanding how the brain flexibly leverages stimulus bias while maintaining robust generalization could lead to novel architectures that adaptively exploit environmental structure without sacrificing performance on out-of-distribution data. To address this disconnect, we investigated the impact of stimulus regularities in a 3-layer hierarchical continuous-time recurrent neural network (ctRNN) to better understand how artificial networks might exploit statistical regularities to improve efficiency while avoiding undesirable biases. We trained the model to reproduce one of six possible inputs under biased conditions (stimulus 1 more probable than stimuli 2-6) or unbiased conditions (all stimuli equally likely). Across all hidden layers, more information was encoded about high-probability stimuli, consistent with the efficient-coding framework. Importantly, reducing feedback from the final hidden layer of trained models selectively magnified representations of high-probability stimuli, at the expense of low-probability stimuli, across all layers. Together, these results suggest that models exploit nonuniform input statistics to improve efficiency, and that feedback pathways evolve to protect the processing of low-probability stimuli by regulating the impact of biased input statistics. [SEP] [HINT] understanding -> Neuroscience (Syns: savvy, intellect, sympathy) | learning -> Bioinformatics (Syns: take, teach, acquire) | networks -> Neuroscience (Syns: network, meshwork, electronic network)",Neuroscience
"The vision of a universal AI tutor has remained elusive, despite decades of effort. Could LLMs be the game-changer? We overview novel issues arising from developing a nationwide AI tutor. We highlight the practical questions that point to specific gaps in our scientific understanding of the learning process.",Neuroscience
"The vision of a universal AI tutor has remained elusive, despite decades of effort. Could LLMs be the game-changer? We overview novel issues arising from developing a nationwide AI tutor. We highlight the practical questions that point to specific gaps in our scientific understanding of the learning process. [SEP] [HINT] understanding -> Neuroscience (Syns: savvy, intellect, sympathy) | learning -> Bioinformatics (Syns: take, teach, acquire) | novel -> Bioinformatics (Syns: refreshing, fresh, new)",Neuroscience
"Quantum confinement not only reshapes electronic states but also reorganizes the vibrational landscape of low-dimensional semiconductors. In halide perovskites, however, the role of confinement in governing symmetry effects on vibrational modes has remained unresolved. Here we synthesize 2D CsPbBr3 nanoplatelets with atomically defined thicknesses for 2-5 monolayers (MLs) and perform exciton absorption and emission analysis, crystalline phase determination, and phonon analysis. The lowest dimensional structure (2 MLs) reveal a co-existence of cubic and orthorhombic structure, energetically converging to orthorhombic for 3 MLs and beyond. Through polarization-resolved Raman spectroscopy and first-principles theory for 2-5 MLs, a striking symmetry contrast is found: B1g modes intensify and evolve in line with the phonon-confinement model, while Ag modes deviate, reflecting their distinct spatial localization. First principles calculations show that B1g vibrational modes largely reside in the xy-plane, Pb-Br-Pb units connect octahedra along the xy-direction with increased lattice dynamics as inner layers accumulate, whereas A1g vibrations couple to out-of-plane distortions and remain susceptible to surface disorder and finite-size effects. This symmetry-driven dichotomy provides a general framework for understanding phonon localization in layered halide perovskites. Beyond mechanism, we establish Raman fingerprints, particularly the A1g/B1g intensity ratio in cross-polarized geometry, as a calibrated, non-destructive metrology for 2D nanoplatelet thickness through 2-5 MLs. These results bridge electronic and phonon confinement and highlight symmetry engineering as a route to understand and control phonons, excitons, and their interactions in low-dimensional optoelectronic materials.",Materials Science
"Quantum confinement not only reshapes electronic states but also reorganizes the vibrational landscape of low-dimensional semiconductors. In halide perovskites, however, the role of confinement in governing symmetry effects on vibrational modes has remained unresolved. Here we synthesize 2D CsPbBr3 nanoplatelets with atomically defined thicknesses for 2-5 monolayers (MLs) and perform exciton absorption and emission analysis, crystalline phase determination, and phonon analysis. The lowest dimensional structure (2 MLs) reveal a co-existence of cubic and orthorhombic structure, energetically converging to orthorhombic for 3 MLs and beyond. Through polarization-resolved Raman spectroscopy and first-principles theory for 2-5 MLs, a striking symmetry contrast is found: B1g modes intensify and evolve in line with the phonon-confinement model, while Ag modes deviate, reflecting their distinct spatial localization. First principles calculations show that B1g vibrational modes largely reside in the xy-plane, Pb-Br-Pb units connect octahedra along the xy-direction with increased lattice dynamics as inner layers accumulate, whereas A1g vibrations couple to out-of-plane distortions and remain susceptible to surface disorder and finite-size effects. This symmetry-driven dichotomy provides a general framework for understanding phonon localization in layered halide perovskites. Beyond mechanism, we establish Raman fingerprints, particularly the A1g/B1g intensity ratio in cross-polarized geometry, as a calibrated, non-destructive metrology for 2D nanoplatelet thickness through 2-5 MLs. These results bridge electronic and phonon confinement and highlight symmetry engineering as a route to understand and control phonons, excitons, and their interactions in low-dimensional optoelectronic materials. [SEP] [HINT] phonon -> Materials Science (Syns: ) | understanding -> Neuroscience (Syns: savvy, intellect, sympathy) | electronic -> Materials Science (Syns: )",Materials Science
"Characterizing the brain dynamics during different cortical states can reveal valuable information about its patterns across various cognitive processes. In particular, studying the differences between awake and sleep stages can shed light on the understanding of brain processes essential for physical and mental well-being, such as memory consolidation, information processing, and fatigue recovery. Alterations in these patterns may indicate disorders and pathologies such as obstructive sleep apnea, narcolepsy, as well as Alzheimer's and Parkinson's diseases. Here, we analyze time series obtained from intracranial recordings of 106 patients, covering four sleep stages: Wake, N2, N3, and REM. Intracranial electroencephalography (iEEG), which can include electrocorticography (ECoG) and depth recordings, represents the state-of-the-art measurements of brain activity, offering unparalleled spatial and temporal resolution for investigating neural dynamics. We characterize the signals using Bandt and Pompe symbolic methodology to calculate the Weighted Permutation Entropy (WPE) and the Statistical Complexity Measure (SCM) based on the Jensen and Shannon disequilibrium. By mapping the data onto the complexity-entropy plane, we observe that each stage occupies a distinct region, revealing its own dynamic signature. We show that our empirical results can be reproduced by a whole-brain computational model, in which each cortical region is described by a mean-field formulation based on networks of Adaptive Exponential Integrate-and-Fire (AdEx) neurons, adjusting the adaptation parameter to simulate the different sleep stages. Finally, we show that a classification approach using Support Vector Machine (SVM) provides high accuracy in distinguishing between cortical states.",Neuroscience
"Characterizing the brain dynamics during different cortical states can reveal valuable information about its patterns across various cognitive processes. In particular, studying the differences between awake and sleep stages can shed light on the understanding of brain processes essential for physical and mental well-being, such as memory consolidation, information processing, and fatigue recovery. Alterations in these patterns may indicate disorders and pathologies such as obstructive sleep apnea, narcolepsy, as well as Alzheimer's and Parkinson's diseases. Here, we analyze time series obtained from intracranial recordings of 106 patients, covering four sleep stages: Wake, N2, N3, and REM. Intracranial electroencephalography (iEEG), which can include electrocorticography (ECoG) and depth recordings, represents the state-of-the-art measurements of brain activity, offering unparalleled spatial and temporal resolution for investigating neural dynamics. We characterize the signals using Bandt and Pompe symbolic methodology to calculate the Weighted Permutation Entropy (WPE) and the Statistical Complexity Measure (SCM) based on the Jensen and Shannon disequilibrium. By mapping the data onto the complexity-entropy plane, we observe that each stage occupies a distinct region, revealing its own dynamic signature. We show that our empirical results can be reproduced by a whole-brain computational model, in which each cortical region is described by a mean-field formulation based on networks of Adaptive Exponential Integrate-and-Fire (AdEx) neurons, adjusting the adaptation parameter to simulate the different sleep stages. Finally, we show that a classification approach using Support Vector Machine (SVM) provides high accuracy in distinguishing between cortical states. [SEP] [HINT] based -> Bioinformatics (Syns: ground, free-base, base) | computational -> Neuroscience (Syns: ) | understanding -> Neuroscience (Syns: savvy, intellect, sympathy)",Neuroscience
"The genotype-phenotype gap is a persistent barrier to complex trait genetic dissection, worsened by the explosive growth of genomic data (1.5 billion variants identified in the UK Biobank WGS study) alongside persistently scarce and subjective human-defined phenotypes. Digital phenotyping offers a potential solution, yet existing tools fail to balance scalable non-manual phenotype generation and biological interpretability of these quantitative traits. Here we report AIPheno, the first generative AI-driven ""phenotype sequencer"" that bridges this gap. It enables high-throughput, unsupervised extraction of digital phenotypes from imaging data and unlocks their biological meaning via generative network analysis. AIPheno transforms imaging modalities into a rich source of quantitative traits, dramatically enhancing cross-species genetic discovery, including novel loci such as CCBE1 (humans), KITLG-TMTC3 (domestic pigeons), and SOD2-IGF2R (swine). Critically, its generative module decodes AI-derived phenotypes by synthesizing variant-specific images to yield actionable biological insights. For example, it clarifies how the OCA2-HERC2 locus pleiotropically links pigmentation to retinal vascular traits via vascular visibility modulation. Integrating scalable non-manual phenotyping, enhanced genetic discovery power, and generative mechanistic decoding, AIPheno establishes a transformative closed-loop paradigm. This work addresses the longstanding genotype-phenotype imbalance, redefines digital phenotype utility, and accelerates translation of genetic associations into actionable understanding with profound implications for human health and agriculture.",Bioinformatics
"The genotype-phenotype gap is a persistent barrier to complex trait genetic dissection, worsened by the explosive growth of genomic data (1.5 billion variants identified in the UK Biobank WGS study) alongside persistently scarce and subjective human-defined phenotypes. Digital phenotyping offers a potential solution, yet existing tools fail to balance scalable non-manual phenotype generation and biological interpretability of these quantitative traits. Here we report AIPheno, the first generative AI-driven ""phenotype sequencer"" that bridges this gap. It enables high-throughput, unsupervised extraction of digital phenotypes from imaging data and unlocks their biological meaning via generative network analysis. AIPheno transforms imaging modalities into a rich source of quantitative traits, dramatically enhancing cross-species genetic discovery, including novel loci such as CCBE1 (humans), KITLG-TMTC3 (domestic pigeons), and SOD2-IGF2R (swine). Critically, its generative module decodes AI-derived phenotypes by synthesizing variant-specific images to yield actionable biological insights. For example, it clarifies how the OCA2-HERC2 locus pleiotropically links pigmentation to retinal vascular traits via vascular visibility modulation. Integrating scalable non-manual phenotyping, enhanced genetic discovery power, and generative mechanistic decoding, AIPheno establishes a transformative closed-loop paradigm. This work addresses the longstanding genotype-phenotype imbalance, redefines digital phenotype utility, and accelerates translation of genetic associations into actionable understanding with profound implications for human health and agriculture. [SEP] [HINT] understanding -> Neuroscience (Syns: savvy, intellect, sympathy) | complex -> Bioinformatics (Syns: building complex, coordination compound, composite) | work -> Bioinformatics (Syns: work out, process, bring)",Bioinformatics
"Interfaces in materials are often treated as massless geometric boundaries, and many kinetic models adopt an overdamped assumption. In this Letter, we show that grain boundaries exhibit inertial behavior under high-frequency oscillatory loading and introduce a quantitative method to determine their effective mass from the phase lag between the applied force and interface velocity. The measured effective mass correlates with the mass of atoms participating in interface migration. Using this advance, we reassess prevailing theories and identify regimes where the inertial term materially affects interfacial kinetics, particularly at high frequencies relevant to thermal fluctuations. These results motivate incorporating an effective mass into kinetic descriptions, providing a clearer basis for modeling and interpreting interface migration.",Materials Science
"Interfaces in materials are often treated as massless geometric boundaries, and many kinetic models adopt an overdamped assumption. In this Letter, we show that grain boundaries exhibit inertial behavior under high-frequency oscillatory loading and introduce a quantitative method to determine their effective mass from the phase lag between the applied force and interface velocity. The measured effective mass correlates with the mass of atoms participating in interface migration. Using this advance, we reassess prevailing theories and identify regimes where the inertial term materially affects interfacial kinetics, particularly at high frequencies relevant to thermal fluctuations. These results motivate incorporating an effective mass into kinetic descriptions, providing a clearer basis for modeling and interpreting interface migration. [SEP] [HINT] results -> Bioinformatics (Syns: final result, consequence, resultant role) | using -> Bioinformatics (Syns: utilize, exploitation, apply) | materials -> Materials Science (Syns: stuff, cloth, material)",Materials Science
"Advances in large-scale neural recordings have expanded our ability to describe the activity of distributed brain circuits. However, understanding how neural population dynamics differ across regions and behavioral contexts remains challenging. Here, we surveyed neuronal population dynamics across multiple mouse brain areas (visual cortex, hippocampus, thalamus, and midbrain) using spike data from local ensembles. Two complementary measures were used to characterize these dynamics: the coefficient of variation (CV), a classical indicator of spike-time variability, and statistical complexity, an information-theoretic quantifier of organizational structure. To probe stimulus-dependent activity, we segmented and concatenated recordings from behavioral experiments into distinct time series corresponding to natural image presentations, blank screens during visual task, and spontaneous activity. While the CV failed to discriminate between these conditions, statistical complexity revealed clear, stimulus-specific motifs in population activity. These results indicate that information-theoretic measures can uncover structured, stimulus-dependent patterns in neural population dynamics that remain unobserved in traditional variability metrics.",Neuroscience
"Advances in large-scale neural recordings have expanded our ability to describe the activity of distributed brain circuits. However, understanding how neural population dynamics differ across regions and behavioral contexts remains challenging. Here, we surveyed neuronal population dynamics across multiple mouse brain areas (visual cortex, hippocampus, thalamus, and midbrain) using spike data from local ensembles. Two complementary measures were used to characterize these dynamics: the coefficient of variation (CV), a classical indicator of spike-time variability, and statistical complexity, an information-theoretic quantifier of organizational structure. To probe stimulus-dependent activity, we segmented and concatenated recordings from behavioral experiments into distinct time series corresponding to natural image presentations, blank screens during visual task, and spontaneous activity. While the CV failed to discriminate between these conditions, statistical complexity revealed clear, stimulus-specific motifs in population activity. These results indicate that information-theoretic measures can uncover structured, stimulus-dependent patterns in neural population dynamics that remain unobserved in traditional variability metrics. [SEP] [HINT] used -> Bioinformatics (Syns: utilize, ill-used, apply) | understanding -> Neuroscience (Syns: savvy, intellect, sympathy) | results -> Bioinformatics (Syns: final result, consequence, resultant role)",Neuroscience
"In humans and other animals, category learning enhances discrimination between stimuli close to the category boundary. This phenomenon, called categorical perception, was also empirically observed in artificial neural networks trained on classification tasks. In previous modeling works based on neuroscience data, we show that this expansion/compression is a necessary outcome of efficient learning. Here we extend our theoretical framework to artificial networks. We show that minimizing the Bayes cost (mean of the cross-entropy loss) implies maximizing the mutual information between the set of categories and the neural activities prior to the decision layer. Considering structured data with an underlying feature space of small dimension, we show that maximizing the mutual information implies (i) finding an appropriate projection space, and, (ii) building a neural representation with the appropriate metric. The latter is based on a Fisher information matrix measuring the sensitivity of the neural activity to changes in the projection space. Optimal learning makes this neural Fisher information follow a category-specific Fisher information, measuring the sensitivity of the category membership. Category learning thus induces an expansion of neural space near decision boundaries. We characterize the properties of the categorical Fisher information, showing that its eigenvectors give the most discriminant directions at each point of the projection space. We find that, unexpectedly, its maxima are in general not exactly at, but near, the class boundaries. Considering toy models and the MNIST dataset, we numerically illustrate how after learning the two Fisher information matrices match, and essentially align with the category boundaries. Finally, we relate our approach to the Information Bottleneck one, and we exhibit a bias-variance decomposition of the Bayes cost, of interest on its own.",Neuroscience
"In humans and other animals, category learning enhances discrimination between stimuli close to the category boundary. This phenomenon, called categorical perception, was also empirically observed in artificial neural networks trained on classification tasks. In previous modeling works based on neuroscience data, we show that this expansion/compression is a necessary outcome of efficient learning. Here we extend our theoretical framework to artificial networks. We show that minimizing the Bayes cost (mean of the cross-entropy loss) implies maximizing the mutual information between the set of categories and the neural activities prior to the decision layer. Considering structured data with an underlying feature space of small dimension, we show that maximizing the mutual information implies (i) finding an appropriate projection space, and, (ii) building a neural representation with the appropriate metric. The latter is based on a Fisher information matrix measuring the sensitivity of the neural activity to changes in the projection space. Optimal learning makes this neural Fisher information follow a category-specific Fisher information, measuring the sensitivity of the category membership. Category learning thus induces an expansion of neural space near decision boundaries. We characterize the properties of the categorical Fisher information, showing that its eigenvectors give the most discriminant directions at each point of the projection space. We find that, unexpectedly, its maxima are in general not exactly at, but near, the class boundaries. Considering toy models and the MNIST dataset, we numerically illustrate how after learning the two Fisher information matrices match, and essentially align with the category boundaries. Finally, we relate our approach to the Information Bottleneck one, and we exhibit a bias-variance decomposition of the Bayes cost, of interest on its own. [SEP] [HINT] based -> Bioinformatics (Syns: ground, free-base, base) | learning -> Bioinformatics (Syns: take, teach, acquire) | networks -> Neuroscience (Syns: network, meshwork, electronic network)",Neuroscience
"Many systems of interest exhibit nested emergent layers with their own rules and regularities, and our knowledge about them seems naturally organised around these levels. This paper proposes that this type of hierarchical emergence arises as a result of underlying symmetries. By combining principles from information theory, group theory, and statistical mechanics, one finds that dynamical processes that are equivariant with respect to a symmetry group give rise to emergent macroscopic levels organised into a hierarchy determined by the subgroups of the symmetry. The same symmetries happen to also shape Bayesian beliefs, yielding hierarchies of abstract belief states that can be updated autonomously at different levels of resolution. These results are illustrated in Hopfield networks and Ehrenfest diffusion, showing that familiar macroscopic quantities emerge naturally from their symmetries. Together, these results suggest that symmetries provide a fundamental mechanism for emergence and support a structural correspondence between objective and epistemic processes, making feasible inferential problems that would otherwise be computationally intractable.",Neuroscience
"Many systems of interest exhibit nested emergent layers with their own rules and regularities, and our knowledge about them seems naturally organised around these levels. This paper proposes that this type of hierarchical emergence arises as a result of underlying symmetries. By combining principles from information theory, group theory, and statistical mechanics, one finds that dynamical processes that are equivariant with respect to a symmetry group give rise to emergent macroscopic levels organised into a hierarchy determined by the subgroups of the symmetry. The same symmetries happen to also shape Bayesian beliefs, yielding hierarchies of abstract belief states that can be updated autonomously at different levels of resolution. These results are illustrated in Hopfield networks and Ehrenfest diffusion, showing that familiar macroscopic quantities emerge naturally from their symmetries. Together, these results suggest that symmetries provide a fundamental mechanism for emergence and support a structural correspondence between objective and epistemic processes, making feasible inferential problems that would otherwise be computationally intractable. [SEP] [HINT] networks -> Neuroscience (Syns: network, meshwork, electronic network) | information -> Bioinformatics (Syns: entropy, data, info) | results -> Bioinformatics (Syns: final result, consequence, resultant role)",Neuroscience
"Conflicting clinical trial results on omega-3 highly unsaturated fatty acids (n-3 HUFA) have prompted uncertainty about their cardioprotective effects. While the VITAL trial found no overall cardiovascular benefit from n-3 HUFA supplementation, its substantial African American (AfAm) enrollment provided a unique opportunity to explore racial differences in response to n-3 HUFA supplementation. The current observational study aimed to simulate randomized clinical trial (RCT) conditions by matching 3,766 AfAm and 15,553 non-Hispanic White (NHW) individuals from the VITAL trial utilizing propensity score matching to address the limitations related to differences in confounding variables between the two groups. Within matched groups (3,766 AfAm and 3,766 NHW), n-3 HUFA supplementation's impact on myocardial infarction (MI), stroke, and cardiovascular disease (CVD) mortality was assessed. A weighted decision tree analysis revealed belonging to the n-3 supplementation group as the most significant predictor of MI among AfAm but not NHW. Further logistic regression using the LASSO method and bootstrap estimation of standard errors indicated n-3 supplementation significantly lowered MI risk in AfAm (OR 0.17, 95% CI [0.048, 0.60]), with no such effect in NHW. This study underscores the critical need for future RCT to explore racial disparities in MI risk associated with n-3 HUFA supplementation and highlights potential causal differences between supplementation health outcomes in AfAm versus NHW populations.",Bioinformatics
"Conflicting clinical trial results on omega-3 highly unsaturated fatty acids (n-3 HUFA) have prompted uncertainty about their cardioprotective effects. While the VITAL trial found no overall cardiovascular benefit from n-3 HUFA supplementation, its substantial African American (AfAm) enrollment provided a unique opportunity to explore racial differences in response to n-3 HUFA supplementation. The current observational study aimed to simulate randomized clinical trial (RCT) conditions by matching 3,766 AfAm and 15,553 non-Hispanic White (NHW) individuals from the VITAL trial utilizing propensity score matching to address the limitations related to differences in confounding variables between the two groups. Within matched groups (3,766 AfAm and 3,766 NHW), n-3 HUFA supplementation's impact on myocardial infarction (MI), stroke, and cardiovascular disease (CVD) mortality was assessed. A weighted decision tree analysis revealed belonging to the n-3 supplementation group as the most significant predictor of MI among AfAm but not NHW. Further logistic regression using the LASSO method and bootstrap estimation of standard errors indicated n-3 supplementation significantly lowered MI risk in AfAm (OR 0.17, 95% CI [0.048, 0.60]), with no such effect in NHW. This study underscores the critical need for future RCT to explore racial disparities in MI risk associated with n-3 HUFA supplementation and highlights potential causal differences between supplementation health outcomes in AfAm versus NHW populations. [SEP] [HINT] clinical -> Bioinformatics (Syns: ) | results -> Bioinformatics (Syns: final result, consequence, resultant role) | using -> Bioinformatics (Syns: utilize, exploitation, apply)",Bioinformatics
"Finding food is a fundamental activity for survival of all living organisms. Free-ranging dogs have been known to use their olfaction to assess the quality and type of available food but their use of visual ability in foraging is not well-documented. In the current study, we seek to remedy that by testing free-ranging dogs in a food-based choice test. We tested whether the dogs implemented hierarchical or synergistic usage of cues while finding food. We found limited prioritization of olfactory cues over visual cues in dichromatic choice tests but in phases with similar perceptual elements, the sensory choice was not clear. Furthermore, free-ranging dogs display a dynamic decision-making in unpredictable urban environments adopting a good-enough strategy during foraging. They prefer speed over accuracy, settling for intermediate quality food if their preferred food item is not available. These dogs also displayed left-bias during food choice. In multi-sensorial, natural setting multiple modulators like environmental noise, risk, and internal perceptual elements apart from food cues seem to be affecting the decision-making in dogs.",Neuroscience
"Finding food is a fundamental activity for survival of all living organisms. Free-ranging dogs have been known to use their olfaction to assess the quality and type of available food but their use of visual ability in foraging is not well-documented. In the current study, we seek to remedy that by testing free-ranging dogs in a food-based choice test. We tested whether the dogs implemented hierarchical or synergistic usage of cues while finding food. We found limited prioritization of olfactory cues over visual cues in dichromatic choice tests but in phases with similar perceptual elements, the sensory choice was not clear. Furthermore, free-ranging dogs display a dynamic decision-making in unpredictable urban environments adopting a good-enough strategy during foraging. They prefer speed over accuracy, settling for intermediate quality food if their preferred food item is not available. These dogs also displayed left-bias during food choice. In multi-sensorial, natural setting multiple modulators like environmental noise, risk, and internal perceptual elements apart from food cues seem to be affecting the decision-making in dogs. [SEP] [HINT] quality -> Bioinformatics (Syns: lineament, tone, calibre) | visual -> Neuroscience (Syns: optical, ocular, optic) | perceptual -> Neuroscience (Syns: )",Neuroscience
"Multicellular tissues, such as the epithelium coating a developing embryo, often combine complex tissue shapes with heterogeneity in the spatial arrangement of individual cells. Discrete approximations, such as the cell vertex model, can accommodate these geometric features, but techniques for analysis of such models are underdeveloped. Here, we express differential operators defined on a network representing a monolayer of confluent cells in the framework of discrete exterior calculus, considering scalar fields defined over cell vertices and centres and vector fields defined over cell edges. We achieve this by defining Hodge stars, wedge products and musical isomorphisms that are appropriate for a disordered monolayer for which cell edges and links between cell centres are not orthogonal, as is generic for epithelia. We use this framework to evaluate the harmonic vector field arising in an ablated monolayer, demonstrating an approximate 1/\textit{r} scaling of the upper bound of the field's amplitude, where \textit{r} is the distance from the ablation. Using a vertex model that incorporates osmotic effects, we then calculate the mechanical response of a monolayer in a jammed state to ablation. Perturbation displacements exhibit long-range coherence, monopolar and quadrupolar features, and an approximate 1/\textit{r} near-hole upper-bound scaling, implicating the harmonic field. The upper bounds on perturbation stress amplitudes scale approximately like 1/\textit{r}$^2$, a feature relevant to long-range mechanical signalling.",Bioinformatics
"Multicellular tissues, such as the epithelium coating a developing embryo, often combine complex tissue shapes with heterogeneity in the spatial arrangement of individual cells. Discrete approximations, such as the cell vertex model, can accommodate these geometric features, but techniques for analysis of such models are underdeveloped. Here, we express differential operators defined on a network representing a monolayer of confluent cells in the framework of discrete exterior calculus, considering scalar fields defined over cell vertices and centres and vector fields defined over cell edges. We achieve this by defining Hodge stars, wedge products and musical isomorphisms that are appropriate for a disordered monolayer for which cell edges and links between cell centres are not orthogonal, as is generic for epithelia. We use this framework to evaluate the harmonic vector field arising in an ablated monolayer, demonstrating an approximate 1/\textit{r} scaling of the upper bound of the field's amplitude, where \textit{r} is the distance from the ablation. Using a vertex model that incorporates osmotic effects, we then calculate the mechanical response of a monolayer in a jammed state to ablation. Perturbation displacements exhibit long-range coherence, monopolar and quadrupolar features, and an approximate 1/\textit{r} near-hole upper-bound scaling, implicating the harmonic field. The upper bounds on perturbation stress amplitudes scale approximately like 1/\textit{r}$^2$, a feature relevant to long-range mechanical signalling. [SEP] [HINT] field -> Materials Science (Syns: field of honor, line of business, orbit) | tissue -> Bioinformatics (Syns: tissue paper, weave) | complex -> Bioinformatics (Syns: building complex, coordination compound, composite)",Bioinformatics
"Biological processes rely on finely tuned homo- and heteromeric interactions between (biomacro)molecules. The strength of an interaction, typically given by the dissociation constant (KD), plays a crucial role in basic research and must be monitored throughout the development of drugs and agrochemicals. An ideal method for KD determination is applicable to various analytes with a large range of affinities, tolerates complex matrix compositions, does not require labeling, and simultaneously provides information on the structural integrity of the binding partners. Native mass spectrometry meets these criteria but typically struggles with homooligomeric complexes due to overlapping mass signals. To overcome this, we resolve monomer/dimer contributions to overlapping MS-peaks by separately analyzing the charge state distribution of each oligomeric species via sample dilution and covalent crosslinking. Following this approach, we show that quantitative Laser-Induced Liquid Bead Ion Desorption mass spectrometry (qLILBID-MS) accurately captures the affinities of Bovine Serum Albumin and chemically induced dimers of Tryparedoxin, an oxidoreductase from human pathogenic Trypanosoma brucei parasites, with various molecular glues and homodimer affinities. Conveniently, qLILBID-MS requires a fraction of sample used by other methods such as isothermal titration calorimetry and yields previously inaccessible protein homodimer KDs in the high micromolar range, which allowed us to monitor the gradual decrease in homodimer affinity via mutation of crucial dimer interface contacts. Overall, qLILBID-MS is a sensitive, robust, fast, scalable, and cost-effective alternative to quantify protein/protein interactions that can accelerate contemporary drug discovery workflows, e.g. the efficient screening for proximity inducing molecules like proteolysis targeting chimera and molecular glues.",Bioinformatics
"Biological processes rely on finely tuned homo- and heteromeric interactions between (biomacro)molecules. The strength of an interaction, typically given by the dissociation constant (KD), plays a crucial role in basic research and must be monitored throughout the development of drugs and agrochemicals. An ideal method for KD determination is applicable to various analytes with a large range of affinities, tolerates complex matrix compositions, does not require labeling, and simultaneously provides information on the structural integrity of the binding partners. Native mass spectrometry meets these criteria but typically struggles with homooligomeric complexes due to overlapping mass signals. To overcome this, we resolve monomer/dimer contributions to overlapping MS-peaks by separately analyzing the charge state distribution of each oligomeric species via sample dilution and covalent crosslinking. Following this approach, we show that quantitative Laser-Induced Liquid Bead Ion Desorption mass spectrometry (qLILBID-MS) accurately captures the affinities of Bovine Serum Albumin and chemically induced dimers of Tryparedoxin, an oxidoreductase from human pathogenic Trypanosoma brucei parasites, with various molecular glues and homodimer affinities. Conveniently, qLILBID-MS requires a fraction of sample used by other methods such as isothermal titration calorimetry and yields previously inaccessible protein homodimer KDs in the high micromolar range, which allowed us to monitor the gradual decrease in homodimer affinity via mutation of crucial dimer interface contacts. Overall, qLILBID-MS is a sensitive, robust, fast, scalable, and cost-effective alternative to quantify protein/protein interactions that can accelerate contemporary drug discovery workflows, e.g. the efficient screening for proximity inducing molecules like proteolysis targeting chimera and molecular glues. [SEP] [HINT] used -> Bioinformatics (Syns: utilize, ill-used, apply) | charge -> Materials Science (Syns: tear, bearing, burster) | information -> Bioinformatics (Syns: entropy, data, info)",Bioinformatics
"This paper presents a Physics-\textit{Explainable AI} (XAI) framework to validate and interpret neural networks for the constitutive modeling of solid materials. The study bridges the gap between data-driven models and continuum mechanics by applying a suite of explainability methods to neural networks trained on three distinct material behaviors: hyperelasticity (\textit{Mooney-Rivlin}), elastoplasticity (\textit{Chaboche}), and viscoelasticity (\textit{Fractional Zener}). First, high-fidelity surrogate models, including dense feed-forward networks, LSTMs, and GRUs, are trained on synthetically generated data to accurately capture complex material responses. The core of the work then employs XAI techniques to ""open the black box"" and confirm that the networks learn physically meaningful principles. For hyperelasticity, gradient-based attributions (\textit{Grad Input} (GI)) successfully match the analytical tangent modulus, proving the network learned material stiffness. For elastoplasticity, \textit{SHapley Additive exPlanations} (SHAP) and \textit{Principal Component Analysis} (PCA) demonstrate the \textit{Recurrent Neural Network} (RNN) internalizes path-dependent memory, with SHAP identifying \textit{plastic strain} as the dominant feature governing the stress prediction. For viscoelasticity, latent-space and wavelet analyses of the \textit{Gated Recurrent Unit. } GRU layers reveal a clear temporal hierarchy, with different layers encoding instantaneous elastic response, intermediate relaxation, and long-term fractional memory. Ultimately, the study demonstrates that the XAI framework can verify that the neural networks are not merely curve-fitting but are, in fact, learning the underlying physical mechanisms of stiffness, history-dependence, and temporal damping.",Materials Science
"This paper presents a Physics-\textit{Explainable AI} (XAI) framework to validate and interpret neural networks for the constitutive modeling of solid materials. The study bridges the gap between data-driven models and continuum mechanics by applying a suite of explainability methods to neural networks trained on three distinct material behaviors: hyperelasticity (\textit{Mooney-Rivlin}), elastoplasticity (\textit{Chaboche}), and viscoelasticity (\textit{Fractional Zener}). First, high-fidelity surrogate models, including dense feed-forward networks, LSTMs, and GRUs, are trained on synthetically generated data to accurately capture complex material responses. The core of the work then employs XAI techniques to ""open the black box"" and confirm that the networks learn physically meaningful principles. For hyperelasticity, gradient-based attributions (\textit{Grad Input} (GI)) successfully match the analytical tangent modulus, proving the network learned material stiffness. For elastoplasticity, \textit{SHapley Additive exPlanations} (SHAP) and \textit{Principal Component Analysis} (PCA) demonstrate the \textit{Recurrent Neural Network} (RNN) internalizes path-dependent memory, with SHAP identifying \textit{plastic strain} as the dominant feature governing the stress prediction. For viscoelasticity, latent-space and wavelet analyses of the \textit{Gated Recurrent Unit. } GRU layers reveal a clear temporal hierarchy, with different layers encoding instantaneous elastic response, intermediate relaxation, and long-term fractional memory. Ultimately, the study demonstrates that the XAI framework can verify that the neural networks are not merely curve-fitting but are, in fact, learning the underlying physical mechanisms of stiffness, history-dependence, and temporal damping. [SEP] [HINT] learning -> Bioinformatics (Syns: take, teach, acquire) | networks -> Neuroscience (Syns: network, meshwork, electronic network) | complex -> Bioinformatics (Syns: building complex, coordination compound, composite)",Materials Science
"This review examines the evidence in the literature for physiological co-modulation during human-animal interaction. The aim of this work is to identify studies that assessed co-modulation via simultaneous measurement of physiological signals in both species, performing quantitative comparisons, and evaluate the consistency of the findings.\\ We searched PubMed, EM-BASE, Scopus, Google Scholar, Animal Studies Repository, and the ''Consensus app'' tool between June and August 2025 (last search: August 5, 2025). Risk of bias was assessed using an adapted version of the ROBINS-I V2 tool. Results were grouped by data analysis method, interaction context, and physiological parameter. Data were synthesised narratively, in structured tables and in barplots. Thirty-seven studies were included, primarily focusing on dogs (n=22) and horses (n=15), framed primarily within the interaction contexts of Animal-Assisted Therapy and Intervention (AAT and AAI) and companionship. Cardiac and hormonal measures were most frequently assessed. Most studies (n = 20) performed correlation analyses. Sample sizes ranged from less than 10 to more than 130 dyads. Co-modulation resulted significant in 22 studies, partial (limited to subsets of data) in 9, and absent in 6. Time-series coupling methods yielded more consistent evidence than discrete-time correlations. Many studies had small samples and did not explicitly test for significant co-modulation. Evidence, while not conclusive, supports physiological co-modulation during human-animal interactions. However, studies' heterogeneity limits generalizability: rather than indicating a universal phenomenon, findings suggest co-modulation may emerge under specific biological and methodological conditions. Future research should explicitly test its presence across contexts.",Neuroscience
"This review examines the evidence in the literature for physiological co-modulation during human-animal interaction. The aim of this work is to identify studies that assessed co-modulation via simultaneous measurement of physiological signals in both species, performing quantitative comparisons, and evaluate the consistency of the findings.\\ We searched PubMed, EM-BASE, Scopus, Google Scholar, Animal Studies Repository, and the ''Consensus app'' tool between June and August 2025 (last search: August 5, 2025). Risk of bias was assessed using an adapted version of the ROBINS-I V2 tool. Results were grouped by data analysis method, interaction context, and physiological parameter. Data were synthesised narratively, in structured tables and in barplots. Thirty-seven studies were included, primarily focusing on dogs (n=22) and horses (n=15), framed primarily within the interaction contexts of Animal-Assisted Therapy and Intervention (AAT and AAI) and companionship. Cardiac and hormonal measures were most frequently assessed. Most studies (n = 20) performed correlation analyses. Sample sizes ranged from less than 10 to more than 130 dyads. Co-modulation resulted significant in 22 studies, partial (limited to subsets of data) in 9, and absent in 6. Time-series coupling methods yielded more consistent evidence than discrete-time correlations. Many studies had small samples and did not explicitly test for significant co-modulation. Evidence, while not conclusive, supports physiological co-modulation during human-animal interactions. However, studies' heterogeneity limits generalizability: rather than indicating a universal phenomenon, findings suggest co-modulation may emerge under specific biological and methodological conditions. Future research should explicitly test its presence across contexts. [SEP] [HINT] work -> Bioinformatics (Syns: work out, process, bring) | results -> Bioinformatics (Syns: final result, consequence, resultant role) | using -> Bioinformatics (Syns: utilize, exploitation, apply)",Neuroscience
"Electronic properties of silicon-based clathrates can be tuned by boron incorporation into the silicon cage network. Sodium borosilicides clathrate outstands with uncommon stoichiometry and expected metallic properties, in contrast to other alcali metal semiconductive Zintl borosilicides. In this study, we report an experimental investigation of the high-pressure behavior of type-I and type-VIII sodium borosilicide clathrates. An isostructural phase transition, marked by an abrupt volume collapse at 13 GPa, is observed exclusively in type-I sodium borosilicide clathrates. This transition is attributed to the pressure-induced diffusion of silicon atoms into cationic sites. This mechanism provides the first experimental validation of a transition predicted theoretically for this class of materials. Isostructural phase transitions were only observed in type-I borosilicide. In contrast, the type-VIII borosilicide phase exhibits conventional elastic compression. The metallic character was established using reflectance spectroscopy over a wide energy range, in good agreement with crystallographic data on the boron content.",Materials Science
"Electronic properties of silicon-based clathrates can be tuned by boron incorporation into the silicon cage network. Sodium borosilicides clathrate outstands with uncommon stoichiometry and expected metallic properties, in contrast to other alcali metal semiconductive Zintl borosilicides. In this study, we report an experimental investigation of the high-pressure behavior of type-I and type-VIII sodium borosilicide clathrates. An isostructural phase transition, marked by an abrupt volume collapse at 13 GPa, is observed exclusively in type-I sodium borosilicide clathrates. This transition is attributed to the pressure-induced diffusion of silicon atoms into cationic sites. This mechanism provides the first experimental validation of a transition predicted theoretically for this class of materials. Isostructural phase transitions were only observed in type-I borosilicide. In contrast, the type-VIII borosilicide phase exhibits conventional elastic compression. The metallic character was established using reflectance spectroscopy over a wide energy range, in good agreement with crystallographic data on the boron content. [SEP] [HINT] transition -> Materials Science (Syns: passage, modulation, changeover) | electronic -> Materials Science (Syns: ) | metal -> Materials Science (Syns: metallic element, metallic, alloy)",Materials Science
"Large-scale pre-trained models hold significant potential for learning universal EEG representations. However, most existing methods, particularly autoregressive (AR) frameworks, primarily rely on straightforward temporal sequencing of multi-channel EEG data, which fails to capture the rich physiological characteristics inherent to EEG signals. Moreover, their time-centered modeling approach also limits the effective representation of the dynamic spatial topology of brain activity. To address these challenges and fully exploit the potential of large-scale EEG models, we propose a novel Topology Hierarchical Derived Brain Autoregressive Modeling (THD-BAR) for EEG generic representations. The core innovation of THD-BAR lies in the introduction of the Brain Topology Hierarchy (BTH), which establishes a multi-scale spatial order for EEG channels. This hierarchical structure enables a redefinition of autoregressive learning as a ""next-scale-time prediction"" problem, effectively capturing both spatial and temporal dynamics. Based on BTH, we design a Topology-Hierarchical Vector Quantized-Variational Autoencoder (THVQ-VAE) for multi-scale tokenization and develop an enhanced Brain Autoregressive (BAR) module with specialized masking strategies for prediction. Through extensive large-scale pre-training on 17 datasets, followed by rigorous validation on 10 downstream datasets spanning 5 distinct tasks, THD-BAR consistently outperforms existing methods. These results highlight the superior generalization and modeling capabilities of our proposed approach.",Neuroscience
"Large-scale pre-trained models hold significant potential for learning universal EEG representations. However, most existing methods, particularly autoregressive (AR) frameworks, primarily rely on straightforward temporal sequencing of multi-channel EEG data, which fails to capture the rich physiological characteristics inherent to EEG signals. Moreover, their time-centered modeling approach also limits the effective representation of the dynamic spatial topology of brain activity. To address these challenges and fully exploit the potential of large-scale EEG models, we propose a novel Topology Hierarchical Derived Brain Autoregressive Modeling (THD-BAR) for EEG generic representations. The core innovation of THD-BAR lies in the introduction of the Brain Topology Hierarchy (BTH), which establishes a multi-scale spatial order for EEG channels. This hierarchical structure enables a redefinition of autoregressive learning as a ""next-scale-time prediction"" problem, effectively capturing both spatial and temporal dynamics. Based on BTH, we design a Topology-Hierarchical Vector Quantized-Variational Autoencoder (THVQ-VAE) for multi-scale tokenization and develop an enhanced Brain Autoregressive (BAR) module with specialized masking strategies for prediction. Through extensive large-scale pre-training on 17 datasets, followed by rigorous validation on 10 downstream datasets spanning 5 distinct tasks, THD-BAR consistently outperforms existing methods. These results highlight the superior generalization and modeling capabilities of our proposed approach. [SEP] [HINT] based -> Bioinformatics (Syns: ground, free-base, base) | learning -> Bioinformatics (Syns: take, teach, acquire) | structure -> Bioinformatics (Syns: social system, complex body part, social structure)",Neuroscience
"The scientific study of the retina has reached a remarkable state of completion. We can now explain many aspects of early visual processing based on a relatively simple model of neural circuitry in the retina. The same model, with different parameters, produces a great diversity of neural computations. In this article I lay out what that ""standard model"" is and how it accounts for such a diversity of phenomena. The emergence of such a powerful standard model is unique in systems neuroscience, and I consider what conditions made it possible. The standard model now serves as a baseline from which to organize future retinal research, either by testing the model's assumptions directly, or by identifying phenomena that remain unexplained.",Neuroscience
"The scientific study of the retina has reached a remarkable state of completion. We can now explain many aspects of early visual processing based on a relatively simple model of neural circuitry in the retina. The same model, with different parameters, produces a great diversity of neural computations. In this article I lay out what that ""standard model"" is and how it accounts for such a diversity of phenomena. The emergence of such a powerful standard model is unique in systems neuroscience, and I consider what conditions made it possible. The standard model now serves as a baseline from which to organize future retinal research, either by testing the model's assumptions directly, or by identifying phenomena that remain unexplained. [SEP] [HINT] based -> Bioinformatics (Syns: ground, free-base, base) | processing -> Neuroscience (Syns: work, process, march) | systems -> Bioinformatics (Syns: organization, organisation, system)",Neuroscience
"Empirical evidence of scaling behaviors in neuronal avalanches suggests that neuronal populations in the brain operate near criticality. Departure from scaling in neuronal avalanches has been used as a measure of distance to criticality and linked to brain disorders. A distinct line of evidence for brain criticality has come from thermodynamic signatures in maximum entropy (ME) models. Both of these approaches have been widely applied to the analysis of neuronal data. However, the relationship between deviations from avalanche criticality and thermodynamics of ME models of neuronal populations remains poorly understood. To address this question, we study spontaneous activity of organotypic rat cortex slice cultures in physiological and drug-induced hypo- or hyper-excitable conditions, which are classified as critical, subcritical and supercritical based on avalanche dynamics. We find that ME models inferred from critical cultures show signatures of criticality in thermodynamic quantities, e.g. specific heat. However, such signatures are also present, and equally strong, in models inferred from supercritical cultures -- despite their altered dynamics and poor functional performance. On the contrary, ME models inferred from subcritical cultures do not show thermodynamic hints of criticality. Importantly, we confirm these results using an interpretable neural network model that can be tuned to and away from avalanche criticality. Our findings indicate that maximum entropy models correctly distinguish subcritical from critical/supercritical systems. However, they may not be able to discriminate between avalanche criticality and supercriticality, although they may still capture a number of important features from neuronal data.",Neuroscience
"Empirical evidence of scaling behaviors in neuronal avalanches suggests that neuronal populations in the brain operate near criticality. Departure from scaling in neuronal avalanches has been used as a measure of distance to criticality and linked to brain disorders. A distinct line of evidence for brain criticality has come from thermodynamic signatures in maximum entropy (ME) models. Both of these approaches have been widely applied to the analysis of neuronal data. However, the relationship between deviations from avalanche criticality and thermodynamics of ME models of neuronal populations remains poorly understood. To address this question, we study spontaneous activity of organotypic rat cortex slice cultures in physiological and drug-induced hypo- or hyper-excitable conditions, which are classified as critical, subcritical and supercritical based on avalanche dynamics. We find that ME models inferred from critical cultures show signatures of criticality in thermodynamic quantities, e.g. specific heat. However, such signatures are also present, and equally strong, in models inferred from supercritical cultures -- despite their altered dynamics and poor functional performance. On the contrary, ME models inferred from subcritical cultures do not show thermodynamic hints of criticality. Importantly, we confirm these results using an interpretable neural network model that can be tuned to and away from avalanche criticality. Our findings indicate that maximum entropy models correctly distinguish subcritical from critical/supercritical systems. However, they may not be able to discriminate between avalanche criticality and supercriticality, although they may still capture a number of important features from neuronal data. [SEP] [HINT] used -> Bioinformatics (Syns: utilize, ill-used, apply) | based -> Bioinformatics (Syns: ground, free-base, base) | features -> Bioinformatics (Syns: characteristic, lineament, feature of speech)",Neuroscience
"Protein sequence alignment is a cornerstone of bioinformatics, traditionally approached using dynamic programming (DP) algorithms that find an optimal sequential path. This paper introduces UniOTalign, a novel framework that recasts alignment from a fundamentally different perspective: global matching via Optimal Transport (OT). Instead of finding a path, UniOTalign computes an optimal flow or transport plan between two proteins, which are represented as distributions of residues in a high-dimensional feature space. We leverage pre-trained Protein Language Models (PLMs) to generate rich, context-aware embeddings for each residue. The core of our method is the Fused Unbalanced Gromov-Wasserstein (FUGW) distance, which finds a correspondence that simultaneously minimizes feature dissimilarity and preserves the internal geometric structure of the sequences. This approach naturally handles sequences of different lengths and is particularly powerful for aligning proteins with nonsequential similarities, such as domain shuffling or circular permutations, which are challenging for traditional DP methods. UniOTalign therefore offers a new, mathematically principled, global matching paradigm for protein alignment, moving beyond the limitations of path-finding algorithms.",Bioinformatics
"Protein sequence alignment is a cornerstone of bioinformatics, traditionally approached using dynamic programming (DP) algorithms that find an optimal sequential path. This paper introduces UniOTalign, a novel framework that recasts alignment from a fundamentally different perspective: global matching via Optimal Transport (OT). Instead of finding a path, UniOTalign computes an optimal flow or transport plan between two proteins, which are represented as distributions of residues in a high-dimensional feature space. We leverage pre-trained Protein Language Models (PLMs) to generate rich, context-aware embeddings for each residue. The core of our method is the Fused Unbalanced Gromov-Wasserstein (FUGW) distance, which finds a correspondence that simultaneously minimizes feature dissimilarity and preserves the internal geometric structure of the sequences. This approach naturally handles sequences of different lengths and is particularly powerful for aligning proteins with nonsequential similarities, such as domain shuffling or circular permutations, which are challenging for traditional DP methods. UniOTalign therefore offers a new, mathematically principled, global matching paradigm for protein alignment, moving beyond the limitations of path-finding algorithms. [SEP] [HINT] language -> Neuroscience (Syns: linguistic process, linguistic communication, spoken communication) | transport -> Materials Science (Syns: transferral, enthral, shipping) | structure -> Bioinformatics (Syns: social system, complex body part, social structure)",Bioinformatics
"Understanding structure-property relationships in materials is fundamental in condensed matter physics and materials science. Over the past few years, machine learning (ML) has emerged as a powerful tool for advancing this understanding and accelerating materials discovery. Early ML approaches primarily focused on constructing and screening large material spaces to identify promising candidates for various applications. More recently, research efforts have increasingly shifted toward generating crystal structures using end-to-end generative models. This review analyzes the current state of generative modeling for crystal structure prediction and \textit{de novo} generation. It examines crystal representations, outlines the generative models used to design crystal structures, and evaluates their respective strengths and limitations. Furthermore, the review highlights experimental considerations for evaluating generated structures and provides recommendations for suitable existing software tools. Emerging topics, such as modeling disorder and defects, integration in advanced characterization, and incorporating synthetic feasibility constraints, are explored. Ultimately, this work aims to inform both experimental scientists looking to adapt suitable ML models to their specific circumstances and ML specialists seeking to understand the unique challenges related to inverse materials design and discovery.",Materials Science
"Understanding structure-property relationships in materials is fundamental in condensed matter physics and materials science. Over the past few years, machine learning (ML) has emerged as a powerful tool for advancing this understanding and accelerating materials discovery. Early ML approaches primarily focused on constructing and screening large material spaces to identify promising candidates for various applications. More recently, research efforts have increasingly shifted toward generating crystal structures using end-to-end generative models. This review analyzes the current state of generative modeling for crystal structure prediction and \textit{de novo} generation. It examines crystal representations, outlines the generative models used to design crystal structures, and evaluates their respective strengths and limitations. Furthermore, the review highlights experimental considerations for evaluating generated structures and provides recommendations for suitable existing software tools. Emerging topics, such as modeling disorder and defects, integration in advanced characterization, and incorporating synthetic feasibility constraints, are explored. Ultimately, this work aims to inform both experimental scientists looking to adapt suitable ML models to their specific circumstances and ML specialists seeking to understand the unique challenges related to inverse materials design and discovery. [SEP] [HINT] used -> Bioinformatics (Syns: utilize, ill-used, apply) | understanding -> Neuroscience (Syns: savvy, intellect, sympathy) | learning -> Bioinformatics (Syns: take, teach, acquire)",Materials Science
"Variants of Uncertain Significance (VUS) limit the clinical utility of prostate cancer genomics by delaying diagnosis and therapy when evidence for pathogenicity or benignity is incomplete. Progress is further limited by inconsistent annotations across sources and the absence of a prostate-specific benchmark for fair comparison. We introduce Prostate-VarBench, a curated pipeline for creating prostate-specific benchmarks that integrates COSMIC (somatic cancer mutations), ClinVar (expert-curated clinical variants), and TCGA-PRAD (prostate tumor genomics from The Cancer Genome Atlas) into a harmonized dataset of 193,278 variants supporting patient- or gene-aware splits to prevent data leakage. To ensure data integrity, we corrected a Variant Effect Predictor (VEP) issue that merged multiple transcript records, introducing ambiguity in clinical significance fields. We then standardized 56 interpretable features across eight clinically relevant tiers, including population frequency, variant type, and clinical context. AlphaMissense pathogenicity scores were incorporated to enhance missense variant classification and reduce VUS uncertainty. Building on this resource, we trained an interpretable TabNet model to classify variant pathogenicity, whose step-wise sparse masks provide per-case rationales consistent with molecular tumor board review practices. On the held-out test set, the model achieved 89.9% accuracy with balanced class metrics, and the VEP correction yields an 6.5% absolute reduction in VUS.",Bioinformatics
"Variants of Uncertain Significance (VUS) limit the clinical utility of prostate cancer genomics by delaying diagnosis and therapy when evidence for pathogenicity or benignity is incomplete. Progress is further limited by inconsistent annotations across sources and the absence of a prostate-specific benchmark for fair comparison. We introduce Prostate-VarBench, a curated pipeline for creating prostate-specific benchmarks that integrates COSMIC (somatic cancer mutations), ClinVar (expert-curated clinical variants), and TCGA-PRAD (prostate tumor genomics from The Cancer Genome Atlas) into a harmonized dataset of 193,278 variants supporting patient- or gene-aware splits to prevent data leakage. To ensure data integrity, we corrected a Variant Effect Predictor (VEP) issue that merged multiple transcript records, introducing ambiguity in clinical significance fields. We then standardized 56 interpretable features across eight clinically relevant tiers, including population frequency, variant type, and clinical context. AlphaMissense pathogenicity scores were incorporated to enhance missense variant classification and reduce VUS uncertainty. Building on this resource, we trained an interpretable TabNet model to classify variant pathogenicity, whose step-wise sparse masks provide per-case rationales consistent with molecular tumor board review practices. On the held-out test set, the model achieved 89.9% accuracy with balanced class metrics, and the VEP correction yields an 6.5% absolute reduction in VUS. [SEP] [HINT] clinical -> Bioinformatics (Syns: ) | features -> Bioinformatics (Syns: characteristic, lineament, feature of speech) | molecular -> Bioinformatics (Syns: )",Bioinformatics
"Criticality describes a regime between order and chaos that supports flexible yet stable information processing. Here we examine whether neural dynamics can be volitionally shifted toward criticality through the self-regulation of attention. We examined ten experienced practitioners of meditation during a 10-day retreat, comparing refined states of meditative absorption, called the jhanas, to regular mindfulness of breathing. We collected electroencephalography (EEG) and physiological data during these practices and quantified the signal's dynamical properties using Lempel-Ziv complexity, signal entropy, chaoticity and long-range temporal correlations. In addition, we estimated perturbational sensitivity using a global auditory oddball mismatch negativity (MMN) during meditation. Relative to mindfulness, jhana was associated with pronounced self-reported sensory fading, slower respiration, higher neural signal diversity across multiple measures, reduced chaoticity, and enhanced MMN amplitude over frontocentral sites. Spectral analyses showed a flatter aperiodic one over f component and a frequency-specific reorganization of long-range temporal correlations. Together, increased diversity with reduced chaoticity and heightened deviance detection indicate a shift toward a metastable, near-critical regime during jhana. We propose an overlap of the phenomenology of jhana with minimal phenomenal experiences in terms of progressive attenuation of sensory content with preserved tonic alertness. Accordingly, our findings suggest that criticality is a candidate neurophysiological marker of the absorptive, minimal-content dimension of the minimal phenomenal experience.",Neuroscience
"Criticality describes a regime between order and chaos that supports flexible yet stable information processing. Here we examine whether neural dynamics can be volitionally shifted toward criticality through the self-regulation of attention. We examined ten experienced practitioners of meditation during a 10-day retreat, comparing refined states of meditative absorption, called the jhanas, to regular mindfulness of breathing. We collected electroencephalography (EEG) and physiological data during these practices and quantified the signal's dynamical properties using Lempel-Ziv complexity, signal entropy, chaoticity and long-range temporal correlations. In addition, we estimated perturbational sensitivity using a global auditory oddball mismatch negativity (MMN) during meditation. Relative to mindfulness, jhana was associated with pronounced self-reported sensory fading, slower respiration, higher neural signal diversity across multiple measures, reduced chaoticity, and enhanced MMN amplitude over frontocentral sites. Spectral analyses showed a flatter aperiodic one over f component and a frequency-specific reorganization of long-range temporal correlations. Together, increased diversity with reduced chaoticity and heightened deviance detection indicate a shift toward a metastable, near-critical regime during jhana. We propose an overlap of the phenomenology of jhana with minimal phenomenal experiences in terms of progressive attenuation of sensory content with preserved tonic alertness. Accordingly, our findings suggest that criticality is a candidate neurophysiological marker of the absorptive, minimal-content dimension of the minimal phenomenal experience. [SEP] [HINT] information -> Bioinformatics (Syns: entropy, data, info) | order -> Materials Science (Syns: enjoin, dictate, social club) | using -> Bioinformatics (Syns: utilize, exploitation, apply)",Neuroscience
"Neural decoding from electroencephalography (EEG) remains fundamentally limited by poor generalization to unseen subjects, driven by high inter-subject variability and the lack of large-scale datasets to model it effectively. Existing methods often rely on synthetic subject generation or simplistic data augmentation, but these strategies fail to scale or generalize reliably. We introduce \textit{MultiDiffNet}, a diffusion-based framework that bypasses generative augmentation entirely by learning a compact latent space optimized for multiple objectives. We decode directly from this space and achieve state-of-the-art generalization across various neural decoding tasks using subject and session disjoint evaluation. We also curate and release a unified benchmark suite spanning four EEG decoding tasks of increasing complexity (SSVEP, Motor Imagery, P300, and Imagined Speech) and an evaluation protocol that addresses inconsistent split practices in prior EEG research. Finally, we develop a statistical reporting framework tailored for low-trial EEG settings. Our work provides a reproducible and open-source foundation for subject-agnostic EEG decoding in real-world BCI systems.",Neuroscience
"Neural decoding from electroencephalography (EEG) remains fundamentally limited by poor generalization to unseen subjects, driven by high inter-subject variability and the lack of large-scale datasets to model it effectively. Existing methods often rely on synthetic subject generation or simplistic data augmentation, but these strategies fail to scale or generalize reliably. We introduce \textit{MultiDiffNet}, a diffusion-based framework that bypasses generative augmentation entirely by learning a compact latent space optimized for multiple objectives. We decode directly from this space and achieve state-of-the-art generalization across various neural decoding tasks using subject and session disjoint evaluation. We also curate and release a unified benchmark suite spanning four EEG decoding tasks of increasing complexity (SSVEP, Motor Imagery, P300, and Imagined Speech) and an evaluation protocol that addresses inconsistent split practices in prior EEG research. Finally, we develop a statistical reporting framework tailored for low-trial EEG settings. Our work provides a reproducible and open-source foundation for subject-agnostic EEG decoding in real-world BCI systems. [SEP] [HINT] decoding -> Neuroscience (Syns: decrypt, decipherment, decryption) | tasks -> Neuroscience (Syns: tax, task, project) | learning -> Bioinformatics (Syns: take, teach, acquire)",Neuroscience
"Photoplethysmography (PPG) is a common tool for monitoring cardiopulmonary health. Relying on absorption or reflectance of light by hemoglobin in the blood, the measured PPG waveform can be analyzed per heart beat using physiological assumptions to extract metrics ranging from heart rate to specific blood oxygenation (SpO2). This has led to the widespread use of PPG for bedside clinical monitoring to wearable consumer health monitoring. However, PPG is notoriously noisy and the measured absorption or reflectance of light is sensitive to factors such as body movement and contact with the skin. To reduce the noise in the PPG-derived SpO2, we developed combined traditional methods of estimating SpO2 from the PPG waveform with a new method to extract changes in SpO2 from the PPG waveform in a Kalman filter, and demonstrated its ability to better estimate SpO2 in humans undergoing controlled hypoxia (down to 14% atmospheric oxygen). The Kalman filter reduced variability in SpO2 to 4.30%SpO2 compared to the beat-to-beat SpO2 variability of 12.59%SpO2. This mirrored current methods of window-averaging the beat-to-beat SpO2, with a 30s window-average reducing SpO2 variability to 4.73%. However, current window-average methods also introduce delays, with 10s and 30s window-averaging introducing delays of 5s and 14s respectively compared to the beat-to-beat SpO2. The Kalman filter reduced this delay to within 3s of the beat-to-beat SpO2, highlighting its ability to reduce noise while maintaining SpO2 dynamics. This capability is particularly useful in reliably detecting clinically meaningful, but transient, hypoxic states, such as those observed during apnea.",Bioinformatics
"Photoplethysmography (PPG) is a common tool for monitoring cardiopulmonary health. Relying on absorption or reflectance of light by hemoglobin in the blood, the measured PPG waveform can be analyzed per heart beat using physiological assumptions to extract metrics ranging from heart rate to specific blood oxygenation (SpO2). This has led to the widespread use of PPG for bedside clinical monitoring to wearable consumer health monitoring. However, PPG is notoriously noisy and the measured absorption or reflectance of light is sensitive to factors such as body movement and contact with the skin. To reduce the noise in the PPG-derived SpO2, we developed combined traditional methods of estimating SpO2 from the PPG waveform with a new method to extract changes in SpO2 from the PPG waveform in a Kalman filter, and demonstrated its ability to better estimate SpO2 in humans undergoing controlled hypoxia (down to 14% atmospheric oxygen). The Kalman filter reduced variability in SpO2 to 4.30%SpO2 compared to the beat-to-beat SpO2 variability of 12.59%SpO2. This mirrored current methods of window-averaging the beat-to-beat SpO2, with a 30s window-average reducing SpO2 variability to 4.73%. However, current window-average methods also introduce delays, with 10s and 30s window-averaging introducing delays of 5s and 14s respectively compared to the beat-to-beat SpO2. The Kalman filter reduced this delay to within 3s of the beat-to-beat SpO2, highlighting its ability to reduce noise while maintaining SpO2 dynamics. This capability is particularly useful in reliably detecting clinically meaningful, but transient, hypoxic states, such as those observed during apnea. [SEP] [HINT] clinical -> Bioinformatics (Syns: ) | using -> Bioinformatics (Syns: utilize, exploitation, apply) | specific -> Bioinformatics (Syns: particular)",Bioinformatics
"The structural hierarchy and chemical flexibility of metallosilicates enable broad technological applications, yet they also make it challenging to uncover structure--property relations. Previous large-scale atomistic simulations have provided mechanistic insight, but their accuracy and achievable model complexity remain constrained by the available interatomic potentials. Here, we present an end-to-end workflow for developing accurate and efficient machine-learning potentials, specifically moment tensor potentials (MTPs), tailored for structurally and chemically complex systems such as metallosilicates. The workflow integrates de novo structure generation, surface functionalization, and property evaluation. A domain-specific training strategy is employed: Configurations associated with melt--quench generation and subsequent functionalization train the syn-MTP, whereas configurations near equilibrium train the eq-MTP. We apply the workflow to prototypical metallosilicates, i.e., aluminosilicates, which we also experimentally synthesize and characterize for benchmarking the simulations. The syn-MTP reliably generates amorphous aluminosilicates that match experimental density and pair distribution functions measured with synchrotron X-ray diffraction. The eq-MTP reproduces experimental infrared spectra and surface hydroxyl densities, along with density-functional-theory-derived dehydrogenation energies, demonstrating meta-GGA-level accuracy and validating the end-to-end workflow. Finally, we showcase the applicability of the developed potentials by predicting infrared spectra of functionalized porous aluminosilicates. This study establishes a robust path toward accurate modeling of realistic metallosilicates under operando-relevant conditions.",Materials Science
"The structural hierarchy and chemical flexibility of metallosilicates enable broad technological applications, yet they also make it challenging to uncover structure--property relations. Previous large-scale atomistic simulations have provided mechanistic insight, but their accuracy and achievable model complexity remain constrained by the available interatomic potentials. Here, we present an end-to-end workflow for developing accurate and efficient machine-learning potentials, specifically moment tensor potentials (MTPs), tailored for structurally and chemically complex systems such as metallosilicates. The workflow integrates de novo structure generation, surface functionalization, and property evaluation. A domain-specific training strategy is employed: Configurations associated with melt--quench generation and subsequent functionalization train the syn-MTP, whereas configurations near equilibrium train the eq-MTP. We apply the workflow to prototypical metallosilicates, i.e., aluminosilicates, which we also experimentally synthesize and characterize for benchmarking the simulations. The syn-MTP reliably generates amorphous aluminosilicates that match experimental density and pair distribution functions measured with synchrotron X-ray diffraction. The eq-MTP reproduces experimental infrared spectra and surface hydroxyl densities, along with density-functional-theory-derived dehydrogenation energies, demonstrating meta-GGA-level accuracy and validating the end-to-end workflow. Finally, we showcase the applicability of the developed potentials by predicting infrared spectra of functionalized porous aluminosilicates. This study establishes a robust path toward accurate modeling of realistic metallosilicates under operando-relevant conditions. [SEP] [HINT] structure -> Bioinformatics (Syns: social system, complex body part, social structure) | complex -> Bioinformatics (Syns: building complex, coordination compound, composite) | systems -> Bioinformatics (Syns: organization, organisation, system)",Materials Science
"Electroencephalography (EEG) provides a non-invasive window into brain activity, enabling Brain-Computer Interfaces (BCIs) for communication and control. However, their performance is limited by signal fidelity issues, among which the choice of re-referencing strategy is a pervasive but often overlooked preprocessing bias. Addressing controversies about its necessity and optimal choice, we adopted a quantified approach to evaluate four strategies - no re-referencing, Common Average Reference (CAR), small Laplacian, and large Laplacian - using 62-channels EEG (31 subjects, 2,520 trials). To our knowledge, this is the first study systematically quantifying their impact on single-trial P300 classification accuracy. Our controlled pipeline isolated re-referencing effects for source-space reconstruction (eLORETA with Phase Lag Index) and anatomically constrained classification. The large Laplacian resolves distributed P3b networks while maintaining P3a specificity, achieving the best P300 peak classification accuracy (81.57% hybrid method; 75.97% majority regions of interest). Performance follows a consistent and statistically significant hierarchy: large Laplacian > CAR > no re-reference > small Laplacian, providing a foundation for unified methodological evaluation.",Bioinformatics
"Electroencephalography (EEG) provides a non-invasive window into brain activity, enabling Brain-Computer Interfaces (BCIs) for communication and control. However, their performance is limited by signal fidelity issues, among which the choice of re-referencing strategy is a pervasive but often overlooked preprocessing bias. Addressing controversies about its necessity and optimal choice, we adopted a quantified approach to evaluate four strategies - no re-referencing, Common Average Reference (CAR), small Laplacian, and large Laplacian - using 62-channels EEG (31 subjects, 2,520 trials). To our knowledge, this is the first study systematically quantifying their impact on single-trial P300 classification accuracy. Our controlled pipeline isolated re-referencing effects for source-space reconstruction (eLORETA with Phase Lag Index) and anatomically constrained classification. The large Laplacian resolves distributed P3b networks while maintaining P3a specificity, achieving the best P300 peak classification accuracy (81.57% hybrid method; 75.97% majority regions of interest). Performance follows a consistent and statistically significant hierarchy: large Laplacian > CAR > no re-reference > small Laplacian, providing a foundation for unified methodological evaluation. [SEP] [HINT] networks -> Neuroscience (Syns: network, meshwork, electronic network) | performance -> Bioinformatics (Syns: functioning, operation, carrying out) | using -> Bioinformatics (Syns: utilize, exploitation, apply)",Bioinformatics
"Understanding the encoding and decoding mechanisms of dynamic neural responses to different visual stimuli is an important topic in exploring how the brain represents visual information. Currently, hierarchically deep neural networks (DNNs) have played a significant role as tools for mining the core features of complex data. However, most methods often overlook the dynamic generation process of neural data, such as hierarchical brain's visual data, within the brain's structure. In the decoding of brain's visual data, two main paradigms are 'fine-grained decoding tests' and 'rough-grained decoding tests', which we define as focusing on a single brain region and studying the overall structure across multiple brain regions, respectively. In this paper, we mainly use the Visual Coding Neuropixel dataset from the Allen Brain Institute, and the hierarchical information extracted from some single brain regions (i.e., fine-grained decoding tests) is provided to the proposed method for studying the adaptive topological decoding between brain regions, called the Adaptive Topological Vision Transformer, or AT-ViT. In numerous experiments, the results reveal the importance of the proposed method in hierarchical networks in the visual tasks, and also validate the hypothesis that ""the hierarchical information content in brain regions of the visual system can be quantified by decoding outcomes to reflect an information hierarchy."" Among them, we found that neural data collected in the hippocampus can have a random decoding performance, and this negative impact on performance still holds significant scientific value.",Neuroscience
"Understanding the encoding and decoding mechanisms of dynamic neural responses to different visual stimuli is an important topic in exploring how the brain represents visual information. Currently, hierarchically deep neural networks (DNNs) have played a significant role as tools for mining the core features of complex data. However, most methods often overlook the dynamic generation process of neural data, such as hierarchical brain's visual data, within the brain's structure. In the decoding of brain's visual data, two main paradigms are 'fine-grained decoding tests' and 'rough-grained decoding tests', which we define as focusing on a single brain region and studying the overall structure across multiple brain regions, respectively. In this paper, we mainly use the Visual Coding Neuropixel dataset from the Allen Brain Institute, and the hierarchical information extracted from some single brain regions (i.e., fine-grained decoding tests) is provided to the proposed method for studying the adaptive topological decoding between brain regions, called the Adaptive Topological Vision Transformer, or AT-ViT. In numerous experiments, the results reveal the importance of the proposed method in hierarchical networks in the visual tasks, and also validate the hypothesis that ""the hierarchical information content in brain regions of the visual system can be quantified by decoding outcomes to reflect an information hierarchy."" Among them, we found that neural data collected in the hippocampus can have a random decoding performance, and this negative impact on performance still holds significant scientific value. [SEP] [HINT] decoding -> Neuroscience (Syns: decrypt, decipherment, decryption) | features -> Bioinformatics (Syns: characteristic, lineament, feature of speech) | understanding -> Neuroscience (Syns: savvy, intellect, sympathy)",Neuroscience
"Ultra low voltage operation of Perovskite light emitting diodes (PeLEDs) has been demonstrated in recent years as high radiance with minimal power consumption is a desired feature. However, the light output at such conditions from PeLEDs is typically very low, and the maximum in external quantum efficiency (EQE) and energy conversion efficiency (ECE) are achieved at large biases with significant power consumption. Here, we explore the possibility of achieving maximums in EQE and ECE at sub band gap voltages for PeLEDs. Our analysis consistently interprets otherwise scattered experimental data from literature, identifies the limits for low voltage operation, and elucidates optimization routes for sub band gap high radiance operation of PeLEDs.",Materials Science
"Ultra low voltage operation of Perovskite light emitting diodes (PeLEDs) has been demonstrated in recent years as high radiance with minimal power consumption is a desired feature. However, the light output at such conditions from PeLEDs is typically very low, and the maximum in external quantum efficiency (EQE) and energy conversion efficiency (ECE) are achieved at large biases with significant power consumption. Here, we explore the possibility of achieving maximums in EQE and ECE at sub band gap voltages for PeLEDs. Our analysis consistently interprets otherwise scattered experimental data from literature, identifies the limits for low voltage operation, and elucidates optimization routes for sub band gap high radiance operation of PeLEDs. [SEP] [HINT] low -> Materials Science (Syns: low-spirited, scurvy, depressed) | perovskite -> Materials Science (Syns: ) | band -> Materials Science (Syns: set, stria, dance orchestra)",Materials Science
"Recent advances in protein structure prediction, such as AlphaFold, have demonstrated the power of deep neural architectures like the Evoformer for capturing complex spatial and evolutionary constraints on protein conformation. However, the depth of the Evoformer, comprising 48 stacked blocks, introduces high computational costs and rigid layerwise discretization. Inspired by Neural Ordinary Differential Equations (Neural ODEs), we propose a continuous-depth formulation of the Evoformer, replacing its 48 discrete blocks with a Neural ODE parameterization that preserves its core attention-based operations. This continuous-time Evoformer achieves constant memory cost (in depth) via the adjoint method, while allowing a principled trade-off between runtime and accuracy through adaptive ODE solvers. Benchmarking on protein structure prediction tasks, we find that the Neural ODE-based Evoformer produces structurally plausible predictions and reliably captures certain secondary structure elements, such as alpha-helices, though it does not fully replicate the accuracy of the original architecture. However, our model achieves this performance using dramatically fewer resources, just 17.5 hours of training on a single GPU, highlighting the promise of continuous-depth models as a lightweight and interpretable alternative for biomolecular modeling. This work opens new directions for efficient and adaptive protein structure prediction frameworks.",Bioinformatics
"Recent advances in protein structure prediction, such as AlphaFold, have demonstrated the power of deep neural architectures like the Evoformer for capturing complex spatial and evolutionary constraints on protein conformation. However, the depth of the Evoformer, comprising 48 stacked blocks, introduces high computational costs and rigid layerwise discretization. Inspired by Neural Ordinary Differential Equations (Neural ODEs), we propose a continuous-depth formulation of the Evoformer, replacing its 48 discrete blocks with a Neural ODE parameterization that preserves its core attention-based operations. This continuous-time Evoformer achieves constant memory cost (in depth) via the adjoint method, while allowing a principled trade-off between runtime and accuracy through adaptive ODE solvers. Benchmarking on protein structure prediction tasks, we find that the Neural ODE-based Evoformer produces structurally plausible predictions and reliably captures certain secondary structure elements, such as alpha-helices, though it does not fully replicate the accuracy of the original architecture. However, our model achieves this performance using dramatically fewer resources, just 17.5 hours of training on a single GPU, highlighting the promise of continuous-depth models as a lightweight and interpretable alternative for biomolecular modeling. This work opens new directions for efficient and adaptive protein structure prediction frameworks. [SEP] [HINT] computational -> Neuroscience (Syns: ) | structure -> Bioinformatics (Syns: social system, complex body part, social structure) | complex -> Bioinformatics (Syns: building complex, coordination compound, composite)",Bioinformatics
"This paper introduces an innovative Electronic Health Record (EHR) foundation model that integrates Polygenic Risk Scores (PRS) as a foundational data modality, moving beyond traditional EHR-only approaches to build more holistic health profiles. Leveraging the extensive and diverse data from the All of Us (AoU) Research Program, this multimodal framework aims to learn complex relationships between clinical data and genetic predispositions. The methodology extends advancements in generative AI to the EHR foundation model space, enhancing predictive capabilities and interpretability. Evaluation on AoU data demonstrates the model's predictive value for the onset of various conditions, particularly Type 2 Diabetes (T2D), and illustrates the interplay between PRS and EHR data. The work also explores transfer learning for custom classification tasks, showcasing the architecture's versatility and efficiency. This approach is pivotal for unlocking new insights into disease prediction, proactive health management, risk stratification, and personalized treatment strategies, laying the groundwork for more personalized, equitable, and actionable real-world evidence generation in healthcare.",Bioinformatics
"This paper introduces an innovative Electronic Health Record (EHR) foundation model that integrates Polygenic Risk Scores (PRS) as a foundational data modality, moving beyond traditional EHR-only approaches to build more holistic health profiles. Leveraging the extensive and diverse data from the All of Us (AoU) Research Program, this multimodal framework aims to learn complex relationships between clinical data and genetic predispositions. The methodology extends advancements in generative AI to the EHR foundation model space, enhancing predictive capabilities and interpretability. Evaluation on AoU data demonstrates the model's predictive value for the onset of various conditions, particularly Type 2 Diabetes (T2D), and illustrates the interplay between PRS and EHR data. The work also explores transfer learning for custom classification tasks, showcasing the architecture's versatility and efficiency. This approach is pivotal for unlocking new insights into disease prediction, proactive health management, risk stratification, and personalized treatment strategies, laying the groundwork for more personalized, equitable, and actionable real-world evidence generation in healthcare. [SEP] [HINT] clinical -> Bioinformatics (Syns: ) | learning -> Bioinformatics (Syns: take, teach, acquire) | electronic -> Materials Science (Syns: )",Bioinformatics
"Negatively charged silicon vacancy centers in diamond (SiV$^-$) are promising for quantum photonic technologies. However, when subject to resonant optical excitation, they can inadvertently transfer into a zero-spin optically dark state. We show that this unwanted change of charge state can be quickly reversed by the resonant laser itself in combination with static electric fields. By defining interdigitated metallic contacts on the diamond surface, we increase the steady-state SiV$^-$ photoluminescence under resonant excitation by a factor $\ge3$ for most emitters, making it practically constant for certain individual emitters. We electrically activate single \sivs near the positively biased electrode, which are entirely dark without applying local electric fields. Using time-resolved 3-color experiments, we show that the resonant laser not only excites the SiV$^-$, but also creates free holes that convert SiV$^{2-}$ to SiV$^-$ on a timescale of milliseconds. Through analysis of several individual emitters, our results show that the degree of electrical charge state controllability differs between individual emitters, indicating that their local environment plays a key role. Our proposed electric-field-based stabilization scheme enhances deterministic charge state control in group-IV color centers and improves its understanding, offering a scalable path toward quantum applications such as entanglement generation and quantum key distribution.",Materials Science
"Negatively charged silicon vacancy centers in diamond (SiV$^-$) are promising for quantum photonic technologies. However, when subject to resonant optical excitation, they can inadvertently transfer into a zero-spin optically dark state. We show that this unwanted change of charge state can be quickly reversed by the resonant laser itself in combination with static electric fields. By defining interdigitated metallic contacts on the diamond surface, we increase the steady-state SiV$^-$ photoluminescence under resonant excitation by a factor $\ge3$ for most emitters, making it practically constant for certain individual emitters. We electrically activate single \sivs near the positively biased electrode, which are entirely dark without applying local electric fields. Using time-resolved 3-color experiments, we show that the resonant laser not only excites the SiV$^-$, but also creates free holes that convert SiV$^{2-}$ to SiV$^-$ on a timescale of milliseconds. Through analysis of several individual emitters, our results show that the degree of electrical charge state controllability differs between individual emitters, indicating that their local environment plays a key role. Our proposed electric-field-based stabilization scheme enhances deterministic charge state control in group-IV color centers and improves its understanding, offering a scalable path toward quantum applications such as entanglement generation and quantum key distribution. [SEP] [HINT] charge -> Materials Science (Syns: tear, bearing, burster) | results -> Bioinformatics (Syns: final result, consequence, resultant role) | using -> Bioinformatics (Syns: utilize, exploitation, apply)",Materials Science
"Analysing how neural networks represent data features in their activations can help interpret how they perform tasks. Hence, a long line of work has focused on mathematically characterising the geometry of such ""neural representations."" In parallel, machine learning has seen a surge of interest in understanding how dynamical systems perform computations on time-varying input data. Yet, the link between computation-through-dynamics and representational geometry remains poorly understood. Here, we hypothesise that recurrent neural networks (RNNs) perform computations by dynamically warping their representations of task variables. To test this hypothesis, we develop a Riemannian geometric framework that enables the derivation of the manifold topology and geometry of a dynamical system from the manifold of its inputs. By characterising the time-varying geometry of RNNs, we show that dynamic warping is a fundamental feature of their computations.",Neuroscience
"Analysing how neural networks represent data features in their activations can help interpret how they perform tasks. Hence, a long line of work has focused on mathematically characterising the geometry of such ""neural representations."" In parallel, machine learning has seen a surge of interest in understanding how dynamical systems perform computations on time-varying input data. Yet, the link between computation-through-dynamics and representational geometry remains poorly understood. Here, we hypothesise that recurrent neural networks (RNNs) perform computations by dynamically warping their representations of task variables. To test this hypothesis, we develop a Riemannian geometric framework that enables the derivation of the manifold topology and geometry of a dynamical system from the manifold of its inputs. By characterising the time-varying geometry of RNNs, we show that dynamic warping is a fundamental feature of their computations. [SEP] [HINT] task -> Neuroscience (Syns: tax, project, chore) | features -> Bioinformatics (Syns: characteristic, lineament, feature of speech) | understanding -> Neuroscience (Syns: savvy, intellect, sympathy)",Neuroscience
"Travelling waves of neural firing activity are observed in brain tissue as a part of various sensory, motor and cognitive processes. They represent an object of major interest in the study of excitable networks, with analysis conducted in both neural field models and spiking neuronal networks. The latter class exposes the single-neuron dynamics directly, allowing us to study the details of their influence upon network-scale behaviour. Here we present a study of a laterally-inhibited network of leaky integrate-and-fire neurons modulated by a slow voltage-gated ion channel that acts as a linear adaptation variable. As the strength of the ion channel increases, we find that its interaction with the lateral inhibition increases wave speeds. The ion channel can enable subthreshold oscillations, with the intervals between the firing events of loosely-coupled travelling wave solutions structured around the neuron's natural period. These subthreshold oscillations also enable the occurrence of codimension-2 grazing bifurcations; along with the emergence of fold bifurcations along wave solution branches, the slow ion channel introduces a variety of intermediate structures in the solution space. These point towards further investigation of the role neighbouring solution branches play in the behaviour of waves forced across bifurcations, which we illustrate with the aid of simulations using a novel root-finding algorithm designed to handle uncertainty over the existence of firing solutions.",Neuroscience
"Travelling waves of neural firing activity are observed in brain tissue as a part of various sensory, motor and cognitive processes. They represent an object of major interest in the study of excitable networks, with analysis conducted in both neural field models and spiking neuronal networks. The latter class exposes the single-neuron dynamics directly, allowing us to study the details of their influence upon network-scale behaviour. Here we present a study of a laterally-inhibited network of leaky integrate-and-fire neurons modulated by a slow voltage-gated ion channel that acts as a linear adaptation variable. As the strength of the ion channel increases, we find that its interaction with the lateral inhibition increases wave speeds. The ion channel can enable subthreshold oscillations, with the intervals between the firing events of loosely-coupled travelling wave solutions structured around the neuron's natural period. These subthreshold oscillations also enable the occurrence of codimension-2 grazing bifurcations; along with the emergence of fold bifurcations along wave solution branches, the slow ion channel introduces a variety of intermediate structures in the solution space. These point towards further investigation of the role neighbouring solution branches play in the behaviour of waves forced across bifurcations, which we illustrate with the aid of simulations using a novel root-finding algorithm designed to handle uncertainty over the existence of firing solutions. [SEP] [HINT] field -> Materials Science (Syns: field of honor, line of business, orbit) | tissue -> Bioinformatics (Syns: tissue paper, weave) | using -> Bioinformatics (Syns: utilize, exploitation, apply)",Neuroscience
"mRNA design and optimization are important in synthetic biology and therapeutic development, but remain understudied in machine learning. Systematic optimization of mRNAs is hindered by the scarce and imbalanced data as well as complex sequence-function relationships. We present RNAGenScape, a property-guided manifold Langevin dynamics framework that iteratively updates mRNA sequences within a learned latent manifold. RNAGenScape combines an organized autoencoder, which structures the latent space by target properties for efficient and biologically plausible exploration, with a manifold projector that contracts each step of update back to the manifold. RNAGenScape supports property-guided optimization and smooth interpolation between sequences, while remaining robust under scarce and undersampled data, and ensuring that intermediate products are close to the viable mRNA manifold. Across three real mRNA datasets, RNAGenScape improves the target properties with high success rates and efficiency, outperforming various generative or optimization methods developed for proteins or non-biological data. By providing continuous, data-aligned trajectories that reveal how edits influence function, RNAGenScape establishes a scalable paradigm for controllable mRNA design and latent space exploration in mRNA sequence modeling.",Bioinformatics
"mRNA design and optimization are important in synthetic biology and therapeutic development, but remain understudied in machine learning. Systematic optimization of mRNAs is hindered by the scarce and imbalanced data as well as complex sequence-function relationships. We present RNAGenScape, a property-guided manifold Langevin dynamics framework that iteratively updates mRNA sequences within a learned latent manifold. RNAGenScape combines an organized autoencoder, which structures the latent space by target properties for efficient and biologically plausible exploration, with a manifold projector that contracts each step of update back to the manifold. RNAGenScape supports property-guided optimization and smooth interpolation between sequences, while remaining robust under scarce and undersampled data, and ensuring that intermediate products are close to the viable mRNA manifold. Across three real mRNA datasets, RNAGenScape improves the target properties with high success rates and efficiency, outperforming various generative or optimization methods developed for proteins or non-biological data. By providing continuous, data-aligned trajectories that reveal how edits influence function, RNAGenScape establishes a scalable paradigm for controllable mRNA design and latent space exploration in mRNA sequence modeling. [SEP] [HINT] space -> Neuroscience (Syns: distance, place, outer space) | complex -> Bioinformatics (Syns: building complex, coordination compound, composite) | framework -> Bioinformatics (Syns: theoretical account, model, fabric)",Bioinformatics
"Human cooperation depends on how accurately we infer others' motives--how much they value fairness, generosity, or self-interest from the choices they make. We model that process in binary dictator games, which isolate moral trade-offs between self and other stripped of strategic complexity. Participants observed others' allocation decisions and predicted their future behavior while playing through an exhaustive, randomized payoff space implemented on The Morality Game platform. We formalize social-preference learning as Bayesian belief updating over continuous parameters such as self-interest, altruism, envy, and guilt. The resulting Utility Bayesian Model (UBM) outperformed non-Bayesian alternatives and Bayesian models that categorize others into discrete social types. Because Bayesian updating requires a utility function in its likelihood term, we conducted the largest utility-function comparison to date--476 candidate forms differing in psychologically meaningful properties (e.g., payoff exponents, reference dependence, payoff ratios, and envy-guilt asymmetries). Exploring this joint space of payoffs and models allowed us to identify the function that unifies prior theories and generalizes across payoff conditions. Parameter estimation revealed moderate altruism, strong inequality aversion, and nonlinear payoff valuation (exponent > 1). Altruism and social-comparison motives were largely independent, revealing diverse moral phenotypes from cooperative to competitive or sadistic. Together, these findings provide a computational framework and a map of social motives, clarifying how humans learn whom to trust and offering quantitative foundations for promoting cooperation in social and artificial systems.",Neuroscience
"Human cooperation depends on how accurately we infer others' motives--how much they value fairness, generosity, or self-interest from the choices they make. We model that process in binary dictator games, which isolate moral trade-offs between self and other stripped of strategic complexity. Participants observed others' allocation decisions and predicted their future behavior while playing through an exhaustive, randomized payoff space implemented on The Morality Game platform. We formalize social-preference learning as Bayesian belief updating over continuous parameters such as self-interest, altruism, envy, and guilt. The resulting Utility Bayesian Model (UBM) outperformed non-Bayesian alternatives and Bayesian models that categorize others into discrete social types. Because Bayesian updating requires a utility function in its likelihood term, we conducted the largest utility-function comparison to date--476 candidate forms differing in psychologically meaningful properties (e.g., payoff exponents, reference dependence, payoff ratios, and envy-guilt asymmetries). Exploring this joint space of payoffs and models allowed us to identify the function that unifies prior theories and generalizes across payoff conditions. Parameter estimation revealed moderate altruism, strong inequality aversion, and nonlinear payoff valuation (exponent > 1). Altruism and social-comparison motives were largely independent, revealing diverse moral phenotypes from cooperative to competitive or sadistic. Together, these findings provide a computational framework and a map of social motives, clarifying how humans learn whom to trust and offering quantitative foundations for promoting cooperation in social and artificial systems. [SEP] [HINT] computational -> Neuroscience (Syns: ) | learning -> Bioinformatics (Syns: take, teach, acquire) | space -> Neuroscience (Syns: distance, place, outer space)",Neuroscience
"Cognitive impairment in multiple sclerosis (MS) is driven by both focal inflammation and compartmentalized neurodegeneration, yet the relative effect of lesion-independent thalamic atrophy on information processing speed (IPS) remains unclear. This retrospective cohort study included 100 participants with MS. Automatic segmentation techniques quantified lesion load and delineated 26 thalamic regions of interest (ROIs). Linear models compared associations between ROI volumes and Symbol Digit Modalities Test (SDMT) performance in lesion-adjusted and unadjusted models. Twenty-one of 26 ROIs showed significant SDMT associations before lesion adjustment; twelve remained significant after adjustment. Lesion-independent associations were observed in the global thalamus, sensory relay nuclei (ventral posterolateral, medial and lateral geniculate), and associative hubs (pulvinar and mediodorsal-parafascicular complex). These intrinsically vulnerable nuclei exhibited significantly lower lesion-mediated effects (13.4%) than those losing significance after adjustment (34.2%, p < 0.001). Our findings suggest that IPS impairment reflects heterogenous contributions from both primary and secondary degeneration, with nucleus-specific phenotyping potentially informing identification of higher risk individuals.",Neuroscience
"Cognitive impairment in multiple sclerosis (MS) is driven by both focal inflammation and compartmentalized neurodegeneration, yet the relative effect of lesion-independent thalamic atrophy on information processing speed (IPS) remains unclear. This retrospective cohort study included 100 participants with MS. Automatic segmentation techniques quantified lesion load and delineated 26 thalamic regions of interest (ROIs). Linear models compared associations between ROI volumes and Symbol Digit Modalities Test (SDMT) performance in lesion-adjusted and unadjusted models. Twenty-one of 26 ROIs showed significant SDMT associations before lesion adjustment; twelve remained significant after adjustment. Lesion-independent associations were observed in the global thalamus, sensory relay nuclei (ventral posterolateral, medial and lateral geniculate), and associative hubs (pulvinar and mediodorsal-parafascicular complex). These intrinsically vulnerable nuclei exhibited significantly lower lesion-mediated effects (13.4%) than those losing significance after adjustment (34.2%, p < 0.001). Our findings suggest that IPS impairment reflects heterogenous contributions from both primary and secondary degeneration, with nucleus-specific phenotyping potentially informing identification of higher risk individuals. [SEP] [HINT] information -> Bioinformatics (Syns: entropy, data, info) | processing -> Neuroscience (Syns: work, process, march) | performance -> Bioinformatics (Syns: functioning, operation, carrying out)",Neuroscience
"In real life, psychological and physiological states rarely change along a single dimension. Through self-tracking and discussions with clinicians, I have come to recognise with increasing clarity that sleep patterns, autonomic arousal, bodily sensations, and cognitive load are in constant interaction. Existing models often fail to capture this complexity. Many theoretical frameworks continue to analyse these elements in isolation, making it difficult to explain sudden changes reported by individuals,such as abrupt spikes in anxiety, sudden drops in dissociation, or even moments of heightened alertness. The mathematical modelling employed herein does not replace clinical or subjective narratives, but rather provides a structural framework for these rapid transitions and elucidates why bodily-driven and cognitively-driven changes manifest differently. The objective is to build a conceptual bridge between physiological signals and lived experience, laying the groundwork for dynamic modelling and future case analyses.",Neuroscience
"In real life, psychological and physiological states rarely change along a single dimension. Through self-tracking and discussions with clinicians, I have come to recognise with increasing clarity that sleep patterns, autonomic arousal, bodily sensations, and cognitive load are in constant interaction. Existing models often fail to capture this complexity. Many theoretical frameworks continue to analyse these elements in isolation, making it difficult to explain sudden changes reported by individuals,such as abrupt spikes in anxiety, sudden drops in dissociation, or even moments of heightened alertness. The mathematical modelling employed herein does not replace clinical or subjective narratives, but rather provides a structural framework for these rapid transitions and elucidates why bodily-driven and cognitively-driven changes manifest differently. The objective is to build a conceptual bridge between physiological signals and lived experience, laying the groundwork for dynamic modelling and future case analyses. [SEP] [HINT] clinical -> Bioinformatics (Syns: ) | framework -> Bioinformatics (Syns: theoretical account, model, fabric) | existing -> Bioinformatics (Syns: subsist, existent, survive)",Neuroscience
"In recent years there has been a paradigm shift from the study of local task-related activation to the organization and functioning of large-scale functional and structural brain networks. However, a long-standing challenge in this large-scale brain network analysis is how to compare network organizations irrespective of their complexity. The maximum spanning tree (MST) has served as a simple, unbiased, standardized representation of complex brain networks and effectively addressed this long-standing challenge. This tree representation, however, has been limited to individual networks. Group-level trees are always constructed from the average network or through a bootstrap procedure. Constructing the group-level tree from the average network introduces bias from individual subjects with outlying connectivities. The bootstrap method can be computationally prohibitive if a good approximation is desired. To address these issues, we propose a novel spectral representation of trees using the spanning tree basis. This spectral representation enables us to compute the average MST and demonstrate that this average tree captures the global properties of all the MSTs in the group and also overlaps with the union of the shortest paths in the functional brain networks.",Bioinformatics
"In recent years there has been a paradigm shift from the study of local task-related activation to the organization and functioning of large-scale functional and structural brain networks. However, a long-standing challenge in this large-scale brain network analysis is how to compare network organizations irrespective of their complexity. The maximum spanning tree (MST) has served as a simple, unbiased, standardized representation of complex brain networks and effectively addressed this long-standing challenge. This tree representation, however, has been limited to individual networks. Group-level trees are always constructed from the average network or through a bootstrap procedure. Constructing the group-level tree from the average network introduces bias from individual subjects with outlying connectivities. The bootstrap method can be computationally prohibitive if a good approximation is desired. To address these issues, we propose a novel spectral representation of trees using the spanning tree basis. This spectral representation enables us to compute the average MST and demonstrate that this average tree captures the global properties of all the MSTs in the group and also overlaps with the union of the shortest paths in the functional brain networks. [SEP] [HINT] networks -> Neuroscience (Syns: network, meshwork, electronic network) | functional -> Neuroscience (Syns: working, usable, running) | complex -> Bioinformatics (Syns: building complex, coordination compound, composite)",Bioinformatics
"Genome-wide association studies (GWAS) are an essential tool in biomedical research for identifying genetic factors linked to health and disease. However, publicly releasing GWAS summary statistics poses well-recognized privacy risks, including the potential to infer an individual's participation in the study or to reveal sensitive phenotypic information (e.g., disease status). While differential privacy (DP) offers a rigorous mathematical framework for mitigating these risks, existing DP techniques for GWAS either introduce excessive noise or restrict the release to a limited set of results. In this work, we present practical DP mechanisms for releasing the complete set of genome-wide association statistics with privacy guarantees. We demonstrate the accuracy of the privacy-preserving statistics released by our mechanisms on a range of GWAS datasets from the UK Biobank, utilizing both real and simulated phenotypes. We introduce two key techniques to overcome the limitations of prior approaches: (1) an optimization-based randomization mechanism that directly minimizes the expected error in GWAS results to enhance utility, and (2) the use of personalized priors, derived from predictive models privately trained on a subset of the dataset, to enable sample-specific optimization which further reduces the amount of noise introduced by DP. Overall, our work provides practical tools for accurately releasing comprehensive GWAS results with provable protection of study participants.",Bioinformatics
"Genome-wide association studies (GWAS) are an essential tool in biomedical research for identifying genetic factors linked to health and disease. However, publicly releasing GWAS summary statistics poses well-recognized privacy risks, including the potential to infer an individual's participation in the study or to reveal sensitive phenotypic information (e.g., disease status). While differential privacy (DP) offers a rigorous mathematical framework for mitigating these risks, existing DP techniques for GWAS either introduce excessive noise or restrict the release to a limited set of results. In this work, we present practical DP mechanisms for releasing the complete set of genome-wide association statistics with privacy guarantees. We demonstrate the accuracy of the privacy-preserving statistics released by our mechanisms on a range of GWAS datasets from the UK Biobank, utilizing both real and simulated phenotypes. We introduce two key techniques to overcome the limitations of prior approaches: (1) an optimization-based randomization mechanism that directly minimizes the expected error in GWAS results to enhance utility, and (2) the use of personalized priors, derived from predictive models privately trained on a subset of the dataset, to enable sample-specific optimization which further reduces the amount of noise introduced by DP. Overall, our work provides practical tools for accurately releasing comprehensive GWAS results with provable protection of study participants. [SEP] [HINT] information -> Bioinformatics (Syns: entropy, data, info) | datasets -> Bioinformatics (Syns: ) | work -> Bioinformatics (Syns: work out, process, bring)",Bioinformatics
"The collective frequency that emerges from synchronized neuronal populations--the network resonance--shows a systematic relationship with brain size: whole-brain's large networks oscillate slowly, whereas finer parcellations of fixed volume exhibit faster rhythms. This resonance-size scaling has been reported in delayed neural mass models and human neuroimaging, yet the physical mechanism remained unresolved. Here we show that size-dependent resonance follows directly from propagation delays in delay-coupled phase oscillators. Starting from a Kuramoto model with heterogeneous delays, we linearize around the near-synchronous solution and obtain a closed-form approximation linking the resonance $Ω$ to the mean delay and the effective coupling field. The analysis predicts a generic scaling law: $Ω\approx (\sum_j c_{ij} τ)^{-1}$, so resonance is delay-limited and therefore depends systematically on geometric size or parcellation density. We evaluate four growth scenarios--expanding geometry, fixed-volume parcellation, constant geometry, and an unphysical reference case--and show that only geometry-consistent scaling satisfies the analytical prediction. Numerical simulations with heterogeneous delays validate the law and quantify its error as a function of delay dispersion. These results identify a minimal physical mechanism for size-dependent cortical resonance and provide an analytical framework that unifies numeric simulation outputs.",Neuroscience
"The collective frequency that emerges from synchronized neuronal populations--the network resonance--shows a systematic relationship with brain size: whole-brain's large networks oscillate slowly, whereas finer parcellations of fixed volume exhibit faster rhythms. This resonance-size scaling has been reported in delayed neural mass models and human neuroimaging, yet the physical mechanism remained unresolved. Here we show that size-dependent resonance follows directly from propagation delays in delay-coupled phase oscillators. Starting from a Kuramoto model with heterogeneous delays, we linearize around the near-synchronous solution and obtain a closed-form approximation linking the resonance $Ω$ to the mean delay and the effective coupling field. The analysis predicts a generic scaling law: $Ω\approx (\sum_j c_{ij} τ)^{-1}$, so resonance is delay-limited and therefore depends systematically on geometric size or parcellation density. We evaluate four growth scenarios--expanding geometry, fixed-volume parcellation, constant geometry, and an unphysical reference case--and show that only geometry-consistent scaling satisfies the analytical prediction. Numerical simulations with heterogeneous delays validate the law and quantify its error as a function of delay dispersion. These results identify a minimal physical mechanism for size-dependent cortical resonance and provide an analytical framework that unifies numeric simulation outputs. [SEP] [HINT] cortical -> Neuroscience (Syns: ) | networks -> Neuroscience (Syns: network, meshwork, electronic network) | results -> Bioinformatics (Syns: final result, consequence, resultant role)",Neuroscience
"Metal halide perovskites (MHPs) exhibit pronounced spin-orbit coupling (SOC) as a result of their heavy metal constituents, leading to distinctive electronic properties such as Rashba type band splitting which make them promising candidates for next generation spintronic applications. Here, using circularly polarized luminescence (CPL) and polarization dependent pump-probe spectroscopy, we found that spin polarization is present across all phases of our two-dimensional (2D) Ruddlesden-Popper (RP) mixed-phase perovskites, (C6H7SNH3)2 (CH3NH3)n-1PbnI3n+1 (n=1-4), irrespective of the number of inorganic layers. The origin of these spin polarized bands is attributed to the Rashba effect. Interestingly, the highly disordered nature of this system facilitates remarkably efficient ultrafast funneling of photoexcited spin-polarized excitons from the pure 2D phase (n=1) to higher-n phases at room temperature. We demonstrate that significant polaron formation due to the inherent soft crystal lattice and higher exciton-phonon interaction is responsible for the observed spin funneling effect in mixed-phase 2D RP perovskites. Polaron act as a protective mechanism for spin-polarized excitons, preserving their spin information through the screening of omnipresent phonon-induced momentum scattering. These findings not only offer valuable guidance for the design of 2D RP perovskites with pronounced Rashba effects but also unveil a compelling class of solution-processed perovskites capable of efficient spin-preserving energy transport at room temperature.",Materials Science
"Metal halide perovskites (MHPs) exhibit pronounced spin-orbit coupling (SOC) as a result of their heavy metal constituents, leading to distinctive electronic properties such as Rashba type band splitting which make them promising candidates for next generation spintronic applications. Here, using circularly polarized luminescence (CPL) and polarization dependent pump-probe spectroscopy, we found that spin polarization is present across all phases of our two-dimensional (2D) Ruddlesden-Popper (RP) mixed-phase perovskites, (C6H7SNH3)2 (CH3NH3)n-1PbnI3n+1 (n=1-4), irrespective of the number of inorganic layers. The origin of these spin polarized bands is attributed to the Rashba effect. Interestingly, the highly disordered nature of this system facilitates remarkably efficient ultrafast funneling of photoexcited spin-polarized excitons from the pure 2D phase (n=1) to higher-n phases at room temperature. We demonstrate that significant polaron formation due to the inherent soft crystal lattice and higher exciton-phonon interaction is responsible for the observed spin funneling effect in mixed-phase 2D RP perovskites. Polaron act as a protective mechanism for spin-polarized excitons, preserving their spin information through the screening of omnipresent phonon-induced momentum scattering. These findings not only offer valuable guidance for the design of 2D RP perovskites with pronounced Rashba effects but also unveil a compelling class of solution-processed perovskites capable of efficient spin-preserving energy transport at room temperature. [SEP] [HINT] spin -> Materials Science (Syns: twisting, whirl, tailspin) | transport -> Materials Science (Syns: transferral, enthral, shipping) | electronic -> Materials Science (Syns: )",Materials Science
"High-definition transcranial direct current stimulation (HD-tDCS) dosing in children remains largely empirical, relying on one-size-fits-all protocols despite rapid developmental changes in head anatomy and tissue properties that strongly modulate how currents reach the developing brain. Using 70 pediatric head models and commonly used cortical targets, our forward simulations find that standard montages produce marked age-dependent reductions in target electric-field intensity and systematic sex differences linked to tissue-volume covariation, underscoring the profound limitations of conventional uniform montages. To overcome these limitations, we introduce a developmentally informed, dual-objective optimization framework designed to generate personalized Pareto fronts summarizing the trade-off between electric-field intensity and focality. From these optimized solutions, we derive two practical dosing prescriptions: a dose-consistency strategy that, for the first time, enforces fixed target intensity across individuals to implicitly mitigate demographic effects, and a target-engagement strategy that maximizes target intensity under safety limits. Both strategies remain robust to large conductivity variations, and we further show that dense HD-tDCS solutions admit sparse equivalents without performance loss under the target-engagement strategy. We also find that tissue conductivity sensitivity is depth-dependent, with Pareto-front distributions for superficial cortical targets most influenced by gray matter, scalp, and bone conductivities, and those for a deep target predominantly shaped by gray and white matter conductivities. Together, these results establish a principled framework for pediatric HD-tDCS planning that explicitly accounts for developmental anatomy and physiological uncertainty, enabling reliable and individualized neuromodulation dosing in pediatric populations.",Bioinformatics
"High-definition transcranial direct current stimulation (HD-tDCS) dosing in children remains largely empirical, relying on one-size-fits-all protocols despite rapid developmental changes in head anatomy and tissue properties that strongly modulate how currents reach the developing brain. Using 70 pediatric head models and commonly used cortical targets, our forward simulations find that standard montages produce marked age-dependent reductions in target electric-field intensity and systematic sex differences linked to tissue-volume covariation, underscoring the profound limitations of conventional uniform montages. To overcome these limitations, we introduce a developmentally informed, dual-objective optimization framework designed to generate personalized Pareto fronts summarizing the trade-off between electric-field intensity and focality. From these optimized solutions, we derive two practical dosing prescriptions: a dose-consistency strategy that, for the first time, enforces fixed target intensity across individuals to implicitly mitigate demographic effects, and a target-engagement strategy that maximizes target intensity under safety limits. Both strategies remain robust to large conductivity variations, and we further show that dense HD-tDCS solutions admit sparse equivalents without performance loss under the target-engagement strategy. We also find that tissue conductivity sensitivity is depth-dependent, with Pareto-front distributions for superficial cortical targets most influenced by gray matter, scalp, and bone conductivities, and those for a deep target predominantly shaped by gray and white matter conductivities. Together, these results establish a principled framework for pediatric HD-tDCS planning that explicitly accounts for developmental anatomy and physiological uncertainty, enabling reliable and individualized neuromodulation dosing in pediatric populations. [SEP] [HINT] used -> Bioinformatics (Syns: utilize, ill-used, apply) | tissue -> Bioinformatics (Syns: tissue paper, weave) | cortical -> Neuroscience (Syns: )",Bioinformatics
"Neural populations exhibit complex recurrent structures that drive behavior, while continuously receiving and integrating external inputs from sensory stimuli, upstream regions, and neurostimulation. However, neural populations are often modeled as autonomous dynamical systems, with little consideration given to the influence of external inputs that shape the population activity and behavioral outcomes. Here, we introduce BRAID, a deep learning framework that models nonlinear neural dynamics underlying behavior while explicitly incorporating any measured external inputs. Our method disentangles intrinsic recurrent neural population dynamics from the effects of inputs by including a forecasting objective within input-driven recurrent neural networks. BRAID further prioritizes the learning of intrinsic dynamics that are related to a behavior of interest by using a multi-stage optimization scheme. We validate BRAID with nonlinear simulations, showing that it can accurately learn the intrinsic dynamics shared between neural and behavioral modalities. We then apply BRAID to motor cortical activity recorded during a motor task and demonstrate that our method more accurately fits the neural-behavioral data by incorporating measured sensory stimuli into the model and improves the forecasting of neural-behavioral data compared with various baseline methods, whether input-driven or not.",Neuroscience
"Neural populations exhibit complex recurrent structures that drive behavior, while continuously receiving and integrating external inputs from sensory stimuli, upstream regions, and neurostimulation. However, neural populations are often modeled as autonomous dynamical systems, with little consideration given to the influence of external inputs that shape the population activity and behavioral outcomes. Here, we introduce BRAID, a deep learning framework that models nonlinear neural dynamics underlying behavior while explicitly incorporating any measured external inputs. Our method disentangles intrinsic recurrent neural population dynamics from the effects of inputs by including a forecasting objective within input-driven recurrent neural networks. BRAID further prioritizes the learning of intrinsic dynamics that are related to a behavior of interest by using a multi-stage optimization scheme. We validate BRAID with nonlinear simulations, showing that it can accurately learn the intrinsic dynamics shared between neural and behavioral modalities. We then apply BRAID to motor cortical activity recorded during a motor task and demonstrate that our method more accurately fits the neural-behavioral data by incorporating measured sensory stimuli into the model and improves the forecasting of neural-behavioral data compared with various baseline methods, whether input-driven or not. [SEP] [HINT] task -> Neuroscience (Syns: tax, project, chore) | learning -> Bioinformatics (Syns: take, teach, acquire) | cortical -> Neuroscience (Syns: )",Neuroscience
"Accurate wave-function descriptions of pristine and defected solids remain challenging due to the simultaneous presence of finite-size, basis-set, and correlation errors. While embedding techniques alleviate finite-size effects and correlated wave-function approaches systematically improve correlation, basis-set incompleteness continues to limit practical accuracy. Here we present a study of transcorrelated (TC) many-body wave-function methods on properties of solid state systems. We augment the existing xTC theory to periodic systems, and establish an unified transcorrelated embedding framework that integrates periodic TC theory with fragment-based correlated solvers. Using silicon as a test case, we validate the method against coupled-cluster, FCIQMC, and diffusion Monte Carlo benchmarks for bulk. Then we apply TC embedding to calculation of formation energies of two silicon self-interstitials. The TC Hamiltonian yields rapid basis convergence and quantitatively reliable defect formation energies at the triple-$ζ$ level, substantially reducing the basis-set bottleneck for wave-function treatments of crystalline defects.",Materials Science
"Accurate wave-function descriptions of pristine and defected solids remain challenging due to the simultaneous presence of finite-size, basis-set, and correlation errors. While embedding techniques alleviate finite-size effects and correlated wave-function approaches systematically improve correlation, basis-set incompleteness continues to limit practical accuracy. Here we present a study of transcorrelated (TC) many-body wave-function methods on properties of solid state systems. We augment the existing xTC theory to periodic systems, and establish an unified transcorrelated embedding framework that integrates periodic TC theory with fragment-based correlated solvers. Using silicon as a test case, we validate the method against coupled-cluster, FCIQMC, and diffusion Monte Carlo benchmarks for bulk. Then we apply TC embedding to calculation of formation energies of two silicon self-interstitials. The TC Hamiltonian yields rapid basis convergence and quantitatively reliable defect formation energies at the triple-$ζ$ level, substantially reducing the basis-set bottleneck for wave-function treatments of crystalline defects. [SEP] [HINT] defect -> Materials Science (Syns: mar, shortcoming, fault) | framework -> Bioinformatics (Syns: theoretical account, model, fabric) | using -> Bioinformatics (Syns: utilize, exploitation, apply)",Materials Science
"The Free Energy Principle (FEP) states that self-organizing systems must minimize variational free energy to persist, but the path from principle to implementable algorithm has remained unclear. We present a constructive proof that the FEP can be realized through exact local credit assignment. The system decomposes gradient computation hierarchically: spatial credit via feedback alignment, temporal credit via eligibility traces, and structural credit via a Trophic Field Map (TFM) that estimates expected gradient magnitude for each connection block. We prove these mechanisms are exact at their respective levels and validate the central claim empirically: the TFM achieves 0.9693 Pearson correlation with oracle gradients. This exactness produces emergent capabilities including 98.6% retention after task interference, autonomous recovery from 75% structural damage, self-organized criticality (spectral radius p ~= 1.0$), and sample-efficient reinforcement learning on continuous control tasks without replay buffers. The architecture unifies Prigogine's dissipative structures, Friston's free energy minimization, and Hopfield's attractor dynamics, demonstrating that exact hierarchical inference over network topology can be implemented with local, biologically plausible rules.",Neuroscience
"The Free Energy Principle (FEP) states that self-organizing systems must minimize variational free energy to persist, but the path from principle to implementable algorithm has remained unclear. We present a constructive proof that the FEP can be realized through exact local credit assignment. The system decomposes gradient computation hierarchically: spatial credit via feedback alignment, temporal credit via eligibility traces, and structural credit via a Trophic Field Map (TFM) that estimates expected gradient magnitude for each connection block. We prove these mechanisms are exact at their respective levels and validate the central claim empirically: the TFM achieves 0.9693 Pearson correlation with oracle gradients. This exactness produces emergent capabilities including 98.6% retention after task interference, autonomous recovery from 75% structural damage, self-organized criticality (spectral radius p ~= 1.0$), and sample-efficient reinforcement learning on continuous control tasks without replay buffers. The architecture unifies Prigogine's dissipative structures, Friston's free energy minimization, and Hopfield's attractor dynamics, demonstrating that exact hierarchical inference over network topology can be implemented with local, biologically plausible rules. [SEP] [HINT] field -> Materials Science (Syns: field of honor, line of business, orbit) | task -> Neuroscience (Syns: tax, project, chore) | tasks -> Neuroscience (Syns: tax, task, project)",Neuroscience
"The classification of diabetes and prediabetes by static glucose thresholds obscures the pathophysiological dysglycemia heterogeneity, primarily driven by insulin resistance (IR), beta-cell dysfunction, and incretin deficiency. This review demonstrates that continuous glucose monitoring and wearable technologies enable a paradigm shift towards non-invasive, dynamic metabolic phenotyping. We show evidence that machine learning models can leverage high-resolution glucose data from at-home, CGM-enabled oral glucose tolerance tests to accurately predict gold-standard measures of muscle IR and beta-cell function. This personalized characterization extends to real-world nutrition, where an individual's unique postprandial glycemic response (PPGR) to standardized meals, such as the relative glucose spike to potatoes versus grapes, could serve as a biomarker for their metabolic subtype. Moreover, integrating wearable data reveals that habitual diet, sleep, and physical activity patterns, particularly their timing, are uniquely associated with specific metabolic dysfunctions, informing precision lifestyle interventions. The efficacy of dietary mitigators in attenuating PPGR is also shown to be phenotype-dependent. Collectively, this evidence demonstrates that CGM can deconstruct the complexity of early dysglycemia into distinct, actionable subphenotypes. This approach moves beyond simple glycemic control, paving the way for targeted nutritional, behavioral, and pharmacological strategies tailored to an individual's core metabolic defects, thereby paving the way for a new era of precision diabetes prevention.",Bioinformatics
"The classification of diabetes and prediabetes by static glucose thresholds obscures the pathophysiological dysglycemia heterogeneity, primarily driven by insulin resistance (IR), beta-cell dysfunction, and incretin deficiency. This review demonstrates that continuous glucose monitoring and wearable technologies enable a paradigm shift towards non-invasive, dynamic metabolic phenotyping. We show evidence that machine learning models can leverage high-resolution glucose data from at-home, CGM-enabled oral glucose tolerance tests to accurately predict gold-standard measures of muscle IR and beta-cell function. This personalized characterization extends to real-world nutrition, where an individual's unique postprandial glycemic response (PPGR) to standardized meals, such as the relative glucose spike to potatoes versus grapes, could serve as a biomarker for their metabolic subtype. Moreover, integrating wearable data reveals that habitual diet, sleep, and physical activity patterns, particularly their timing, are uniquely associated with specific metabolic dysfunctions, informing precision lifestyle interventions. The efficacy of dietary mitigators in attenuating PPGR is also shown to be phenotype-dependent. Collectively, this evidence demonstrates that CGM can deconstruct the complexity of early dysglycemia into distinct, actionable subphenotypes. This approach moves beyond simple glycemic control, paving the way for targeted nutritional, behavioral, and pharmacological strategies tailored to an individual's core metabolic defects, thereby paving the way for a new era of precision diabetes prevention. [SEP] [HINT] learning -> Bioinformatics (Syns: take, teach, acquire) | specific -> Bioinformatics (Syns: particular) | activity -> Neuroscience (Syns: activeness, body process, bodily process)",Bioinformatics
"Stroke is a leading cause of long-term disability and the second most common cause of death worldwide. Although acute treatments have advanced, recovery remains challenging and limited. Brain-computer interfaces (BCIs) have emerged as a promising tool for post-stroke rehabilitation by promoting neuroplasticity. However, clinical outcomes remain variable, and optimal protocols have yet to be established. This study explores strategies to optimize BCI-based rehabilitation by comparing motor imagery of affected hand movement versus rest, instead of the conventional left-versus-right motor imagery. This alternative aims to simplify the task and address the weak contralateral activation commonly observed in stroke patients. Two datasets, one from healthy individuals and one from stroke patients, were used to evaluate the proposed approach. The results showed improved performance using both FBCSP and EEGNet. Additionally, we investigated the impact of session duration and found that shorter training sessions produced better BCI performance than longer sessions.",Neuroscience
"Stroke is a leading cause of long-term disability and the second most common cause of death worldwide. Although acute treatments have advanced, recovery remains challenging and limited. Brain-computer interfaces (BCIs) have emerged as a promising tool for post-stroke rehabilitation by promoting neuroplasticity. However, clinical outcomes remain variable, and optimal protocols have yet to be established. This study explores strategies to optimize BCI-based rehabilitation by comparing motor imagery of affected hand movement versus rest, instead of the conventional left-versus-right motor imagery. This alternative aims to simplify the task and address the weak contralateral activation commonly observed in stroke patients. Two datasets, one from healthy individuals and one from stroke patients, were used to evaluate the proposed approach. The results showed improved performance using both FBCSP and EEGNet. Additionally, we investigated the impact of session duration and found that shorter training sessions produced better BCI performance than longer sessions. [SEP] [HINT] used -> Bioinformatics (Syns: utilize, ill-used, apply) | task -> Neuroscience (Syns: tax, project, chore) | clinical -> Bioinformatics (Syns: )",Neuroscience
"We introduce a framework combining geometric modeling with disease progression analysis to investigate tau deposition in Alzheimer's disease (AD) using positron emission tomography (PET) data. Focusing on the hippocampus, we construct a principal surface that captures the spatial distribution and morphological changes of tau pathology. By projecting voxels onto this surface, we quantify tau coverage, intensity, and thickness through bidirectional projection distances and interpolated standardized uptake value ratios (SUVR). This low-dimensional embedding preserves spatial specificity while mitigating multiple comparison issues. Covariate effects are analyzed using a two-stage regression model with inverse probability weighting to adjust for signal sparsity and selection bias. Using the SuStaIn model, we identify subtypes and stages of AD, revealing distinct tau dynamics: the limbic-predominant subtype shows age-related nonlinear accumulation in coverage and thickness, whereas the posterior subtype exhibits uniform SUVR increases across disease progression. Model-based predictions show that hippocampal tau deposition follows a structured spatial trajectory expanding bidirectionally with increasing thickness, while subtype differences highlight posterior hippocampal involvement consistent with whole-brain patterns. Finally, directional signal patterns on the principal surface reveal contamination from the choroid plexus, demonstrating the broader applicability of the proposed framework across modalities including amyloid PET.",Bioinformatics
"We introduce a framework combining geometric modeling with disease progression analysis to investigate tau deposition in Alzheimer's disease (AD) using positron emission tomography (PET) data. Focusing on the hippocampus, we construct a principal surface that captures the spatial distribution and morphological changes of tau pathology. By projecting voxels onto this surface, we quantify tau coverage, intensity, and thickness through bidirectional projection distances and interpolated standardized uptake value ratios (SUVR). This low-dimensional embedding preserves spatial specificity while mitigating multiple comparison issues. Covariate effects are analyzed using a two-stage regression model with inverse probability weighting to adjust for signal sparsity and selection bias. Using the SuStaIn model, we identify subtypes and stages of AD, revealing distinct tau dynamics: the limbic-predominant subtype shows age-related nonlinear accumulation in coverage and thickness, whereas the posterior subtype exhibits uniform SUVR increases across disease progression. Model-based predictions show that hippocampal tau deposition follows a structured spatial trajectory expanding bidirectionally with increasing thickness, while subtype differences highlight posterior hippocampal involvement consistent with whole-brain patterns. Finally, directional signal patterns on the principal surface reveal contamination from the choroid plexus, demonstrating the broader applicability of the proposed framework across modalities including amyloid PET. [SEP] [HINT] including -> Bioinformatics (Syns: admit, include, let in) | framework -> Bioinformatics (Syns: theoretical account, model, fabric) | using -> Bioinformatics (Syns: utilize, exploitation, apply)",Bioinformatics
"Wilson-Cowan and Amari-type models capture nonlinear neural population dynamics, providing a fundamental framework for modeling how sensory and other exogenous inputs shape activity in neural tissue. We study the controllability properties of Amari-type neural fields subject to piecewise/constant-in-time inputs. The model describes the time evolution of the polarization of neural tissue within a spatial continuum, with synaptic interactions represented by a convolution kernel. We study the synthesis of piecewise/constant-in-time inputs to achieve two-point boundary-type control objectives, namely, steering neural activity from an initial state to a prescribed target state. This approach is particularly relevant for predicting the emergence of paradoxical neural representations, such as discordant visual illusions that occur in response to overt sensory stimuli. We first present a control synthesis based on the Banach fixed-point theorem, which yields an iterative construction of a constant-in-time input under minimal regularity assumptions on the kernel and transfer function; however, it exhibits practical limitations, even in the linear case. To overcome these challenges, we then develop a generic synthesis framework based on the flow of neural dynamics drift, enabling explicit piecewise constant and constant-in-time inputs. Extensive numerical results in one and two spatial dimensions confirm the effectiveness of the proposed syntheses and demonstrate their superior performance compared to inputs derived from naive linearization at the initial or target states when these states are not equilibria of the drift dynamics. By providing a mathematically rigorous framework for controlling Amari-type neural fields, this work advances our understanding of nonlinear neural population control with potential applications in computational neuroscience, psychophysics, and neurostimulation.",Neuroscience
"Wilson-Cowan and Amari-type models capture nonlinear neural population dynamics, providing a fundamental framework for modeling how sensory and other exogenous inputs shape activity in neural tissue. We study the controllability properties of Amari-type neural fields subject to piecewise/constant-in-time inputs. The model describes the time evolution of the polarization of neural tissue within a spatial continuum, with synaptic interactions represented by a convolution kernel. We study the synthesis of piecewise/constant-in-time inputs to achieve two-point boundary-type control objectives, namely, steering neural activity from an initial state to a prescribed target state. This approach is particularly relevant for predicting the emergence of paradoxical neural representations, such as discordant visual illusions that occur in response to overt sensory stimuli. We first present a control synthesis based on the Banach fixed-point theorem, which yields an iterative construction of a constant-in-time input under minimal regularity assumptions on the kernel and transfer function; however, it exhibits practical limitations, even in the linear case. To overcome these challenges, we then develop a generic synthesis framework based on the flow of neural dynamics drift, enabling explicit piecewise constant and constant-in-time inputs. Extensive numerical results in one and two spatial dimensions confirm the effectiveness of the proposed syntheses and demonstrate their superior performance compared to inputs derived from naive linearization at the initial or target states when these states are not equilibria of the drift dynamics. By providing a mathematically rigorous framework for controlling Amari-type neural fields, this work advances our understanding of nonlinear neural population control with potential applications in computational neuroscience, psychophysics, and neurostimulation. [SEP] [HINT] tissue -> Bioinformatics (Syns: tissue paper, weave) | based -> Bioinformatics (Syns: ground, free-base, base) | computational -> Neuroscience (Syns: )",Neuroscience
"RFdiffusion is a popular and well-established model for generation of protein structures. However, this generative process offers limited insight into its internal representations and how they contribute to the final protein structure. Concurrently, recent work in mechanistic interpretability has successfully used Sparse Autoencoders (SAEs) to discover interpretable features within neural networks. We combine these concepts by applying SAE to the internal representations of RFdiffusion to uncover secondary structure-specific features and establish a relationship between them and generated protein structures. Building on these insights, we introduce a novel steering mechanism that enables precise control of secondary structure formation through a tunable hyperparameter, while simultaneously revealing interpretable block and neuron-level representations within RFdiffusion. Our work pioneers a new framework for making RFdiffusion more interpretable, demonstrating how understanding internal features can be directly translated into precise control over the protein design process.",Bioinformatics
"RFdiffusion is a popular and well-established model for generation of protein structures. However, this generative process offers limited insight into its internal representations and how they contribute to the final protein structure. Concurrently, recent work in mechanistic interpretability has successfully used Sparse Autoencoders (SAEs) to discover interpretable features within neural networks. We combine these concepts by applying SAE to the internal representations of RFdiffusion to uncover secondary structure-specific features and establish a relationship between them and generated protein structures. Building on these insights, we introduce a novel steering mechanism that enables precise control of secondary structure formation through a tunable hyperparameter, while simultaneously revealing interpretable block and neuron-level representations within RFdiffusion. Our work pioneers a new framework for making RFdiffusion more interpretable, demonstrating how understanding internal features can be directly translated into precise control over the protein design process. [SEP] [HINT] used -> Bioinformatics (Syns: utilize, ill-used, apply) | features -> Bioinformatics (Syns: characteristic, lineament, feature of speech) | understanding -> Neuroscience (Syns: savvy, intellect, sympathy)",Bioinformatics
"EEG recordings are inherently contaminated by artifacts such as ocular, muscular, and environmental noise, which obscure neural activity and complicate preprocessing. Artifact classification offers advantages in stability and transparency, providing a viable alternative to ICA-based methods that enable flexible use alongside human inspections and across various applications. However, artifact classification is limited by its training data as it requires extensive manual labeling, which cannot fully cover the diversity of real-world EEG. Semi-synthetic data (SSD) methods have been proposed to address this limitation, but prior approaches typically injected single artifact types using ICA components or required separately recorded artifact signals, reducing both the realism of the generated data and the applicability of the method. To overcome these issues, we introduce SSDLabeler, a framework that generates realistic, annotated SSDs by decomposing real EEG with ICA, epoch-level artifact verification using RMS and PSD criteria, and reinjecting multiple artifact types into clean data. When applied to train a multi-label artifact classifier, it improved accuracy on raw EEG across diverse conditions compared to prior SSD and raw EEG training, establishing a scalable foundation for artifact handling that captures the co-occurrence and complexity of real EEG.",Neuroscience
"EEG recordings are inherently contaminated by artifacts such as ocular, muscular, and environmental noise, which obscure neural activity and complicate preprocessing. Artifact classification offers advantages in stability and transparency, providing a viable alternative to ICA-based methods that enable flexible use alongside human inspections and across various applications. However, artifact classification is limited by its training data as it requires extensive manual labeling, which cannot fully cover the diversity of real-world EEG. Semi-synthetic data (SSD) methods have been proposed to address this limitation, but prior approaches typically injected single artifact types using ICA components or required separately recorded artifact signals, reducing both the realism of the generated data and the applicability of the method. To overcome these issues, we introduce SSDLabeler, a framework that generates realistic, annotated SSDs by decomposing real EEG with ICA, epoch-level artifact verification using RMS and PSD criteria, and reinjecting multiple artifact types into clean data. When applied to train a multi-label artifact classifier, it improved accuracy on raw EEG across diverse conditions compared to prior SSD and raw EEG training, establishing a scalable foundation for artifact handling that captures the co-occurrence and complexity of real EEG. [SEP] [HINT] human -> Neuroscience (Syns: human being, man, homo) | framework -> Bioinformatics (Syns: theoretical account, model, fabric) | using -> Bioinformatics (Syns: utilize, exploitation, apply)",Neuroscience
"We report a temperature-composition phase diagram for the chemically disordered and CeO2-LA2O3 high entropy oxides (HEOs), where LA denotes equimolar Y, La, Sm, and Pr, delineating stability regions for bixbyite, disordered fluorite, and intermediate vacancy-ordered fluorite phases. The diagram is constructed from a characterization package applied to bulk ceramics including X-ray diffraction (XRD), transmission electron microscopy (TEM) electron diffraction, Raman spectroscopy, energy-dispersive spectroscopy, X-ray absorption near-edge structure spectroscopy, and ultraviolet-visible spectroscopy, to quantify crystal structure at multiple length-scales, local coordination environments, and electronic structures across the formulation space. This comprehensive measurement suite is critical to identify boundaries between the closely related phases. For example, Raman scattering reveals local structural and defect environments unique to bixbyite local order that persist to ~50% Ce under equilibrium synthesis conditions but are invisible to XRD and TEM. We also report a companion thin film study to demonstrate that quenched kinetic energy from a physical deposition process can metastabilize the high symmetry, and thus high entropy, fluorite phase with only 20% Ce. This is noteworthy because electroneutrality constraints demand an exceptionally vacated oxygen sublattice; we estimate 16.7%, approaching that of delta-Bi2O3. Together, our equilibrium ceramics and far-from-equilibrium thin films show that when synthesis is coupled with rigorously chosen, multi-length-scale characterization, now one can identify the phase stability thermodynamic drivers and simultaneously derive practical guidelines for experimentally realizing targeted phases and structures - and thereby deliberately engineer properties in CeO2-LA2O3 HEOs, whose broad defect chemistries demand such an approach.",Materials Science
"We report a temperature-composition phase diagram for the chemically disordered and CeO2-LA2O3 high entropy oxides (HEOs), where LA denotes equimolar Y, La, Sm, and Pr, delineating stability regions for bixbyite, disordered fluorite, and intermediate vacancy-ordered fluorite phases. The diagram is constructed from a characterization package applied to bulk ceramics including X-ray diffraction (XRD), transmission electron microscopy (TEM) electron diffraction, Raman spectroscopy, energy-dispersive spectroscopy, X-ray absorption near-edge structure spectroscopy, and ultraviolet-visible spectroscopy, to quantify crystal structure at multiple length-scales, local coordination environments, and electronic structures across the formulation space. This comprehensive measurement suite is critical to identify boundaries between the closely related phases. For example, Raman scattering reveals local structural and defect environments unique to bixbyite local order that persist to ~50% Ce under equilibrium synthesis conditions but are invisible to XRD and TEM. We also report a companion thin film study to demonstrate that quenched kinetic energy from a physical deposition process can metastabilize the high symmetry, and thus high entropy, fluorite phase with only 20% Ce. This is noteworthy because electroneutrality constraints demand an exceptionally vacated oxygen sublattice; we estimate 16.7%, approaching that of delta-Bi2O3. Together, our equilibrium ceramics and far-from-equilibrium thin films show that when synthesis is coupled with rigorously chosen, multi-length-scale characterization, now one can identify the phase stability thermodynamic drivers and simultaneously derive practical guidelines for experimentally realizing targeted phases and structures - and thereby deliberately engineer properties in CeO2-LA2O3 HEOs, whose broad defect chemistries demand such an approach. [SEP] [HINT] defect -> Materials Science (Syns: mar, shortcoming, fault) | electronic -> Materials Science (Syns: ) | structure -> Bioinformatics (Syns: social system, complex body part, social structure)",Materials Science
"When modeling complex, hierarchical, and time-dynamic systems, such as biological systems, good computational tools are essential. Current tools, while powerful, often lack comprehensive frameworks for modular model composition, hierarchical system building, and time-dependent input handling, particularly within the Python ecosystem. We present SUND (Simulation Using Nonlinear Dynamic models), a Python toolbox designed to address these challenges. SUND provides a unified framework for defining, combining, and simulating multi-level time-dynamic systems. The toolbox enables users to define models with interconnectable inputs and outputs, facilitating the construction of complex systems from simpler, reusable components. It supports time-dependent functions and piecewise constant inputs, enabling intuitive simulation of various experimental conditions such as multiple dosing schemes. We demonstrate the toolbox's capabilities through simulation of a multi-level human glucose-insulin system model, showcasing its flexibility in handling multiple temporal scales, and levels of biological detail. SUND is open-source, easily extensible, and available at PyPI (https://pypi.org/project/sund/) and at Gitlab (https://gitlab.liu.se/ISBgroup/projects/sund/).",Bioinformatics
"When modeling complex, hierarchical, and time-dynamic systems, such as biological systems, good computational tools are essential. Current tools, while powerful, often lack comprehensive frameworks for modular model composition, hierarchical system building, and time-dependent input handling, particularly within the Python ecosystem. We present SUND (Simulation Using Nonlinear Dynamic models), a Python toolbox designed to address these challenges. SUND provides a unified framework for defining, combining, and simulating multi-level time-dynamic systems. The toolbox enables users to define models with interconnectable inputs and outputs, facilitating the construction of complex systems from simpler, reusable components. It supports time-dependent functions and piecewise constant inputs, enabling intuitive simulation of various experimental conditions such as multiple dosing schemes. We demonstrate the toolbox's capabilities through simulation of a multi-level human glucose-insulin system model, showcasing its flexibility in handling multiple temporal scales, and levels of biological detail. SUND is open-source, easily extensible, and available at PyPI (https://pypi.org/project/sund/) and at Gitlab (https://gitlab.liu.se/ISBgroup/projects/sund/). [SEP] [HINT] computational -> Neuroscience (Syns: ) | complex -> Bioinformatics (Syns: building complex, coordination compound, composite) | systems -> Bioinformatics (Syns: organization, organisation, system)",Bioinformatics
"We report the synthesis of bell-shaped Bi/Bi13S18Br2 metal/semiconductor heterostructures as a photocatalyst based on non-toxic and Earth-abundant elements. Their unique morphology arises from a multi-step growth process, involving 1) the nucleation of Bi13S18Br2 nanorods, 2) the reduction of a metallic-Bi domain on their surface induced by N,N-didodecylmethylamine, and 3) the heterostructure accretion by a localized reaction at the Bi/Bi13S18Br2 interface promoted by Ostwald ripening. These heterostructures display remarkable stability in polar solvents, remaining almost unaffected by prolonged exposure to isopropanol and water, and exhibit high photocatalytic efficiency for the degradation of organic dyes (i.e., Rhodamine-B and Methylene Blue) under visible-light irradiation, with good recyclability. Additionally, preliminary tests demonstrate CO2 reduction capabilities, which make them promising for both the photocatalytic degradation of pollutants and photo-electro CO2 conversion. The straightforward synthesis process and the use of non-toxic and earth-abundant elements offers significant potential for sustainable energy conversion technologies.",Materials Science
"We report the synthesis of bell-shaped Bi/Bi13S18Br2 metal/semiconductor heterostructures as a photocatalyst based on non-toxic and Earth-abundant elements. Their unique morphology arises from a multi-step growth process, involving 1) the nucleation of Bi13S18Br2 nanorods, 2) the reduction of a metallic-Bi domain on their surface induced by N,N-didodecylmethylamine, and 3) the heterostructure accretion by a localized reaction at the Bi/Bi13S18Br2 interface promoted by Ostwald ripening. These heterostructures display remarkable stability in polar solvents, remaining almost unaffected by prolonged exposure to isopropanol and water, and exhibit high photocatalytic efficiency for the degradation of organic dyes (i.e., Rhodamine-B and Methylene Blue) under visible-light irradiation, with good recyclability. Additionally, preliminary tests demonstrate CO2 reduction capabilities, which make them promising for both the photocatalytic degradation of pollutants and photo-electro CO2 conversion. The straightforward synthesis process and the use of non-toxic and earth-abundant elements offers significant potential for sustainable energy conversion technologies. [SEP] [HINT] based -> Bioinformatics (Syns: ground, free-base, base) | demonstrate -> Bioinformatics (Syns: evidence, march, prove) | potential -> Bioinformatics (Syns: voltage, potential difference, electric potential)",Materials Science
"Medical imaging has revolutionized diagnosis, yet unnecessary procedures are rising, exposing patients to radiation and stress, limiting equitable access, and straining healthcare systems. The American College of Radiology Appropriateness Criteria, developed through extensive multidisciplinary review, provide evidence-based guidance but remain underutilized. Leveraging advances in LLM reasoning, we introduce a Reasoning Agent trained with Reinforcement Learning (RL), specifically Group Relative Policy Optimization (GRPO), to replicate expert clinical reasoning from the ACR Criteria. We present a novel RL approach for structured medical reasoning, systematically comparing reasoning-focused reward functions and evidence integration strategies. Our lightweight 8B model, MedReason-Embed, improves macro F1 by 18% over baseline, shows stronger reasoning alignment, and outperforms both larger and alternatively trained models, showing that reasoning-based supervision enables efficient, trustworthy clinical AI. Building on this, we design a modular end-to-end agentic architecture that automates imaging referrals: mapping diagnoses to ICD codes, retrieving PubMed evidence, and recommending optimal procedures. Crucially, the ability to generalize beyond static ACR guidelines not only enables clinicians to handle out-of-distribution cases, but also supports scaling the guideline development process itself, potentially reducing the significant effort required to create and update them. This work shows the potential of reasoning-focused RL within agentic architectures to deliver transparent, scalable, and reliable clinical decision support. Our code is available at: https://anonymous.4open.science/r/agentic-imaging-recommender-iclr-877D",Bioinformatics
"Medical imaging has revolutionized diagnosis, yet unnecessary procedures are rising, exposing patients to radiation and stress, limiting equitable access, and straining healthcare systems. The American College of Radiology Appropriateness Criteria, developed through extensive multidisciplinary review, provide evidence-based guidance but remain underutilized. Leveraging advances in LLM reasoning, we introduce a Reasoning Agent trained with Reinforcement Learning (RL), specifically Group Relative Policy Optimization (GRPO), to replicate expert clinical reasoning from the ACR Criteria. We present a novel RL approach for structured medical reasoning, systematically comparing reasoning-focused reward functions and evidence integration strategies. Our lightweight 8B model, MedReason-Embed, improves macro F1 by 18% over baseline, shows stronger reasoning alignment, and outperforms both larger and alternatively trained models, showing that reasoning-based supervision enables efficient, trustworthy clinical AI. Building on this, we design a modular end-to-end agentic architecture that automates imaging referrals: mapping diagnoses to ICD codes, retrieving PubMed evidence, and recommending optimal procedures. Crucially, the ability to generalize beyond static ACR guidelines not only enables clinicians to handle out-of-distribution cases, but also supports scaling the guideline development process itself, potentially reducing the significant effort required to create and update them. This work shows the potential of reasoning-focused RL within agentic architectures to deliver transparent, scalable, and reliable clinical decision support. Our code is available at: https://anonymous.4open.science/r/agentic-imaging-recommender-iclr-877D [SEP] [HINT] clinical -> Bioinformatics (Syns: ) | learning -> Bioinformatics (Syns: take, teach, acquire) | work -> Bioinformatics (Syns: work out, process, bring)",Bioinformatics
"Repurposing existing drugs to treat new diseases is a cost-effective alternative to de novo drug development, but there are millions of potential drug-disease combinations to be considered with only a small fraction being viable. In silico predictions of drug-disease associations can be invaluable for reducing the size of the search space. In this work we present a novel network of drugs and the diseases they treat, compiled using a combination of existing textual and machine-readable databases, natural-language processing tools, and hand curation, and analyze it using network-based link prediction methods to identify potential drug-disease combinations. We measure the efficacy of these methods using cross-validation tests and find that several methods, particularly those based on graph embedding and network model fitting, achieve impressive prediction performance, significantly better than previous approaches, with area under the ROC curve above 0.95 and average precision almost a thousand times better than chance.",Bioinformatics
"Repurposing existing drugs to treat new diseases is a cost-effective alternative to de novo drug development, but there are millions of potential drug-disease combinations to be considered with only a small fraction being viable. In silico predictions of drug-disease associations can be invaluable for reducing the size of the search space. In this work we present a novel network of drugs and the diseases they treat, compiled using a combination of existing textual and machine-readable databases, natural-language processing tools, and hand curation, and analyze it using network-based link prediction methods to identify potential drug-disease combinations. We measure the efficacy of these methods using cross-validation tests and find that several methods, particularly those based on graph embedding and network model fitting, achieve impressive prediction performance, significantly better than previous approaches, with area under the ROC curve above 0.95 and average precision almost a thousand times better than chance. [SEP] [HINT] based -> Bioinformatics (Syns: ground, free-base, base) | processing -> Neuroscience (Syns: work, process, march) | work -> Bioinformatics (Syns: work out, process, bring)",Bioinformatics
"Quantification of protoporphyrin IX (PpIX) fluorescence in human brain tumours has the potential to significantly improve patient outcomes in neuro-oncology, but represents a formidable imaging challenge. Protoporphyrin is a biological molecule which interacts with the tissue micro-environment to form two photochemical states in glioma. Each exhibits markedly different quantum efficiencies, with distinct but overlapping emission spectra that also overlap with tissue autofluorescence. Fluorescence emission is known to be distorted by the intrinsic optical properties of tissue, coupled with marked intra-tumoural heterogeneity as a hallmark of glioma tumours. Existing quantitative fluorescence systems are developed and validated using simplified phantoms that do not simultaneously mimic the complex interactions between fluorophores and tissue optical properties or micro-environment. Consequently, existing systems risk introducing systematic errors into PpIX quantification when used in tissue. In this work, we introduce a novel pipeline for quantification of PpIX in glioma, which robustly differentiates both emission states from background autofluorescence without reliance on a priori spectral information, and accounts for variations in their quantum efficiency. Unmixed PpIX emission forms are then corrected for wavelength-dependent optical distortions and weighted for accurate quantification. Significantly, this pipeline is developed and validated using novel tissue-mimicking phantoms replicating the optical properties of glioma tissues and photochemical variability of PpIX fluorescence in glioma. Our workflow achieves strong correlation with ground-truth PpIX concentrations (R2 = 0.918+-0.002), demonstrating its potential for robust, quantitative PpIX fluorescence imaging in clinical settings.",Bioinformatics
"Quantification of protoporphyrin IX (PpIX) fluorescence in human brain tumours has the potential to significantly improve patient outcomes in neuro-oncology, but represents a formidable imaging challenge. Protoporphyrin is a biological molecule which interacts with the tissue micro-environment to form two photochemical states in glioma. Each exhibits markedly different quantum efficiencies, with distinct but overlapping emission spectra that also overlap with tissue autofluorescence. Fluorescence emission is known to be distorted by the intrinsic optical properties of tissue, coupled with marked intra-tumoural heterogeneity as a hallmark of glioma tumours. Existing quantitative fluorescence systems are developed and validated using simplified phantoms that do not simultaneously mimic the complex interactions between fluorophores and tissue optical properties or micro-environment. Consequently, existing systems risk introducing systematic errors into PpIX quantification when used in tissue. In this work, we introduce a novel pipeline for quantification of PpIX in glioma, which robustly differentiates both emission states from background autofluorescence without reliance on a priori spectral information, and accounts for variations in their quantum efficiency. Unmixed PpIX emission forms are then corrected for wavelength-dependent optical distortions and weighted for accurate quantification. Significantly, this pipeline is developed and validated using novel tissue-mimicking phantoms replicating the optical properties of glioma tissues and photochemical variability of PpIX fluorescence in glioma. Our workflow achieves strong correlation with ground-truth PpIX concentrations (R2 = 0.918+-0.002), demonstrating its potential for robust, quantitative PpIX fluorescence imaging in clinical settings. [SEP] [HINT] used -> Bioinformatics (Syns: utilize, ill-used, apply) | tissue -> Bioinformatics (Syns: tissue paper, weave) | clinical -> Bioinformatics (Syns: )",Bioinformatics
"Genetic mutations can disrupt protein structure, stability, and solubility, contributing to a wide range of diseases. Existing predictive models often lack interpretability and fail to integrate physical and chemical interactions critical to molecular mechanisms. Moreover, current approaches treat disease association, stability changes, and solubility alterations as separate tasks, limiting model generalizability. In this study, we introduce a unified framework based on multiscale commutative algebra to capture intrinsic physical and chemical interactions for the first time. Leveraging Persistent Stanley-Reisner Theory, we extract multiscale algebraic invariants to build a Commutative Algebra neural Network (CANet). Integrated with transformer features and auxiliary physical features, we apply CANet to tackle three key domains for the first time: disease-associated mutations, mutation-induced protein stability changes, and solubility changes upon mutations. Across six benchmark tasks, CANet and its gradient boosting tree counterpart, CATree, consistently attain state-of-the-art performance, achieving up to 7.5% improvement in predictive accuracy. Our approach offers multiscale, mechanistic, interpretable,and generalizable models for predicting disease-mutation associations.",Bioinformatics
"Genetic mutations can disrupt protein structure, stability, and solubility, contributing to a wide range of diseases. Existing predictive models often lack interpretability and fail to integrate physical and chemical interactions critical to molecular mechanisms. Moreover, current approaches treat disease association, stability changes, and solubility alterations as separate tasks, limiting model generalizability. In this study, we introduce a unified framework based on multiscale commutative algebra to capture intrinsic physical and chemical interactions for the first time. Leveraging Persistent Stanley-Reisner Theory, we extract multiscale algebraic invariants to build a Commutative Algebra neural Network (CANet). Integrated with transformer features and auxiliary physical features, we apply CANet to tackle three key domains for the first time: disease-associated mutations, mutation-induced protein stability changes, and solubility changes upon mutations. Across six benchmark tasks, CANet and its gradient boosting tree counterpart, CATree, consistently attain state-of-the-art performance, achieving up to 7.5% improvement in predictive accuracy. Our approach offers multiscale, mechanistic, interpretable,and generalizable models for predicting disease-mutation associations. [SEP] [HINT] based -> Bioinformatics (Syns: ground, free-base, base) | features -> Bioinformatics (Syns: characteristic, lineament, feature of speech) | molecular -> Bioinformatics (Syns: )",Bioinformatics
"We present our submission to the Algonauts 2025 Challenge, where the goal is to predict fMRI brain responses to movie stimuli. Our approach integrates multimodal representations from large language models, video encoders, audio models, and vision-language models, combining both off-the-shelf and fine-tuned variants. To improve performance, we enhanced textual inputs with detailed transcripts and summaries, and we explored stimulus-tuning and fine-tuning strategies for language and vision models. Predictions from individual models were combined using stacked regression, yielding solid results. Our submission, under the team name Seinfeld, ranked 10th. We make all code and resources publicly available, contributing to ongoing efforts in developing multimodal encoding models for brain activity.",Neuroscience
"We present our submission to the Algonauts 2025 Challenge, where the goal is to predict fMRI brain responses to movie stimuli. Our approach integrates multimodal representations from large language models, video encoders, audio models, and vision-language models, combining both off-the-shelf and fine-tuned variants. To improve performance, we enhanced textual inputs with detailed transcripts and summaries, and we explored stimulus-tuning and fine-tuning strategies for language and vision models. Predictions from individual models were combined using stacked regression, yielding solid results. Our submission, under the team name Seinfeld, ranked 10th. We make all code and resources publicly available, contributing to ongoing efforts in developing multimodal encoding models for brain activity. [SEP] [HINT] language -> Neuroscience (Syns: linguistic process, linguistic communication, spoken communication) | using -> Bioinformatics (Syns: utilize, exploitation, apply) | fmri -> Neuroscience (Syns: functional magnetic resonance imaging)",Neuroscience
"Understanding how distributed brain regions coordinate to produce behavior requires models that are both predictive and interpretable. We introduce Behavior-Adaptive Connectivity Estimation (BACE), an end-to-end framework that learns phase-specific, directed inter-regional connectivity directly from multi-region intracranial local field potentials (LFP). BACE aggregates many micro-contacts within each anatomical region via per-region temporal encoders, applies a learnable adjacency specific to each behavioral phase, and is trained on a forecasting objective. On synthetic multivariate time series with known graphs, BACE accurately recovers ground-truth directed interactions while achieving forecasting performance comparable to state-of-the-art baselines. Applied to human subcortical LFP recorded simultaneously from eight regions during a cued reaching task, BACE yields an explicit connectivity matrix for each within-trial behavioral phase. The resulting behavioral phase-specific graphs reveal behavior-aligned reconfiguration of inter-regional influence and provide compact, interpretable adjacency matrices for comparing network organization across behavioral phases. By linking predictive success to explicit connectivity estimates, BACE offers a practical tool for generating data-driven hypotheses about the dynamic coordination of subcortical regions during behavior.",Neuroscience
"Understanding how distributed brain regions coordinate to produce behavior requires models that are both predictive and interpretable. We introduce Behavior-Adaptive Connectivity Estimation (BACE), an end-to-end framework that learns phase-specific, directed inter-regional connectivity directly from multi-region intracranial local field potentials (LFP). BACE aggregates many micro-contacts within each anatomical region via per-region temporal encoders, applies a learnable adjacency specific to each behavioral phase, and is trained on a forecasting objective. On synthetic multivariate time series with known graphs, BACE accurately recovers ground-truth directed interactions while achieving forecasting performance comparable to state-of-the-art baselines. Applied to human subcortical LFP recorded simultaneously from eight regions during a cued reaching task, BACE yields an explicit connectivity matrix for each within-trial behavioral phase. The resulting behavioral phase-specific graphs reveal behavior-aligned reconfiguration of inter-regional influence and provide compact, interpretable adjacency matrices for comparing network organization across behavioral phases. By linking predictive success to explicit connectivity estimates, BACE offers a practical tool for generating data-driven hypotheses about the dynamic coordination of subcortical regions during behavior. [SEP] [HINT] field -> Materials Science (Syns: field of honor, line of business, orbit) | connectivity -> Neuroscience (Syns: ) | understanding -> Neuroscience (Syns: savvy, intellect, sympathy)",Neuroscience
"Microstructural evolution in metallic materials feedbacks with the loading conditions and influences the life time of parts and components. Therefore, the deformation mechanisms have to be fundamentally understood. Tribological loading causes a non-trivial, position-dependent, moving stress field. We present a systematic study on the influence of the complexity of the implemented material models on the calculated stress field. For the stress field validation, results of tribological experiments on single crystals with the activation of deformation twins are used. The resolved shear stresses calculated with the stress field models have to be highest on the experimentally identified twin systems. From this combination of modelling and experiment, it clearly follows that a stress field model considering plasticity is required. The widely used Hamilton stress field for tribological loading is limited due to only considering elastic strains. Here, the predictive quality of the stress field is sensitive to the assumed yield strength, work hardening and plastic anisotropy. Certain stress field models are close to the experimental data, but none completely replicate them. These results highlight that the model type and parameters have to be carefully determined in order to be able to predict how a metallic material deforms due to a sliding load.",Materials Science
"Microstructural evolution in metallic materials feedbacks with the loading conditions and influences the life time of parts and components. Therefore, the deformation mechanisms have to be fundamentally understood. Tribological loading causes a non-trivial, position-dependent, moving stress field. We present a systematic study on the influence of the complexity of the implemented material models on the calculated stress field. For the stress field validation, results of tribological experiments on single crystals with the activation of deformation twins are used. The resolved shear stresses calculated with the stress field models have to be highest on the experimentally identified twin systems. From this combination of modelling and experiment, it clearly follows that a stress field model considering plasticity is required. The widely used Hamilton stress field for tribological loading is limited due to only considering elastic strains. Here, the predictive quality of the stress field is sensitive to the assumed yield strength, work hardening and plastic anisotropy. Certain stress field models are close to the experimental data, but none completely replicate them. These results highlight that the model type and parameters have to be carefully determined in order to be able to predict how a metallic material deforms due to a sliding load. [SEP] [HINT] used -> Bioinformatics (Syns: utilize, ill-used, apply) | field -> Materials Science (Syns: field of honor, line of business, orbit) | quality -> Bioinformatics (Syns: lineament, tone, calibre)",Materials Science
"Viruses are microscopic infectious agents that require a host cell for replication. Viral replication occurs in several stages, and the completion time for each stage varies due to differences in the cellular environment. Thus, the time to complete each stage in viral replication is a random variable. However, no analytic expression exists for the viral population at the cellular level when the completion time for each process constituting viral replication is a random variable. This paper presents a simplified model of viral replication, treating each stage as a renewal process with independently and identically distributed completion times. Using the proposed model, we derive an analytical formula for viral populations at the cellular level, based on viewing viral replication as a birth-death process. The mean viral count is expressed via probability density functions representing the completion time for each step in the replication process. This work validates the results with stochastic simulations. This study provides a new quantitative framework for understanding viral infection dynamics.",Bioinformatics
"Viruses are microscopic infectious agents that require a host cell for replication. Viral replication occurs in several stages, and the completion time for each stage varies due to differences in the cellular environment. Thus, the time to complete each stage in viral replication is a random variable. However, no analytic expression exists for the viral population at the cellular level when the completion time for each process constituting viral replication is a random variable. This paper presents a simplified model of viral replication, treating each stage as a renewal process with independently and identically distributed completion times. Using the proposed model, we derive an analytical formula for viral populations at the cellular level, based on viewing viral replication as a birth-death process. The mean viral count is expressed via probability density functions representing the completion time for each step in the replication process. This work validates the results with stochastic simulations. This study provides a new quantitative framework for understanding viral infection dynamics. [SEP] [HINT] based -> Bioinformatics (Syns: ground, free-base, base) | understanding -> Neuroscience (Syns: savvy, intellect, sympathy) | work -> Bioinformatics (Syns: work out, process, bring)",Bioinformatics
"Microwell microfluidics has been utilized for single-cell analysis to reveal heterogeneity in gene expression, signaling pathways, and phenotypic responses for identifying rare cell types, understanding disease progression, and developing more precise therapeutic strategies. However, designing microwell microfluidics is a considerably complex task, requiring knowledge, experience, and CAD software, as well as manual intervention, which often fails initial designs, demanding multiple costly and time-consuming iterations. In this study, we establish an autonomous large language model (LLM)-driven microwell design framework to generate code-based computer-aided design (CAD) scripts, that enables the rapid and reproducible creation of microwells with diverse geometries and imaging-based analysis. We propose a multimodal large language model (MLLM)-logistic regression framework based on integrating high-level semantic descriptions generated by MLLMs with image embeddings for image classification tasks, aiming to identify microwell occupancy and microwell shape. The fused multimodal representation is input to a logistic regression model, which is both interpretable and computationally efficient. We achieved significant improvements, exceeding 0.92 for occupancy classification and 0.99 for shape classification, across all evaluated MLLMs, compared with 0.50 and 0.55, respectively, when relying solely on direct classification. The MLLM-logistic regression framework is a scalable, efficient solution for high-throughput microwell image analysis. Our study demonstrates an autonomous design microwell platform by translating natural language prompts into optimized device geometries, CAD scripts and image analysis, facilitating the development of next-generation digital discovery by integration of literature mining, autonomous design and experimental data analysis.",Neuroscience
"Microwell microfluidics has been utilized for single-cell analysis to reveal heterogeneity in gene expression, signaling pathways, and phenotypic responses for identifying rare cell types, understanding disease progression, and developing more precise therapeutic strategies. However, designing microwell microfluidics is a considerably complex task, requiring knowledge, experience, and CAD software, as well as manual intervention, which often fails initial designs, demanding multiple costly and time-consuming iterations. In this study, we establish an autonomous large language model (LLM)-driven microwell design framework to generate code-based computer-aided design (CAD) scripts, that enables the rapid and reproducible creation of microwells with diverse geometries and imaging-based analysis. We propose a multimodal large language model (MLLM)-logistic regression framework based on integrating high-level semantic descriptions generated by MLLMs with image embeddings for image classification tasks, aiming to identify microwell occupancy and microwell shape. The fused multimodal representation is input to a logistic regression model, which is both interpretable and computationally efficient. We achieved significant improvements, exceeding 0.92 for occupancy classification and 0.99 for shape classification, across all evaluated MLLMs, compared with 0.50 and 0.55, respectively, when relying solely on direct classification. The MLLM-logistic regression framework is a scalable, efficient solution for high-throughput microwell image analysis. Our study demonstrates an autonomous design microwell platform by translating natural language prompts into optimized device geometries, CAD scripts and image analysis, facilitating the development of next-generation digital discovery by integration of literature mining, autonomous design and experimental data analysis. [SEP] [HINT] based -> Bioinformatics (Syns: ground, free-base, base) | language -> Neuroscience (Syns: linguistic process, linguistic communication, spoken communication) | understanding -> Neuroscience (Syns: savvy, intellect, sympathy)",Neuroscience
"Two-dimensional fullerene networks have recently attracted increasing interest due to their diverse bonding topologies and mechanically robust architectures. In this work, we develop an accurate machine-learned potential NEP-C$_{24}$ for both the quasi-hexagonal phase (qHP) and the quasi-tetragonal phase (qTP) C$_{24}$ monolayers, based on the neuroevolution potential (NEP) framework. Using this NEP-C$_{24}$ model, we systematically investigate the elastic and thermal transport properties. Compared with C$_{60}$ monolayers, both C$_{24}$ phases exhibit markedly enhanced stiffness, arising from the combination of reduced molecular size and increased density of covalent bonds. The qTP C$_{24}$ monolayer shows nearly isotropic elastic properties and thermal conductivities along its two principal axes owing to its four-fold symmetry, whereas the chain-like, misaligned bonding topology of the qHP C$_{24}$ monolayer leads to pronounced in-plane anisotropy. Homogeneous nonequilibrium molecular dynamics and spectral decomposition analyses reveal that low-frequency ($<5$ THz) acoustic phonons dominate heat transport, with directional variations in phonon group velocity and mean free path governing the anisotropic response in qHP C$_{24}$. Real-space heat flow visualizations further show that, in these fullerene networks, phonon transport is dominated by strong inter-fullerene covalent bonds rather than weak van der Waals interactions. These findings establish a direct link between intermolecular bonding topology and phonon-mediated heat transport, providing guidance for the rational design of fullerene-based two-dimensional materials with tunable mechanical and thermal properties.",Materials Science
"Two-dimensional fullerene networks have recently attracted increasing interest due to their diverse bonding topologies and mechanically robust architectures. In this work, we develop an accurate machine-learned potential NEP-C$_{24}$ for both the quasi-hexagonal phase (qHP) and the quasi-tetragonal phase (qTP) C$_{24}$ monolayers, based on the neuroevolution potential (NEP) framework. Using this NEP-C$_{24}$ model, we systematically investigate the elastic and thermal transport properties. Compared with C$_{60}$ monolayers, both C$_{24}$ phases exhibit markedly enhanced stiffness, arising from the combination of reduced molecular size and increased density of covalent bonds. The qTP C$_{24}$ monolayer shows nearly isotropic elastic properties and thermal conductivities along its two principal axes owing to its four-fold symmetry, whereas the chain-like, misaligned bonding topology of the qHP C$_{24}$ monolayer leads to pronounced in-plane anisotropy. Homogeneous nonequilibrium molecular dynamics and spectral decomposition analyses reveal that low-frequency ($<5$ THz) acoustic phonons dominate heat transport, with directional variations in phonon group velocity and mean free path governing the anisotropic response in qHP C$_{24}$. Real-space heat flow visualizations further show that, in these fullerene networks, phonon transport is dominated by strong inter-fullerene covalent bonds rather than weak van der Waals interactions. These findings establish a direct link between intermolecular bonding topology and phonon-mediated heat transport, providing guidance for the rational design of fullerene-based two-dimensional materials with tunable mechanical and thermal properties. [SEP] [HINT] phonon -> Materials Science (Syns: ) | based -> Bioinformatics (Syns: ground, free-base, base) | transport -> Materials Science (Syns: transferral, enthral, shipping)",Materials Science
"Medically uncontrolled epileptic seizures affect nearly 15 million people worldwide, resulting in enormous economic and psychological burdens. Treatment of medically refractory epilepsy is essential for patients to achieve remission, improve psychological functioning, and enhance social and vocational outcomes. Here, we show a state-of-the-art method that stabilizes fractional dynamical networks modeled from intracranial EEG data, effectively suppressing seizure activity in 34 out of 35 total spontaneous episodes from patients at the University of Pennsylvania and the Mayo Clinic. We perform a multi-scale analysis and show that the fractal behavior and stability properties of these data distinguish between four epileptic states: interictal, pre-ictal, ictal, and post-ictal. Furthermore, the simulated controlled signals exhibit substantial amplitude reduction ($49\%$ average). These findings highlight the potential of fractional dynamics to characterize seizure-related brain states and demonstrate its capability to suppress epileptic activity.",Bioinformatics
"Medically uncontrolled epileptic seizures affect nearly 15 million people worldwide, resulting in enormous economic and psychological burdens. Treatment of medically refractory epilepsy is essential for patients to achieve remission, improve psychological functioning, and enhance social and vocational outcomes. Here, we show a state-of-the-art method that stabilizes fractional dynamical networks modeled from intracranial EEG data, effectively suppressing seizure activity in 34 out of 35 total spontaneous episodes from patients at the University of Pennsylvania and the Mayo Clinic. We perform a multi-scale analysis and show that the fractal behavior and stability properties of these data distinguish between four epileptic states: interictal, pre-ictal, ictal, and post-ictal. Furthermore, the simulated controlled signals exhibit substantial amplitude reduction ($49\%$ average). These findings highlight the potential of fractional dynamics to characterize seizure-related brain states and demonstrate its capability to suppress epileptic activity. [SEP] [HINT] networks -> Neuroscience (Syns: network, meshwork, electronic network) | activity -> Neuroscience (Syns: activeness, body process, bodily process) | method -> Bioinformatics (Syns: method acting)",Bioinformatics
"This study enhances breast cancer prediction by using large language models to infer the likelihood of confounding diseases, namely diabetes, obesity, and cardiovascular disease, from routine clinical data. These AI-generated features improved Random Forest model performance, particularly for LLMs like Gemma (3.9%) and Llama (6.4%). The approach shows promise for noninvasive prescreening and clinical integration, supporting improved early detection and shared decision-making in breast cancer diagnosis.",Bioinformatics
"This study enhances breast cancer prediction by using large language models to infer the likelihood of confounding diseases, namely diabetes, obesity, and cardiovascular disease, from routine clinical data. These AI-generated features improved Random Forest model performance, particularly for LLMs like Gemma (3.9%) and Llama (6.4%). The approach shows promise for noninvasive prescreening and clinical integration, supporting improved early detection and shared decision-making in breast cancer diagnosis. [SEP] [HINT] large -> Bioinformatics (Syns: prominent, great, tumid) | clinical -> Bioinformatics (Syns: ) | language -> Neuroscience (Syns: linguistic process, linguistic communication, spoken communication)",Bioinformatics
"Accurate and scalable cell type annotation remains a challenge in single-cell transcriptomics, especially when datasets exhibit strong batch effects or contain previously unseen cell populations. Here we introduce SpikGPT, a hybrid deep learning framework that integrates scGPT-derived cell embeddings with a spiking Transformer architecture to achieve efficient and robust annotation. scGPT provides biologically informed dense representations of each cell, which are further processed by a multi-head Spiking Self-Attention mechanism for energy-efficient feature extraction. Across multiple benchmark datasets, SpikGPT consistently matches or exceeds the performance of leading annotation tools. Notably, SpikGPT uniquely identifies unseen cell types by assigning low-confidence predictions to an ""Unknown"" category, allowing accurate rejection of cell states absent from the training reference. Together, these results demonstrate that SpikGPT is a versatile and reliable annotation tool capable of generalizing across datasets, resolving complex cellular heterogeneity, and facilitating discovery of novel or disease-associated cell populations.",Bioinformatics
"Accurate and scalable cell type annotation remains a challenge in single-cell transcriptomics, especially when datasets exhibit strong batch effects or contain previously unseen cell populations. Here we introduce SpikGPT, a hybrid deep learning framework that integrates scGPT-derived cell embeddings with a spiking Transformer architecture to achieve efficient and robust annotation. scGPT provides biologically informed dense representations of each cell, which are further processed by a multi-head Spiking Self-Attention mechanism for energy-efficient feature extraction. Across multiple benchmark datasets, SpikGPT consistently matches or exceeds the performance of leading annotation tools. Notably, SpikGPT uniquely identifies unseen cell types by assigning low-confidence predictions to an ""Unknown"" category, allowing accurate rejection of cell states absent from the training reference. Together, these results demonstrate that SpikGPT is a versatile and reliable annotation tool capable of generalizing across datasets, resolving complex cellular heterogeneity, and facilitating discovery of novel or disease-associated cell populations. [SEP] [HINT] learning -> Bioinformatics (Syns: take, teach, acquire) | complex -> Bioinformatics (Syns: building complex, coordination compound, composite) | datasets -> Bioinformatics (Syns: )",Bioinformatics
"Modeling cellular responses to genetic and chemical perturbations remains a central challenge in single-cell biology. Existing data-driven framework have advanced perturbation prediction through variational autoencoders, chemically conditioned autoencoders, and large-scale transformer pretraining. However, these models are prone to local optima in the nonconvex Waddington landscape of cell fate decisions, where poor initialization can trap trajectories in spurious lineages or implausible differentiation outcomes. While executable gene regulatory networks complement these approaches, automated design frameworks incorporate biological priors through multi-agent optimization. Yet, an approach that is completely data-driven with well-designed initialization to escape local optima and converge to a proper lineage remains elusive. In this work, we introduce a multistage reinforcement learning algorithm tailored for single-cell perturbation modeling. We first compute an explicit natural gradient update using Fisher-vector products and a conjugate gradient solver, scaled by a KL trust-region constraint to provide a safe, curvature-aware the first step for the policy. Starting with these preconditioned parameters, we then apply a second phase of proximal policy optimization (PPO) with clipped surrogates, exploiting minibatch efficiency to refine the policy. We demonstrate that this initialization substantially improves generalization on Single-cell RNA sequencing (scRNA-seq) and Single-cell ATAC sequencing (scATAC-seq) pertubation analysis.",Bioinformatics
"Modeling cellular responses to genetic and chemical perturbations remains a central challenge in single-cell biology. Existing data-driven framework have advanced perturbation prediction through variational autoencoders, chemically conditioned autoencoders, and large-scale transformer pretraining. However, these models are prone to local optima in the nonconvex Waddington landscape of cell fate decisions, where poor initialization can trap trajectories in spurious lineages or implausible differentiation outcomes. While executable gene regulatory networks complement these approaches, automated design frameworks incorporate biological priors through multi-agent optimization. Yet, an approach that is completely data-driven with well-designed initialization to escape local optima and converge to a proper lineage remains elusive. In this work, we introduce a multistage reinforcement learning algorithm tailored for single-cell perturbation modeling. We first compute an explicit natural gradient update using Fisher-vector products and a conjugate gradient solver, scaled by a KL trust-region constraint to provide a safe, curvature-aware the first step for the policy. Starting with these preconditioned parameters, we then apply a second phase of proximal policy optimization (PPO) with clipped surrogates, exploiting minibatch efficiency to refine the policy. We demonstrate that this initialization substantially improves generalization on Single-cell RNA sequencing (scRNA-seq) and Single-cell ATAC sequencing (scATAC-seq) pertubation analysis. [SEP] [HINT] learning -> Bioinformatics (Syns: take, teach, acquire) | networks -> Neuroscience (Syns: network, meshwork, electronic network) | framework -> Bioinformatics (Syns: theoretical account, model, fabric)",Bioinformatics
"Non-invasive colorectal cancer (CRC) screening represents a key opportunity to improve colonoscopy participation rates and reduce CRC mortality. This study explores the potential of the gut-liver axis for predicting colorectal neoplasia through liver-derived radiomic features extracted from routine CT images as a novel opportunistic screening approach. In this retrospective study, we analyzed data from 1,997 patients who underwent colonoscopy and abdominal CT. Patients either had no colorectal neoplasia (n=1,189) or colorectal neoplasia (n_total=808; adenomas n=423, CRC n=385). Radiomics features were extracted from 3D liver segmentations using the Radiomics Processing ToolKit (RPTK), which performed feature extraction, filtering, and classification. The dataset was split into training (n=1,397) and test (n=600) cohorts. Five machine learning models were trained with 5-fold cross-validation on the 20 most informative features, and the best model ensemble was selected based on the validation AUROC. The best radiomics-based XGBoost model achieved a test AUROC of 0.810, clearly outperforming the best clinical-only model (test AUROC: 0.457). Subclassification between colorectal cancer and adenoma showed lower accuracy (test AUROC: 0.674). Our findings establish proof-of-concept that liver-derived radiomics from routine abdominal CT can predict colorectal neoplasia. Beyond offering a pragmatic, widely accessible adjunct to CRC screening, this approach highlights the gut-liver axis as a novel biomarker source for opportunistic screening and sparks new mechanistic hypotheses for future translational research.",Bioinformatics
"Non-invasive colorectal cancer (CRC) screening represents a key opportunity to improve colonoscopy participation rates and reduce CRC mortality. This study explores the potential of the gut-liver axis for predicting colorectal neoplasia through liver-derived radiomic features extracted from routine CT images as a novel opportunistic screening approach. In this retrospective study, we analyzed data from 1,997 patients who underwent colonoscopy and abdominal CT. Patients either had no colorectal neoplasia (n=1,189) or colorectal neoplasia (n_total=808; adenomas n=423, CRC n=385). Radiomics features were extracted from 3D liver segmentations using the Radiomics Processing ToolKit (RPTK), which performed feature extraction, filtering, and classification. The dataset was split into training (n=1,397) and test (n=600) cohorts. Five machine learning models were trained with 5-fold cross-validation on the 20 most informative features, and the best model ensemble was selected based on the validation AUROC. The best radiomics-based XGBoost model achieved a test AUROC of 0.810, clearly outperforming the best clinical-only model (test AUROC: 0.457). Subclassification between colorectal cancer and adenoma showed lower accuracy (test AUROC: 0.674). Our findings establish proof-of-concept that liver-derived radiomics from routine abdominal CT can predict colorectal neoplasia. Beyond offering a pragmatic, widely accessible adjunct to CRC screening, this approach highlights the gut-liver axis as a novel biomarker source for opportunistic screening and sparks new mechanistic hypotheses for future translational research. [SEP] [HINT] based -> Bioinformatics (Syns: ground, free-base, base) | features -> Bioinformatics (Syns: characteristic, lineament, feature of speech) | learning -> Bioinformatics (Syns: take, teach, acquire)",Bioinformatics
"The spatiotemporal patterns of neural dynamics are jointly shaped by directed structural interactions and heterogeneous intrinsic features of the neural components. Despite well-developed methods for estimating directionality in network connections from network of homogeneous nodes, how local heterogeneity impacts on directionality estimation remains poorly understood. In particular, the role of excitatory-inhibitory interactions in shaping network directionality and how these interactions should be incorporated into reconstruction frameworks remain largely unexplored. Here, we present a novel reconstruction framework that simultaneously estimates effective heterogeneity across network nodes and asymmetric network connections from neural activity and symmetric connection, both are assessible in experimental data, validated using macaque cortical connectivity data and several circuit models. We found that the estimated local heterogeneity remains consistent across various forms of parameterized local circuit heterogeneity. Furthermore, we demonstrated and quantified how hidden local inhibitory populations only modify within-region connection strengths, elucidating the functional equivalence between dynamics of excitatory-inhibitory networks and purely observing excitatory networks when estimating effective heterogeneity and asymmetry. Finally, we demonstrated the sampling interval effect in estimating network interactions with respect to the sampling resolution. Together, our results not only provide a unified framework for evaluating relative functional contributions of local heterogeneity and asymmetry to overall system dynamics but also reveal the fundamental limitations and scaling principles in reconstructing neural circuit connectivity from experimental observations.",Neuroscience
"The spatiotemporal patterns of neural dynamics are jointly shaped by directed structural interactions and heterogeneous intrinsic features of the neural components. Despite well-developed methods for estimating directionality in network connections from network of homogeneous nodes, how local heterogeneity impacts on directionality estimation remains poorly understood. In particular, the role of excitatory-inhibitory interactions in shaping network directionality and how these interactions should be incorporated into reconstruction frameworks remain largely unexplored. Here, we present a novel reconstruction framework that simultaneously estimates effective heterogeneity across network nodes and asymmetric network connections from neural activity and symmetric connection, both are assessible in experimental data, validated using macaque cortical connectivity data and several circuit models. We found that the estimated local heterogeneity remains consistent across various forms of parameterized local circuit heterogeneity. Furthermore, we demonstrated and quantified how hidden local inhibitory populations only modify within-region connection strengths, elucidating the functional equivalence between dynamics of excitatory-inhibitory networks and purely observing excitatory networks when estimating effective heterogeneity and asymmetry. Finally, we demonstrated the sampling interval effect in estimating network interactions with respect to the sampling resolution. Together, our results not only provide a unified framework for evaluating relative functional contributions of local heterogeneity and asymmetry to overall system dynamics but also reveal the fundamental limitations and scaling principles in reconstructing neural circuit connectivity from experimental observations. [SEP] [HINT] connectivity -> Neuroscience (Syns: ) | features -> Bioinformatics (Syns: characteristic, lineament, feature of speech) | cortical -> Neuroscience (Syns: )",Neuroscience
"Electroencephalography (EEG) interpretation using multimodal large language models (MLLMs) offers a novel approach for analyzing brain signals. However, the complex nature of brain activity introduces critical challenges: EEG signals simultaneously encode both cognitive processes and intrinsic neural states, creating a mismatch in EEG paired-data modality that hinders effective cross-modal representation learning. Through a pivot investigation, we uncover complementary relationships between these modalities. Leveraging this insight, we propose mapping EEG signals and their corresponding modalities into a unified semantic space to achieve generalized interpretation. To fully enable conversational capabilities, we further introduce WaveMind-Instruct-338k, the first cross-task EEG dataset for instruction tuning. The resulting model demonstrates robust classification accuracy while supporting flexible, open-ended conversations across four downstream tasks, thereby offering valuable insights for both neuroscience research and the development of general-purpose EEG models.",Neuroscience
"Electroencephalography (EEG) interpretation using multimodal large language models (MLLMs) offers a novel approach for analyzing brain signals. However, the complex nature of brain activity introduces critical challenges: EEG signals simultaneously encode both cognitive processes and intrinsic neural states, creating a mismatch in EEG paired-data modality that hinders effective cross-modal representation learning. Through a pivot investigation, we uncover complementary relationships between these modalities. Leveraging this insight, we propose mapping EEG signals and their corresponding modalities into a unified semantic space to achieve generalized interpretation. To fully enable conversational capabilities, we further introduce WaveMind-Instruct-338k, the first cross-task EEG dataset for instruction tuning. The resulting model demonstrates robust classification accuracy while supporting flexible, open-ended conversations across four downstream tasks, thereby offering valuable insights for both neuroscience research and the development of general-purpose EEG models. [SEP] [HINT] language -> Neuroscience (Syns: linguistic process, linguistic communication, spoken communication) | space -> Neuroscience (Syns: distance, place, outer space) | complex -> Bioinformatics (Syns: building complex, coordination compound, composite)",Neuroscience
"To understand how neural systems process information, it is often essential to compare one circuit with another, one brain with another, or data with a model. Traditional similarity measures ignore the dynamical processes underlying neural representations. Dynamical similarity methods offer a framework to compare the temporal structure of dynamical systems by embedding their (possibly) nonlinear dynamics into a globally linear space and there computing conjugacy metrics. However, identifying the best embedding and computing these metrics can be computationally slow. Here we introduce fast Dynamical Similarity Analysis (fastDSA), which is computationally far more efficient than previous methods while maintaining their accuracy and robustness. FastDSA introduces two key components that boost efficiency: (1) automatic selection of the effective model order of the Hankel (delay) embedding from the data via a data-driven singular-value threshold that identifies the informative subspace and discards noise to lower computational cost without sacrificing signal, and (2) a novel optimization procedure and objective, which replaces the slow exact orthogonality constraint in finding a minimal distance between dynamics matrices with a lightweight process to keep the search close to the space of orthogonal transformations. We demonstrate that fastDSA is at least an order of magnitude faster than the previous methods. Furthermore, we demonstrate that fastDSA has the properties of its ancestor, including its invariances and sensitivities to system dynamics. FastDSA, therefore, provides a computationally efficient and accurate method for dynamical similarity analysis.",Neuroscience
"To understand how neural systems process information, it is often essential to compare one circuit with another, one brain with another, or data with a model. Traditional similarity measures ignore the dynamical processes underlying neural representations. Dynamical similarity methods offer a framework to compare the temporal structure of dynamical systems by embedding their (possibly) nonlinear dynamics into a globally linear space and there computing conjugacy metrics. However, identifying the best embedding and computing these metrics can be computationally slow. Here we introduce fast Dynamical Similarity Analysis (fastDSA), which is computationally far more efficient than previous methods while maintaining their accuracy and robustness. FastDSA introduces two key components that boost efficiency: (1) automatic selection of the effective model order of the Hankel (delay) embedding from the data via a data-driven singular-value threshold that identifies the informative subspace and discards noise to lower computational cost without sacrificing signal, and (2) a novel optimization procedure and objective, which replaces the slow exact orthogonality constraint in finding a minimal distance between dynamics matrices with a lightweight process to keep the search close to the space of orthogonal transformations. We demonstrate that fastDSA is at least an order of magnitude faster than the previous methods. Furthermore, we demonstrate that fastDSA has the properties of its ancestor, including its invariances and sensitivities to system dynamics. FastDSA, therefore, provides a computationally efficient and accurate method for dynamical similarity analysis. [SEP] [HINT] computational -> Neuroscience (Syns: ) | space -> Neuroscience (Syns: distance, place, outer space) | structure -> Bioinformatics (Syns: social system, complex body part, social structure)",Neuroscience
"The need for effective biomonitoring in wastewater has become clear due to the impracticality of continuously tracking all chemicals and emerging contaminants in the aquatic exposome. Effect-based biomonitoring provides a cost-effective solution. The ToxMate device, which uses videotracking of locomotor behavior in aquatic invertebrates, has proven efficient for real-time detection of micropollutant surges in effluents. To extend the approach, this proof-of-concept study evaluates the potential to formalize behavioral fingerprints from real-time videotracking data to characterize qualitative variations in effluent contamination. We present the first application of a functional data analysis (FDA) framework in ecotoxicology. Data were obtained by simultaneously tracking three sentinel organisms from distinct taxa (a crustacean, an annelid, and a gastropod) during pulse exposures to four chemicals in the laboratory (two metals, one pharmaceutical, and one insecticide). Individual and multispecies responses were analy-zed to determine whether combining species enhances the resolution of contamination fingerprints through multidimensional FDA. Applying the same data-driven approach to field data from a wastewater treatment plant (WWTP) revealed four recurring types of micropollution events. This proof of concept demonstrates the potential of behavioral fingerprints to improve wastewater monitoring and reduce pollutant transfer to the environment.",Bioinformatics
"The need for effective biomonitoring in wastewater has become clear due to the impracticality of continuously tracking all chemicals and emerging contaminants in the aquatic exposome. Effect-based biomonitoring provides a cost-effective solution. The ToxMate device, which uses videotracking of locomotor behavior in aquatic invertebrates, has proven efficient for real-time detection of micropollutant surges in effluents. To extend the approach, this proof-of-concept study evaluates the potential to formalize behavioral fingerprints from real-time videotracking data to characterize qualitative variations in effluent contamination. We present the first application of a functional data analysis (FDA) framework in ecotoxicology. Data were obtained by simultaneously tracking three sentinel organisms from distinct taxa (a crustacean, an annelid, and a gastropod) during pulse exposures to four chemicals in the laboratory (two metals, one pharmaceutical, and one insecticide). Individual and multispecies responses were analy-zed to determine whether combining species enhances the resolution of contamination fingerprints through multidimensional FDA. Applying the same data-driven approach to field data from a wastewater treatment plant (WWTP) revealed four recurring types of micropollution events. This proof of concept demonstrates the potential of behavioral fingerprints to improve wastewater monitoring and reduce pollutant transfer to the environment. [SEP] [HINT] field -> Materials Science (Syns: field of honor, line of business, orbit) | functional -> Neuroscience (Syns: working, usable, running) | framework -> Bioinformatics (Syns: theoretical account, model, fabric)",Bioinformatics
"Cell migration often exhibits long-range temporal correlations and anomalous diffusion, even in the absence of external guidance cues such as chemical gradients or topographical constraints. These observations raise a fundamental question: do such correlations simply reflect internal cellular processes, or do they enhance a cell's ability to navigate complex environments? In this work, we explore how temporally correlated noise (modeled using fractional Brownian motion) influences chemotactic search dynamics. Through computational experiments, we show that superdiffusive motion, when combined with gradient-driven migration, enables robust exploration of the chemoattractant landscape. Cells reliably reach the global maximum of the concentration field, even in the presence of spatial noise, secondary cues, or irregular signal geometry. We quantify this behavior by analyzing the distribution of first hitting times under varying degrees of temporal correlation. Notably, our results are consistent across diverse conditions, including flat and curved substrates, and scenarios involving both primary and self-generated chemotactic signals. Beyond biological implications, these findings also offer insight into the design of optimization and sampling algorithms that benefit from structured stochasticity.",Bioinformatics
"Cell migration often exhibits long-range temporal correlations and anomalous diffusion, even in the absence of external guidance cues such as chemical gradients or topographical constraints. These observations raise a fundamental question: do such correlations simply reflect internal cellular processes, or do they enhance a cell's ability to navigate complex environments? In this work, we explore how temporally correlated noise (modeled using fractional Brownian motion) influences chemotactic search dynamics. Through computational experiments, we show that superdiffusive motion, when combined with gradient-driven migration, enables robust exploration of the chemoattractant landscape. Cells reliably reach the global maximum of the concentration field, even in the presence of spatial noise, secondary cues, or irregular signal geometry. We quantify this behavior by analyzing the distribution of first hitting times under varying degrees of temporal correlation. Notably, our results are consistent across diverse conditions, including flat and curved substrates, and scenarios involving both primary and self-generated chemotactic signals. Beyond biological implications, these findings also offer insight into the design of optimization and sampling algorithms that benefit from structured stochasticity. [SEP] [HINT] computational -> Neuroscience (Syns: ) | complex -> Bioinformatics (Syns: building complex, coordination compound, composite) | results -> Bioinformatics (Syns: final result, consequence, resultant role)",Bioinformatics
"Multimodal protein language models deliver strong performance on mutation-effect prediction, but training such models from scratch demands substantial computational resources. In this paper, we propose a fine-tuning framework called InstructPLM-mu and try to answer a question: \textit{Can multimodal fine-tuning of a pretrained, sequence-only protein language model match the performance of models trained end-to-end? } Surprisingly, our experiments show that fine-tuning ESM2 with structural inputs can reach performance comparable to ESM3. To understand how this is achieved, we systematically compare three different feature-fusion designs and fine-tuning recipes. Our results reveal that both the fusion method and the tuning strategy strongly affect final accuracy, indicating that the fine-tuning process is not trivial. We hope this work offers practical guidance for injecting structure into pretrained protein language models and motivates further research on better fusion mechanisms and fine-tuning protocols.",Bioinformatics
"Multimodal protein language models deliver strong performance on mutation-effect prediction, but training such models from scratch demands substantial computational resources. In this paper, we propose a fine-tuning framework called InstructPLM-mu and try to answer a question: \textit{Can multimodal fine-tuning of a pretrained, sequence-only protein language model match the performance of models trained end-to-end? } Surprisingly, our experiments show that fine-tuning ESM2 with structural inputs can reach performance comparable to ESM3. To understand how this is achieved, we systematically compare three different feature-fusion designs and fine-tuning recipes. Our results reveal that both the fusion method and the tuning strategy strongly affect final accuracy, indicating that the fine-tuning process is not trivial. We hope this work offers practical guidance for injecting structure into pretrained protein language models and motivates further research on better fusion mechanisms and fine-tuning protocols. [SEP] [HINT] language -> Neuroscience (Syns: linguistic process, linguistic communication, spoken communication) | computational -> Neuroscience (Syns: ) | structure -> Bioinformatics (Syns: social system, complex body part, social structure)",Bioinformatics
"Biomarkers are critical tools in the diagnosis and monitoring of neurodegenerative diseases. Reliable quantification depends on assay validity, especially the demonstration of parallelism between diluted biological samples and the assay's standard curve. Inadequate parallelism can lead to biased concentration estimates, jeopardizing both clinical and research applications. Here we systematically review the evidence of analytical parallelism in body fluid (serum, plasma, cerebrospinal fluid) biomarker assays for neurodegeneration and evaluate the extent, reproducibility, and reporting quality of partial parallelism.   This systematic review was registered on PROSPERO (CRD42024568766) and conducted in accordance with PRISMA guidelines. We included studies published between December 2010 to July 2024 without language restrictions. ...   In conclusion, partial parallelism was infrequently observed and inconsistently reported in most biomarker assays for neurodegeneration. Narrow dilution ranges and variable methodologies limit generalizability. Transparent reporting of dilution protocols and adherence to established analytical validation guidelines is needed. This systematic review has practical implications for clinical trial design, regulatory approval processes, and the reliability of biomarker-based diagnostics.",Bioinformatics
"Biomarkers are critical tools in the diagnosis and monitoring of neurodegenerative diseases. Reliable quantification depends on assay validity, especially the demonstration of parallelism between diluted biological samples and the assay's standard curve. Inadequate parallelism can lead to biased concentration estimates, jeopardizing both clinical and research applications. Here we systematically review the evidence of analytical parallelism in body fluid (serum, plasma, cerebrospinal fluid) biomarker assays for neurodegeneration and evaluate the extent, reproducibility, and reporting quality of partial parallelism.   This systematic review was registered on PROSPERO (CRD42024568766) and conducted in accordance with PRISMA guidelines. We included studies published between December 2010 to July 2024 without language restrictions. ...   In conclusion, partial parallelism was infrequently observed and inconsistently reported in most biomarker assays for neurodegeneration. Narrow dilution ranges and variable methodologies limit generalizability. Transparent reporting of dilution protocols and adherence to established analytical validation guidelines is needed. This systematic review has practical implications for clinical trial design, regulatory approval processes, and the reliability of biomarker-based diagnostics. [SEP] [HINT] clinical -> Bioinformatics (Syns: ) | language -> Neuroscience (Syns: linguistic process, linguistic communication, spoken communication) | quality -> Bioinformatics (Syns: lineament, tone, calibre)",Bioinformatics
"Indium-tin oxide (ITO) has been leveraged as a crucial functional layer in the optoelectronic frameworks, such as non-volatile color display thin films based on the ITO/phase-change material (PCM)/ITO/reflective metal multilayer structures on a silicon substrate. In addition to non-volatile color tuning by PCMs, phase transition of ITO may pose a substantial impact on display performances. Yet, a comprehensive colormap of ITO thin films as functions of annealing temperature and film thickness is missing. In this work, we systematically investigate properties of ITO films based on X-ray diffraction, spectroscopic ellipsometry and ultraviolet-visible spectrophotometry measurements. We provide a colormap of the ITO/platinum/silicon structure in terms of the annealing temperature (150-350 °C) and thickness (5-100 nm) for the non-volatile color display, and we observe strong color changes under 250 °C annealing treatment for the 50-nm and 100-nm-thick ITO films. We suggest that the intrinsic change in colors of the ITO functional thin-film layers should also be taken into account, when the PCM-based reconfigurable color devices are used in practice.",Materials Science
"Indium-tin oxide (ITO) has been leveraged as a crucial functional layer in the optoelectronic frameworks, such as non-volatile color display thin films based on the ITO/phase-change material (PCM)/ITO/reflective metal multilayer structures on a silicon substrate. In addition to non-volatile color tuning by PCMs, phase transition of ITO may pose a substantial impact on display performances. Yet, a comprehensive colormap of ITO thin films as functions of annealing temperature and film thickness is missing. In this work, we systematically investigate properties of ITO films based on X-ray diffraction, spectroscopic ellipsometry and ultraviolet-visible spectrophotometry measurements. We provide a colormap of the ITO/platinum/silicon structure in terms of the annealing temperature (150-350 °C) and thickness (5-100 nm) for the non-volatile color display, and we observe strong color changes under 250 °C annealing treatment for the 50-nm and 100-nm-thick ITO films. We suggest that the intrinsic change in colors of the ITO functional thin-film layers should also be taken into account, when the PCM-based reconfigurable color devices are used in practice. [SEP] [HINT] used -> Bioinformatics (Syns: utilize, ill-used, apply) | transition -> Materials Science (Syns: passage, modulation, changeover) | based -> Bioinformatics (Syns: ground, free-base, base)",Materials Science
"Psychedelics, such as psilocybin, reorganise large-scale brain connectivity, yet how these changes are reflected across electrophysiological (electroencephalogram, EEG) and haemodynamic (functional magnetic resonance imaging, fMRI) networks remains unclear. We present Brain-MGF, a multimodal graph fusion network for joint EEG-fMRI connectivity analysis. For each modality, we construct graphs with partial-correlation edges and Pearson-profile node features, and learn subject-level embeddings via graph convolution. An adaptive softmax gate then fuses modalities with sample-specific weights to capture context-dependent contributions. Using the world's largest single-site psilocybin dataset, PsiConnect, Brain-MGF distinguishes psilocybin from no-psilocybin conditions in meditation and rest. Fusion improves over unimodal and non-adaptive variants, achieving 74.0% accuracy and 76.5% F1 score on meditation, and 76.0% accuracy with 85.8% ROC-AUC on rest. UMAP visualisations reveal clearer class separation for fused embeddings. These results indicate that adaptive graph fusion effectively integrates complementary EEG-fMRI information, providing an interpretable framework for characterising psilocybin-induced alterations in large-scale neural organisation.",Neuroscience
"Psychedelics, such as psilocybin, reorganise large-scale brain connectivity, yet how these changes are reflected across electrophysiological (electroencephalogram, EEG) and haemodynamic (functional magnetic resonance imaging, fMRI) networks remains unclear. We present Brain-MGF, a multimodal graph fusion network for joint EEG-fMRI connectivity analysis. For each modality, we construct graphs with partial-correlation edges and Pearson-profile node features, and learn subject-level embeddings via graph convolution. An adaptive softmax gate then fuses modalities with sample-specific weights to capture context-dependent contributions. Using the world's largest single-site psilocybin dataset, PsiConnect, Brain-MGF distinguishes psilocybin from no-psilocybin conditions in meditation and rest. Fusion improves over unimodal and non-adaptive variants, achieving 74.0% accuracy and 76.5% F1 score on meditation, and 76.0% accuracy with 85.8% ROC-AUC on rest. UMAP visualisations reveal clearer class separation for fused embeddings. These results indicate that adaptive graph fusion effectively integrates complementary EEG-fMRI information, providing an interpretable framework for characterising psilocybin-induced alterations in large-scale neural organisation. [SEP] [HINT] connectivity -> Neuroscience (Syns: ) | networks -> Neuroscience (Syns: network, meshwork, electronic network) | results -> Bioinformatics (Syns: final result, consequence, resultant role)",Neuroscience
"The accuracy with which the human proprioceptive system estimates hand speed is not well understood. To investigate this, we designed an experiment using hobby-grade mechatronics parts and integrated it as a laboratory exercise in a large remote laboratory course. In a simple joint position reproduction task, participants (N = 191) grasped a servomotor-driven shaft with one hand as it followed a randomized trajectory composed of sinusoidal submovements. They simultaneously attempted to reproduce the movement by turning the shaft of a potentiometer with the other hand. Focusing on the first movement of the trajectory, we found that participants consistently overestimated the speed of the slowest rotations by ~45% and underestimated the speed of the fastest rotations also by ~30%. Speed estimation errors were near zero for trajectories with peak velocities ~63 deg/s. Participants' movements also overshot slow trajectories and undershot fast trajectories. We show that these trajectory errors can be explained by a model in which the proprioceptive system integrates velocity misestimates to infer position.",Neuroscience
"The accuracy with which the human proprioceptive system estimates hand speed is not well understood. To investigate this, we designed an experiment using hobby-grade mechatronics parts and integrated it as a laboratory exercise in a large remote laboratory course. In a simple joint position reproduction task, participants (N = 191) grasped a servomotor-driven shaft with one hand as it followed a randomized trajectory composed of sinusoidal submovements. They simultaneously attempted to reproduce the movement by turning the shaft of a potentiometer with the other hand. Focusing on the first movement of the trajectory, we found that participants consistently overestimated the speed of the slowest rotations by ~45% and underestimated the speed of the fastest rotations also by ~30%. Speed estimation errors were near zero for trajectories with peak velocities ~63 deg/s. Participants' movements also overshot slow trajectories and undershot fast trajectories. We show that these trajectory errors can be explained by a model in which the proprioceptive system integrates velocity misestimates to infer position. [SEP] [HINT] human -> Neuroscience (Syns: human being, man, homo) | using -> Bioinformatics (Syns: utilize, exploitation, apply) | accuracy -> Bioinformatics (Syns: truth)",Neuroscience
"This paper introduces SpikeFit, a novel training method for Spiking Neural Networks (SNNs) that enables efficient inference on neuromorphic hardware, considering all its stringent requirements: the number of neurons and synapses that can fit on a single device, and lower bit-width representations (e.g., 4-bit, 8-bit). Unlike conventional compressing approaches that address only a subset of these requirements (limited numerical precision and limited number of neurons in the network), SpikeFit treats the allowed weights' discrete values themselves as learnable parameters co-optimized with the model, allowing for optimal Clusterization-Aware Training (CAT) of the model's weights at low precision (2-, 4-, or 8-bit) which results in higher network compression efficiency, as well as limiting the number of unique synaptic connections to a value required by neuromorphic processor. This joint optimization allows SpikeFit to find a discrete weight set aligned with hardware constraints, enabling the most complete deployment across a broader range of neuromorphic processors than existing methods of SNN compression support. Moreover, SpikeFit introduces a new hardware-friendly Fisher Spike Contribution (FSC) pruning method showing the state-of-the-art performance. We demonstrate that for spiking neural networks constrained to only four unique synaptic weight values (M = 4), our SpikeFit method not only outperforms state-of-the-art SNNs compression methods and conventional baselines combining extreme quantization schemes and clustering algorithms, but also meets a wider range of neuromorphic hardware requirements and provides the lowest energy use in experiments.",Neuroscience
"This paper introduces SpikeFit, a novel training method for Spiking Neural Networks (SNNs) that enables efficient inference on neuromorphic hardware, considering all its stringent requirements: the number of neurons and synapses that can fit on a single device, and lower bit-width representations (e.g., 4-bit, 8-bit). Unlike conventional compressing approaches that address only a subset of these requirements (limited numerical precision and limited number of neurons in the network), SpikeFit treats the allowed weights' discrete values themselves as learnable parameters co-optimized with the model, allowing for optimal Clusterization-Aware Training (CAT) of the model's weights at low precision (2-, 4-, or 8-bit) which results in higher network compression efficiency, as well as limiting the number of unique synaptic connections to a value required by neuromorphic processor. This joint optimization allows SpikeFit to find a discrete weight set aligned with hardware constraints, enabling the most complete deployment across a broader range of neuromorphic processors than existing methods of SNN compression support. Moreover, SpikeFit introduces a new hardware-friendly Fisher Spike Contribution (FSC) pruning method showing the state-of-the-art performance. We demonstrate that for spiking neural networks constrained to only four unique synaptic weight values (M = 4), our SpikeFit method not only outperforms state-of-the-art SNNs compression methods and conventional baselines combining extreme quantization schemes and clustering algorithms, but also meets a wider range of neuromorphic hardware requirements and provides the lowest energy use in experiments. [SEP] [HINT] low -> Materials Science (Syns: low-spirited, scurvy, depressed) | networks -> Neuroscience (Syns: network, meshwork, electronic network) | results -> Bioinformatics (Syns: final result, consequence, resultant role)",Neuroscience
"As a class of electron-rich materials, electrides demonstrate promising applications in many fields. However, the required high pressure restricts the practical applications to some extent. This study reveals that the unique feature of electride, i.e., the localization of interstitial electrons, can be greatly enhanced and tuned by self-defective doping, applying tensile/compressive stress, or shear stress. Moreover, the requirement of orbital orthogonality between the valence and core electron wave functions, as well as the Pauli exclusion principle, should be the driven force for the electron interstitial localization; and the exertion of external pressure modifies the available space to accommodate the electronic wave functions, thus enhances the interstitial localization. These discoveries lay down the ground for searching for promising electrides that are practicable at ambient conditions.",Materials Science
"As a class of electron-rich materials, electrides demonstrate promising applications in many fields. However, the required high pressure restricts the practical applications to some extent. This study reveals that the unique feature of electride, i.e., the localization of interstitial electrons, can be greatly enhanced and tuned by self-defective doping, applying tensile/compressive stress, or shear stress. Moreover, the requirement of orbital orthogonality between the valence and core electron wave functions, as well as the Pauli exclusion principle, should be the driven force for the electron interstitial localization; and the exertion of external pressure modifies the available space to accommodate the electronic wave functions, thus enhances the interstitial localization. These discoveries lay down the ground for searching for promising electrides that are practicable at ambient conditions. [SEP] [HINT] electronic -> Materials Science (Syns: ) | space -> Neuroscience (Syns: distance, place, outer space) | electron -> Materials Science (Syns: negatron)",Materials Science
"Many properties of perceptual decision making are well-modeled by deep neural networks. However, such architectures typically treat decisions as instantaneous readouts, overlooking the temporal dynamics of the decision process. We present an image-computable model of perceptual decision making in which choices and response times arise from efficient sensory encoding and Bayesian decoding of neural spiking activity. We use a Poisson variational autoencoder to learn unsupervised representations of visual stimuli in a population of rate-coded neurons, modeled as independent homogeneous Poisson processes. A task-optimized decoder then continually infers an approximate posterior over actions conditioned on incoming spiking activity. Combining these components with an entropy-based stopping rule yields a principled and image-computable model of perceptual decisions capable of generating trial-by-trial patterns of choices and response times. Applied to MNIST digit classification, the model reproduces key empirical signatures of perceptual decision making, including stochastic variability, right-skewed response time distributions, logarithmic scaling of response times with the number of alternatives (Hick's law), and speed-accuracy trade-offs.",Neuroscience
"Many properties of perceptual decision making are well-modeled by deep neural networks. However, such architectures typically treat decisions as instantaneous readouts, overlooking the temporal dynamics of the decision process. We present an image-computable model of perceptual decision making in which choices and response times arise from efficient sensory encoding and Bayesian decoding of neural spiking activity. We use a Poisson variational autoencoder to learn unsupervised representations of visual stimuli in a population of rate-coded neurons, modeled as independent homogeneous Poisson processes. A task-optimized decoder then continually infers an approximate posterior over actions conditioned on incoming spiking activity. Combining these components with an entropy-based stopping rule yields a principled and image-computable model of perceptual decisions capable of generating trial-by-trial patterns of choices and response times. Applied to MNIST digit classification, the model reproduces key empirical signatures of perceptual decision making, including stochastic variability, right-skewed response time distributions, logarithmic scaling of response times with the number of alternatives (Hick's law), and speed-accuracy trade-offs. [SEP] [HINT] decoding -> Neuroscience (Syns: decrypt, decipherment, decryption) | including -> Bioinformatics (Syns: admit, include, let in) | visual -> Neuroscience (Syns: optical, ocular, optic)",Neuroscience
"Far from equilibrium, neural systems self-organize across multiple scales. Exploiting multiscale self-organization in neuroscience and artificial intelligence requires a computational framework for modeling the effective non-equilibrium dynamics of stochastic neural trajectories. Non-equilibrium thermodynamics and representational geometry offer theoretical foundations, but we need scalable data-driven techniques for modeling collective properties of high-dimensional neural networks from partial subsampled observations. Renormalization is a coarse-graining technique central to studying emergent scaling properties of many-body and nonlinear dynamical systems. While widely applied in physics and machine learning, coarse-graining complex dynamical networks remains unsolved, affecting many computational sciences. Recent diffusion-based renormalization, inspired by quantum statistical mechanics, coarse-grains networks near entropy transitions marked by maximal changes in specific heat or information transmission. Here I explore diffusion-based renormalization of neural systems by generating symmetry-breaking representations across scales and offering scalable algorithms using tensor networks. Diffusion-guided renormalization bridges microscale and mesoscale dynamics of dissipative neural systems. For microscales, I developed a scalable graph inference algorithm for discovering community structure from subsampled neural activity. Using community-based node orderings, diffusion-guided renormalization generates renormalization group flow through metagraphs and joint probability functions. Towards mesoscales, diffusion-guided renormalization targets learning the effective non-equilibrium dynamics of dissipative neural trajectories occupying lower-dimensional subspaces, enabling coarse-to-fine control in systems neuroscience and artificial intelligence.",Neuroscience
"Far from equilibrium, neural systems self-organize across multiple scales. Exploiting multiscale self-organization in neuroscience and artificial intelligence requires a computational framework for modeling the effective non-equilibrium dynamics of stochastic neural trajectories. Non-equilibrium thermodynamics and representational geometry offer theoretical foundations, but we need scalable data-driven techniques for modeling collective properties of high-dimensional neural networks from partial subsampled observations. Renormalization is a coarse-graining technique central to studying emergent scaling properties of many-body and nonlinear dynamical systems. While widely applied in physics and machine learning, coarse-graining complex dynamical networks remains unsolved, affecting many computational sciences. Recent diffusion-based renormalization, inspired by quantum statistical mechanics, coarse-grains networks near entropy transitions marked by maximal changes in specific heat or information transmission. Here I explore diffusion-based renormalization of neural systems by generating symmetry-breaking representations across scales and offering scalable algorithms using tensor networks. Diffusion-guided renormalization bridges microscale and mesoscale dynamics of dissipative neural systems. For microscales, I developed a scalable graph inference algorithm for discovering community structure from subsampled neural activity. Using community-based node orderings, diffusion-guided renormalization generates renormalization group flow through metagraphs and joint probability functions. Towards mesoscales, diffusion-guided renormalization targets learning the effective non-equilibrium dynamics of dissipative neural trajectories occupying lower-dimensional subspaces, enabling coarse-to-fine control in systems neuroscience and artificial intelligence. [SEP] [HINT] computational -> Neuroscience (Syns: ) | learning -> Bioinformatics (Syns: take, teach, acquire) | networks -> Neuroscience (Syns: network, meshwork, electronic network)",Neuroscience
"Effective monitoring of mobile animal populations is crucial for ecological research, wildlife management, and agricultural applications. Monitoring of bats specifically can help understand the spread of disease as well as shine light on bat migration patterns, population dynamics, and the impacts of environmental changes on bat colonies. Fixed sensing modalities, such as infrared sensors, cameras, radar, and acoustic detectors, play a pivotal role in tracking and understanding animal behavior. This survey goes over context-informing details about bat biology, and then reviews these fixed sensing modalities, discussing the unique challenges and contributions of each approach. We highlight the coverage, applications, accuracy, and limitations associated with each of these sensing modalities. By synthesizing recent advances, we provide a comprehensive overview to guide future research in this area.",Bioinformatics
"Effective monitoring of mobile animal populations is crucial for ecological research, wildlife management, and agricultural applications. Monitoring of bats specifically can help understand the spread of disease as well as shine light on bat migration patterns, population dynamics, and the impacts of environmental changes on bat colonies. Fixed sensing modalities, such as infrared sensors, cameras, radar, and acoustic detectors, play a pivotal role in tracking and understanding animal behavior. This survey goes over context-informing details about bat biology, and then reviews these fixed sensing modalities, discussing the unique challenges and contributions of each approach. We highlight the coverage, applications, accuracy, and limitations associated with each of these sensing modalities. By synthesizing recent advances, we provide a comprehensive overview to guide future research in this area. [SEP] [HINT] understanding -> Neuroscience (Syns: savvy, intellect, sympathy) | disease -> Bioinformatics (Syns: )",Bioinformatics
"A recent high-profile study by Koide-Majima et al. (2024) claimed a major advance in reconstructing visual imagery from brain activity using a novel variant of a generative AI-based method. However, our independent reanalysis reveals multiple methodological concerns that raise questions about the validity of their conclusions. Specifically, our evaluation demonstrates that: (1) the reconstruction results are biased by selective reporting of only the best-performing examples at multiple levels; (2) performance is artificially inflated by circular metrics that fail to reflect perceptual accuracy; (3) fair baseline comparisons reveal no discernible advantages of the study's key innovations over existing techniques; (4) the central ""Bayesian"" sampling component is functionally inert, producing outcomes identical to the standard optimization result; and (5) even if the component were successfully implemented, the claims of Bayesian novelty are unsubstantiated, as the proposed method does not leverage the principles of a proper Bayesian framework. These systemic issues necessitate a critical reassessment of the study's contributions. This commentary dissects these deficiencies to underscore the need for greater credibility and transparency in the rapidly advancing field of brain decoding.",Neuroscience
"A recent high-profile study by Koide-Majima et al. (2024) claimed a major advance in reconstructing visual imagery from brain activity using a novel variant of a generative AI-based method. However, our independent reanalysis reveals multiple methodological concerns that raise questions about the validity of their conclusions. Specifically, our evaluation demonstrates that: (1) the reconstruction results are biased by selective reporting of only the best-performing examples at multiple levels; (2) performance is artificially inflated by circular metrics that fail to reflect perceptual accuracy; (3) fair baseline comparisons reveal no discernible advantages of the study's key innovations over existing techniques; (4) the central ""Bayesian"" sampling component is functionally inert, producing outcomes identical to the standard optimization result; and (5) even if the component were successfully implemented, the claims of Bayesian novelty are unsubstantiated, as the proposed method does not leverage the principles of a proper Bayesian framework. These systemic issues necessitate a critical reassessment of the study's contributions. This commentary dissects these deficiencies to underscore the need for greater credibility and transparency in the rapidly advancing field of brain decoding. [SEP] [HINT] field -> Materials Science (Syns: field of honor, line of business, orbit) | performance -> Bioinformatics (Syns: functioning, operation, carrying out) | results -> Bioinformatics (Syns: final result, consequence, resultant role)",Neuroscience
"Deep generative models are rapidly advancing structure-based drug design, offering substantial promise for generating small molecule ligands that bind to specific protein targets. However, most current approaches assume a rigid protein binding pocket, neglecting the intrinsic flexibility of proteins and the conformational rearrangements induced by ligand binding, limiting their applicability in practical drug discovery. Here, we propose Apo2Mol, a diffusion-based generative framework for 3D molecule design that explicitly accounts for conformational flexibility in protein binding pockets. To support this, we curate a dataset of over 24,000 experimentally resolved apo-holo structure pairs from the Protein Data Bank, enabling the characterization of protein structure changes associated with ligand binding. Apo2Mol employs a full-atom hierarchical graph-based diffusion model that simultaneously generates 3D ligand molecules and their corresponding holo pocket conformations from input apo states. Empirical studies demonstrate that Apo2Mol can achieve state-of-the-art performance in generating high-affinity ligands and accurately capture realistic protein pocket conformational changes.",Bioinformatics
"Deep generative models are rapidly advancing structure-based drug design, offering substantial promise for generating small molecule ligands that bind to specific protein targets. However, most current approaches assume a rigid protein binding pocket, neglecting the intrinsic flexibility of proteins and the conformational rearrangements induced by ligand binding, limiting their applicability in practical drug discovery. Here, we propose Apo2Mol, a diffusion-based generative framework for 3D molecule design that explicitly accounts for conformational flexibility in protein binding pockets. To support this, we curate a dataset of over 24,000 experimentally resolved apo-holo structure pairs from the Protein Data Bank, enabling the characterization of protein structure changes associated with ligand binding. Apo2Mol employs a full-atom hierarchical graph-based diffusion model that simultaneously generates 3D ligand molecules and their corresponding holo pocket conformations from input apo states. Empirical studies demonstrate that Apo2Mol can achieve state-of-the-art performance in generating high-affinity ligands and accurately capture realistic protein pocket conformational changes. [SEP] [HINT] structure -> Bioinformatics (Syns: social system, complex body part, social structure) | performance -> Bioinformatics (Syns: functioning, operation, carrying out) | framework -> Bioinformatics (Syns: theoretical account, model, fabric)",Bioinformatics
"Predicting the binding affinity of protein protein complexes directly from sequence remains a challenging problem, particularly in the absence of reliable structural information. Here I present ProtT Affinity, a sequence only model that combines ProtT5 embeddings with a lightweight Transformer architecture. The model is trained and evaluated on homology filtered subsets of the PDBBind database following a curation protocol consistent with prior structure based work. Across two independent test sets,ProtT Affinity reaches Pearson correlation coefficients of 0.628 and 0.459, respectively.Although its performance does not match the strongest structure based methods, it is competitive with several widely used approaches and provides a practical alternative when structural data are missing or uncertain. The results suggest that large protein language models capture features relevant to binding energetics, and that these features can be exploited to approximate affinity trends at scale.",Bioinformatics
"Predicting the binding affinity of protein protein complexes directly from sequence remains a challenging problem, particularly in the absence of reliable structural information. Here I present ProtT Affinity, a sequence only model that combines ProtT5 embeddings with a lightweight Transformer architecture. The model is trained and evaluated on homology filtered subsets of the PDBBind database following a curation protocol consistent with prior structure based work. Across two independent test sets,ProtT Affinity reaches Pearson correlation coefficients of 0.628 and 0.459, respectively.Although its performance does not match the strongest structure based methods, it is competitive with several widely used approaches and provides a practical alternative when structural data are missing or uncertain. The results suggest that large protein language models capture features relevant to binding energetics, and that these features can be exploited to approximate affinity trends at scale. [SEP] [HINT] used -> Bioinformatics (Syns: utilize, ill-used, apply) | based -> Bioinformatics (Syns: ground, free-base, base) | language -> Neuroscience (Syns: linguistic process, linguistic communication, spoken communication)",Bioinformatics
"The computational role of imagination remains debated. While classical accounts emphasize reward maximization, emerging evidence suggests imagination serves a broader function: accessing internal world models (IWMs). Here, we employ psychological network analysis to compare IWMs in humans and large language models (LLMs) through imagination vividness ratings. Using the Vividness of Visual Imagery Questionnaire (VVIQ-2) and Plymouth Sensory Imagery Questionnaire (PSIQ), we construct imagination networks from three human populations (Florida, Poland, London; N=2,743) and six LLM variants in two conversation conditions. Human imagination networks demonstrate robust correlations across centrality measures (expected influence, strength, closeness) and consistent clustering patterns, indicating shared structural organization of IWMs across populations. In contrast, LLM-derived networks show minimal clustering and weak centrality correlations, even when manipulating conversational memory. These systematic differences persist across environmental scenes (VVIQ-2) and sensory modalities (PSIQ), revealing fundamental disparities between human and artificial world models. Our network-based approach provides a quantitative framework for comparing internally-generated representations across cognitive agents, with implications for developing human-like imagination in artificial intelligence systems.",Neuroscience
"The computational role of imagination remains debated. While classical accounts emphasize reward maximization, emerging evidence suggests imagination serves a broader function: accessing internal world models (IWMs). Here, we employ psychological network analysis to compare IWMs in humans and large language models (LLMs) through imagination vividness ratings. Using the Vividness of Visual Imagery Questionnaire (VVIQ-2) and Plymouth Sensory Imagery Questionnaire (PSIQ), we construct imagination networks from three human populations (Florida, Poland, London; N=2,743) and six LLM variants in two conversation conditions. Human imagination networks demonstrate robust correlations across centrality measures (expected influence, strength, closeness) and consistent clustering patterns, indicating shared structural organization of IWMs across populations. In contrast, LLM-derived networks show minimal clustering and weak centrality correlations, even when manipulating conversational memory. These systematic differences persist across environmental scenes (VVIQ-2) and sensory modalities (PSIQ), revealing fundamental disparities between human and artificial world models. Our network-based approach provides a quantitative framework for comparing internally-generated representations across cognitive agents, with implications for developing human-like imagination in artificial intelligence systems. [SEP] [HINT] language -> Neuroscience (Syns: linguistic process, linguistic communication, spoken communication) | computational -> Neuroscience (Syns: ) | networks -> Neuroscience (Syns: network, meshwork, electronic network)",Neuroscience
"Large language models (LLMs) increasingly mediate human decision-making and behaviour. Ensuring LLM processing of moral meaning therefore has become a critical challenge. Current approaches rely predominantly on bottom-up methods such as fine-tuning and reinforcement learning from human feedback. We propose a fundamentally different approach: embedding moral meaning processing directly into the architectural mechanisms and frameworks of transformer-based models through top-down design principles. We first sketch a framework that conceptualizes attention as a dynamic interface mediating between structure and processing, contrasting with existing linear attention frameworks in psychology. We start from established biological-artificial attention analogies in neural architecture design to improve cognitive processing. We extend this analysis to moral processing, using Iris Murdoch's theory of loving attention (sustained, just observation that enables moral transformation by reseeing others with clarity and compassion) to philosophically discuss functional analogies between human and LLM moral processing. We formulate and evaluate potentially promising technical operationalizations to embed morality in LLM architectures and frameworks. We acknowledge the limitations of our exploration and give three key contributions. (1) We conceptualize attention as a dynamic system mechanism mediating between structure and processing. (2) Drawing on the Murdoch notion of loving attention, we outline technical pathways for embedding morality in LLMs, through modified training objectives, runtime weight adjustments, and architectural refinements to attention. (3) We argue that integrating morality into architectures and frameworks complements external, constraint-based methods. We conclude with a call for collaboration between transformer designers and philosophers engaged in AI ethics.",Neuroscience
"Large language models (LLMs) increasingly mediate human decision-making and behaviour. Ensuring LLM processing of moral meaning therefore has become a critical challenge. Current approaches rely predominantly on bottom-up methods such as fine-tuning and reinforcement learning from human feedback. We propose a fundamentally different approach: embedding moral meaning processing directly into the architectural mechanisms and frameworks of transformer-based models through top-down design principles. We first sketch a framework that conceptualizes attention as a dynamic interface mediating between structure and processing, contrasting with existing linear attention frameworks in psychology. We start from established biological-artificial attention analogies in neural architecture design to improve cognitive processing. We extend this analysis to moral processing, using Iris Murdoch's theory of loving attention (sustained, just observation that enables moral transformation by reseeing others with clarity and compassion) to philosophically discuss functional analogies between human and LLM moral processing. We formulate and evaluate potentially promising technical operationalizations to embed morality in LLM architectures and frameworks. We acknowledge the limitations of our exploration and give three key contributions. (1) We conceptualize attention as a dynamic system mechanism mediating between structure and processing. (2) Drawing on the Murdoch notion of loving attention, we outline technical pathways for embedding morality in LLMs, through modified training objectives, runtime weight adjustments, and architectural refinements to attention. (3) We argue that integrating morality into architectures and frameworks complements external, constraint-based methods. We conclude with a call for collaboration between transformer designers and philosophers engaged in AI ethics. [SEP] [HINT] language -> Neuroscience (Syns: linguistic process, linguistic communication, spoken communication) | learning -> Bioinformatics (Syns: take, teach, acquire) | functional -> Neuroscience (Syns: working, usable, running)",Neuroscience
"Multilayer networks provide a framework to study complex systems with multiple types of interactions, multiple dynamical processes, and/or multiple subsystems. When studying a dynamical process on a multilayer network, it is important to consider how both layer structure and heterogeneity across layers impacts the overall dynamics. As a concrete example, we study Ising dynamics on multilayer networks and investigate how network structure affects its qualitative features. We focus primarily on multiplex networks, which are multilayer networks in which interlayer edges occur only between manifestations of the same entity on different layers, although we also consider one empirical example with a more general multilayer structure. We use numerical simulations and a mean-field approximation to examine the steady-state behavior of the Ising dynamics as a function of temperature (which is a key model parameter) for a variety of two-layer multilayer networks from both models and empirical data. We examine both the steady-state behavior and a metastable state in which the two layers are anti-aligned, and we explore the effects of interlayer coupling strength and structural heterogeneity. In synthetic multilayer networks with core--periphery structure, we show that interlayer edges that involve peripheral nodes can exert more influence than interlayer edges that involve only core nodes. Finally, we consider empirical multilayer networks from biological and social systems. Our work illustrates how heterogeneity across the layers of a multilayer network influences dynamics on the whole network.",Neuroscience
"Multilayer networks provide a framework to study complex systems with multiple types of interactions, multiple dynamical processes, and/or multiple subsystems. When studying a dynamical process on a multilayer network, it is important to consider how both layer structure and heterogeneity across layers impacts the overall dynamics. As a concrete example, we study Ising dynamics on multilayer networks and investigate how network structure affects its qualitative features. We focus primarily on multiplex networks, which are multilayer networks in which interlayer edges occur only between manifestations of the same entity on different layers, although we also consider one empirical example with a more general multilayer structure. We use numerical simulations and a mean-field approximation to examine the steady-state behavior of the Ising dynamics as a function of temperature (which is a key model parameter) for a variety of two-layer multilayer networks from both models and empirical data. We examine both the steady-state behavior and a metastable state in which the two layers are anti-aligned, and we explore the effects of interlayer coupling strength and structural heterogeneity. In synthetic multilayer networks with core--periphery structure, we show that interlayer edges that involve peripheral nodes can exert more influence than interlayer edges that involve only core nodes. Finally, we consider empirical multilayer networks from biological and social systems. Our work illustrates how heterogeneity across the layers of a multilayer network influences dynamics on the whole network. [SEP] [HINT] networks -> Neuroscience (Syns: network, meshwork, electronic network) | structure -> Bioinformatics (Syns: social system, complex body part, social structure) | complex -> Bioinformatics (Syns: building complex, coordination compound, composite)",Neuroscience
"Dirac semimetals, with their protected Dirac points, present an ideal platform for realizing intrinsic topological superconductivity. In this work, we investigate superconductivity in a two-dimensional, square-lattice nonsymmorphic Dirac semimetal. In the normal state near half-filling, the Fermi surface consists of two distinct pockets, each enclosing a Dirac point at a time-reversal invariant momentum ($\textbf{X}=(π,0)$ and $\textbf{Y}=(0,π)$). Considering an on-site repulsive and nearest-neighbor attractive interaction, we use self-consistent mean-field theory to determine the ground-state pairing symmetry. We find that an even-parity, spin-singlet $d_{x^{2}-y^{2}}$-wave pairing is favored as it gives rise to a fully gapped superconducting state. Since the pairing amplitude has opposite signs on the two Dirac Fermi pockets, the superconducting state is identified as a second-order topological superconductor. The hallmark of this topological phase is the emergence of Majorana zero modes at the system's boundaries. Notably, the positions of these Majorana modes are highly controllable and can be manipulated simply by tailoring the boundary sublattice terminations. Our results highlight the promise of nonsymmorphic Dirac semimetals for realizing and manipulating Majorana modes.",Materials Science
"Dirac semimetals, with their protected Dirac points, present an ideal platform for realizing intrinsic topological superconductivity. In this work, we investigate superconductivity in a two-dimensional, square-lattice nonsymmorphic Dirac semimetal. In the normal state near half-filling, the Fermi surface consists of two distinct pockets, each enclosing a Dirac point at a time-reversal invariant momentum ($\textbf{X}=(π,0)$ and $\textbf{Y}=(0,π)$). Considering an on-site repulsive and nearest-neighbor attractive interaction, we use self-consistent mean-field theory to determine the ground-state pairing symmetry. We find that an even-parity, spin-singlet $d_{x^{2}-y^{2}}$-wave pairing is favored as it gives rise to a fully gapped superconducting state. Since the pairing amplitude has opposite signs on the two Dirac Fermi pockets, the superconducting state is identified as a second-order topological superconductor. The hallmark of this topological phase is the emergence of Majorana zero modes at the system's boundaries. Notably, the positions of these Majorana modes are highly controllable and can be manipulated simply by tailoring the boundary sublattice terminations. Our results highlight the promise of nonsymmorphic Dirac semimetals for realizing and manipulating Majorana modes. [SEP] [HINT] results -> Bioinformatics (Syns: final result, consequence, resultant role) | theory -> Materials Science (Syns: possibility, hypothesis) | phase -> Materials Science (Syns: stage, phase angle, form)",Materials Science
"Synthetic molecular communication (MC) in the cardiovascular system (CVS) is a key enabler for many envisioned medical applications in the human body, such as targeted drug delivery, early cancer detection, and continuous health monitoring. The design of MC systems for such applications requires suitable models for the signaling molecule propagation through complex vessel networks (VNs). Existing theoretical models offer limited analytical tractability and lack closed-form solutions, making the analysis of large-scale VNs either infeasible or not insightful. To overcome these limitations, in this paper, we propose a novel closed-form physical model, termed MIGHT, for advection-diffusion-driven transport of signaling molecules through complex VNs. The model represents the received molecule flux as a weighted sum of inverse Gaussian (IG) distributions, parameterized by physical properties of the network. The proposed model is validated by comparison with an existing convolution-based model and finite-element simulations. Further, we show that the model can be applied for the reduction of large VNs to simplified representations preserving the essential transport dynamics and for estimating representative VN based on received signals from unknown VNs.",Bioinformatics
"Synthetic molecular communication (MC) in the cardiovascular system (CVS) is a key enabler for many envisioned medical applications in the human body, such as targeted drug delivery, early cancer detection, and continuous health monitoring. The design of MC systems for such applications requires suitable models for the signaling molecule propagation through complex vessel networks (VNs). Existing theoretical models offer limited analytical tractability and lack closed-form solutions, making the analysis of large-scale VNs either infeasible or not insightful. To overcome these limitations, in this paper, we propose a novel closed-form physical model, termed MIGHT, for advection-diffusion-driven transport of signaling molecules through complex VNs. The model represents the received molecule flux as a weighted sum of inverse Gaussian (IG) distributions, parameterized by physical properties of the network. The proposed model is validated by comparison with an existing convolution-based model and finite-element simulations. Further, we show that the model can be applied for the reduction of large VNs to simplified representations preserving the essential transport dynamics and for estimating representative VN based on received signals from unknown VNs. [SEP] [HINT] based -> Bioinformatics (Syns: ground, free-base, base) | transport -> Materials Science (Syns: transferral, enthral, shipping) | networks -> Neuroscience (Syns: network, meshwork, electronic network)",Bioinformatics
"Cellular image segmentation is essential for quantitative biology yet remains difficult due to heterogeneous modalities, morphological variability, and limited annotations. We present GenCellAgent, a training-free multi-agent framework that orchestrates specialist segmenters and generalist vision-language models via a planner-executor-evaluator loop (choose tool $\rightarrow$ run $\rightarrow$ quality-check) with long-term memory. The system (i) automatically routes images to the best tool, (ii) adapts on the fly using a few reference images when imaging conditions differ from what a tool expects, (iii) supports text-guided segmentation of organelles not covered by existing models, and (iv) commits expert edits to memory, enabling self-evolution and personalized workflows. Across four cell-segmentation benchmarks, this routing yields a 15.7\% mean accuracy gain over state-of-the-art baselines. On endoplasmic reticulum and mitochondria from new datasets, GenCellAgent improves average IoU by 37.6\% over specialist models. It also segments novel objects such as the Golgi apparatus via iterative text-guided refinement, with light human correction further boosting performance. Together, these capabilities provide a practical path to robust, adaptable cellular image segmentation without retraining, while reducing annotation burden and matching user preferences.",Bioinformatics
"Cellular image segmentation is essential for quantitative biology yet remains difficult due to heterogeneous modalities, morphological variability, and limited annotations. We present GenCellAgent, a training-free multi-agent framework that orchestrates specialist segmenters and generalist vision-language models via a planner-executor-evaluator loop (choose tool $\rightarrow$ run $\rightarrow$ quality-check) with long-term memory. The system (i) automatically routes images to the best tool, (ii) adapts on the fly using a few reference images when imaging conditions differ from what a tool expects, (iii) supports text-guided segmentation of organelles not covered by existing models, and (iv) commits expert edits to memory, enabling self-evolution and personalized workflows. Across four cell-segmentation benchmarks, this routing yields a 15.7\% mean accuracy gain over state-of-the-art baselines. On endoplasmic reticulum and mitochondria from new datasets, GenCellAgent improves average IoU by 37.6\% over specialist models. It also segments novel objects such as the Golgi apparatus via iterative text-guided refinement, with light human correction further boosting performance. Together, these capabilities provide a practical path to robust, adaptable cellular image segmentation without retraining, while reducing annotation burden and matching user preferences. [SEP] [HINT] human -> Neuroscience (Syns: human being, man, homo) | framework -> Bioinformatics (Syns: theoretical account, model, fabric) | using -> Bioinformatics (Syns: utilize, exploitation, apply)",Bioinformatics
"Materials with broken fundamental symmetries, such as chiral crystals, provide a rich playground for exploring unconventional spin-dependent transport phenomena. The interplay between a material's chirality, strong spin-orbit coupling, and charge currents can lead to complex non-reciprocal effects, where electrical resistance depends on the direction of current and magnetic fields. In this study, we systematically investigate the angular dependencies of magnetoresistance in single-crystalline chiral Tellurium (Te). We observe distinct non-reciprocal magnetoresistances for magnetic fields applied along three orthogonal directions: parallel to the current along the chiral axis (z), in the sample plane but perpendicular to the current (y), and out of the sample plane (x). Through detailed analysis of the chirality- and thickness-dependence of the signals, we successfully disentangle multiple coexisting mechanisms. We conclude that the Edelstein effect, arising from the chiral structure's radial spin texture, is responsible for the non-reciprocity along the z-axis. In contrast, the chirality-independent signal along the y-axis is attributed to the Nernst effect, and the non-reciprocity along the x-axis may originate from intrinsic orbital magnetizations. These findings elucidate the complex interplay of spin, orbital, and thermal effects in Te, providing a complete picture of its non-reciprocal transport properties.",Materials Science
"Materials with broken fundamental symmetries, such as chiral crystals, provide a rich playground for exploring unconventional spin-dependent transport phenomena. The interplay between a material's chirality, strong spin-orbit coupling, and charge currents can lead to complex non-reciprocal effects, where electrical resistance depends on the direction of current and magnetic fields. In this study, we systematically investigate the angular dependencies of magnetoresistance in single-crystalline chiral Tellurium (Te). We observe distinct non-reciprocal magnetoresistances for magnetic fields applied along three orthogonal directions: parallel to the current along the chiral axis (z), in the sample plane but perpendicular to the current (y), and out of the sample plane (x). Through detailed analysis of the chirality- and thickness-dependence of the signals, we successfully disentangle multiple coexisting mechanisms. We conclude that the Edelstein effect, arising from the chiral structure's radial spin texture, is responsible for the non-reciprocity along the z-axis. In contrast, the chirality-independent signal along the y-axis is attributed to the Nernst effect, and the non-reciprocity along the x-axis may originate from intrinsic orbital magnetizations. These findings elucidate the complex interplay of spin, orbital, and thermal effects in Te, providing a complete picture of its non-reciprocal transport properties. [SEP] [HINT] spin -> Materials Science (Syns: twisting, whirl, tailspin) | transport -> Materials Science (Syns: transferral, enthral, shipping) | charge -> Materials Science (Syns: tear, bearing, burster)",Materials Science
"Clarifying the neural basis of speech intelligibility is critical for computational neuroscience and digital speech processing. Recent neuroimaging studies have shown that intelligibility modulates cortical activity beyond simple acoustics, primarily in the superior temporal and inferior frontal gyri. However, previous studies have been largely confined to clean speech, leaving it unclear whether the brain employs condition-invariant neural codes across diverse listening environments. To address this gap, we propose a novel architecture built upon a deep state space model for decoding intelligibility from fMRI signals, specifically tailored to their high-dimensional temporal structure. We present the first attempt to decode intelligibility across acoustically distinct conditions, showing our method significantly outperforms classical approaches. Furthermore, region-wise analysis highlights contributions from auditory, frontal, and parietal regions, and cross-condition transfer indicates the presence of condition-invariant neural codes, thereby advancing understanding of abstract linguistic representations in the brain.",Neuroscience
"Clarifying the neural basis of speech intelligibility is critical for computational neuroscience and digital speech processing. Recent neuroimaging studies have shown that intelligibility modulates cortical activity beyond simple acoustics, primarily in the superior temporal and inferior frontal gyri. However, previous studies have been largely confined to clean speech, leaving it unclear whether the brain employs condition-invariant neural codes across diverse listening environments. To address this gap, we propose a novel architecture built upon a deep state space model for decoding intelligibility from fMRI signals, specifically tailored to their high-dimensional temporal structure. We present the first attempt to decode intelligibility across acoustically distinct conditions, showing our method significantly outperforms classical approaches. Furthermore, region-wise analysis highlights contributions from auditory, frontal, and parietal regions, and cross-condition transfer indicates the presence of condition-invariant neural codes, thereby advancing understanding of abstract linguistic representations in the brain. [SEP] [HINT] decoding -> Neuroscience (Syns: decrypt, decipherment, decryption) | computational -> Neuroscience (Syns: ) | understanding -> Neuroscience (Syns: savvy, intellect, sympathy)",Neuroscience
"The metallic oxide RuO$_2$ hosts a fascinating edge case of magnetism: while nonmagnetic in ideal bulk material, density functional theory (DFT) predicts an altermagnetic ground state within the DFT$+U$ method. The magnetic state of strained or doped thin films remains controversial, but evidence for a nontrivial magnetic state is ample. Here, I study the altermagnetic ground state of RuO$_2$ on a higher rung of Jacob's ladder of density functional approximations, the meta-GGA level including the kinetic energy density and the density Laplacian. While the workhorse functional of solid-state physics is a generalized gradient approximation (GGA), the modern r$^2$SCAN-L functional has been established as a general-purpose functional which can replace GGA, while systematically improving solid-state properties without introducing spurious errors like erroneous magnetic ground states. Comparison of LSDA+U, GGA+U, and meta-GGA+U results on RuO$_2$ shows systematic enhancement of the exchange interaction, leading to a reduction of the onset value of the Hubbard $U$ parameter at different levels of density functional approximation. However, the magnetic ground state, studied at the experimental lattice constants, remains nonmagnetic with r$^2$SCAN-L. I demonstrate that altermagnetism is easily formed upon lattice expansion, hole doping, and uniaxial strain on the c-axis. The r$^2$SCAN-L calculations set conservative thresholds for distortions and doping levels for the onset of altermagnetism in a parameter-free framework.",Materials Science
"The metallic oxide RuO$_2$ hosts a fascinating edge case of magnetism: while nonmagnetic in ideal bulk material, density functional theory (DFT) predicts an altermagnetic ground state within the DFT$+U$ method. The magnetic state of strained or doped thin films remains controversial, but evidence for a nontrivial magnetic state is ample. Here, I study the altermagnetic ground state of RuO$_2$ on a higher rung of Jacob's ladder of density functional approximations, the meta-GGA level including the kinetic energy density and the density Laplacian. While the workhorse functional of solid-state physics is a generalized gradient approximation (GGA), the modern r$^2$SCAN-L functional has been established as a general-purpose functional which can replace GGA, while systematically improving solid-state properties without introducing spurious errors like erroneous magnetic ground states. Comparison of LSDA+U, GGA+U, and meta-GGA+U results on RuO$_2$ shows systematic enhancement of the exchange interaction, leading to a reduction of the onset value of the Hubbard $U$ parameter at different levels of density functional approximation. However, the magnetic ground state, studied at the experimental lattice constants, remains nonmagnetic with r$^2$SCAN-L. I demonstrate that altermagnetism is easily formed upon lattice expansion, hole doping, and uniaxial strain on the c-axis. The r$^2$SCAN-L calculations set conservative thresholds for distortions and doping levels for the onset of altermagnetism in a parameter-free framework. [SEP] [HINT] functional -> Neuroscience (Syns: working, usable, running) | results -> Bioinformatics (Syns: final result, consequence, resultant role) | different -> Neuroscience (Syns: unlike, dissimilar)",Materials Science
"Infrastructure parts for a hydrogen (H) economy need alloys that are mechanically strong and at the same time resistant to the most dangerous and abrupt type of failure mode, namely, H embrittlement. These two properties are in fundamental conflict, as increasing strength typically amplifies susceptibility to H-related failure. Here, we introduce a new approach to make alloys resistant to H embrittlement, by creating a topological passivation layer (up to a few hundred micrometers thick) near the material surface, the region that is most vulnerable to H ingress and attack. It features instead a layer of ultrafine laminated grains with tens of times higher dislocation density than conventional materials, altering H diffusion, trapping and crack evolution. We tested the concept on a face-centered cubic (FCC) CoCrNi medium entropy model alloy which undergoes severe H-induced intergranular cracking. Two key mechanisms create the topological passivation: First, the high density (up to ~1.3e15 m-2) of H-trapping dislocations within the passivating grain layer decelerates H migration by up to about an order of magnitude, delaying H-induced crack initiation at grain boundaries. More importantly, once unavoidable micro-sized H-induced intergranular cracks emerge in the topmost surface region, they become completely arrested by the laminated grains, due to a transition in the embrittlement mechanism from H-enhanced grain boundary decohesion to highly energy-dissipative dislocation-associated cracking. These effects almost completely eliminate H embrittlement, at even doubled yield strength, when exposing the so architected material to harsh H attack. Our approach leverages surface mechanical treatments to tailor metallic microstructures in surface regions most susceptible to H attack, providing a scalable solution to protect alloys from H-induced damage.",Materials Science
"Infrastructure parts for a hydrogen (H) economy need alloys that are mechanically strong and at the same time resistant to the most dangerous and abrupt type of failure mode, namely, H embrittlement. These two properties are in fundamental conflict, as increasing strength typically amplifies susceptibility to H-related failure. Here, we introduce a new approach to make alloys resistant to H embrittlement, by creating a topological passivation layer (up to a few hundred micrometers thick) near the material surface, the region that is most vulnerable to H ingress and attack. It features instead a layer of ultrafine laminated grains with tens of times higher dislocation density than conventional materials, altering H diffusion, trapping and crack evolution. We tested the concept on a face-centered cubic (FCC) CoCrNi medium entropy model alloy which undergoes severe H-induced intergranular cracking. Two key mechanisms create the topological passivation: First, the high density (up to ~1.3e15 m-2) of H-trapping dislocations within the passivating grain layer decelerates H migration by up to about an order of magnitude, delaying H-induced crack initiation at grain boundaries. More importantly, once unavoidable micro-sized H-induced intergranular cracks emerge in the topmost surface region, they become completely arrested by the laminated grains, due to a transition in the embrittlement mechanism from H-enhanced grain boundary decohesion to highly energy-dissipative dislocation-associated cracking. These effects almost completely eliminate H embrittlement, at even doubled yield strength, when exposing the so architected material to harsh H attack. Our approach leverages surface mechanical treatments to tailor metallic microstructures in surface regions most susceptible to H attack, providing a scalable solution to protect alloys from H-induced damage. [SEP] [HINT] transition -> Materials Science (Syns: passage, modulation, changeover) | features -> Bioinformatics (Syns: characteristic, lineament, feature of speech) | order -> Materials Science (Syns: enjoin, dictate, social club)",Materials Science
"Twisted bilayers of transition metal dichalcogenides (TMDC) form moiré superlattices resulting in moiré minibands in momentum space and hosting localized excitons in real space. While moiré superlattices provide access to Mott-Hubbard physics, their energy potential landscape and electronic correlations are highly sensitive to fluctuations of the twist angle, disorder and lattice reconstructions. However, fast and non-invasive experimental access to local twist angle and its spatial variations is challenging. Here, we systematically correlate twist angle variations of twisted WSe2 bilayers across micrometer length scales using a combined lateral force microscopy (LFM) and a micro- Raman spectroscopy approach. These measurements uncover lateral variations in the twist angle by more than 1° across length scales relevant to optical and transport measurements. We demonstrate that twist angles in the range of 3° < $α$ < 12° show distinct Raman response from scattering on optical moiré phonons allowing twist angle determination with high precision and sub-micrometer spatial resolution under ambient conditions. These modes are particularly sensitive in the low-angle twist regime, predicted to host emergent quantum phases. Our results establish micro-Raman spectroscopy of optical moiré phonons as a rapid, non-invasive probe to determine twist angle and to screen local twist angle variations with a precision better than $\pm$ 0.3° and a lateral resolution below one micrometer. This methodology is also applicable to fully hBN-encapsulated heterostructures.",Materials Science
"Twisted bilayers of transition metal dichalcogenides (TMDC) form moiré superlattices resulting in moiré minibands in momentum space and hosting localized excitons in real space. While moiré superlattices provide access to Mott-Hubbard physics, their energy potential landscape and electronic correlations are highly sensitive to fluctuations of the twist angle, disorder and lattice reconstructions. However, fast and non-invasive experimental access to local twist angle and its spatial variations is challenging. Here, we systematically correlate twist angle variations of twisted WSe2 bilayers across micrometer length scales using a combined lateral force microscopy (LFM) and a micro- Raman spectroscopy approach. These measurements uncover lateral variations in the twist angle by more than 1° across length scales relevant to optical and transport measurements. We demonstrate that twist angles in the range of 3° < $α$ < 12° show distinct Raman response from scattering on optical moiré phonons allowing twist angle determination with high precision and sub-micrometer spatial resolution under ambient conditions. These modes are particularly sensitive in the low-angle twist regime, predicted to host emergent quantum phases. Our results establish micro-Raman spectroscopy of optical moiré phonons as a rapid, non-invasive probe to determine twist angle and to screen local twist angle variations with a precision better than $\pm$ 0.3° and a lateral resolution below one micrometer. This methodology is also applicable to fully hBN-encapsulated heterostructures. [SEP] [HINT] transition -> Materials Science (Syns: passage, modulation, changeover) | transport -> Materials Science (Syns: transferral, enthral, shipping) | electronic -> Materials Science (Syns: )",Materials Science
"In the literature of cognitive neuroscience, researchers tend to assume a linear relationship between brain activation level and task performance; however, controversial findings have been reported in participants at different ages and different proficiency levels. Therefore, there may be a non-linear relationship between task performance and brain activation if a full range of task performance is considered. In the current study, using the Human Connectome Project (HCP) dataset we examined the relationship between brain activation and working memory performance in two conditions (i.e. faces and places). We found a gradual change from a U-shaped relationship to an inverted U-shaped relationship along the sensorimotor-association (S-A) axis in the face condition. In other words, in low-order sensorimotor areas, it is U-shaped and in the high-order prefrontal and association areas, it is inverted U-shaped, which suggests different properties in the encoding/representation region and in the cognitive calculation regions. However, in the place condition, such a shift is missing, presumably because most of the regions that are sensitive to task performance in the place condition are in the lower end of the S-A axis. Taken together, our study revealed a novel difference of functional property in response to task performance in the sensorimotor areas versus the association areas.",Neuroscience
"In the literature of cognitive neuroscience, researchers tend to assume a linear relationship between brain activation level and task performance; however, controversial findings have been reported in participants at different ages and different proficiency levels. Therefore, there may be a non-linear relationship between task performance and brain activation if a full range of task performance is considered. In the current study, using the Human Connectome Project (HCP) dataset we examined the relationship between brain activation and working memory performance in two conditions (i.e. faces and places). We found a gradual change from a U-shaped relationship to an inverted U-shaped relationship along the sensorimotor-association (S-A) axis in the face condition. In other words, in low-order sensorimotor areas, it is U-shaped and in the high-order prefrontal and association areas, it is inverted U-shaped, which suggests different properties in the encoding/representation region and in the cognitive calculation regions. However, in the place condition, such a shift is missing, presumably because most of the regions that are sensitive to task performance in the place condition are in the lower end of the S-A axis. Taken together, our study revealed a novel difference of functional property in response to task performance in the sensorimotor areas versus the association areas. [SEP] [HINT] task -> Neuroscience (Syns: tax, project, chore) | functional -> Neuroscience (Syns: working, usable, running) | performance -> Bioinformatics (Syns: functioning, operation, carrying out)",Neuroscience
"For decades, forensic statisticians have debated whether searching large DNA databases undermines the evidential value of a match. Modern surveillance faces an exponentially harder problem: screening populations across thousands of attributes using threshold rules rather than exact matching. Intuition suggests that requiring many coincidental matches should make false alerts astronomically unlikely. This intuition fails.   Consider a system that monitors 1,000 attributes, each with a 0.5 percent innocent match rate. Matching 15 pre-specified attributes has probability \(10^{-35}\), one in 30 decillion, effectively impossible. But operational systems require no such specificity. They might flag anyone who matches \emph{any} 15 of the 1,000. In a city of one million innocent people, this produces about 226 false alerts. A seemingly impossible event becomes all but guaranteed. This is not an implementation flaw but a mathematical consequence of high-dimensional screening.   We identify fundamental probabilistic limits on screening reliability. Systems undergo sharp transitions from reliable to unreliable with small increases in data scale, a fragility worsened by data growth and correlations. As data accumulate and correlation collapses effective dimensionality, systems enter regimes where alerts lose evidential value even when individual coincidences remain vanishingly rare. This framework reframes the DNA database controversy as a shift between operational regimes. Unequal surveillance exposures magnify failure, making ``structural bias'' mathematically inevitable. These limits are structural: beyond a critical scale, failure cannot be prevented through threshold adjustment or algorithmic refinement.",Bioinformatics
"For decades, forensic statisticians have debated whether searching large DNA databases undermines the evidential value of a match. Modern surveillance faces an exponentially harder problem: screening populations across thousands of attributes using threshold rules rather than exact matching. Intuition suggests that requiring many coincidental matches should make false alerts astronomically unlikely. This intuition fails.   Consider a system that monitors 1,000 attributes, each with a 0.5 percent innocent match rate. Matching 15 pre-specified attributes has probability \(10^{-35}\), one in 30 decillion, effectively impossible. But operational systems require no such specificity. They might flag anyone who matches \emph{any} 15 of the 1,000. In a city of one million innocent people, this produces about 226 false alerts. A seemingly impossible event becomes all but guaranteed. This is not an implementation flaw but a mathematical consequence of high-dimensional screening.   We identify fundamental probabilistic limits on screening reliability. Systems undergo sharp transitions from reliable to unreliable with small increases in data scale, a fragility worsened by data growth and correlations. As data accumulate and correlation collapses effective dimensionality, systems enter regimes where alerts lose evidential value even when individual coincidences remain vanishingly rare. This framework reframes the DNA database controversy as a shift between operational regimes. Unequal surveillance exposures magnify failure, making ``structural bias'' mathematically inevitable. These limits are structural: beyond a critical scale, failure cannot be prevented through threshold adjustment or algorithmic refinement. [SEP] [HINT] systems -> Bioinformatics (Syns: organization, organisation, system) | framework -> Bioinformatics (Syns: theoretical account, model, fabric) | using -> Bioinformatics (Syns: utilize, exploitation, apply)",Bioinformatics
"Understanding the behavior of light interstitial elements in multicomponent alloys remains challenging due to the complexity of local chemical environments and the high computational cost of first-principles calculations. Here we demonstrate that three universal machine-learning interatomic potentials (uMLIPs) - MACE-MATPES-PBE-0, Orb-v3, and SevenNet-0 can efficiently map the energetics of C, N, O, and H interstitials in a Ti-23Nb-0.7Ta-2Zr gum metal base alloy while being several orders of magnitude faster than density functional theory (DFT). All uMLIPs predict broad energy distributions (1-3 eV) for all four interstitial elements, reflecting their strong sensitivity to local lattice chemistry. Despite alloy disorder, MACE-MATPES-PBE-0 and Orb-v3 reproduce the expected site preferences of the bcc structure: C, N, and O relax into octahedral sites, whereas H stabilizes in tetrahedral positions. In contrast, SevenNet-0 predicts H to be most stable in octahedral coordination, indicating a limitation of this model. Correlation analysis reveals two dominant chemical trends: Ti-rich environments strongly stabilize interstitials, whereas close proximity to Nb is destabilizing; Zr and Ta show no statistically significant influence, likely due to their low concentrations. Benchmarking representative O interstitial configurations against DFT confirms that the uMLIPs reasonably reproduce the energetic ordering of chemically distinct environments. Overall, these results demonstrate that uMLIPs enable computationally efficient, statistically converged characterization of defect energetics in gum metal base alloy and provide insight into how local chemical environments govern interstitial stability.",Materials Science
"Understanding the behavior of light interstitial elements in multicomponent alloys remains challenging due to the complexity of local chemical environments and the high computational cost of first-principles calculations. Here we demonstrate that three universal machine-learning interatomic potentials (uMLIPs) - MACE-MATPES-PBE-0, Orb-v3, and SevenNet-0 can efficiently map the energetics of C, N, O, and H interstitials in a Ti-23Nb-0.7Ta-2Zr gum metal base alloy while being several orders of magnitude faster than density functional theory (DFT). All uMLIPs predict broad energy distributions (1-3 eV) for all four interstitial elements, reflecting their strong sensitivity to local lattice chemistry. Despite alloy disorder, MACE-MATPES-PBE-0 and Orb-v3 reproduce the expected site preferences of the bcc structure: C, N, and O relax into octahedral sites, whereas H stabilizes in tetrahedral positions. In contrast, SevenNet-0 predicts H to be most stable in octahedral coordination, indicating a limitation of this model. Correlation analysis reveals two dominant chemical trends: Ti-rich environments strongly stabilize interstitials, whereas close proximity to Nb is destabilizing; Zr and Ta show no statistically significant influence, likely due to their low concentrations. Benchmarking representative O interstitial configurations against DFT confirms that the uMLIPs reasonably reproduce the energetic ordering of chemically distinct environments. Overall, these results demonstrate that uMLIPs enable computationally efficient, statistically converged characterization of defect energetics in gum metal base alloy and provide insight into how local chemical environments govern interstitial stability. [SEP] [HINT] low -> Materials Science (Syns: low-spirited, scurvy, depressed) | dft -> Materials Science (Syns: ) | computational -> Neuroscience (Syns: )",Materials Science
"In neuroscience, methods from information geometry (IG) have been successfully applied in the modelling of binary vectors from spike train data, using the orthogonal decomposition of the Kullback-Leibler divergence and mutual information to isolate different orders of interaction between neurons. While spike train data is well-approximated with a binary model, here we apply these IG methods to data from electroencephalography (EEG), a continuous signal requiring appropriate discretization strategies. We developed and compared three different binarization methods and used them to identify third-order interactions in an experiment involving imagined motor movements. The statistical significance of these interactions was assessed using phase-randomized surrogate data that eliminated higher-order dependencies while preserving the spectral characteristics of the original signals. We validated our approach by implementing known second- and third-order dependencies in a forward model and quantified information attenuation at different steps of the analysis. This revealed that the greatest loss in information occurred when going from the idealized binary case to enforcing these dependencies using oscillatory signals. When applied to the real EEG dataset, our analysis detected statistically significant third-order interactions during the task condition despite the relatively sparse data (45 trials per condition). This work demonstrates that IG methods can successfully extract genuine higher-order dependencies from continuous neural recordings when paired with appropriate binarization schemes.",Bioinformatics
"In neuroscience, methods from information geometry (IG) have been successfully applied in the modelling of binary vectors from spike train data, using the orthogonal decomposition of the Kullback-Leibler divergence and mutual information to isolate different orders of interaction between neurons. While spike train data is well-approximated with a binary model, here we apply these IG methods to data from electroencephalography (EEG), a continuous signal requiring appropriate discretization strategies. We developed and compared three different binarization methods and used them to identify third-order interactions in an experiment involving imagined motor movements. The statistical significance of these interactions was assessed using phase-randomized surrogate data that eliminated higher-order dependencies while preserving the spectral characteristics of the original signals. We validated our approach by implementing known second- and third-order dependencies in a forward model and quantified information attenuation at different steps of the analysis. This revealed that the greatest loss in information occurred when going from the idealized binary case to enforcing these dependencies using oscillatory signals. When applied to the real EEG dataset, our analysis detected statistically significant third-order interactions during the task condition despite the relatively sparse data (45 trials per condition). This work demonstrates that IG methods can successfully extract genuine higher-order dependencies from continuous neural recordings when paired with appropriate binarization schemes. [SEP] [HINT] used -> Bioinformatics (Syns: utilize, ill-used, apply) | task -> Neuroscience (Syns: tax, project, chore) | information -> Bioinformatics (Syns: entropy, data, info)",Bioinformatics
"Many tasks require mapping continuous input data (e.g. images) to discrete task outputs (e.g. class labels). Yet, how neural networks learn to perform such discrete computations on continuous data manifolds remains poorly understood. Here, we show that signatures of such computations emerge in the representational geometry of neural networks as they learn. By analysing the Riemannian pullback metric across layers of a neural network, we find that network computation can be decomposed into two functions: discretising continuous input features and performing logical operations on these discretised variables. Furthermore, we demonstrate how different learning regimes (rich vs. lazy) have contrasting metric and curvature structures, affecting the ability of the networks to generalise to unseen inputs. Overall, our work provides a geometric framework for understanding how neural networks learn to perform discrete computations on continuous manifolds.",Neuroscience
"Many tasks require mapping continuous input data (e.g. images) to discrete task outputs (e.g. class labels). Yet, how neural networks learn to perform such discrete computations on continuous data manifolds remains poorly understood. Here, we show that signatures of such computations emerge in the representational geometry of neural networks as they learn. By analysing the Riemannian pullback metric across layers of a neural network, we find that network computation can be decomposed into two functions: discretising continuous input features and performing logical operations on these discretised variables. Furthermore, we demonstrate how different learning regimes (rich vs. lazy) have contrasting metric and curvature structures, affecting the ability of the networks to generalise to unseen inputs. Overall, our work provides a geometric framework for understanding how neural networks learn to perform discrete computations on continuous manifolds. [SEP] [HINT] task -> Neuroscience (Syns: tax, project, chore) | tasks -> Neuroscience (Syns: tax, task, project) | features -> Bioinformatics (Syns: characteristic, lineament, feature of speech)",Neuroscience
"The human neocortex is functionally organised at its highest level along a continuous sensory-to-association (AS) hierarchy. This study characterises the AS hierarchy of patients with schizophrenia in a comparison with controls. Using a large fMRI dataset (N=355), we extracted individual AS gradients via spectral analysis of brain connectivity, quantified hierarchical specialisation by gradient spread, and related this spread with connectivity geometry. We found that schizophrenia compresses the AS hierarchy indicating reduced functional differentiation. By modelling neural timescale with the Ornstein-Uhlenbeck process, we observed that the most specialised, locally cohesive regions at the gradient extremes exhibit dynamics with a longer time constant, an effect that is attenuated in schizophrenia. To study computation, we used the gradients to regularise subject-specific recurrent neural networks (RNNs) trained on working memory tasks. Networks endowed with greater gradient spread learned more efficiently, plateaued at lower task loss, and maintained stronger alignment to the prescribed AS hierarchical geometry. Fixed point linearisation showed that high-range networks settled into more stable neural states during memory delay, evidenced by lower energy and smaller maximal Jacobian eigenvalues. This gradient-regularised RNN framework therefore links large-scale cortical architecture with fixed point stability, providing a mechanistic account of how gradient de-differentiation could destabilise neural computations in schizophrenia, convergently supported by empirical timescale flattening and model-based evidence of less stable fixed points.",Neuroscience
"The human neocortex is functionally organised at its highest level along a continuous sensory-to-association (AS) hierarchy. This study characterises the AS hierarchy of patients with schizophrenia in a comparison with controls. Using a large fMRI dataset (N=355), we extracted individual AS gradients via spectral analysis of brain connectivity, quantified hierarchical specialisation by gradient spread, and related this spread with connectivity geometry. We found that schizophrenia compresses the AS hierarchy indicating reduced functional differentiation. By modelling neural timescale with the Ornstein-Uhlenbeck process, we observed that the most specialised, locally cohesive regions at the gradient extremes exhibit dynamics with a longer time constant, an effect that is attenuated in schizophrenia. To study computation, we used the gradients to regularise subject-specific recurrent neural networks (RNNs) trained on working memory tasks. Networks endowed with greater gradient spread learned more efficiently, plateaued at lower task loss, and maintained stronger alignment to the prescribed AS hierarchical geometry. Fixed point linearisation showed that high-range networks settled into more stable neural states during memory delay, evidenced by lower energy and smaller maximal Jacobian eigenvalues. This gradient-regularised RNN framework therefore links large-scale cortical architecture with fixed point stability, providing a mechanistic account of how gradient de-differentiation could destabilise neural computations in schizophrenia, convergently supported by empirical timescale flattening and model-based evidence of less stable fixed points. [SEP] [HINT] used -> Bioinformatics (Syns: utilize, ill-used, apply) | task -> Neuroscience (Syns: tax, project, chore) | connectivity -> Neuroscience (Syns: )",Neuroscience
"Artificially intelligent (AI) co-scientists must be able to sift through research literature cost-efficiently while applying nuanced scientific reasoning. We evaluate Small Language Models (SLMs, <= 8B parameters) for classifying medical research papers. Using literature on the oncogenic potential of HMTV/MMTV-like viruses in breast cancer as a case study, we assess model performance with both zero-shot and in-context learning (ICL; few-shot prompting) strategies against frontier proprietary Large Language Models (LLMs). Llama 3 and Qwen2.5 outperform GPT-5 (API, low/high effort), Gemini 3 Pro Preview, and Meerkat in zero-shot settings, though trailing Gemini 2.5 Pro. ICL leads to improved performance on a case-by-case basis, allowing Llama 3 and Qwen2.5 to match Gemini 2.5 Pro in binary classification. Systematic lexical-ablation experiments show that SLM decisions are often grounded in valid scientific cues but can be influenced by spurious textual artifacts, underscoring need for interpretability in high-stakes pipelines. Our results reveal both promise and limitations of modern SLMs for scientific triage; pairing SLMs with simple but principled prompting strategies can approach performance of the strongest LLMs for targeted literature filtering in co-scientist pipelines.",Bioinformatics
"Artificially intelligent (AI) co-scientists must be able to sift through research literature cost-efficiently while applying nuanced scientific reasoning. We evaluate Small Language Models (SLMs, <= 8B parameters) for classifying medical research papers. Using literature on the oncogenic potential of HMTV/MMTV-like viruses in breast cancer as a case study, we assess model performance with both zero-shot and in-context learning (ICL; few-shot prompting) strategies against frontier proprietary Large Language Models (LLMs). Llama 3 and Qwen2.5 outperform GPT-5 (API, low/high effort), Gemini 3 Pro Preview, and Meerkat in zero-shot settings, though trailing Gemini 2.5 Pro. ICL leads to improved performance on a case-by-case basis, allowing Llama 3 and Qwen2.5 to match Gemini 2.5 Pro in binary classification. Systematic lexical-ablation experiments show that SLM decisions are often grounded in valid scientific cues but can be influenced by spurious textual artifacts, underscoring need for interpretability in high-stakes pipelines. Our results reveal both promise and limitations of modern SLMs for scientific triage; pairing SLMs with simple but principled prompting strategies can approach performance of the strongest LLMs for targeted literature filtering in co-scientist pipelines. [SEP] [HINT] language -> Neuroscience (Syns: linguistic process, linguistic communication, spoken communication) | learning -> Bioinformatics (Syns: take, teach, acquire) | performance -> Bioinformatics (Syns: functioning, operation, carrying out)",Bioinformatics
"Rhythmic fluctuations in acoustic energy and accompanying neuronal excitations in cortical oscillations are characteristic of human speech, yet whether a corresponding rhythmicity inheres in the articulatory movements that generate speech remains unclear. The received understanding of speech movements as discrete, goal-oriented actions struggles to make contact with the rhythmicity findings. In this work, we demonstrate that an unintuitive -- but no less principled than the conventional -- representation for discrete movements reveals a pervasive limit cycle organization and unlocks the recovery of previously inaccessible rhythmic structure underlying the motor activity of speech. These results help resolve a time-honored tension between the ubiquity of biological rhythmicity and discreteness in speech, the quintessential human higher function, by revealing a rhythmic organization at the most fundamental level of individual articulatory actions.",Neuroscience
"Rhythmic fluctuations in acoustic energy and accompanying neuronal excitations in cortical oscillations are characteristic of human speech, yet whether a corresponding rhythmicity inheres in the articulatory movements that generate speech remains unclear. The received understanding of speech movements as discrete, goal-oriented actions struggles to make contact with the rhythmicity findings. In this work, we demonstrate that an unintuitive -- but no less principled than the conventional -- representation for discrete movements reveals a pervasive limit cycle organization and unlocks the recovery of previously inaccessible rhythmic structure underlying the motor activity of speech. These results help resolve a time-honored tension between the ubiquity of biological rhythmicity and discreteness in speech, the quintessential human higher function, by revealing a rhythmic organization at the most fundamental level of individual articulatory actions. [SEP] [HINT] understanding -> Neuroscience (Syns: savvy, intellect, sympathy) | cortical -> Neuroscience (Syns: ) | structure -> Bioinformatics (Syns: social system, complex body part, social structure)",Neuroscience
"Mapping habitat quality, based on factors like host availability and environmental suitability, is a common approach to determining which locations are important for the spread of a species. Mapping habitat connectivity takes geographic analyses a step further, evaluating the potential roles of locations in biological invasions, pandemics, or species conservation. Locations with high habitat quality may play a minor role in species spread if they are geographically isolated. Yet, a location with lower habitat quality may play a major role in a species' spread if it acts as a bridge between regions that would otherwise be physically fragmented.   Here we introduce the geohabnet R package, which evaluates the potential importance of locations for the spread of species through habitat landscapes. geohabnet incorporates key factors such as dispersal probabilities and habitat availability in a network framework, for better understanding habitat connectivity for host-dependent species, such as pathogens, arthropod pests, or pollinators.   geohabnet uses publicly available or user-provided datasets, six network centrality metrics, and a user-selected geographic scale. We provide examples using geohabnet for surveillance prioritization of emerging plant pests in Africa and the Americas. These examples illustrate how users can apply geohabnet for their species of interest and generate maps of the estimated importance of geographic locations for species spread.   geohabnet provides a quick, open-source, and reproducible baseline to quantify a species' habitat connectivity across a wide range of geographic scales and evaluates potential scenarios for the expansion of a species through habitat landscapes. geohabnet supports biosecurity programs, invasion science, and conservation biology when prioritizing management efforts for transboundary pathogens, pests, or endangered species.",Bioinformatics
"Mapping habitat quality, based on factors like host availability and environmental suitability, is a common approach to determining which locations are important for the spread of a species. Mapping habitat connectivity takes geographic analyses a step further, evaluating the potential roles of locations in biological invasions, pandemics, or species conservation. Locations with high habitat quality may play a minor role in species spread if they are geographically isolated. Yet, a location with lower habitat quality may play a major role in a species' spread if it acts as a bridge between regions that would otherwise be physically fragmented.   Here we introduce the geohabnet R package, which evaluates the potential importance of locations for the spread of species through habitat landscapes. geohabnet incorporates key factors such as dispersal probabilities and habitat availability in a network framework, for better understanding habitat connectivity for host-dependent species, such as pathogens, arthropod pests, or pollinators.   geohabnet uses publicly available or user-provided datasets, six network centrality metrics, and a user-selected geographic scale. We provide examples using geohabnet for surveillance prioritization of emerging plant pests in Africa and the Americas. These examples illustrate how users can apply geohabnet for their species of interest and generate maps of the estimated importance of geographic locations for species spread.   geohabnet provides a quick, open-source, and reproducible baseline to quantify a species' habitat connectivity across a wide range of geographic scales and evaluates potential scenarios for the expansion of a species through habitat landscapes. geohabnet supports biosecurity programs, invasion science, and conservation biology when prioritizing management efforts for transboundary pathogens, pests, or endangered species. [SEP] [HINT] connectivity -> Neuroscience (Syns: ) | based -> Bioinformatics (Syns: ground, free-base, base) | understanding -> Neuroscience (Syns: savvy, intellect, sympathy)",Bioinformatics
"Trions, three-body bound states composed of an exciton and an additional charge, are typically fragile and require external excitation to form. Here, we report the spontaneous emergence of a stable trion gas at the surface of the layered semiconductor Ta2NiS5, revealed through angle-resolved photoemission spectroscopy. We observe a sharp, highly localized in-gap feature that cannot be explained by conventional band-theory. Instead, we argue that it arises from the formation of negative trions, stabilized by surface-induced band bending and the material's quasi-one-dimensional geometry. Unlike excitons, these trions form without optical pumping and persist at equilibrium, marking a rare example of an interaction-driven surface state in a nominally conventional semiconductor. Our findings establish Ta2NiS5 as a unique platform for exploring many-body physics at surfaces and open new avenues for studying and controlling collective excitations in low-dimensional systems.",Materials Science
"Trions, three-body bound states composed of an exciton and an additional charge, are typically fragile and require external excitation to form. Here, we report the spontaneous emergence of a stable trion gas at the surface of the layered semiconductor Ta2NiS5, revealed through angle-resolved photoemission spectroscopy. We observe a sharp, highly localized in-gap feature that cannot be explained by conventional band-theory. Instead, we argue that it arises from the formation of negative trions, stabilized by surface-induced band bending and the material's quasi-one-dimensional geometry. Unlike excitons, these trions form without optical pumping and persist at equilibrium, marking a rare example of an interaction-driven surface state in a nominally conventional semiconductor. Our findings establish Ta2NiS5 as a unique platform for exploring many-body physics at surfaces and open new avenues for studying and controlling collective excitations in low-dimensional systems. [SEP] [HINT] band -> Materials Science (Syns: set, stria, dance orchestra) | optical -> Materials Science (Syns: ocular, opthalmic, optic) | findings -> Neuroscience (Syns: determination, finding)",Materials Science
"Objectives. The aim of the present study was to develop a fully deep learning model to reduce the intra- and inter-operator reproducibility of sector classification systems for predicting unerupted maxillary canine likelihood of impaction. Methods. Three orthodontists (Os) and three general dental practitioners (GDPs) classified the position of unerupted maxillary canines on 306 radiographs (T0) according to the three different sector classification systems (5-, 4-, and 3-sector classification system). The assessment was repeated after four weeks (T1). Intra- and inter-observer agreement were evaluated with Cohen's K and Fleiss K, and between group differences with a z-test. The same radiographs were tested on different artificial intelligence (AI) models, pre-trained on an extended dataset of 1,222 radiographs. The best-performing model was identified based on its sensitivity and precision. Results. The 3-sector system was found to be the classification method with highest reproducibility, with an agreement (Cohen's K values) between observations (T0 versus T1) for each examiner ranged from 0.80 to 0.92, and an overall agreement of 0.85 [95% confidence interval (CI) = 0.83-0.87]. The overall inter-observer agreement (Fleiss K) ranged from 0.69 to 0.7. The educational background did not affect either intra- or inter-observer agreement (p>0.05). DenseNet121 proved to be the best-performing model in allocating impacted canines in the three different classes, with an overall accuracy of 76.8%. Conclusion. AI models can be designed to automatically classify the position of unerupted maxillary canines.",Bioinformatics
"Objectives. The aim of the present study was to develop a fully deep learning model to reduce the intra- and inter-operator reproducibility of sector classification systems for predicting unerupted maxillary canine likelihood of impaction. Methods. Three orthodontists (Os) and three general dental practitioners (GDPs) classified the position of unerupted maxillary canines on 306 radiographs (T0) according to the three different sector classification systems (5-, 4-, and 3-sector classification system). The assessment was repeated after four weeks (T1). Intra- and inter-observer agreement were evaluated with Cohen's K and Fleiss K, and between group differences with a z-test. The same radiographs were tested on different artificial intelligence (AI) models, pre-trained on an extended dataset of 1,222 radiographs. The best-performing model was identified based on its sensitivity and precision. Results. The 3-sector system was found to be the classification method with highest reproducibility, with an agreement (Cohen's K values) between observations (T0 versus T1) for each examiner ranged from 0.80 to 0.92, and an overall agreement of 0.85 [95% confidence interval (CI) = 0.83-0.87]. The overall inter-observer agreement (Fleiss K) ranged from 0.69 to 0.7. The educational background did not affect either intra- or inter-observer agreement (p>0.05). DenseNet121 proved to be the best-performing model in allocating impacted canines in the three different classes, with an overall accuracy of 76.8%. Conclusion. AI models can be designed to automatically classify the position of unerupted maxillary canines. [SEP] [HINT] based -> Bioinformatics (Syns: ground, free-base, base) | learning -> Bioinformatics (Syns: take, teach, acquire) | systems -> Bioinformatics (Syns: organization, organisation, system)",Bioinformatics
"Van der Waals (vdW) crystals offer unique opportunities for modern nanophotonic applications owing to their intrinsic anisotropic nature. While most of them exhibit uniaxial anisotropy arising from weak out-of-plane vdW interaction, some of their representative families also exhibit an in-plane biaxial anisotropy. Among the latter, outstand vdW oxochlorides with in-plane axes of a different physical character (metallic or dielectric). Here, we present an accurate dynamics of dielectric permittivity tensor components of vdW MoOCl2 in the ultraviolet (UV) to visible (Vis) spectral region partly covering near-infrared (NIR). Addressing its enormously anisotropic optical constants, we focus on another hyperbolicity window of vdW MoOCl2 emerging in the UV spectral region that may potentially unlock rich light-matter interaction effects. Furthermore, we propose an approach towards designing nanoscale handedness preserved Vis light circular polarizers based on twisted helical vdW MoOCl2 heterostructures. Our findings display that vdW MoOCl2 provides a highly promising platform not only for hyperbolic, but also for chiral nanophotonic applications.",Materials Science
"Van der Waals (vdW) crystals offer unique opportunities for modern nanophotonic applications owing to their intrinsic anisotropic nature. While most of them exhibit uniaxial anisotropy arising from weak out-of-plane vdW interaction, some of their representative families also exhibit an in-plane biaxial anisotropy. Among the latter, outstand vdW oxochlorides with in-plane axes of a different physical character (metallic or dielectric). Here, we present an accurate dynamics of dielectric permittivity tensor components of vdW MoOCl2 in the ultraviolet (UV) to visible (Vis) spectral region partly covering near-infrared (NIR). Addressing its enormously anisotropic optical constants, we focus on another hyperbolicity window of vdW MoOCl2 emerging in the UV spectral region that may potentially unlock rich light-matter interaction effects. Furthermore, we propose an approach towards designing nanoscale handedness preserved Vis light circular polarizers based on twisted helical vdW MoOCl2 heterostructures. Our findings display that vdW MoOCl2 provides a highly promising platform not only for hyperbolic, but also for chiral nanophotonic applications. [SEP] [HINT] based -> Bioinformatics (Syns: ground, free-base, base) | different -> Neuroscience (Syns: unlike, dissimilar) | optical -> Materials Science (Syns: ocular, opthalmic, optic)",Materials Science
"The Poisson Generalized Linear Model (GLM) is a foundational tool for analyzing neural spike train data. However, standard implementations rely on discretizing spike times into binned count data, limiting temporal resolution and scalability. Here, we develop Monte Carlo (MC) methods and polynomial approximations (PA) to the continuous-time analog of these models, and show them to be advantageous over their discrete-time counterparts. Further, we propose using a set of exponentially scaled Laguerre polynomials as an orthogonal temporal basis, which improves filter identification and yields closed-form integral solutions under the polynomial approximation. Applied to both synthetic and real spike-time data from rodent hippocampus, our methods demonstrate superior accuracy and scalability compared to traditional binned GLMs, enabling functional connectivity inference in large-scale neural recordings that are temporally precise on the order of synaptic dynamical timescales and in agreement with known anatomical properties of hippocampal subregions. We provide open-source implementations of both MC and PA estimators, optimized for GPU acceleration, to facilitate adoption in the neuroscience community.",Neuroscience
"The Poisson Generalized Linear Model (GLM) is a foundational tool for analyzing neural spike train data. However, standard implementations rely on discretizing spike times into binned count data, limiting temporal resolution and scalability. Here, we develop Monte Carlo (MC) methods and polynomial approximations (PA) to the continuous-time analog of these models, and show them to be advantageous over their discrete-time counterparts. Further, we propose using a set of exponentially scaled Laguerre polynomials as an orthogonal temporal basis, which improves filter identification and yields closed-form integral solutions under the polynomial approximation. Applied to both synthetic and real spike-time data from rodent hippocampus, our methods demonstrate superior accuracy and scalability compared to traditional binned GLMs, enabling functional connectivity inference in large-scale neural recordings that are temporally precise on the order of synaptic dynamical timescales and in agreement with known anatomical properties of hippocampal subregions. We provide open-source implementations of both MC and PA estimators, optimized for GPU acceleration, to facilitate adoption in the neuroscience community. [SEP] [HINT] connectivity -> Neuroscience (Syns: ) | functional -> Neuroscience (Syns: working, usable, running) | order -> Materials Science (Syns: enjoin, dictate, social club)",Neuroscience
"Normative and task-driven theories offer powerful top-down explanations for biological systems, yet the goals of quantitatively arbitrating between competing theories, and utilizing them as inductive biases to improve data-driven fits of real biological datasets are prohibitively laborious, and often impossible. To this end, we introduce a Bayesian meta-learning framework designed to automatically convert raw functional predictions from normative theories into tractable probabilistic models. We employ adaptive deep kernel Gaussian processes, meta-learning a kernel on synthetic data generated from a normative theory. This Theory-Informed Kernel specifies a probabilistic model representing the theory predictions -- usable for both fitting data and rigorously validating the theory. As a demonstration, we apply our framework to the early visual system, using efficient coding as our normative theory. We show improved response prediction accuracy in ex vivo recordings of mouse retinal ganglion cells stimulated by natural scenes compared to conventional data-driven baselines, while providing well-calibrated uncertainty estimates and interpretable representations. Using exact Bayesian model selection, we also show that our informed kernel can accurately infer the degree of theory-match from data, confirming faithful encapsulation of theory structure. This work provides a more general, scalable, and automated approach for integrating theoretical knowledge into data-driven scientific inquiry in neuroscience and beyond.",Neuroscience
"Normative and task-driven theories offer powerful top-down explanations for biological systems, yet the goals of quantitatively arbitrating between competing theories, and utilizing them as inductive biases to improve data-driven fits of real biological datasets are prohibitively laborious, and often impossible. To this end, we introduce a Bayesian meta-learning framework designed to automatically convert raw functional predictions from normative theories into tractable probabilistic models. We employ adaptive deep kernel Gaussian processes, meta-learning a kernel on synthetic data generated from a normative theory. This Theory-Informed Kernel specifies a probabilistic model representing the theory predictions -- usable for both fitting data and rigorously validating the theory. As a demonstration, we apply our framework to the early visual system, using efficient coding as our normative theory. We show improved response prediction accuracy in ex vivo recordings of mouse retinal ganglion cells stimulated by natural scenes compared to conventional data-driven baselines, while providing well-calibrated uncertainty estimates and interpretable representations. Using exact Bayesian model selection, we also show that our informed kernel can accurately infer the degree of theory-match from data, confirming faithful encapsulation of theory structure. This work provides a more general, scalable, and automated approach for integrating theoretical knowledge into data-driven scientific inquiry in neuroscience and beyond. [SEP] [HINT] functional -> Neuroscience (Syns: working, usable, running) | datasets -> Bioinformatics (Syns: ) | work -> Bioinformatics (Syns: work out, process, bring)",Neuroscience
"Protein-protein docking tools help in studying interactions between proteins, and are essential for drug, vaccine, and therapeutic development. However, the accuracy of a docking tool depends on a robust scoring function that can reliably differentiate between native and non-native complexes. PIsToN is a state-of-the-art deep learning-based scoring function that uses Vision Transformers in its architecture. Recently, the Mamba architecture has demonstrated exceptional performance in both natural language processing and computer vision, often outperforming Transformer-based models in their domains. In this study, we introduce PUMBA (Protein-protein interface evaluation with Vision Mamba), which improves PIsToN by replacing its Vision Transformer backbone with Vision Mamba. This change allows us to leverage Mamba's efficient long-range sequence modeling for sequences of image patches. As a result, the model's ability to capture both global and local patterns in protein-protein interface features is significantly improved. Evaluation on several widely-used, large-scale public datasets demonstrates that PUMBA consistently outperforms its original Transformer-based predecessor, PIsToN.",Bioinformatics
"Protein-protein docking tools help in studying interactions between proteins, and are essential for drug, vaccine, and therapeutic development. However, the accuracy of a docking tool depends on a robust scoring function that can reliably differentiate between native and non-native complexes. PIsToN is a state-of-the-art deep learning-based scoring function that uses Vision Transformers in its architecture. Recently, the Mamba architecture has demonstrated exceptional performance in both natural language processing and computer vision, often outperforming Transformer-based models in their domains. In this study, we introduce PUMBA (Protein-protein interface evaluation with Vision Mamba), which improves PIsToN by replacing its Vision Transformer backbone with Vision Mamba. This change allows us to leverage Mamba's efficient long-range sequence modeling for sequences of image patches. As a result, the model's ability to capture both global and local patterns in protein-protein interface features is significantly improved. Evaluation on several widely-used, large-scale public datasets demonstrates that PUMBA consistently outperforms its original Transformer-based predecessor, PIsToN. [SEP] [HINT] language -> Neuroscience (Syns: linguistic process, linguistic communication, spoken communication) | features -> Bioinformatics (Syns: characteristic, lineament, feature of speech) | processing -> Neuroscience (Syns: work, process, march)",Bioinformatics
"Bioinformatics tools are essential for complex computational biology tasks, yet their integration with emerging AI-agent frameworks is hindered by incompatible interfaces, heterogeneous input-output formats, and inconsistent parameter conventions. The Model Context Protocol (MCP) provides a standardized framework for tool-AI communication, but manually converting hundreds of existing and rapidly growing specialized bioinformatics tools into MCP-compliant servers is labor-intensive and unsustainable. Here, we present BioinfoMCP, a unified platform comprising two components: BioinfoMCP Converter, which automatically generates robust MCP servers from tool documentation using large language models, and BioinfoMCP Benchmark, which systematically validates the reliability and versatility of converted tools across diverse computational tasks. We present a platform of 38 MCP-converted bioinformatics tools, extensively validated to show that 94.7% successfully executed complex workflows across three widely used AI-agent platforms. By removing technical barriers to AI automation, BioinfoMCP enables natural-language interaction with sophisticated bioinformatics analyses without requiring extensive programming expertise, offering a scalable path to intelligent, interoperable computational biology.",Bioinformatics
"Bioinformatics tools are essential for complex computational biology tasks, yet their integration with emerging AI-agent frameworks is hindered by incompatible interfaces, heterogeneous input-output formats, and inconsistent parameter conventions. The Model Context Protocol (MCP) provides a standardized framework for tool-AI communication, but manually converting hundreds of existing and rapidly growing specialized bioinformatics tools into MCP-compliant servers is labor-intensive and unsustainable. Here, we present BioinfoMCP, a unified platform comprising two components: BioinfoMCP Converter, which automatically generates robust MCP servers from tool documentation using large language models, and BioinfoMCP Benchmark, which systematically validates the reliability and versatility of converted tools across diverse computational tasks. We present a platform of 38 MCP-converted bioinformatics tools, extensively validated to show that 94.7% successfully executed complex workflows across three widely used AI-agent platforms. By removing technical barriers to AI automation, BioinfoMCP enables natural-language interaction with sophisticated bioinformatics analyses without requiring extensive programming expertise, offering a scalable path to intelligent, interoperable computational biology. [SEP] [HINT] used -> Bioinformatics (Syns: utilize, ill-used, apply) | language -> Neuroscience (Syns: linguistic process, linguistic communication, spoken communication) | computational -> Neuroscience (Syns: )",Bioinformatics
"An accurate prediction of protein-nucleic acid binding affinity is vital for deciphering genomic processes, yet existing approaches often struggle in reconciling high accuracy with interpretability and computational efficiency. In this study, we introduce commutative algebra prediction (CAP), which couples persistent Stanley-Reisner theory with advanced sequence embedding for predicting protein-nucleic acid binding affinities. CAP encodes proteins through transformer-learned embeddings that retain long-range evolutionary context and represents DNA and RNA with $\textit{k}$-mer algebra embeddings derived from persistent facet ideals, which capture fine-scale nucleotide geometry. We demonstrate that CAP surpasses the SVSBI protein-nucleic acid benchmark and, in a further test, maintains reasonable performance on newly curated protein-RNA and protein-nucleic acid datasets. Leveraging only primary sequences, CAP generalizes to any protein-nucleic acid pair with minimal preprocessing, enabling genome-scale analyses without 3D structural data and promising faster virtual screening for drug discovery and protein engineering.",Bioinformatics
"An accurate prediction of protein-nucleic acid binding affinity is vital for deciphering genomic processes, yet existing approaches often struggle in reconciling high accuracy with interpretability and computational efficiency. In this study, we introduce commutative algebra prediction (CAP), which couples persistent Stanley-Reisner theory with advanced sequence embedding for predicting protein-nucleic acid binding affinities. CAP encodes proteins through transformer-learned embeddings that retain long-range evolutionary context and represents DNA and RNA with $\textit{k}$-mer algebra embeddings derived from persistent facet ideals, which capture fine-scale nucleotide geometry. We demonstrate that CAP surpasses the SVSBI protein-nucleic acid benchmark and, in a further test, maintains reasonable performance on newly curated protein-RNA and protein-nucleic acid datasets. Leveraging only primary sequences, CAP generalizes to any protein-nucleic acid pair with minimal preprocessing, enabling genome-scale analyses without 3D structural data and promising faster virtual screening for drug discovery and protein engineering. [SEP] [HINT] computational -> Neuroscience (Syns: ) | performance -> Bioinformatics (Syns: functioning, operation, carrying out) | existing -> Bioinformatics (Syns: subsist, existent, survive)",Bioinformatics
"Layered perovskite lithium yttrium titanate ($\rm LiYTiO_4$) has recently emerged as a promising low-potential, ultrahigh-rate intercalation-type anode material for lithium-ion batteries; however, its lattice dynamics and thermal transport properties remain poorly understood, limiting a complete evaluation of its practical potential. Here, we combine experimental measurements with theoretical modeling to systematically investigate the anharmonic lattice dynamics and heat transport in $\rm LiYTiO_4$. We employ a neural evolution potential (NEP)-based framework that integrates the temperature-dependent effective potential method with the Wigner thermal transport (WTT) formalism, explicitly including both diagonal and off-diagonal terms of the heat-flux operator. Zero-temperature phonon calculations reveal dynamical instabilities associated with $\rm TiO_6$ octahedral rotation, which are stabilized at finite temperatures through anharmonic renormalization. Using the WTT approach with contributions from phonon propagation and coherence contributions, we predict a room-temperature lattice thermal conductivity ($κ_{\rm L}$) of 3.8 $\rm Wm^{-1}K^{-1}$ averaged over all crystal orientations, in close agreement with the measured value of 3.2 \pm 0.08 $\rm Wm^{-1}K^{-1}$ for polycrystalline samples. To further examine the possible influence of ionic motion on high-temperature thermal transport, we compute $κ_{\rm L}$ using a Green-Kubo equilibrium molecular dynamics approach based on the same NEP, which yields consistent results with both experiment and WTT predictions, confirming the negligible role of Li-ion mobility in heat conduction. Our study not only identifies the ultralow thermal conductivity of $\rm LiYTiO_4$ as a key limitation for its practical application but also establishes a reliable computational framework for studying thermal properties in battery materials.",Materials Science
"Layered perovskite lithium yttrium titanate ($\rm LiYTiO_4$) has recently emerged as a promising low-potential, ultrahigh-rate intercalation-type anode material for lithium-ion batteries; however, its lattice dynamics and thermal transport properties remain poorly understood, limiting a complete evaluation of its practical potential. Here, we combine experimental measurements with theoretical modeling to systematically investigate the anharmonic lattice dynamics and heat transport in $\rm LiYTiO_4$. We employ a neural evolution potential (NEP)-based framework that integrates the temperature-dependent effective potential method with the Wigner thermal transport (WTT) formalism, explicitly including both diagonal and off-diagonal terms of the heat-flux operator. Zero-temperature phonon calculations reveal dynamical instabilities associated with $\rm TiO_6$ octahedral rotation, which are stabilized at finite temperatures through anharmonic renormalization. Using the WTT approach with contributions from phonon propagation and coherence contributions, we predict a room-temperature lattice thermal conductivity ($κ_{\rm L}$) of 3.8 $\rm Wm^{-1}K^{-1}$ averaged over all crystal orientations, in close agreement with the measured value of 3.2 \pm 0.08 $\rm Wm^{-1}K^{-1}$ for polycrystalline samples. To further examine the possible influence of ionic motion on high-temperature thermal transport, we compute $κ_{\rm L}$ using a Green-Kubo equilibrium molecular dynamics approach based on the same NEP, which yields consistent results with both experiment and WTT predictions, confirming the negligible role of Li-ion mobility in heat conduction. Our study not only identifies the ultralow thermal conductivity of $\rm LiYTiO_4$ as a key limitation for its practical application but also establishes a reliable computational framework for studying thermal properties in battery materials. [SEP] [HINT] phonon -> Materials Science (Syns: ) | based -> Bioinformatics (Syns: ground, free-base, base) | computational -> Neuroscience (Syns: )",Materials Science
"Scalable quantum computing currently requires a large array of qubit integration, but present two-dimensional interconnects face challenges such as wiring congestion, electromagnetic interference, and limited cryogenic space. To overcome this challenge, implementing three-dimensional (3D) vertical architectures becomes crucial. Niobium (Nb), due to its excellent superconducting characteristics and strong fabrication process compatibility, stands out as a prime material choice. The main challenge in Nb-Nb bonding is the presence of an oxide layer at the interface, even after post-bonding annealing across various bonding methods. The native Nb oxide forms rapidly in air, creating a resistive barrier to supercurrent flow and introducing two-level system losses that degrade qubit coherence while increasing the overall thermal budget. These issues show the need for effective surface engineering to suppress oxidation during bonding. This study introduces an ultrathin gold (Au) capping layer as a passivation strategy to prevent oxygen incorporation at the Nb surface. This approach enables low-temperature Nb-Nb thermocompression bonding at 350 °C under a reduced bonding pressure of 0.495 MPa. Detailed microstructural and interfacial analyses confirm that Au passivation effectively suppresses oxide formation and hence enhances bonding uniformity and strength with keeping the superconductivity, establishing a robust route toward low-temperature, low-pressure Nb-Nb bonding for scalable 3D superconducting quantum computing architectures.",Materials Science
"Scalable quantum computing currently requires a large array of qubit integration, but present two-dimensional interconnects face challenges such as wiring congestion, electromagnetic interference, and limited cryogenic space. To overcome this challenge, implementing three-dimensional (3D) vertical architectures becomes crucial. Niobium (Nb), due to its excellent superconducting characteristics and strong fabrication process compatibility, stands out as a prime material choice. The main challenge in Nb-Nb bonding is the presence of an oxide layer at the interface, even after post-bonding annealing across various bonding methods. The native Nb oxide forms rapidly in air, creating a resistive barrier to supercurrent flow and introducing two-level system losses that degrade qubit coherence while increasing the overall thermal budget. These issues show the need for effective surface engineering to suppress oxidation during bonding. This study introduces an ultrathin gold (Au) capping layer as a passivation strategy to prevent oxygen incorporation at the Nb surface. This approach enables low-temperature Nb-Nb thermocompression bonding at 350 °C under a reduced bonding pressure of 0.495 MPa. Detailed microstructural and interfacial analyses confirm that Au passivation effectively suppresses oxide formation and hence enhances bonding uniformity and strength with keeping the superconductivity, establishing a robust route toward low-temperature, low-pressure Nb-Nb bonding for scalable 3D superconducting quantum computing architectures. [SEP] [HINT] thermal -> Materials Science (Syns: thermic, caloric) | material -> Materials Science (Syns: stuff, cloth, real) | study -> Bioinformatics (Syns: sketch, meditate, take)",Materials Science
"We explore surface alignment and edge dislocations in the recently discovered twist-bend ferroelectric nematic, NTBF, in which the vector of spontaneous polarization follows an oblique helicoidal trajectory around a polar twist-bend axis. In a planar cell, the polar axis aligns at some angle to the rubbing direction to mitigate surface electric charge. We demonstrate that the pseudolayers in planar cells form chevron defects, a hallmark defect of one-dimensionally positionally ordered phases, such as smectic A and smectic C. The polar character of the twist-bend axis prevents the cores of NTBF edge dislocations from splitting into semi-integer disclinations, in stark contrast to dislocations in paraelectric and ferroelectric chiral nematics. The tilt of pseudolayers around the defect core allows us to estimate the elastic penetration length as being close to the pitch of NTBF. Compression/dilation stresses around the core modify the heliconical tilt angle of molecules as evidenced by a substantial variation in local birefringence. The climb of dislocations exhibits high mobility, allowing the system to equilibrate the temperature-dependent pitch. The uncovered properties facilitate the development of NTBF materials for electro-optical applications, such as electrically controlled diffraction lattices and structural colors.",Materials Science
"We explore surface alignment and edge dislocations in the recently discovered twist-bend ferroelectric nematic, NTBF, in which the vector of spontaneous polarization follows an oblique helicoidal trajectory around a polar twist-bend axis. In a planar cell, the polar axis aligns at some angle to the rubbing direction to mitigate surface electric charge. We demonstrate that the pseudolayers in planar cells form chevron defects, a hallmark defect of one-dimensionally positionally ordered phases, such as smectic A and smectic C. The polar character of the twist-bend axis prevents the cores of NTBF edge dislocations from splitting into semi-integer disclinations, in stark contrast to dislocations in paraelectric and ferroelectric chiral nematics. The tilt of pseudolayers around the defect core allows us to estimate the elastic penetration length as being close to the pitch of NTBF. Compression/dilation stresses around the core modify the heliconical tilt angle of molecules as evidenced by a substantial variation in local birefringence. The climb of dislocations exhibits high mobility, allowing the system to equilibrate the temperature-dependent pitch. The uncovered properties facilitate the development of NTBF materials for electro-optical applications, such as electrically controlled diffraction lattices and structural colors. [SEP] [HINT] defect -> Materials Science (Syns: mar, shortcoming, fault) | materials -> Materials Science (Syns: stuff, cloth, material) | structural -> Materials Science (Syns: geomorphologic, morphologic, morphological)",Materials Science
"Early identification of sensitive cancer cell lines is essential for accelerating biomarker discovery and elucidating drug mechanism of action. Given the efficiency and low cost of small-scale drug screens relative to extensive omics profiling, we compared drug-response panel (DRP) descriptors against omics features for predictive capacity using gradient boosting tree models across the GDSC and CCLE drug response datasets. DRP descriptors consistently outperformed omics data across key performance metrics, with variable performance across different drugs. Using complementary explainability approaches, we confirmed known MAPK-inhibitor sensitivity signatures, and identified novel potential biomarker candidates for MEK1/2 and BTK/MNK inhibitors. Lastly, to demonstrate the utility of this approach in distinguishing phenotypes, we applied our models to the breast cancer line MCF7 versus the non-tumorigenic MCF10A, and successfully identified compounds that selectively inhibit MCF7 while sparing the non-tumorigenic MCF10A. This methodology, developed using focused drug and cell line panels, supports early-stage drug development by facilitating rational cell line selection and compound prioritisation, enabling more efficient biomarker identification and candidate assessment.",Bioinformatics
"Early identification of sensitive cancer cell lines is essential for accelerating biomarker discovery and elucidating drug mechanism of action. Given the efficiency and low cost of small-scale drug screens relative to extensive omics profiling, we compared drug-response panel (DRP) descriptors against omics features for predictive capacity using gradient boosting tree models across the GDSC and CCLE drug response datasets. DRP descriptors consistently outperformed omics data across key performance metrics, with variable performance across different drugs. Using complementary explainability approaches, we confirmed known MAPK-inhibitor sensitivity signatures, and identified novel potential biomarker candidates for MEK1/2 and BTK/MNK inhibitors. Lastly, to demonstrate the utility of this approach in distinguishing phenotypes, we applied our models to the breast cancer line MCF7 versus the non-tumorigenic MCF10A, and successfully identified compounds that selectively inhibit MCF7 while sparing the non-tumorigenic MCF10A. This methodology, developed using focused drug and cell line panels, supports early-stage drug development by facilitating rational cell line selection and compound prioritisation, enabling more efficient biomarker identification and candidate assessment. [SEP] [HINT] low -> Materials Science (Syns: low-spirited, scurvy, depressed) | features -> Bioinformatics (Syns: characteristic, lineament, feature of speech) | performance -> Bioinformatics (Syns: functioning, operation, carrying out)",Bioinformatics
"We present an approach to the molecular-beam epitaxy of high-Q planar GaAs-based microcavities in which the AlGaAs high-index layers of the distributed Bragg reflectors (DBRs) are replaced by short-period GaAs/AlAs superlattices (digital alloys) with similar optical properties. This design enables a significant reduction of interface roughness, precise control of the quarter-wavelength optical thickness and the effective Al content, suppression of the propagation of structural defects, and efficient tuning of intrinsic absorption at the polariton emission wavelength via optimization of the superlattice parameters.   Using this approach, we fabricate a microcavity with a low polariton-lasing threshold of approximately 200 W/cm$^2$ and a high experimental quality factor of about 5.4 x $10^4$. This value exceeds by almost a factor of two the theoretical estimate obtained within an equivalent ternary-alloy model. We demonstrate that accurate modeling of the stop-band characteristics and the Q factor requires incorporating the modified electronic density of states in the superlattice, including quantum-confinement and excitonic effects.",Materials Science
"We present an approach to the molecular-beam epitaxy of high-Q planar GaAs-based microcavities in which the AlGaAs high-index layers of the distributed Bragg reflectors (DBRs) are replaced by short-period GaAs/AlAs superlattices (digital alloys) with similar optical properties. This design enables a significant reduction of interface roughness, precise control of the quarter-wavelength optical thickness and the effective Al content, suppression of the propagation of structural defects, and efficient tuning of intrinsic absorption at the polariton emission wavelength via optimization of the superlattice parameters.   Using this approach, we fabricate a microcavity with a low polariton-lasing threshold of approximately 200 W/cm$^2$ and a high experimental quality factor of about 5.4 x $10^4$. This value exceeds by almost a factor of two the theoretical estimate obtained within an equivalent ternary-alloy model. We demonstrate that accurate modeling of the stop-band characteristics and the Q factor requires incorporating the modified electronic density of states in the superlattice, including quantum-confinement and excitonic effects. [SEP] [HINT] low -> Materials Science (Syns: low-spirited, scurvy, depressed) | electronic -> Materials Science (Syns: ) | quality -> Bioinformatics (Syns: lineament, tone, calibre)",Materials Science
"Early detection of malignant lung nodules is critical, but its dependence on size and growth in screening inherently delays diagnosis. We present an AI system that redefines lung cancer screening by performing both detection and malignancy diagnosis directly at the nodule level on low-dose CT scans. To address limitations in dataset scale and explainability, we designed an ensemble of shallow deep learning and feature-based specialized models. Trained and evaluated on 25,709 scans with 69,449 annotated nodules, the system outperforms radiologists, Lung-RADS, and leading AI models (Sybil, Brock, Google, Kaggle). It achieves an area under the receiver operating characteristic curve (AUC) of 0.98 internally and 0.945 on an independent cohort. With 0.5 false positives per scan at 99.3\% sensitivity, it addresses key barriers to AI adoption. Critically, it outperforms radiologists across all nodule sizes and stages, excelling in stage 1 cancers, and all growth-based metrics, including the least accurate: Volume-Doubling Time. It also surpasses radiologists by up to one year in diagnosing indeterminate and slow-growing nodules.",Neuroscience
"Early detection of malignant lung nodules is critical, but its dependence on size and growth in screening inherently delays diagnosis. We present an AI system that redefines lung cancer screening by performing both detection and malignancy diagnosis directly at the nodule level on low-dose CT scans. To address limitations in dataset scale and explainability, we designed an ensemble of shallow deep learning and feature-based specialized models. Trained and evaluated on 25,709 scans with 69,449 annotated nodules, the system outperforms radiologists, Lung-RADS, and leading AI models (Sybil, Brock, Google, Kaggle). It achieves an area under the receiver operating characteristic curve (AUC) of 0.98 internally and 0.945 on an independent cohort. With 0.5 false positives per scan at 99.3\% sensitivity, it addresses key barriers to AI adoption. Critically, it outperforms radiologists across all nodule sizes and stages, excelling in stage 1 cancers, and all growth-based metrics, including the least accurate: Volume-Doubling Time. It also surpasses radiologists by up to one year in diagnosing indeterminate and slow-growing nodules. [SEP] [HINT] learning -> Bioinformatics (Syns: take, teach, acquire) | including -> Bioinformatics (Syns: admit, include, let in) | scale -> Bioinformatics (Syns: shell, graduated table, plate)",Neuroscience
"The Fe-Si-O ternary system, central to modeling the interiors of terrestrial planets, remains poorly constrained at Terapascal (TPa) pressures characteristic of super-Earth mantles. Using a combination of crystal-structure prediction and ab initio calculations, we identify three ternary compounds stable near 1 TPa: P3 FeSiO4, P3 Fe4Si5O18, and P-3 FeSi2O6. The first two phases are thermodynamically stable at low temperatures, whereas P-3 FeSi2O6 becomes favored above approximately 2000 K. All three are metallic, paramagnetic, and adopt pseudo-binary arrangements derived from the FeO2 and SiO2 end-member structures. Their crystal structures emerge through substitutions of Fe for Si in Fe2P-type SiO2 or of Si for Fe in Pnma-type FeO2, the stable elemental oxides at ~1 TPa. This structural continuity suggests that Fe preferentially substitutes for Si in the canonical Mg-silicates expected at TPa pressures. Notably, these new pseudo-binaries accommodate Fe in six- and nine-fold coordination, in contrast to the eight-fold cubic coordination found in FeO at similar pressures. The thermodynamic conditions under which these phases form from FeO2 and SiO2 mixtures are clarified through quasi-harmonic free energy calculations. Their prevalence in super-Earth's mantles is found to depend on the abundance of FeO2, which may be generated by the dehydrogenation of FeOOH goethite as in the Earth's deep mantle. The existence of these phases implies a markedly different pattern of Fe incorporation in high-pressure Mg-silicates at TPa pressures, compared with the behavior inferred at the GPa pressures of the Earth's mantle.",Materials Science
"The Fe-Si-O ternary system, central to modeling the interiors of terrestrial planets, remains poorly constrained at Terapascal (TPa) pressures characteristic of super-Earth mantles. Using a combination of crystal-structure prediction and ab initio calculations, we identify three ternary compounds stable near 1 TPa: P3 FeSiO4, P3 Fe4Si5O18, and P-3 FeSi2O6. The first two phases are thermodynamically stable at low temperatures, whereas P-3 FeSi2O6 becomes favored above approximately 2000 K. All three are metallic, paramagnetic, and adopt pseudo-binary arrangements derived from the FeO2 and SiO2 end-member structures. Their crystal structures emerge through substitutions of Fe for Si in Fe2P-type SiO2 or of Si for Fe in Pnma-type FeO2, the stable elemental oxides at ~1 TPa. This structural continuity suggests that Fe preferentially substitutes for Si in the canonical Mg-silicates expected at TPa pressures. Notably, these new pseudo-binaries accommodate Fe in six- and nine-fold coordination, in contrast to the eight-fold cubic coordination found in FeO at similar pressures. The thermodynamic conditions under which these phases form from FeO2 and SiO2 mixtures are clarified through quasi-harmonic free energy calculations. Their prevalence in super-Earth's mantles is found to depend on the abundance of FeO2, which may be generated by the dehydrogenation of FeOOH goethite as in the Earth's deep mantle. The existence of these phases implies a markedly different pattern of Fe incorporation in high-pressure Mg-silicates at TPa pressures, compared with the behavior inferred at the GPa pressures of the Earth's mantle. [SEP] [HINT] low -> Materials Science (Syns: low-spirited, scurvy, depressed) | different -> Neuroscience (Syns: unlike, dissimilar) | crystal -> Materials Science (Syns: crystallization, quartz, lechatelierite)",Materials Science
"Predicting interspecies interactions is a key challenge in microbial ecology, as these interactions are critical to determining the structure and activity of microbial communities. In this work, we used data on monoculture growth capabilities, interactions with other species, and phylogeny to predict a negative or positive effect of interactions. More precisely, we used one of the largest available pairwise interaction datasets to train our models, comprising over 7,500 interactions be- tween 20 species from two taxonomic groups co-cultured under 40 distinct carbon conditions, with a primary focus on the work of Nestor et al.[28 ]. In this work, we propose Graph Neural Networks (GNNs) as a powerful classifier to predict the direction of the effect. We construct edge-graphs of pairwise microbial interactions in order to leverage shared information across individual co-culture experiments, and use GNNs to predict modes of interaction. Our model can not only predict binary interactions (positive/negative) but also classify more complex interaction types such as mutualism, competition, and parasitism. Our initial results were encouraging, achieving an F1-score of 80.44%. This significantly outperforms comparable methods in the literature, including conventional Extreme Gradient Boosting (XGBoost) models, which reported an F1-score of 72.76%.",Bioinformatics
"Predicting interspecies interactions is a key challenge in microbial ecology, as these interactions are critical to determining the structure and activity of microbial communities. In this work, we used data on monoculture growth capabilities, interactions with other species, and phylogeny to predict a negative or positive effect of interactions. More precisely, we used one of the largest available pairwise interaction datasets to train our models, comprising over 7,500 interactions be- tween 20 species from two taxonomic groups co-cultured under 40 distinct carbon conditions, with a primary focus on the work of Nestor et al.[28 ]. In this work, we propose Graph Neural Networks (GNNs) as a powerful classifier to predict the direction of the effect. We construct edge-graphs of pairwise microbial interactions in order to leverage shared information across individual co-culture experiments, and use GNNs to predict modes of interaction. Our model can not only predict binary interactions (positive/negative) but also classify more complex interaction types such as mutualism, competition, and parasitism. Our initial results were encouraging, achieving an F1-score of 80.44%. This significantly outperforms comparable methods in the literature, including conventional Extreme Gradient Boosting (XGBoost) models, which reported an F1-score of 72.76%. [SEP] [HINT] used -> Bioinformatics (Syns: utilize, ill-used, apply) | networks -> Neuroscience (Syns: network, meshwork, electronic network) | structure -> Bioinformatics (Syns: social system, complex body part, social structure)",Bioinformatics
"Spin-torque and spin-Hall oscillators (SHOs) have emerged as promising candidates for building blocks in neuromorphic computing due to their ability to synchronize mutually, a process that can be mediated by propagating spin waves. We demonstrate a SHO that takes advantage of a low-damping magnetic garnet with dominant perpendicular magnetic anisotropy (PMA), namely gallium-substituted yttrium-iron-garnet (Ga:YIG). In-plane magnetized Ga:YIG allows for the operation at a high efficiency level while also enabling resonant spin-wave emission. A nonlinear self-localization of the excitation is avoided by exploiting the positive nonlinear frequency shift, which facilitates a current-controlled frequency of the emitted spin waves. Via micro-focused Brillouin light scattering spectroscopy, we investigate the properties of the local auto-oscillation and its spin-wave emission. Multiple modes are excited and compete internally, with two propagating modes detected up to distances larger than \SI{10}{\micro\meter}. Their frequencies combine to an extended frequency bandwidth of approximately \SI{1.6}{\giga\hertz}. The experimentally observed two-mode system and its transition to a single mode at higher currents are reproduced via micromagnetic simulations, which account for spatial variation of the PMA arising due to the microstructures on Ga:YIG. Our results propose a promising platform for hosting SHOs, interconnected via propagating spin waves with particular relevance to neuromorphic computing.",Materials Science
"Spin-torque and spin-Hall oscillators (SHOs) have emerged as promising candidates for building blocks in neuromorphic computing due to their ability to synchronize mutually, a process that can be mediated by propagating spin waves. We demonstrate a SHO that takes advantage of a low-damping magnetic garnet with dominant perpendicular magnetic anisotropy (PMA), namely gallium-substituted yttrium-iron-garnet (Ga:YIG). In-plane magnetized Ga:YIG allows for the operation at a high efficiency level while also enabling resonant spin-wave emission. A nonlinear self-localization of the excitation is avoided by exploiting the positive nonlinear frequency shift, which facilitates a current-controlled frequency of the emitted spin waves. Via micro-focused Brillouin light scattering spectroscopy, we investigate the properties of the local auto-oscillation and its spin-wave emission. Multiple modes are excited and compete internally, with two propagating modes detected up to distances larger than \SI{10}{\micro\meter}. Their frequencies combine to an extended frequency bandwidth of approximately \SI{1.6}{\giga\hertz}. The experimentally observed two-mode system and its transition to a single mode at higher currents are reproduced via micromagnetic simulations, which account for spatial variation of the PMA arising due to the microstructures on Ga:YIG. Our results propose a promising platform for hosting SHOs, interconnected via propagating spin waves with particular relevance to neuromorphic computing. [SEP] [HINT] transition -> Materials Science (Syns: passage, modulation, changeover) | spin -> Materials Science (Syns: twisting, whirl, tailspin) | results -> Bioinformatics (Syns: final result, consequence, resultant role)",Materials Science
"Despite rapid advances in molecular and materials machine learning, most models still lack physical transferability: they fit correlations across whole molecules or crystals rather than learning the quantum interactions between atomic pairs. Yet bonding, charge redistribution, orbital hybridization, and electronic coupling all emerge from these two-body interactions that define local quantum fields in many-body systems. We introduce QuantumCanvas, a large-scale multimodal benchmark that treats two-body quantum systems as foundational units of matter. The dataset spans 2,850 element-element pairs, each annotated with 18 electronic, thermodynamic, and geometric properties and paired with ten-channel image representations derived from l- and m-resolved orbital densities, angular field transforms, co-occupancy maps, and charge-density projections. These physically grounded images encode spatial, angular, and electrostatic symmetries without explicit coordinates, providing an interpretable visual modality for quantum learning. Benchmarking eight architectures across 18 targets, we report mean absolute errors of 0.201 eV on energy gap using GATv2, 0.265 eV on HOMO and 0.274 eV on LUMO using EGNN. For energy-related quantities, DimeNet attains 2.27 eV total-energy MAE and 0.132 eV repulsive-energy MAE, while a multimodal fusion model achieves a 2.15 eV Mermin free-energy MAE. Pretraining on QuantumCanvas further improves convergence stability and generalization when fine-tuned on larger datasets such as QM9, MD17, and CrysMTM. By unifying orbital physics with vision-based representation learning, QuantumCanvas provides a principled and interpretable basis for learning transferable quantum interactions through coupled visual and numerical modalities. Dataset and model implementations are available at https://github.com/KurbanIntelligenceLab/QuantumCanvas.",Materials Science
"Despite rapid advances in molecular and materials machine learning, most models still lack physical transferability: they fit correlations across whole molecules or crystals rather than learning the quantum interactions between atomic pairs. Yet bonding, charge redistribution, orbital hybridization, and electronic coupling all emerge from these two-body interactions that define local quantum fields in many-body systems. We introduce QuantumCanvas, a large-scale multimodal benchmark that treats two-body quantum systems as foundational units of matter. The dataset spans 2,850 element-element pairs, each annotated with 18 electronic, thermodynamic, and geometric properties and paired with ten-channel image representations derived from l- and m-resolved orbital densities, angular field transforms, co-occupancy maps, and charge-density projections. These physically grounded images encode spatial, angular, and electrostatic symmetries without explicit coordinates, providing an interpretable visual modality for quantum learning. Benchmarking eight architectures across 18 targets, we report mean absolute errors of 0.201 eV on energy gap using GATv2, 0.265 eV on HOMO and 0.274 eV on LUMO using EGNN. For energy-related quantities, DimeNet attains 2.27 eV total-energy MAE and 0.132 eV repulsive-energy MAE, while a multimodal fusion model achieves a 2.15 eV Mermin free-energy MAE. Pretraining on QuantumCanvas further improves convergence stability and generalization when fine-tuned on larger datasets such as QM9, MD17, and CrysMTM. By unifying orbital physics with vision-based representation learning, QuantumCanvas provides a principled and interpretable basis for learning transferable quantum interactions through coupled visual and numerical modalities. Dataset and model implementations are available at https://github.com/KurbanIntelligenceLab/QuantumCanvas. [SEP] [HINT] field -> Materials Science (Syns: field of honor, line of business, orbit) | learning -> Bioinformatics (Syns: take, teach, acquire) | charge -> Materials Science (Syns: tear, bearing, burster)",Materials Science
"Nitrogen, the most abundant element in Earth's atmosphere, exists as a diatomic gas under standard temperature and pressure. In the two-dimensional (2D) limit, atomically thin nitrogen, termed nitrogene, has been theoretically predicted to form crystalline materials with various polymorphic configurations, exhibiting diverse chemical and physical properties. However, the synthesis of nitrogene has remained elusive due to the strong nitrogen-nitrogen triple bonds. Here, we report experimental evidence of the formation of nitrogen-based crystalline structures compatible with nitrogene on silver surfaces via ion-beam-assisted epitaxy. Through a combination of scanning tunneling microscopy, angle-resolved photoemission spectroscopy, and first-principles calculations, we demonstrate that the nitrogene-like structure adopts a puckered honeycomb lattice. Notably, our calculations predict a nitrogene band gap of up to 7.5 eV, positioning it as a promising candidate for ultraviolet optoelectronic devices and high-k dielectric applications.",Materials Science
"Nitrogen, the most abundant element in Earth's atmosphere, exists as a diatomic gas under standard temperature and pressure. In the two-dimensional (2D) limit, atomically thin nitrogen, termed nitrogene, has been theoretically predicted to form crystalline materials with various polymorphic configurations, exhibiting diverse chemical and physical properties. However, the synthesis of nitrogene has remained elusive due to the strong nitrogen-nitrogen triple bonds. Here, we report experimental evidence of the formation of nitrogen-based crystalline structures compatible with nitrogene on silver surfaces via ion-beam-assisted epitaxy. Through a combination of scanning tunneling microscopy, angle-resolved photoemission spectroscopy, and first-principles calculations, we demonstrate that the nitrogene-like structure adopts a puckered honeycomb lattice. Notably, our calculations predict a nitrogene band gap of up to 7.5 eV, positioning it as a promising candidate for ultraviolet optoelectronic devices and high-k dielectric applications. [SEP] [HINT] structure -> Bioinformatics (Syns: social system, complex body part, social structure) | band -> Materials Science (Syns: set, stria, dance orchestra) | materials -> Materials Science (Syns: stuff, cloth, material)",Materials Science
"As artificial intelligence (AI) advances toward superhuman capabilities, aligning these systems with human values becomes increasingly critical. Current alignment strategies rely largely on externally specified constraints that may prove insufficient against future super-intelligent AI capable of circumventing top-down controls.   This research investigates whether artificial neural networks (ANNs) can develop patterns analogous to biological mirror neurons cells that activate both when performing and observing actions, and how such patterns might contribute to intrinsic alignment in AI. Mirror neurons play a crucial role in empathy, imitation, and social cognition in humans. The study therefore asks: (1) Can simple ANNs develop mirror-neuron patterns? and (2) How might these patterns contribute to ethical and cooperative decision-making in AI systems?   Using a novel Frog and Toad game framework designed to promote cooperative behaviors, we identify conditions under which mirror-neuron patterns emerge, evaluate their influence on action circuits, introduce the Checkpoint Mirror Neuron Index (CMNI) to quantify activation strength and consistency, and propose a theoretical framework for further study.   Our findings indicate that appropriately scaled model capacities and self/other coupling foster shared neural representations in ANNs similar to biological mirror neurons. These empathy-like circuits support cooperative behavior and suggest that intrinsic motivations modeled through mirror-neuron dynamics could complement existing alignment techniques by embedding empathy-like mechanisms directly within AI architectures.",Neuroscience
"As artificial intelligence (AI) advances toward superhuman capabilities, aligning these systems with human values becomes increasingly critical. Current alignment strategies rely largely on externally specified constraints that may prove insufficient against future super-intelligent AI capable of circumventing top-down controls.   This research investigates whether artificial neural networks (ANNs) can develop patterns analogous to biological mirror neurons cells that activate both when performing and observing actions, and how such patterns might contribute to intrinsic alignment in AI. Mirror neurons play a crucial role in empathy, imitation, and social cognition in humans. The study therefore asks: (1) Can simple ANNs develop mirror-neuron patterns? and (2) How might these patterns contribute to ethical and cooperative decision-making in AI systems?   Using a novel Frog and Toad game framework designed to promote cooperative behaviors, we identify conditions under which mirror-neuron patterns emerge, evaluate their influence on action circuits, introduce the Checkpoint Mirror Neuron Index (CMNI) to quantify activation strength and consistency, and propose a theoretical framework for further study.   Our findings indicate that appropriately scaled model capacities and self/other coupling foster shared neural representations in ANNs similar to biological mirror neurons. These empathy-like circuits support cooperative behavior and suggest that intrinsic motivations modeled through mirror-neuron dynamics could complement existing alignment techniques by embedding empathy-like mechanisms directly within AI architectures. [SEP] [HINT] networks -> Neuroscience (Syns: network, meshwork, electronic network) | systems -> Bioinformatics (Syns: organization, organisation, system) | human -> Neuroscience (Syns: human being, man, homo)",Neuroscience
"Traditional neural networks, while powerful, rely on biologically implausible learning mechanisms such as global backpropagation. This paper introduces the Structurally Adaptive Predictive Inference Network (SAPIN), a novel computational model inspired by the principles of active inference and the morphological plasticity observed in biological neural cultures. SAPIN operates on a 2D grid where processing units, or cells, learn by minimizing local prediction errors. The model features two primary, concurrent learning mechanisms: a local, Hebbian-like synaptic plasticity rule based on the temporal difference between a cell's actual activation and its learned expectation, and a structural plasticity mechanism where cells physically migrate across the grid to optimize their information-receptive fields. This dual approach allows the network to learn both how to process information (synaptic weights) and also where to position its computational resources (network topology). We validated the SAPIN model on the classic Cart Pole reinforcement learning benchmark. Our results demonstrate that the architecture can successfully solve the CartPole task, achieving robust performance. The network's intrinsic drive to minimize prediction error and maintain homeostasis was sufficient to discover a stable balancing policy. We also found that while continual learning led to instability, locking the network's parameters after achieving success resulted in a stable policy. When evaluated for 100 episodes post-locking (repeated over 100 successful agents), the locked networks maintained an average 82% success rate.",Neuroscience
"Traditional neural networks, while powerful, rely on biologically implausible learning mechanisms such as global backpropagation. This paper introduces the Structurally Adaptive Predictive Inference Network (SAPIN), a novel computational model inspired by the principles of active inference and the morphological plasticity observed in biological neural cultures. SAPIN operates on a 2D grid where processing units, or cells, learn by minimizing local prediction errors. The model features two primary, concurrent learning mechanisms: a local, Hebbian-like synaptic plasticity rule based on the temporal difference between a cell's actual activation and its learned expectation, and a structural plasticity mechanism where cells physically migrate across the grid to optimize their information-receptive fields. This dual approach allows the network to learn both how to process information (synaptic weights) and also where to position its computational resources (network topology). We validated the SAPIN model on the classic Cart Pole reinforcement learning benchmark. Our results demonstrate that the architecture can successfully solve the CartPole task, achieving robust performance. The network's intrinsic drive to minimize prediction error and maintain homeostasis was sufficient to discover a stable balancing policy. We also found that while continual learning led to instability, locking the network's parameters after achieving success resulted in a stable policy. When evaluated for 100 episodes post-locking (repeated over 100 successful agents), the locked networks maintained an average 82% success rate. [SEP] [HINT] based -> Bioinformatics (Syns: ground, free-base, base) | computational -> Neuroscience (Syns: ) | features -> Bioinformatics (Syns: characteristic, lineament, feature of speech)",Neuroscience
"When conflicting images are presented to either eye, binocular fusion is disrupted. Rather than experiencing a blend of both percepts, often only one eye's image is experienced, whilst the other is suppressed from awareness. Importantly, suppression is transient - the two rival images compete for dominance, with stochastic switches between mutually exclusive percepts occurring every few seconds with law-like regularity. From the perspective of dynamical systems theory, visual rivalry offers an experimentally tractable window into the dynamical mechanisms governing perceptual awareness. In a recently developed visual rivalry paradigm - tracking continuous flash suppression (tCFS) - it was shown that the transition between awareness and suppression is hysteretic, with a higher contrast threshold required for a stimulus to breakthrough suppression into awareness than to be suppressed from awareness. Here, we present an analytically-tractable model of visual rivalry that quantitatively explains the hysteretic transition between periods of awareness and suppression in tCFS. Grounded in the theory of neural dynamics, we derive closed-form expressions for the duration of perceptual dominance and suppression, and for the degree of hysteresis (i.e. the depth of perceptual suppression), as a function of model parameters. Finally, our model yields a series of novel behavioural predictions, the first of which - distributions of dominance and suppression durations during tCFS should be approximately equal - we empirically validate in human psychophysical data.",Neuroscience
"When conflicting images are presented to either eye, binocular fusion is disrupted. Rather than experiencing a blend of both percepts, often only one eye's image is experienced, whilst the other is suppressed from awareness. Importantly, suppression is transient - the two rival images compete for dominance, with stochastic switches between mutually exclusive percepts occurring every few seconds with law-like regularity. From the perspective of dynamical systems theory, visual rivalry offers an experimentally tractable window into the dynamical mechanisms governing perceptual awareness. In a recently developed visual rivalry paradigm - tracking continuous flash suppression (tCFS) - it was shown that the transition between awareness and suppression is hysteretic, with a higher contrast threshold required for a stimulus to breakthrough suppression into awareness than to be suppressed from awareness. Here, we present an analytically-tractable model of visual rivalry that quantitatively explains the hysteretic transition between periods of awareness and suppression in tCFS. Grounded in the theory of neural dynamics, we derive closed-form expressions for the duration of perceptual dominance and suppression, and for the degree of hysteresis (i.e. the depth of perceptual suppression), as a function of model parameters. Finally, our model yields a series of novel behavioural predictions, the first of which - distributions of dominance and suppression durations during tCFS should be approximately equal - we empirically validate in human psychophysical data. [SEP] [HINT] transition -> Materials Science (Syns: passage, modulation, changeover) | systems -> Bioinformatics (Syns: organization, organisation, system) | human -> Neuroscience (Syns: human being, man, homo)",Neuroscience
"Self-supervised learning (SSL) plays a central role in molecular representation learning. Yet, many recent innovations in masking-based pretraining are introduced as heuristics and lack principled evaluation, obscuring which design choices are genuinely effective. This work cast the entire pretrain-finetune workflow into a unified probabilistic framework, enabling a transparent comparison and deeper understanding of masking strategies. Building on this formalism, we conduct a controlled study of three core design dimensions: masking distribution, prediction target, and encoder architecture, under rigorously controlled settings. We further employ information-theoretic measures to assess the informativeness of pretraining signals and connect them to empirically benchmarked downstream performance. Our findings reveal a surprising insight: sophisticated masking distributions offer no consistent benefit over uniform sampling for common node-level prediction tasks. Instead, the choice of prediction target and its synergy with the encoder architecture are far more critical. Specifically, shifting to semantically richer targets yields substantial downstream improvements, particularly when paired with expressive Graph Transformer encoders. These insights offer practical guidance for developing more effective SSL methods for molecular graphs.",Bioinformatics
"Self-supervised learning (SSL) plays a central role in molecular representation learning. Yet, many recent innovations in masking-based pretraining are introduced as heuristics and lack principled evaluation, obscuring which design choices are genuinely effective. This work cast the entire pretrain-finetune workflow into a unified probabilistic framework, enabling a transparent comparison and deeper understanding of masking strategies. Building on this formalism, we conduct a controlled study of three core design dimensions: masking distribution, prediction target, and encoder architecture, under rigorously controlled settings. We further employ information-theoretic measures to assess the informativeness of pretraining signals and connect them to empirically benchmarked downstream performance. Our findings reveal a surprising insight: sophisticated masking distributions offer no consistent benefit over uniform sampling for common node-level prediction tasks. Instead, the choice of prediction target and its synergy with the encoder architecture are far more critical. Specifically, shifting to semantically richer targets yields substantial downstream improvements, particularly when paired with expressive Graph Transformer encoders. These insights offer practical guidance for developing more effective SSL methods for molecular graphs. [SEP] [HINT] understanding -> Neuroscience (Syns: savvy, intellect, sympathy) | learning -> Bioinformatics (Syns: take, teach, acquire) | molecular -> Bioinformatics (Syns: )",Bioinformatics
"Drug-target interaction (DTI) prediction is of great significance for drug discovery and drug repurposing. With the accumulation of a large volume of valuable data, data-driven methods have been increasingly harnessed to predict DTIs, reducing costs across various dimensions. Therefore, this paper proposes a $\textbf{L}$arge $\textbf{L}$anguage $\textbf{M}$odel and $\textbf{M}$ulti-$\textbf{M}$odel data co-powered $\textbf{D}$rug $\textbf{T}$arget $\textbf{I}$nteraction prediction framework, named LLM$^3$-DTI. LLM$^3$-DTI constructs multi-modal data embedding to enhance DTI prediction performance. In this framework, the text semantic embeddings of drugs and targets are encoded by a domain-specific LLM. To effectively align and fuse multi-modal embedding. We propose the dual cross-attention mechanism and the TSFusion module. Finally, these multi-modal data are utilized for the DTI task through an output network. The experimental results indicate that LLM$^3$-DTI can proficiently identify validated DTIs, surpassing the performance of the models employed for comparison across diverse scenarios. Consequently, LLM$^3$-DTI is adept at fulfilling the task of DTI prediction with excellence. The data and code are available at https://github.com/chaser-gua/LLM3DTI.",Bioinformatics
"Drug-target interaction (DTI) prediction is of great significance for drug discovery and drug repurposing. With the accumulation of a large volume of valuable data, data-driven methods have been increasingly harnessed to predict DTIs, reducing costs across various dimensions. Therefore, this paper proposes a $\textbf{L}$arge $\textbf{L}$anguage $\textbf{M}$odel and $\textbf{M}$ulti-$\textbf{M}$odel data co-powered $\textbf{D}$rug $\textbf{T}$arget $\textbf{I}$nteraction prediction framework, named LLM$^3$-DTI. LLM$^3$-DTI constructs multi-modal data embedding to enhance DTI prediction performance. In this framework, the text semantic embeddings of drugs and targets are encoded by a domain-specific LLM. To effectively align and fuse multi-modal embedding. We propose the dual cross-attention mechanism and the TSFusion module. Finally, these multi-modal data are utilized for the DTI task through an output network. The experimental results indicate that LLM$^3$-DTI can proficiently identify validated DTIs, surpassing the performance of the models employed for comparison across diverse scenarios. Consequently, LLM$^3$-DTI is adept at fulfilling the task of DTI prediction with excellence. The data and code are available at https://github.com/chaser-gua/LLM3DTI. [SEP] [HINT] task -> Neuroscience (Syns: tax, project, chore) | performance -> Bioinformatics (Syns: functioning, operation, carrying out) | results -> Bioinformatics (Syns: final result, consequence, resultant role)",Bioinformatics
"Understanding how learning algorithms shape the computational strategies that emerge in neural networks remains a fundamental challenge in machine intelligence. While network architectures receive extensive attention, the role of the learning paradigm itself in determining emergent dynamics remains largely unexplored. Here we demonstrate that reinforcement learning (RL) and supervised learning (SL) drive recurrent neural networks (RNNs) toward fundamentally different computational solutions when trained on identical decision-making tasks. Through systematic dynamical systems analysis, we reveal that RL spontaneously discovers hybrid attractor architectures, combining stable fixed-point attractors for decision maintenance with quasi-periodic attractors for flexible evidence integration. This contrasts sharply with SL, which converges almost exclusively to simpler fixed-point-only solutions. We further show that RL sculpts functionally balanced neural populations through a powerful form of implicit regularization -- a structural signature that enhances robustness and is conspicuously absent in the more heterogeneous solutions found by SL-trained networks. The prevalence of these complex dynamics in RL is controllably modulated by weight initialization and correlates strongly with performance gains, particularly as task complexity increases. Our results establish the learning algorithm as a primary determinant of emergent computation, revealing how reward-based optimization autonomously discovers sophisticated dynamical mechanisms that are less accessible to direct gradient-based optimization. These findings provide both mechanistic insights into neural computation and actionable principles for designing adaptive AI systems.",Neuroscience
"Understanding how learning algorithms shape the computational strategies that emerge in neural networks remains a fundamental challenge in machine intelligence. While network architectures receive extensive attention, the role of the learning paradigm itself in determining emergent dynamics remains largely unexplored. Here we demonstrate that reinforcement learning (RL) and supervised learning (SL) drive recurrent neural networks (RNNs) toward fundamentally different computational solutions when trained on identical decision-making tasks. Through systematic dynamical systems analysis, we reveal that RL spontaneously discovers hybrid attractor architectures, combining stable fixed-point attractors for decision maintenance with quasi-periodic attractors for flexible evidence integration. This contrasts sharply with SL, which converges almost exclusively to simpler fixed-point-only solutions. We further show that RL sculpts functionally balanced neural populations through a powerful form of implicit regularization -- a structural signature that enhances robustness and is conspicuously absent in the more heterogeneous solutions found by SL-trained networks. The prevalence of these complex dynamics in RL is controllably modulated by weight initialization and correlates strongly with performance gains, particularly as task complexity increases. Our results establish the learning algorithm as a primary determinant of emergent computation, revealing how reward-based optimization autonomously discovers sophisticated dynamical mechanisms that are less accessible to direct gradient-based optimization. These findings provide both mechanistic insights into neural computation and actionable principles for designing adaptive AI systems. [SEP] [HINT] task -> Neuroscience (Syns: tax, project, chore) | computational -> Neuroscience (Syns: ) | understanding -> Neuroscience (Syns: savvy, intellect, sympathy)",Neuroscience
"We model sensory streams as observations from high-dimensional stochastic dynamical systems and conceptualize sensory neurons as self-supervised learners of compact representations of such dynamics. From prior experience, neurons learn coherent sets-regions of stimulus state space whose trajectories evolve cohesively over finite times-and assign membership indices to new stimuli. Coherent sets are identified via spectral clustering of the stochastic Koopman operator (SKO), where the sign pattern of a subdominant singular function partitions the state space into minimally coupled regions. For multivariate Ornstein-Uhlenbeck processes, this singular function reduces to a linear projection onto the dominant singular vector of the whitened state-transition matrix. Encoding this singular vector as a receptive field enables neurons to compute membership indices via the projection sign in a biologically plausible manner. Each neuron detects either a predictive coherent set (stimuli with common futures) or a retrospective coherent set (stimuli with common pasts), suggesting a functional dichotomy among neurons. Since neurons lack access to explicit dynamical equations, the requisite singular vectors must be estimated directly from data, for example, via past-future canonical correlation analysis on lag-vector representations-an approach that naturally extends to nonlinear dynamics. This framework provides a novel account of neuronal temporal filtering, the ubiquity of rectification in neural responses, and known functional dichotomies. Coherent-set clustering thus emerges as a fundamental computation underlying sensory processing and transferable to bio-inspired artificial systems.",Neuroscience
"We model sensory streams as observations from high-dimensional stochastic dynamical systems and conceptualize sensory neurons as self-supervised learners of compact representations of such dynamics. From prior experience, neurons learn coherent sets-regions of stimulus state space whose trajectories evolve cohesively over finite times-and assign membership indices to new stimuli. Coherent sets are identified via spectral clustering of the stochastic Koopman operator (SKO), where the sign pattern of a subdominant singular function partitions the state space into minimally coupled regions. For multivariate Ornstein-Uhlenbeck processes, this singular function reduces to a linear projection onto the dominant singular vector of the whitened state-transition matrix. Encoding this singular vector as a receptive field enables neurons to compute membership indices via the projection sign in a biologically plausible manner. Each neuron detects either a predictive coherent set (stimuli with common futures) or a retrospective coherent set (stimuli with common pasts), suggesting a functional dichotomy among neurons. Since neurons lack access to explicit dynamical equations, the requisite singular vectors must be estimated directly from data, for example, via past-future canonical correlation analysis on lag-vector representations-an approach that naturally extends to nonlinear dynamics. This framework provides a novel account of neuronal temporal filtering, the ubiquity of rectification in neural responses, and known functional dichotomies. Coherent-set clustering thus emerges as a fundamental computation underlying sensory processing and transferable to bio-inspired artificial systems. [SEP] [HINT] field -> Materials Science (Syns: field of honor, line of business, orbit) | space -> Neuroscience (Syns: distance, place, outer space) | functional -> Neuroscience (Syns: working, usable, running)",Neuroscience
"Effective recognition of foreign antigens by the adaptive immune system relies on T cells being activated by antigen-presenting cells (APCs) in lymph nodes. Here, diffusing T cells may encounter cognate APCs that present matching antigen fragments or non-cognate ones that do not; they are also subject to degradation. We develop a stochastic model in which T cell-APCs interact via a sequence of recognition steps, represented as a multistage Markov chain. T cells are successfully activated only if the terminal state associated with a cognate APC is reached. We compute the probability of successful activation in the presence of interfering non-cognate APCs, T cell degradation, and lymph node exit, and analyze the mean first-passage time to activation. We also incorporate a kinetic proofreading mechanism that enables state resetting, and show how this enhances specificity toward cognate APCs.",Bioinformatics
"Effective recognition of foreign antigens by the adaptive immune system relies on T cells being activated by antigen-presenting cells (APCs) in lymph nodes. Here, diffusing T cells may encounter cognate APCs that present matching antigen fragments or non-cognate ones that do not; they are also subject to degradation. We develop a stochastic model in which T cell-APCs interact via a sequence of recognition steps, represented as a multistage Markov chain. T cells are successfully activated only if the terminal state associated with a cognate APC is reached. We compute the probability of successful activation in the presence of interfering non-cognate APCs, T cell degradation, and lymph node exit, and analyze the mean first-passage time to activation. We also incorporate a kinetic proofreading mechanism that enables state resetting, and show how this enhances specificity toward cognate APCs. [SEP] [HINT] model -> Bioinformatics (Syns: exemplary, framework, modelling) | present -> Bioinformatics (Syns: deliver, exhibit, confront) | time -> Bioinformatics (Syns: fourth dimension, metre, sentence)",Bioinformatics
"In cognitive science and AI, a longstanding question is whether machines learn representations that align with those of the human mind. While current models show promise, it remains an open question whether this alignment is superficial or reflects a deeper correspondence in the underlying dimensions of representation. Here we introduce a methodology to probe the internal geometry of vision-language models (VLMs) by having them generate pairwise similarity judgments for a complex set of natural objects. Using multidimensional scaling, we recover low-dimensional psychological spaces and find that their axes show a strong correspondence with the principal axes of human perceptual space. Critically, when this AI-derived representational geometry is used as the input to a classic exemplar model of categorization, it predicts human classification behavior more accurately than a space constructed from human judgments themselves. This suggests that VLMs can capture an idealized or `denoised' form of human perceptual structure. Our work provides a scalable method to overcome a measurement bottleneck in cognitive science and demonstrates that foundation models can learn a representational geometry that is functionally relevant for modeling key aspects of human cognition, such as categorization.",Neuroscience
"In cognitive science and AI, a longstanding question is whether machines learn representations that align with those of the human mind. While current models show promise, it remains an open question whether this alignment is superficial or reflects a deeper correspondence in the underlying dimensions of representation. Here we introduce a methodology to probe the internal geometry of vision-language models (VLMs) by having them generate pairwise similarity judgments for a complex set of natural objects. Using multidimensional scaling, we recover low-dimensional psychological spaces and find that their axes show a strong correspondence with the principal axes of human perceptual space. Critically, when this AI-derived representational geometry is used as the input to a classic exemplar model of categorization, it predicts human classification behavior more accurately than a space constructed from human judgments themselves. This suggests that VLMs can capture an idealized or `denoised' form of human perceptual structure. Our work provides a scalable method to overcome a measurement bottleneck in cognitive science and demonstrates that foundation models can learn a representational geometry that is functionally relevant for modeling key aspects of human cognition, such as categorization. [SEP] [HINT] used -> Bioinformatics (Syns: utilize, ill-used, apply) | space -> Neuroscience (Syns: distance, place, outer space) | complex -> Bioinformatics (Syns: building complex, coordination compound, composite)",Neuroscience
"Photon scattering has traditionally limited the ability of near-infrared spectroscopy (NIRS) to extract accurate, layer-specific information from the brain. This limitation restricts its clinical utility for precise neurological monitoring. To address this, we introduce an AI-driven, high-density NIRS system optimized to provide real-time, layer-specific oxygenation data from the brain cortex, specifically targeting acute neuro-emergencies. Our system integrates high-density NIRS reflectance data with a neural network trained on MRI-based synthetic datasets. This approach achieves robust cortical oxygenation accuracy across diverse anatomical variations. In simulations, our AI-assisted NIRS demonstrated a strong correlation (R2=0.913) with actual cortical oxygenation, markedly outperforming conventional methods (R2=0.469). Furthermore, biomimetic phantom experiments confirmed its superior anatomical reliability (R2=0.986) compared to standard commercial devices (R2=0.823). In clinical validation with healthy subjects and ischemic stroke patients, the system distinguished between the two groups with an AUC of 0.943. This highlights its potential as an accessible, high-accuracy diagnostic tool for emergency and point-of-care settings. These results underscore the system's capability to advance neuro-monitoring precision through AI, enabling timely, data-driven decisions in critical care environments.",Neuroscience
"Photon scattering has traditionally limited the ability of near-infrared spectroscopy (NIRS) to extract accurate, layer-specific information from the brain. This limitation restricts its clinical utility for precise neurological monitoring. To address this, we introduce an AI-driven, high-density NIRS system optimized to provide real-time, layer-specific oxygenation data from the brain cortex, specifically targeting acute neuro-emergencies. Our system integrates high-density NIRS reflectance data with a neural network trained on MRI-based synthetic datasets. This approach achieves robust cortical oxygenation accuracy across diverse anatomical variations. In simulations, our AI-assisted NIRS demonstrated a strong correlation (R2=0.913) with actual cortical oxygenation, markedly outperforming conventional methods (R2=0.469). Furthermore, biomimetic phantom experiments confirmed its superior anatomical reliability (R2=0.986) compared to standard commercial devices (R2=0.823). In clinical validation with healthy subjects and ischemic stroke patients, the system distinguished between the two groups with an AUC of 0.943. This highlights its potential as an accessible, high-accuracy diagnostic tool for emergency and point-of-care settings. These results underscore the system's capability to advance neuro-monitoring precision through AI, enabling timely, data-driven decisions in critical care environments. [SEP] [HINT] clinical -> Bioinformatics (Syns: ) | cortical -> Neuroscience (Syns: ) | information -> Bioinformatics (Syns: entropy, data, info)",Neuroscience
"Quantum geometry is a differential geometry based on quantum mechanics. It is related to various transport and optical properties in condensed matter physics. The Zeeman quantum geometry is a generalization of quantum geometry including the spin degrees of freedom. It is related to electromagnetic cross responses. Quantum geometry is generalized to non-Hermitian systems and density matrices. Especially, the latter is quantum information geometry, where the quantum Fisher information naturally arises as quantum metric. We apply these results to the $X$-wave magnets, which include $d$-wave, $g$-wave and $i$-wave altermagnets as well as $p$-wave and $f$-wave magnets. They have universal physics for anomalous Hall conductivity, tunneling magneto-resistance and planar Hall effect. We obtain various analytic formulas based on the two-band Hamiltonian.",Materials Science
"Quantum geometry is a differential geometry based on quantum mechanics. It is related to various transport and optical properties in condensed matter physics. The Zeeman quantum geometry is a generalization of quantum geometry including the spin degrees of freedom. It is related to electromagnetic cross responses. Quantum geometry is generalized to non-Hermitian systems and density matrices. Especially, the latter is quantum information geometry, where the quantum Fisher information naturally arises as quantum metric. We apply these results to the $X$-wave magnets, which include $d$-wave, $g$-wave and $i$-wave altermagnets as well as $p$-wave and $f$-wave magnets. They have universal physics for anomalous Hall conductivity, tunneling magneto-resistance and planar Hall effect. We obtain various analytic formulas based on the two-band Hamiltonian. [SEP] [HINT] based -> Bioinformatics (Syns: ground, free-base, base) | spin -> Materials Science (Syns: twisting, whirl, tailspin) | transport -> Materials Science (Syns: transferral, enthral, shipping)",Materials Science
"By introducing the twin concepts of reliability and precision along with the corresponding measures, Mainen and Sejnowski's seminal 1995 paper ""Reliability of spike timing in neocortical neurons"" (Mainen and Sejnowski, 1995) paved the way for a new kind of quantitative spike train analysis. In subsequent years a host of new methods was introduced that measured both the synchrony among neuronal spike trains and the directional component, e.g. how activity propogates between neurons. This development culminated with a new class of measures that are both time scale independent and time resolved. These include the two spike train distances ISI- and SPIKE-Distance as well as the coincidence detector SPIKE-Synchronization and its directional companion SPIKE-Order. This article will not only review all of these measures but also include two recently proposed algorithms for latency correction which build on SPIKE-order and aim to optimize the spike time alignment of sparse spike trains with well-defined global spiking events. For the sake of clarity, all these methods will be illustrated on artificially generated data but in each case exemplary applications to real neuronal data will be described as well.",Neuroscience
"By introducing the twin concepts of reliability and precision along with the corresponding measures, Mainen and Sejnowski's seminal 1995 paper ""Reliability of spike timing in neocortical neurons"" (Mainen and Sejnowski, 1995) paved the way for a new kind of quantitative spike train analysis. In subsequent years a host of new methods was introduced that measured both the synchrony among neuronal spike trains and the directional component, e.g. how activity propogates between neurons. This development culminated with a new class of measures that are both time scale independent and time resolved. These include the two spike train distances ISI- and SPIKE-Distance as well as the coincidence detector SPIKE-Synchronization and its directional companion SPIKE-Order. This article will not only review all of these measures but also include two recently proposed algorithms for latency correction which build on SPIKE-order and aim to optimize the spike time alignment of sparse spike trains with well-defined global spiking events. For the sake of clarity, all these methods will be illustrated on artificially generated data but in each case exemplary applications to real neuronal data will be described as well. [SEP] [HINT] scale -> Bioinformatics (Syns: shell, graduated table, plate) | activity -> Neuroscience (Syns: activeness, body process, bodily process) | methods -> Bioinformatics (Syns: method acting, method)",Neuroscience
"Task-specific pre-training is essential when task representations diverge from generic pre-training features. Existing task-general pre-training EEG models struggle with complex tasks like emotion recognition due to mismatches between task-specific features and broad pre-training approaches. This work aims to develop a task-specific multi-dataset joint pre-training framework for cross-dataset emotion recognition, tackling problems of large inter-dataset distribution shifts, inconsistent emotion category definitions, and substantial inter-subject variability. We introduce a cross-dataset covariance alignment loss to align second-order statistical properties across datasets, enabling robust generalization without the need for extensive labels or per-subject calibration. To capture the long-term dependency and complex dynamics of EEG, we propose a hybrid encoder combining a Mamba-like linear attention channel encoder and a spatiotemporal dynamics model. Our method outperforms state-of-the-art large-scale EEG models by an average of 4.57% in AUROC for few-shot emotion recognition and 11.92% in accuracy for zero-shot generalization to a new dataset. Performance scales with the increase of datasets used in pre-training. Multi-dataset joint pre-training achieves a performance gain of 8.55% over single-dataset training. This work provides a scalable framework for task-specific pre-training and highlights its benefit in generalizable affective computing. Our code is available at https://github.com/ncclab-sustech/mdJPT_nips2025.",Neuroscience
"Task-specific pre-training is essential when task representations diverge from generic pre-training features. Existing task-general pre-training EEG models struggle with complex tasks like emotion recognition due to mismatches between task-specific features and broad pre-training approaches. This work aims to develop a task-specific multi-dataset joint pre-training framework for cross-dataset emotion recognition, tackling problems of large inter-dataset distribution shifts, inconsistent emotion category definitions, and substantial inter-subject variability. We introduce a cross-dataset covariance alignment loss to align second-order statistical properties across datasets, enabling robust generalization without the need for extensive labels or per-subject calibration. To capture the long-term dependency and complex dynamics of EEG, we propose a hybrid encoder combining a Mamba-like linear attention channel encoder and a spatiotemporal dynamics model. Our method outperforms state-of-the-art large-scale EEG models by an average of 4.57% in AUROC for few-shot emotion recognition and 11.92% in accuracy for zero-shot generalization to a new dataset. Performance scales with the increase of datasets used in pre-training. Multi-dataset joint pre-training achieves a performance gain of 8.55% over single-dataset training. This work provides a scalable framework for task-specific pre-training and highlights its benefit in generalizable affective computing. Our code is available at https://github.com/ncclab-sustech/mdJPT_nips2025. [SEP] [HINT] used -> Bioinformatics (Syns: utilize, ill-used, apply) | task -> Neuroscience (Syns: tax, project, chore) | tasks -> Neuroscience (Syns: tax, task, project)",Neuroscience
"Electroencephalogram monitoring devices and online data repositories hold large amounts of data from individuals participating in research and medical studies without direct reference to personal identifiers. This paper explores what types of personal and health information have been detected and classified within task-free EEG data. Additionally, we investigate key characteristics of the collected resting-state and sleep data, in order to determine the privacy risks involved with openly available EEG data. We used Google Scholar, Web of Science and searched relevant journals to find studies which classified or detected the presence of various disorders and personal information in resting state and sleep EEG. Only English full-text peer-reviewed journal articles or conference papers about classifying the presence of medical disorders between individuals were included. A quality analysis carried out by 3 reviewers determined general paper quality based on specified evaluation criteria. In resting state EEG, various disorders including Autism Spectrum Disorder, Parkinson's disease, and alcohol use disorder have been classified with high classification accuracy, often requiring only 5 mins of data or less. Sleep EEG tends to hold classifiable information about sleep disorders such as sleep apnea, insomnia, and REM sleep disorder, but usually involve longer recordings or data from multiple sleep stages. Many classification methods are still developing but even today, access to a person's EEG can reveal sensitive personal health information. With an increasing ability of machine learning methods to re-identify individuals from their EEG data, this review demonstrates the importance of anonymization, and the development of improved tools for keeping study participants and medical EEG users' privacy safe.",Neuroscience
"Electroencephalogram monitoring devices and online data repositories hold large amounts of data from individuals participating in research and medical studies without direct reference to personal identifiers. This paper explores what types of personal and health information have been detected and classified within task-free EEG data. Additionally, we investigate key characteristics of the collected resting-state and sleep data, in order to determine the privacy risks involved with openly available EEG data. We used Google Scholar, Web of Science and searched relevant journals to find studies which classified or detected the presence of various disorders and personal information in resting state and sleep EEG. Only English full-text peer-reviewed journal articles or conference papers about classifying the presence of medical disorders between individuals were included. A quality analysis carried out by 3 reviewers determined general paper quality based on specified evaluation criteria. In resting state EEG, various disorders including Autism Spectrum Disorder, Parkinson's disease, and alcohol use disorder have been classified with high classification accuracy, often requiring only 5 mins of data or less. Sleep EEG tends to hold classifiable information about sleep disorders such as sleep apnea, insomnia, and REM sleep disorder, but usually involve longer recordings or data from multiple sleep stages. Many classification methods are still developing but even today, access to a person's EEG can reveal sensitive personal health information. With an increasing ability of machine learning methods to re-identify individuals from their EEG data, this review demonstrates the importance of anonymization, and the development of improved tools for keeping study participants and medical EEG users' privacy safe. [SEP] [HINT] used -> Bioinformatics (Syns: utilize, ill-used, apply) | based -> Bioinformatics (Syns: ground, free-base, base) | learning -> Bioinformatics (Syns: take, teach, acquire)",Neuroscience
"Alloying and doping are crucial for enhancing the electronic and optical properties of semiconductors while simultaneously introducing disorder. This report explores the effects of alloying and Si (0.5 at.\%) doping on In$_{0.10}$Ga$_{0.90}$N thin films that were grown by metal-organic vapor phase epitaxy. Post-growth X-ray diffraction measurements indicate that Si doping does not affect the lattice parameters and screw dislocations but significantly increases the edge dislocation density. Temperature-dependent time-resolved photoluminescence spectroscopy shows that Si-doped In$_{0.10}$Ga$_{0.90}$N exhibits higher photoluminescence intensity, blue-shifted peaks, narrower emission linewidths, and quenching of lower energy sidebands when compared to pristine In$_{0.10}$Ga$_{0.90}$N. The peak energies of the most dominant feature, the donor-bound exciton, for both samples show an $S$-shape behavior indicating the presence of disorder. Although doping improves luminescence, it also introduces deeper localized states. This suggests that impurity-induced disorder outweighs compositional fluctuations, as confirmed by higher disorder parameters and Stokes shifts. Thus, the Si doping leads to increased localization, reducing nonradiative recombination channels while enhancing radiative processes. The deeper states in the doped sample confirm improved carrier confinement, and their saturation leads to early thermalization, thereby lowering the red-blue shift transition from 165 K to about 50 K. Even though the high doping level makes Si-doped In$_{0.10}$Ga$_{0.90}$N a degenerate system, it exhibits enhanced luminescence properties. These findings shed light on the impact of silicon doping on charge transport in InGaN alloys for optoelectronic applications.",Materials Science
"Alloying and doping are crucial for enhancing the electronic and optical properties of semiconductors while simultaneously introducing disorder. This report explores the effects of alloying and Si (0.5 at.\%) doping on In$_{0.10}$Ga$_{0.90}$N thin films that were grown by metal-organic vapor phase epitaxy. Post-growth X-ray diffraction measurements indicate that Si doping does not affect the lattice parameters and screw dislocations but significantly increases the edge dislocation density. Temperature-dependent time-resolved photoluminescence spectroscopy shows that Si-doped In$_{0.10}$Ga$_{0.90}$N exhibits higher photoluminescence intensity, blue-shifted peaks, narrower emission linewidths, and quenching of lower energy sidebands when compared to pristine In$_{0.10}$Ga$_{0.90}$N. The peak energies of the most dominant feature, the donor-bound exciton, for both samples show an $S$-shape behavior indicating the presence of disorder. Although doping improves luminescence, it also introduces deeper localized states. This suggests that impurity-induced disorder outweighs compositional fluctuations, as confirmed by higher disorder parameters and Stokes shifts. Thus, the Si doping leads to increased localization, reducing nonradiative recombination channels while enhancing radiative processes. The deeper states in the doped sample confirm improved carrier confinement, and their saturation leads to early thermalization, thereby lowering the red-blue shift transition from 165 K to about 50 K. Even though the high doping level makes Si-doped In$_{0.10}$Ga$_{0.90}$N a degenerate system, it exhibits enhanced luminescence properties. These findings shed light on the impact of silicon doping on charge transport in InGaN alloys for optoelectronic applications. [SEP] [HINT] transition -> Materials Science (Syns: passage, modulation, changeover) | transport -> Materials Science (Syns: transferral, enthral, shipping) | charge -> Materials Science (Syns: tear, bearing, burster)",Materials Science
"Laser-induced periodic surface structures (LIPSS) on silicon, generated by ultrashort pulsed lasers, provide an efficient means to tailor surface functionality. This work presents a multiphysics finite element study on the thermomechanical dynamics of silicon wafers irradiated by picosecond laser pulses, focusing on the melting regime where thermomechanical and hydrodynamic effects dominate. To illustrate the sequential nature of laser scanning, single-pulse irradiation models are developed as thermomechanical analogues of double-pulse interactions. By positioning the laser focus near reflective boundaries and corners of the target, these models reproduce the stress-wave interference that would occur between successive pulses in scanning. The results show that periodic surface structures originate from mechanical standing wave interference within the molten layer, forming ripples with near-wavelength periodicity. The penetration depth (PD) is identified as a key factor controlling the duration and stability of these ripples: shallow PDs (75-150 nm) yield distinct, persistent patterns, while deeper PDs (app. 2.5 micrometers) lead to extended melting and hydrodynamic smoothing. Simulations of sequential double-pulse irradiation confirm that residual stresses and strains from the first pulse amplify deformation during the second, enhancing ripple amplitude and uniformity. Controlled excitation of mechanical standing waves governed by PD, boundary geometry, and pulse sequencing - thus represents a fundamental mechanism for deterministic LIPSS formation on silicon.",Materials Science
"Laser-induced periodic surface structures (LIPSS) on silicon, generated by ultrashort pulsed lasers, provide an efficient means to tailor surface functionality. This work presents a multiphysics finite element study on the thermomechanical dynamics of silicon wafers irradiated by picosecond laser pulses, focusing on the melting regime where thermomechanical and hydrodynamic effects dominate. To illustrate the sequential nature of laser scanning, single-pulse irradiation models are developed as thermomechanical analogues of double-pulse interactions. By positioning the laser focus near reflective boundaries and corners of the target, these models reproduce the stress-wave interference that would occur between successive pulses in scanning. The results show that periodic surface structures originate from mechanical standing wave interference within the molten layer, forming ripples with near-wavelength periodicity. The penetration depth (PD) is identified as a key factor controlling the duration and stability of these ripples: shallow PDs (75-150 nm) yield distinct, persistent patterns, while deeper PDs (app. 2.5 micrometers) lead to extended melting and hydrodynamic smoothing. Simulations of sequential double-pulse irradiation confirm that residual stresses and strains from the first pulse amplify deformation during the second, enhancing ripple amplitude and uniformity. Controlled excitation of mechanical standing waves governed by PD, boundary geometry, and pulse sequencing - thus represents a fundamental mechanism for deterministic LIPSS formation on silicon. [SEP] [HINT] work -> Bioinformatics (Syns: work out, process, bring) | results -> Bioinformatics (Syns: final result, consequence, resultant role) | dynamics -> Bioinformatics (Syns: kinetics, dynamic, moral force)",Materials Science
"We present a comprehensive optical characterization of 200-nm-thick CrN(111) films grown simultaneously on Al$_2$O$_3$(0001) and AlN/Al$_2$O$_3$(0001) using plasma-assisted molecular beam epitaxy. Spectroscopic ellipsometry, spanning the far-infrared to ultraviolet range (0.04 - 5.5 eV), is conducted at room temperature to determine the optical constants $n$ and $k$ of the films. Spectral fits reveal two interband transitions at approximately 0.35 and 0.60 eV. In the infrared range, the ellipsometry data also reveals a pronounced Reststrahlen band stemming from transversal and longitudinal optical phonons at approximately 403 and 629 cm$^{-1}$, respectively. The relative static and high-frequency permittivities are estimated to be about 39 and 15, respectively. A Born effective charge of approximately 2.7, extracted from the far-infrared region, indicates that CrN is partially ionic.",Materials Science
"We present a comprehensive optical characterization of 200-nm-thick CrN(111) films grown simultaneously on Al$_2$O$_3$(0001) and AlN/Al$_2$O$_3$(0001) using plasma-assisted molecular beam epitaxy. Spectroscopic ellipsometry, spanning the far-infrared to ultraviolet range (0.04 - 5.5 eV), is conducted at room temperature to determine the optical constants $n$ and $k$ of the films. Spectral fits reveal two interband transitions at approximately 0.35 and 0.60 eV. In the infrared range, the ellipsometry data also reveals a pronounced Reststrahlen band stemming from transversal and longitudinal optical phonons at approximately 403 and 629 cm$^{-1}$, respectively. The relative static and high-frequency permittivities are estimated to be about 39 and 15, respectively. A Born effective charge of approximately 2.7, extracted from the far-infrared region, indicates that CrN is partially ionic. [SEP] [HINT] charge -> Materials Science (Syns: tear, bearing, burster) | molecular -> Bioinformatics (Syns: ) | using -> Bioinformatics (Syns: utilize, exploitation, apply)",Materials Science
"Intense terahertz (THz) pulses induce transient inversion-symmetry breaking in quantum paraelectric SrTiO$_3$, yet the underlying mechanism remains controversial. Using fields up to $\sim$1.1 MV/cm, we reveal spatially inhomogeneous THz-field-induced second harmonic generation (TFISH) governed by competing lattice and defect dynamics. Short-lived coherent antiferrodistortive (AFD) modes suppress dipole correlations within $\sim$5 ps, while heavily damped soft/AFD modes and a defect-induced low-frequency mode ($\sim$0.1-0.3 THz) jointly prevent long-range ferroelectric coherence in oxygen-vacancy-rich regions. Collective modes manifested by oscillatory TFISH components exhibit softening followed by hardening below a critical temperature $T^*\simeq$28 K, confirming transient ferroelectric order where defects are sparse. These results reconcile conflicting interpretations, establish defect-mediated competition as a central regulator of light-induced ferroelectricity, and open routes to ultrafast control of quantum materials.",Materials Science
"Intense terahertz (THz) pulses induce transient inversion-symmetry breaking in quantum paraelectric SrTiO$_3$, yet the underlying mechanism remains controversial. Using fields up to $\sim$1.1 MV/cm, we reveal spatially inhomogeneous THz-field-induced second harmonic generation (TFISH) governed by competing lattice and defect dynamics. Short-lived coherent antiferrodistortive (AFD) modes suppress dipole correlations within $\sim$5 ps, while heavily damped soft/AFD modes and a defect-induced low-frequency mode ($\sim$0.1-0.3 THz) jointly prevent long-range ferroelectric coherence in oxygen-vacancy-rich regions. Collective modes manifested by oscillatory TFISH components exhibit softening followed by hardening below a critical temperature $T^*\simeq$28 K, confirming transient ferroelectric order where defects are sparse. These results reconcile conflicting interpretations, establish defect-mediated competition as a central regulator of light-induced ferroelectricity, and open routes to ultrafast control of quantum materials. [SEP] [HINT] defect -> Materials Science (Syns: mar, shortcoming, fault) | order -> Materials Science (Syns: enjoin, dictate, social club) | results -> Bioinformatics (Syns: final result, consequence, resultant role)",Materials Science
"We investigate here various properties of the responses of excitable systems subject to periodic forcing and noise. While the properties of intrinsic oscillators, subject to added periodic signals, are well understood, much less is known about the factors that determine the response precision of excitable units, intrinsically at rest, when activated by periodic forcing and stochastic noise. One motivation for considering this issue comes from the behavior of auditory neurons. These neurons reportedly have the ability to fire spikes in a precise range of phases in response to incoming sound waves, a behavior for which the mechanism is unknown. To account for such a response precision, we introduce the notion of dynamic threshold curve (DTC), which estimates at each time the effective likelihood that noise will subsequently generate a spike. The DTC effectively summarizes, in a single curve, a representation of the response precision of an excitable model, as we demonstrate by showing that the distribution of spike times produced in this setting is well captured by the first passage time of a simple, Gaussian stochastic process to the distance to the DTC. This result shows that peaks and troughs of the DTC, but also their slopes, convey fine information about spike timing in response to noise. In particular, it explains properties of Type 2 and Type 3 excitable cells studied previously and provides a framework to predict the DTC properties necessary to support the response precision of auditory neurons, as we illustrate in a well-established auditory neuron model.",Neuroscience
"We investigate here various properties of the responses of excitable systems subject to periodic forcing and noise. While the properties of intrinsic oscillators, subject to added periodic signals, are well understood, much less is known about the factors that determine the response precision of excitable units, intrinsically at rest, when activated by periodic forcing and stochastic noise. One motivation for considering this issue comes from the behavior of auditory neurons. These neurons reportedly have the ability to fire spikes in a precise range of phases in response to incoming sound waves, a behavior for which the mechanism is unknown. To account for such a response precision, we introduce the notion of dynamic threshold curve (DTC), which estimates at each time the effective likelihood that noise will subsequently generate a spike. The DTC effectively summarizes, in a single curve, a representation of the response precision of an excitable model, as we demonstrate by showing that the distribution of spike times produced in this setting is well captured by the first passage time of a simple, Gaussian stochastic process to the distance to the DTC. This result shows that peaks and troughs of the DTC, but also their slopes, convey fine information about spike timing in response to noise. In particular, it explains properties of Type 2 and Type 3 excitable cells studied previously and provides a framework to predict the DTC properties necessary to support the response precision of auditory neurons, as we illustrate in a well-established auditory neuron model. [SEP] [HINT] information -> Bioinformatics (Syns: entropy, data, info) | systems -> Bioinformatics (Syns: organization, organisation, system) | framework -> Bioinformatics (Syns: theoretical account, model, fabric)",Neuroscience
"We assess the accuracy of six universal machine-learned interatomic potentials (MLIPs) for predicting the temperature and pressure response of materials by molecular dynamics simulations. Accuracy is evaluated across 13 diverse materials (nine metal-organic frameworks and four inorganic compounds), computing bulk modulus, thermal expansion, and thermal decomposition. These MLIPs employ three different architectures (graph neural networks, graph network simulators, and graph transformers) with varying training datasets. We observe qualitative accuracy across these predictions but systematic underestimation of bulk modulus and overestimation of thermal expansion across all models, consistent with potential energy surface softening. From all tested models, three top performers arise; `MACE-MP-0a', `fairchem_OMAT', and `Orb-v3', with average error across metrics and materials of 41%, 44%, and 47%, respectively. Despite strong overall performance, questions arise about the limits of model transferability: dataset homogeneity and structural representation dominate model accuracy. Our results show that certain architectures can compensate for biases, a step closer to truly universal MLIPs.",Materials Science
"We assess the accuracy of six universal machine-learned interatomic potentials (MLIPs) for predicting the temperature and pressure response of materials by molecular dynamics simulations. Accuracy is evaluated across 13 diverse materials (nine metal-organic frameworks and four inorganic compounds), computing bulk modulus, thermal expansion, and thermal decomposition. These MLIPs employ three different architectures (graph neural networks, graph network simulators, and graph transformers) with varying training datasets. We observe qualitative accuracy across these predictions but systematic underestimation of bulk modulus and overestimation of thermal expansion across all models, consistent with potential energy surface softening. From all tested models, three top performers arise; `MACE-MP-0a', `fairchem_OMAT', and `Orb-v3', with average error across metrics and materials of 41%, 44%, and 47%, respectively. Despite strong overall performance, questions arise about the limits of model transferability: dataset homogeneity and structural representation dominate model accuracy. Our results show that certain architectures can compensate for biases, a step closer to truly universal MLIPs. [SEP] [HINT] molecular -> Bioinformatics (Syns: ) | results -> Bioinformatics (Syns: final result, consequence, resultant role) | different -> Neuroscience (Syns: unlike, dissimilar)",Materials Science
"Two-dimensional (2D) materials have been proposed, among many other applications, as a efficient tool for the separation of atomic and molecular species and their corresponding isotopes, given the confinement provided by their subnanometric dimensions. In this work we present three dimensional quantum wave packet calculations revealing an enhancement in the quantum transport in bilayer over monolayer graphdiyne membranes, one of the most popular 2D materials which is commonly employed for this purpose. Besides, resonances emerge superimposed over the typical monolayer profile for transmission probabilities, a feature that is general to other bilayer nanoporous 2D heterostructures and that shows a strong dependence on the interlayer separation.",Materials Science
"Two-dimensional (2D) materials have been proposed, among many other applications, as a efficient tool for the separation of atomic and molecular species and their corresponding isotopes, given the confinement provided by their subnanometric dimensions. In this work we present three dimensional quantum wave packet calculations revealing an enhancement in the quantum transport in bilayer over monolayer graphdiyne membranes, one of the most popular 2D materials which is commonly employed for this purpose. Besides, resonances emerge superimposed over the typical monolayer profile for transmission probabilities, a feature that is general to other bilayer nanoporous 2D heterostructures and that shows a strong dependence on the interlayer separation. [SEP] [HINT] transport -> Materials Science (Syns: transferral, enthral, shipping) | molecular -> Bioinformatics (Syns: ) | work -> Bioinformatics (Syns: work out, process, bring)",Materials Science
"The response of a MoRe-based superconducting resonator operating near 5 K to pulsed infrared irradiation is investigated, and the underlying physical mechanisms are analyzed. The device exhibits a pronounced nonlinear response dominated by nonequilibrium quasiparticle dynamics rather than uniform thermal heating. Infrared pulses produce strong distortions of the resonance curve and a transient decrease in the resonance frequency, consistent with increased kinetic inductance caused by quasiparticle generation. The frequency shift scales approximately linearly with absorbed power, whereas the dissipation response saturates at higher powers, indicating the formation of a nonequilibrium steady-state quasiparticle population. These observations demonstrate a transition from a linear pair-breaking regime to a saturated dissipation regime, likely associated with a quasiparticle relaxation bottleneck or partial suppression of the smaller superconducting gap in MoRe. The results highlight the relevance of nonequilibrium processes in MoRe and confirm its potential for microwave kinetic-inductance detector applications.",Materials Science
"The response of a MoRe-based superconducting resonator operating near 5 K to pulsed infrared irradiation is investigated, and the underlying physical mechanisms are analyzed. The device exhibits a pronounced nonlinear response dominated by nonequilibrium quasiparticle dynamics rather than uniform thermal heating. Infrared pulses produce strong distortions of the resonance curve and a transient decrease in the resonance frequency, consistent with increased kinetic inductance caused by quasiparticle generation. The frequency shift scales approximately linearly with absorbed power, whereas the dissipation response saturates at higher powers, indicating the formation of a nonequilibrium steady-state quasiparticle population. These observations demonstrate a transition from a linear pair-breaking regime to a saturated dissipation regime, likely associated with a quasiparticle relaxation bottleneck or partial suppression of the smaller superconducting gap in MoRe. The results highlight the relevance of nonequilibrium processes in MoRe and confirm its potential for microwave kinetic-inductance detector applications. [SEP] [HINT] transition -> Materials Science (Syns: passage, modulation, changeover) | results -> Bioinformatics (Syns: final result, consequence, resultant role) | thermal -> Materials Science (Syns: thermic, caloric)",Materials Science
"Multi-omics data integration is crucial for understanding complex diseases, yet limited sample sizes, noise, and heterogeneity often reduce predictive power. To address these challenges, we introduce Omics-GAN, a Generative Adversarial Network (GAN)-based framework designed to generate high-quality synthetic multi-omics profiles while preserving biological relationships. We evaluated Omics-GAN on three omics types (mRNA, miRNA, and DNA methylation) using the ROSMAP cohort for Alzheimer's disease (AD) and TCGA datasets for colon and liver cancer. A support vector machine (SVM) classifier with repeated 5-fold cross-validation demonstrated that synthetic datasets consistently improved prediction accuracy compared to original omics profiles. The AUC of SVM for mRNA improved from 0.72 to 0.74 in AD, and from 0.68 to 0.72 in liver cancer. Synthetic miRNA enhanced classification in colon cancer from 0.59 to 0.69, while synthetic methylation data improved performance in liver cancer from 0.64 to 0.71. Boxplot analyses confirmed that synthetic data preserved statistical distributions while reducing noise and outliers. Feature selection identified significant genes overlapping with original datasets and revealed additional candidates validated by GO and KEGG enrichment analyses. Finally, molecular docking highlighted potential drug repurposing candidates, including Nilotinib for AD, Atovaquone for liver cancer, and Tecovirimat for colon cancer. Omics-GAN enhances disease prediction, preserves biological fidelity, and accelerates biomarker and drug discovery, offering a scalable strategy for precision medicine applications.",Bioinformatics
"Multi-omics data integration is crucial for understanding complex diseases, yet limited sample sizes, noise, and heterogeneity often reduce predictive power. To address these challenges, we introduce Omics-GAN, a Generative Adversarial Network (GAN)-based framework designed to generate high-quality synthetic multi-omics profiles while preserving biological relationships. We evaluated Omics-GAN on three omics types (mRNA, miRNA, and DNA methylation) using the ROSMAP cohort for Alzheimer's disease (AD) and TCGA datasets for colon and liver cancer. A support vector machine (SVM) classifier with repeated 5-fold cross-validation demonstrated that synthetic datasets consistently improved prediction accuracy compared to original omics profiles. The AUC of SVM for mRNA improved from 0.72 to 0.74 in AD, and from 0.68 to 0.72 in liver cancer. Synthetic miRNA enhanced classification in colon cancer from 0.59 to 0.69, while synthetic methylation data improved performance in liver cancer from 0.64 to 0.71. Boxplot analyses confirmed that synthetic data preserved statistical distributions while reducing noise and outliers. Feature selection identified significant genes overlapping with original datasets and revealed additional candidates validated by GO and KEGG enrichment analyses. Finally, molecular docking highlighted potential drug repurposing candidates, including Nilotinib for AD, Atovaquone for liver cancer, and Tecovirimat for colon cancer. Omics-GAN enhances disease prediction, preserves biological fidelity, and accelerates biomarker and drug discovery, offering a scalable strategy for precision medicine applications. [SEP] [HINT] understanding -> Neuroscience (Syns: savvy, intellect, sympathy) | complex -> Bioinformatics (Syns: building complex, coordination compound, composite) | molecular -> Bioinformatics (Syns: )",Bioinformatics
"This paper gives an in-depth theoretical analysis of the direction and speed selectivity properties of idealized models of the spatio-temporal receptive fields of simple cells and complex cells, based on the generalized Gaussian derivative model for visual receptive fields. According to this theory, the receptive fields are modelled as velocity-adapted affine Gaussian derivatives for different image velocities and different degrees of elongation. By probing such idealized receptive field models of visual neurons to moving sine waves with different angular frequencies and image velocities, we characterize the computational models to a structurally similar probing method as is used for characterizing the direction and speed selective properties of biological neurons.   By comparison to results of neurophysiological measurements of direction and speed selectivity for biological neurons in the primary visual cortex, we find that our theoretical results are qualitatively consistent with (i) velocity-tuned visual neurons that are sensitive to particular motion directions and speeds, and (ii)~different visual neurons having broader {\em vs.\/}\ sharper direction and speed selective properties. Our theoretical results in combination with results from neurophysiological characterizations of motion-sensitive visual neurons are also consistent with a previously formulated hypothesis that the simple cells in the primary visual cortex ought to be covariant under local Galilean transformations, so as to enable processing of visual stimuli with different motion directions and speeds.",Neuroscience
"This paper gives an in-depth theoretical analysis of the direction and speed selectivity properties of idealized models of the spatio-temporal receptive fields of simple cells and complex cells, based on the generalized Gaussian derivative model for visual receptive fields. According to this theory, the receptive fields are modelled as velocity-adapted affine Gaussian derivatives for different image velocities and different degrees of elongation. By probing such idealized receptive field models of visual neurons to moving sine waves with different angular frequencies and image velocities, we characterize the computational models to a structurally similar probing method as is used for characterizing the direction and speed selective properties of biological neurons.   By comparison to results of neurophysiological measurements of direction and speed selectivity for biological neurons in the primary visual cortex, we find that our theoretical results are qualitatively consistent with (i) velocity-tuned visual neurons that are sensitive to particular motion directions and speeds, and (ii)~different visual neurons having broader {\em vs.\/}\ sharper direction and speed selective properties. Our theoretical results in combination with results from neurophysiological characterizations of motion-sensitive visual neurons are also consistent with a previously formulated hypothesis that the simple cells in the primary visual cortex ought to be covariant under local Galilean transformations, so as to enable processing of visual stimuli with different motion directions and speeds. [SEP] [HINT] used -> Bioinformatics (Syns: utilize, ill-used, apply) | field -> Materials Science (Syns: field of honor, line of business, orbit) | based -> Bioinformatics (Syns: ground, free-base, base)",Neuroscience
"Graph neural networks (GNNs) are designed to extract latent patterns from graph-structured data, making them particularly well suited for crystal representation learning. Here, we propose a GNN model tailored for estimating electronic transport coefficients in inorganic thermoelectric crystals. The model encodes crystal structures and physicochemical properties in a multiscale manner, encompassing global, atomic, bond, and angular levels. It achieves state-of-the-art performance on benchmark datasets with remarkable extrapolative capability. By combining the proposed GNN with \textit{ab initio} calculations, we successfully identify compounds exhibiting outstanding electronic transport properties and further perform interpretability analyses from both global and atomic perspectives, tracing the origins of their distinct transport behaviors. Interestingly, the decision process of the model naturally reveals underlying physical patterns, offering new insights into computer-assisted materials design.",Materials Science
"Graph neural networks (GNNs) are designed to extract latent patterns from graph-structured data, making them particularly well suited for crystal representation learning. Here, we propose a GNN model tailored for estimating electronic transport coefficients in inorganic thermoelectric crystals. The model encodes crystal structures and physicochemical properties in a multiscale manner, encompassing global, atomic, bond, and angular levels. It achieves state-of-the-art performance on benchmark datasets with remarkable extrapolative capability. By combining the proposed GNN with \textit{ab initio} calculations, we successfully identify compounds exhibiting outstanding electronic transport properties and further perform interpretability analyses from both global and atomic perspectives, tracing the origins of their distinct transport behaviors. Interestingly, the decision process of the model naturally reveals underlying physical patterns, offering new insights into computer-assisted materials design. [SEP] [HINT] transport -> Materials Science (Syns: transferral, enthral, shipping) | networks -> Neuroscience (Syns: network, meshwork, electronic network) | electronic -> Materials Science (Syns: )",Materials Science
"Single-cell technologies generate high-dimensional point clouds of cells, enabling detailed characterization of complex patient states and treatment responses. Yet each patient is represented by an irregular point cloud rather than a simple vector, making it difficult to directly quantify and compare biological differences between individuals. Nonlinear methods such as kernels and neural networks achieve predictive accuracy but act as black boxes, offering little biological interpretability.   To address these limitations, we adapt the Linear Optimal Transport (LOT) framework to this setting, embedding irregular point clouds into a fixed-dimensional Euclidean space while preserving distributional structure. This embedding provides a principled linear representation that preserves optimal transport geometry while enabling downstream analysis. It also forms a registration between any two patients, enabling direct comparison of their cellular distributions. Within this space, LOT enables: (i) \textbf{accurate and interpretable classification} of COVID-19 patient states, where classifier weights map back to specific markers and spatial regions driving predictions; and (ii) \textbf{synthetic data generation} for patient-derived organoids, exploiting the linearity of the LOT embedding. LOT barycenters yield averaged cellular profiles representing combined conditions or samples, supporting drug interaction testing.   Together, these results establish LOT as a unified framework that bridges predictive performance, interpretability, and generative modeling. By transforming heterogeneous point clouds into structured embeddings directly traceable to the original data, LOT opens new opportunities for understanding immune variation and treatment effects in high-dimensional biological systems.",Bioinformatics
"Single-cell technologies generate high-dimensional point clouds of cells, enabling detailed characterization of complex patient states and treatment responses. Yet each patient is represented by an irregular point cloud rather than a simple vector, making it difficult to directly quantify and compare biological differences between individuals. Nonlinear methods such as kernels and neural networks achieve predictive accuracy but act as black boxes, offering little biological interpretability.   To address these limitations, we adapt the Linear Optimal Transport (LOT) framework to this setting, embedding irregular point clouds into a fixed-dimensional Euclidean space while preserving distributional structure. This embedding provides a principled linear representation that preserves optimal transport geometry while enabling downstream analysis. It also forms a registration between any two patients, enabling direct comparison of their cellular distributions. Within this space, LOT enables: (i) \textbf{accurate and interpretable classification} of COVID-19 patient states, where classifier weights map back to specific markers and spatial regions driving predictions; and (ii) \textbf{synthetic data generation} for patient-derived organoids, exploiting the linearity of the LOT embedding. LOT barycenters yield averaged cellular profiles representing combined conditions or samples, supporting drug interaction testing.   Together, these results establish LOT as a unified framework that bridges predictive performance, interpretability, and generative modeling. By transforming heterogeneous point clouds into structured embeddings directly traceable to the original data, LOT opens new opportunities for understanding immune variation and treatment effects in high-dimensional biological systems. [SEP] [HINT] understanding -> Neuroscience (Syns: savvy, intellect, sympathy) | transport -> Materials Science (Syns: transferral, enthral, shipping) | networks -> Neuroscience (Syns: network, meshwork, electronic network)",Bioinformatics
"Blini is a tool for quick lookup of nucleotide sequences in databases, and for quick dereplication of sequence collections. It is meant to help clean and characterize large collections of assembled contigs or long sequences that would otherwise be too big to search with online tools, or too demanding for a local machine to process. Benchmarks on simulated data demonstrate that it is faster than existing tools and requires less RAM, while preserving search and clustering accuracy.",Bioinformatics
"Blini is a tool for quick lookup of nucleotide sequences in databases, and for quick dereplication of sequence collections. It is meant to help clean and characterize large collections of assembled contigs or long sequences that would otherwise be too big to search with online tools, or too demanding for a local machine to process. Benchmarks on simulated data demonstrate that it is faster than existing tools and requires less RAM, while preserving search and clustering accuracy. [SEP] [HINT] demonstrate -> Bioinformatics (Syns: evidence, march, prove) | data -> Bioinformatics (Syns: data point, information, datum) | large -> Bioinformatics (Syns: prominent, great, tumid)",Bioinformatics
"Many proteins useful in modern medicine or bioengineering are challenging to make in the lab, fuse with other proteins in cells, or deliver to tissues in the body, because their sequences are too long. Shortening these sequences typically involves costly, time-consuming experimental campaigns. Ideally, we could instead use modern models of massive databases of sequences from nature to learn how to propose shrunken proteins that resemble sequences found in nature. Unfortunately, these models struggle to efficiently search the combinatorial space of all deletions, and are not trained with inductive biases to learn how to delete. To address this gap, we propose SCISOR, a novel discrete diffusion model that deletes letters from sequences to generate protein samples that resemble those found in nature. To do so, SCISOR trains a de-noiser to reverse a forward noising process that adds random insertions to natural sequences. As a generative model, SCISOR fits evolutionary sequence data competitively with previous large models. In evaluation, SCISOR achieves state-of-the-art predictions of the functional effects of deletions on ProteinGym. Finally, we use the SCISOR de-noiser to shrink long protein sequences, and show that its suggested deletions result in significantly more realistic proteins and more often preserve functional motifs than previous models of evolutionary sequences.",Bioinformatics
"Many proteins useful in modern medicine or bioengineering are challenging to make in the lab, fuse with other proteins in cells, or deliver to tissues in the body, because their sequences are too long. Shortening these sequences typically involves costly, time-consuming experimental campaigns. Ideally, we could instead use modern models of massive databases of sequences from nature to learn how to propose shrunken proteins that resemble sequences found in nature. Unfortunately, these models struggle to efficiently search the combinatorial space of all deletions, and are not trained with inductive biases to learn how to delete. To address this gap, we propose SCISOR, a novel discrete diffusion model that deletes letters from sequences to generate protein samples that resemble those found in nature. To do so, SCISOR trains a de-noiser to reverse a forward noising process that adds random insertions to natural sequences. As a generative model, SCISOR fits evolutionary sequence data competitively with previous large models. In evaluation, SCISOR achieves state-of-the-art predictions of the functional effects of deletions on ProteinGym. Finally, we use the SCISOR de-noiser to shrink long protein sequences, and show that its suggested deletions result in significantly more realistic proteins and more often preserve functional motifs than previous models of evolutionary sequences. [SEP] [HINT] space -> Neuroscience (Syns: distance, place, outer space) | functional -> Neuroscience (Syns: working, usable, running) | protein -> Bioinformatics (Syns: )",Bioinformatics
"Wuchereria bancrofti, the parasitic roundworm responsible for lymphatic filariasis, permanently disables over 36 million people and places 657 million at risk across 39 countries. A major bottleneck for drug discovery is the lack of functional annotation for more than 90 percent of the W. bancrofti dark proteome, leaving many potential targets unidentified. In this work, we present a novel computational pipeline that converts W. bancrofti's unannotated amino acid sequence data into precise four-level Enzyme Commission (EC) numbers and drug candidates. We utilized a DEtection TRansformer to estimate the probability of enzymatic function, fine-tuned a hierarchical nearest neighbor EC predictor on 4,476 labeled parasite proteins, and applied rejection sampling to retain only four-level EC classifications at 100 percent confidence. This pipeline assigned precise EC numbers to 14,772 previously uncharacterized proteins and discovered 543 EC classes not previously known in W. bancrofti. A qualitative triage emphasizing parasite-specific targets, chemical tractability, biochemical importance, and biological plausibility prioritized six enzymes across five separate strategies: anti-Wolbachia cell-wall inhibition, proteolysis blockade, transmission disruption, purinergic immune interference, and cGMP-signaling destabilization. We curated a 43-compound library from ChEMBL and BindingDB and co-folded across multiple protein conformers with Boltz-2. All six targets exhibited at least moderately strong predicted binding affinities below 1 micromolar, with moenomycin analogs against peptidoglycan glycosyltransferase and NTPase inhibitors showing promising nanomolar hits and well-defined binding pockets. While experimental validation remains essential, our results provide the first large-scale functional map of the W. bancrofti dark proteome and accelerate early-stage drug development for the species.",Bioinformatics
"Wuchereria bancrofti, the parasitic roundworm responsible for lymphatic filariasis, permanently disables over 36 million people and places 657 million at risk across 39 countries. A major bottleneck for drug discovery is the lack of functional annotation for more than 90 percent of the W. bancrofti dark proteome, leaving many potential targets unidentified. In this work, we present a novel computational pipeline that converts W. bancrofti's unannotated amino acid sequence data into precise four-level Enzyme Commission (EC) numbers and drug candidates. We utilized a DEtection TRansformer to estimate the probability of enzymatic function, fine-tuned a hierarchical nearest neighbor EC predictor on 4,476 labeled parasite proteins, and applied rejection sampling to retain only four-level EC classifications at 100 percent confidence. This pipeline assigned precise EC numbers to 14,772 previously uncharacterized proteins and discovered 543 EC classes not previously known in W. bancrofti. A qualitative triage emphasizing parasite-specific targets, chemical tractability, biochemical importance, and biological plausibility prioritized six enzymes across five separate strategies: anti-Wolbachia cell-wall inhibition, proteolysis blockade, transmission disruption, purinergic immune interference, and cGMP-signaling destabilization. We curated a 43-compound library from ChEMBL and BindingDB and co-folded across multiple protein conformers with Boltz-2. All six targets exhibited at least moderately strong predicted binding affinities below 1 micromolar, with moenomycin analogs against peptidoglycan glycosyltransferase and NTPase inhibitors showing promising nanomolar hits and well-defined binding pockets. While experimental validation remains essential, our results provide the first large-scale functional map of the W. bancrofti dark proteome and accelerate early-stage drug development for the species. [SEP] [HINT] computational -> Neuroscience (Syns: ) | functional -> Neuroscience (Syns: working, usable, running) | results -> Bioinformatics (Syns: final result, consequence, resultant role)",Bioinformatics
"We propose that consciousness arises from a single control agent, the Modeler-schema. It monitors the brain's Modeler as that system constructs and updates the internal World Model. As part of that monitoring, the Modeler-schema generates experience by applying a qualia-based consistency check to the Modeler's output. The Human Agent comprises three cooperating agents: Modeler, Controller, and Targeter, each paired with an associated regulatory ""schema"" agent. We also describe fast-Modelers and fast-Controllers; evolutionary shortcuts whose rapid actions will precede awareness. Our core prediction is that the Modeler-schema performs a qualia-based consistency check during saccades and issues a bottom-up target when a discrepancy is found. To test this prediction, we propose a saccadic change-detection experiment that distinguishes Modeler-generated from Modeler-schema-generated targets. Locating qualia in the Modeler-schema ties experience to the regulation and refinement of internal representations, clarifies how awareness arises from model control, and suggests a path toward empirical falsification, thereby offering a concrete, testable proposal toward solving the Hard Problem of consciousness.",Neuroscience
"We propose that consciousness arises from a single control agent, the Modeler-schema. It monitors the brain's Modeler as that system constructs and updates the internal World Model. As part of that monitoring, the Modeler-schema generates experience by applying a qualia-based consistency check to the Modeler's output. The Human Agent comprises three cooperating agents: Modeler, Controller, and Targeter, each paired with an associated regulatory ""schema"" agent. We also describe fast-Modelers and fast-Controllers; evolutionary shortcuts whose rapid actions will precede awareness. Our core prediction is that the Modeler-schema performs a qualia-based consistency check during saccades and issues a bottom-up target when a discrepancy is found. To test this prediction, we propose a saccadic change-detection experiment that distinguishes Modeler-generated from Modeler-schema-generated targets. Locating qualia in the Modeler-schema ties experience to the regulation and refinement of internal representations, clarifies how awareness arises from model control, and suggests a path toward empirical falsification, thereby offering a concrete, testable proposal toward solving the Hard Problem of consciousness. [SEP] [HINT] human -> Neuroscience (Syns: human being, man, homo) | model -> Bioinformatics (Syns: exemplary, framework, modelling) | single -> Bioinformatics (Syns: undivided, exclusive, bingle)",Neuroscience
"Sleep disorders have emerged as a critical global health issue, highlighting the urgent need for effective and widely accessible intervention technologies. Non-invasive brain stimulation has garnered attention as it enables direct or indirect modulation of neural activity, thereby promoting sleep enhancement in a safe and unobtrusive manner. This class of approaches is collectively referred to as sleep modulation. To date, the majority of sleep modulation research relies on open-loop paradigms with empirically determined parameters, while achieving individual adaptation and modulation accuracy remains a distant objective. The paradigm-specific constraints inherent to open-loop designs represent a major obstacle to clinical translation and large-scale deployment in home environments. In this paper, we delineate fundamental paradigms of sleep modulation, critically examine the intrinsic limitations of open-loop approaches, and formally conceptualize sleep closed-loop modulation. We further provide a comprehensive synthesis of prior studies involving five commonly employed modulation techniques, evaluating their potential integration within a closed-loop framework. Finally, we identify three primary challenges in constructing an effective sleep closed-loop modulation system: sensor solution selection, monitoring model design, and modulation strategy design, while also proposing potential solutions. Collectively, this work aims to advance the paradigm shift of sleep modulation from open-loop toward closed-loop systems.",Neuroscience
"Sleep disorders have emerged as a critical global health issue, highlighting the urgent need for effective and widely accessible intervention technologies. Non-invasive brain stimulation has garnered attention as it enables direct or indirect modulation of neural activity, thereby promoting sleep enhancement in a safe and unobtrusive manner. This class of approaches is collectively referred to as sleep modulation. To date, the majority of sleep modulation research relies on open-loop paradigms with empirically determined parameters, while achieving individual adaptation and modulation accuracy remains a distant objective. The paradigm-specific constraints inherent to open-loop designs represent a major obstacle to clinical translation and large-scale deployment in home environments. In this paper, we delineate fundamental paradigms of sleep modulation, critically examine the intrinsic limitations of open-loop approaches, and formally conceptualize sleep closed-loop modulation. We further provide a comprehensive synthesis of prior studies involving five commonly employed modulation techniques, evaluating their potential integration within a closed-loop framework. Finally, we identify three primary challenges in constructing an effective sleep closed-loop modulation system: sensor solution selection, monitoring model design, and modulation strategy design, while also proposing potential solutions. Collectively, this work aims to advance the paradigm shift of sleep modulation from open-loop toward closed-loop systems. [SEP] [HINT] clinical -> Bioinformatics (Syns: ) | work -> Bioinformatics (Syns: work out, process, bring) | potential -> Bioinformatics (Syns: voltage, potential difference, electric potential)",Neuroscience
"Dream2Image is the world's first dataset combining EEG signals, dream transcriptions, and AI-generated images. Based on 38 participants and more than 31 hours of dream EEG recordings, it contains 129 samples offering: the final seconds of brain activity preceding awakening (T-15, T-30, T-60, T-120), raw reports of dream experiences, and an approximate visual reconstruction of the dream. This dataset provides a novel resource for dream research, a unique resource to study the neural correlates of dreaming, to develop models for decoding dreams from brain activity, and to explore new approaches in neuroscience, psychology, and artificial intelligence. Available in open access on Hugging Face and GitHub, Dream2Image provides a multimodal resource designed to support research at the interface of artificial intelligence and neuroscience. It was designed to inspire researchers and extend the current approaches to brain activity decoding. Limitations include the relatively small sample size and the variability of dream recall, which may affect generalizability.",Neuroscience
"Dream2Image is the world's first dataset combining EEG signals, dream transcriptions, and AI-generated images. Based on 38 participants and more than 31 hours of dream EEG recordings, it contains 129 samples offering: the final seconds of brain activity preceding awakening (T-15, T-30, T-60, T-120), raw reports of dream experiences, and an approximate visual reconstruction of the dream. This dataset provides a novel resource for dream research, a unique resource to study the neural correlates of dreaming, to develop models for decoding dreams from brain activity, and to explore new approaches in neuroscience, psychology, and artificial intelligence. Available in open access on Hugging Face and GitHub, Dream2Image provides a multimodal resource designed to support research at the interface of artificial intelligence and neuroscience. It was designed to inspire researchers and extend the current approaches to brain activity decoding. Limitations include the relatively small sample size and the variability of dream recall, which may affect generalizability. [SEP] [HINT] decoding -> Neuroscience (Syns: decrypt, decipherment, decryption) | based -> Bioinformatics (Syns: ground, free-base, base) | visual -> Neuroscience (Syns: optical, ocular, optic)",Neuroscience
"Hybrid organic--inorganic perovskites with broken inversion symmetry provide a fertile ground for uncovering coupled spin-orbit and ferroelectric phenomena. Here, we investigate the layered family (PA)$_2$CsY$_2$X$_7$ (Y = Pb, Sn; X = I, Br) using density functional theory, Berry-phase polarization analysis, and effective $\boldsymbol{k \cdot p}$ modeling. Across all four members, we find indirect bandgaps with extrema near $Γ$, sizable spin splittings at both band edges, and robust in-plane ferroelectric polarization that stabilizes out-of-plane persistent spin textures (PSTs). Crucially, polarization reversal switches the spin orientation, enabling electrical control of PSTs and thereby non-volatile manipulation of spin states. These results establish (PA)$_2$CsY$_2$X$_7$ as a versatile materials platform where compositional design and ferroelectric switching jointly enable spintronic functionality.",Materials Science
"Hybrid organic--inorganic perovskites with broken inversion symmetry provide a fertile ground for uncovering coupled spin-orbit and ferroelectric phenomena. Here, we investigate the layered family (PA)$_2$CsY$_2$X$_7$ (Y = Pb, Sn; X = I, Br) using density functional theory, Berry-phase polarization analysis, and effective $\boldsymbol{k \cdot p}$ modeling. Across all four members, we find indirect bandgaps with extrema near $Γ$, sizable spin splittings at both band edges, and robust in-plane ferroelectric polarization that stabilizes out-of-plane persistent spin textures (PSTs). Crucially, polarization reversal switches the spin orientation, enabling electrical control of PSTs and thereby non-volatile manipulation of spin states. These results establish (PA)$_2$CsY$_2$X$_7$ as a versatile materials platform where compositional design and ferroelectric switching jointly enable spintronic functionality. [SEP] [HINT] spin -> Materials Science (Syns: twisting, whirl, tailspin) | functional -> Neuroscience (Syns: working, usable, running) | results -> Bioinformatics (Syns: final result, consequence, resultant role)",Materials Science
"Study Objectives: Wrist accelerometry is widely used for inferring sleep-wake state. Previous works demonstrated poor wake detection, without cross-device generalizability and validation in different age range and sleep disorders. We developed a robust deep learning model for to detect sleep-wakefulness from triaxial accelerometry and evaluated its validity across three devices and in a large adult population spanning a wide range of ages with and without sleep disorders. Methods: We collected wrist accelerometry simultaneous to polysomnography (PSG) in 453 adults undergoing clinical sleep testing at a tertiary care sleep laboratory, using three devices. We extracted features in 30-second epochs and trained a 3-class model to detect wake, sleep, and sleep with arousals, which was then collapsed into wake vs. sleep using a decision tree. To enhance wake detection, the model was specifically trained on randomly selected subjects with low sleep efficiency and/or high arousal index from one device recording and then tested on the remaining recordings. Results: The model showed high performance with F1 Score of 0.86, sensitivity (sleep) of 0.87, and specificity (wakefulness) of 0.78, and significant and moderate correlation to PSG in predicting total sleep time (R=0.69) and sleep efficiency (R=0.63). Model performance was robust to the presence of sleep disorders, including sleep apnea and periodic limb movements in sleep, and was consistent across all three models of accelerometer. Conclusions: We present a deep model to detect sleep-wakefulness from actigraphy in adults with relative robustness to the presence of sleep disorders and generalizability across diverse commonly used wrist accelerometers.",Bioinformatics
"Study Objectives: Wrist accelerometry is widely used for inferring sleep-wake state. Previous works demonstrated poor wake detection, without cross-device generalizability and validation in different age range and sleep disorders. We developed a robust deep learning model for to detect sleep-wakefulness from triaxial accelerometry and evaluated its validity across three devices and in a large adult population spanning a wide range of ages with and without sleep disorders. Methods: We collected wrist accelerometry simultaneous to polysomnography (PSG) in 453 adults undergoing clinical sleep testing at a tertiary care sleep laboratory, using three devices. We extracted features in 30-second epochs and trained a 3-class model to detect wake, sleep, and sleep with arousals, which was then collapsed into wake vs. sleep using a decision tree. To enhance wake detection, the model was specifically trained on randomly selected subjects with low sleep efficiency and/or high arousal index from one device recording and then tested on the remaining recordings. Results: The model showed high performance with F1 Score of 0.86, sensitivity (sleep) of 0.87, and specificity (wakefulness) of 0.78, and significant and moderate correlation to PSG in predicting total sleep time (R=0.69) and sleep efficiency (R=0.63). Model performance was robust to the presence of sleep disorders, including sleep apnea and periodic limb movements in sleep, and was consistent across all three models of accelerometer. Conclusions: We present a deep model to detect sleep-wakefulness from actigraphy in adults with relative robustness to the presence of sleep disorders and generalizability across diverse commonly used wrist accelerometers. [SEP] [HINT] used -> Bioinformatics (Syns: utilize, ill-used, apply) | low -> Materials Science (Syns: low-spirited, scurvy, depressed) | clinical -> Bioinformatics (Syns: )",Bioinformatics
"In the classic view of cortical rhythms, the interaction between excitatory pyramidal neurons (E) and inhibitory parvalbumin neurons (I) has been shown to be sufficient to generate gamma and beta band rhythms. However, it is now clear that there are multiple inhibitory interneuron subtypes and that they play important roles in the generation of these rhythms. In this paper we develop a spiking network that consists of populations of E, I and an additional interneuron type, the somatostatin (S) internerons that receive excitation from the E cells and inhibit both the E cells and the I cells. These S cells are modulated by a third inhibitory subtype, VIP neurons that receive inputs from other cortical areas. We reduce the spiking network to a system of nine differential equations that characterize the mean voltage, firing rate, and synaptic conductance for each population and using this we find many instances of multiple rhythms within the network. Using tools from nonlinear dynamics, we explore the roles of each of the two classes of inhibition as well as the role of the VIP modulation on the properties of these rhythms.",Neuroscience
"In the classic view of cortical rhythms, the interaction between excitatory pyramidal neurons (E) and inhibitory parvalbumin neurons (I) has been shown to be sufficient to generate gamma and beta band rhythms. However, it is now clear that there are multiple inhibitory interneuron subtypes and that they play important roles in the generation of these rhythms. In this paper we develop a spiking network that consists of populations of E, I and an additional interneuron type, the somatostatin (S) internerons that receive excitation from the E cells and inhibit both the E cells and the I cells. These S cells are modulated by a third inhibitory subtype, VIP neurons that receive inputs from other cortical areas. We reduce the spiking network to a system of nine differential equations that characterize the mean voltage, firing rate, and synaptic conductance for each population and using this we find many instances of multiple rhythms within the network. Using tools from nonlinear dynamics, we explore the roles of each of the two classes of inhibition as well as the role of the VIP modulation on the properties of these rhythms. [SEP] [HINT] cortical -> Neuroscience (Syns: ) | using -> Bioinformatics (Syns: utilize, exploitation, apply) | band -> Materials Science (Syns: set, stria, dance orchestra)",Neuroscience
"Diffusion-based models have recently enabled the generation of realistic and diverse protein structures, yet they remain limited in their ability to steer outcomes toward specific functional or biochemical objectives, such as binding affinity or sequence composition. Here we extend the Feynman-Kac (FK) steering framework, an inference-time control approach, to diffusion-based protein design. By coupling FK steering with structure generation, the method guides sampling toward desirable structural or energetic features while maintaining the diversity of the underlying diffusion process. To enable simultaneous generation of both sequence and structure properties, rewards are computed on models refined through ProteinMPNN and all-atom relaxation. Applied to binder design, FK steering consistently improves predicted interface energetics across diverse targets with minimal computational overhead. More broadly, this work demonstrates that inference-time FK control generalizes diffusion-based protein design to arbitrary, non-differentiable, and reward-agnostic objectives, providing a unified and model-independent framework for guided molecular generation.",Bioinformatics
"Diffusion-based models have recently enabled the generation of realistic and diverse protein structures, yet they remain limited in their ability to steer outcomes toward specific functional or biochemical objectives, such as binding affinity or sequence composition. Here we extend the Feynman-Kac (FK) steering framework, an inference-time control approach, to diffusion-based protein design. By coupling FK steering with structure generation, the method guides sampling toward desirable structural or energetic features while maintaining the diversity of the underlying diffusion process. To enable simultaneous generation of both sequence and structure properties, rewards are computed on models refined through ProteinMPNN and all-atom relaxation. Applied to binder design, FK steering consistently improves predicted interface energetics across diverse targets with minimal computational overhead. More broadly, this work demonstrates that inference-time FK control generalizes diffusion-based protein design to arbitrary, non-differentiable, and reward-agnostic objectives, providing a unified and model-independent framework for guided molecular generation. [SEP] [HINT] computational -> Neuroscience (Syns: ) | features -> Bioinformatics (Syns: characteristic, lineament, feature of speech) | functional -> Neuroscience (Syns: working, usable, running)",Bioinformatics
"The performance of Large Language Models (LLMs) often degrades when crucial information is in the middle of a long context, a ""lost-in-the-middle"" phenomenon that mirrors the primacy and recency effects in human memory. We propose that this behavior is not simply a flaw indicative of information loss but an adaptation to different information retrieval demands during pre-training: some tasks require uniform recall across the entire input (a long-term memory demand), while others prioritize the most recent information (a short-term memory demand). Consistent with this view, we show that this U-shaped performance curve emerges when LLMs (GPT-2 and Llama variants) are trained from scratch on two simple human memory paradigms simulating long-term and short-term memory demands. Our analysis reveals that while the recency effect directly aligns with short-term memory demand in the training data, the primacy effect is induced by the uniform long-term memory demand and is additionally influenced by the model's autoregressive properties and the formation of attention sinks. Our main findings from simple human memory paradigms also generalize to a sequence completion task, which more closely resembles the next-token prediction process in LLM pre-training. Together, our findings reveal how information retrieval demands, model architecture, and structural attention dynamics during model training can jointly produce positional bias observed in LLMs.",Neuroscience
"The performance of Large Language Models (LLMs) often degrades when crucial information is in the middle of a long context, a ""lost-in-the-middle"" phenomenon that mirrors the primacy and recency effects in human memory. We propose that this behavior is not simply a flaw indicative of information loss but an adaptation to different information retrieval demands during pre-training: some tasks require uniform recall across the entire input (a long-term memory demand), while others prioritize the most recent information (a short-term memory demand). Consistent with this view, we show that this U-shaped performance curve emerges when LLMs (GPT-2 and Llama variants) are trained from scratch on two simple human memory paradigms simulating long-term and short-term memory demands. Our analysis reveals that while the recency effect directly aligns with short-term memory demand in the training data, the primacy effect is induced by the uniform long-term memory demand and is additionally influenced by the model's autoregressive properties and the formation of attention sinks. Our main findings from simple human memory paradigms also generalize to a sequence completion task, which more closely resembles the next-token prediction process in LLM pre-training. Together, our findings reveal how information retrieval demands, model architecture, and structural attention dynamics during model training can jointly produce positional bias observed in LLMs. [SEP] [HINT] tasks -> Neuroscience (Syns: tax, task, project) | language -> Neuroscience (Syns: linguistic process, linguistic communication, spoken communication) | information -> Bioinformatics (Syns: entropy, data, info)",Neuroscience
"Low-energy molecular conformers generation (MCG) is a foundational yet challenging problem in drug discovery. Denoising-based methods include diffusion and flow-matching methods that learn mappings from a simple base distribution to the molecular conformer distribution. However, these approaches often suffer from error accumulation during sampling, especially in the low SNR steps, which are hard to train. To address these challenges, we propose a flow-matching refiner for the MCG task. The proposed method initializes sampling from mixed-quality outputs produced by upstream denoising models and reschedules the noise scale to bypass the low-SNR phase, thereby improving sample quality. On the GEOM-QM9 and GEOM-Drugs benchmark datasets, the generator-refiner pipeline improves quality with fewer total denoising steps while preserving diversity.",Bioinformatics
"Low-energy molecular conformers generation (MCG) is a foundational yet challenging problem in drug discovery. Denoising-based methods include diffusion and flow-matching methods that learn mappings from a simple base distribution to the molecular conformer distribution. However, these approaches often suffer from error accumulation during sampling, especially in the low SNR steps, which are hard to train. To address these challenges, we propose a flow-matching refiner for the MCG task. The proposed method initializes sampling from mixed-quality outputs produced by upstream denoising models and reschedules the noise scale to bypass the low-SNR phase, thereby improving sample quality. On the GEOM-QM9 and GEOM-Drugs benchmark datasets, the generator-refiner pipeline improves quality with fewer total denoising steps while preserving diversity. [SEP] [HINT] low -> Materials Science (Syns: low-spirited, scurvy, depressed) | molecular -> Bioinformatics (Syns: ) | quality -> Bioinformatics (Syns: lineament, tone, calibre)",Bioinformatics
"The complexity of human cognition has meant that psychology makes more use of theory and conceptual models than perhaps any other biomedical field. To enable precise quantitative study of the full breadth of phenomena in psychological and psychiatric medicine as well as cognitive aspects of AI safety, there is a need for a mathematical formulation which is both mathematically precise and equally accessible to experts from numerous fields. In this paper we formalize human psychodynamics via the diagrammatic framework of process theory, describe its key properties, and explain the links between a diagrammatic representation and central concepts in analysis of cognitive processes in contexts such as psychotherapy, neurotechnology, AI alignment, AI agent representation of individuals in autonomous negotiations, developing human-like AI systems, and other aspects of AI safety.",Neuroscience
"The complexity of human cognition has meant that psychology makes more use of theory and conceptual models than perhaps any other biomedical field. To enable precise quantitative study of the full breadth of phenomena in psychological and psychiatric medicine as well as cognitive aspects of AI safety, there is a need for a mathematical formulation which is both mathematically precise and equally accessible to experts from numerous fields. In this paper we formalize human psychodynamics via the diagrammatic framework of process theory, describe its key properties, and explain the links between a diagrammatic representation and central concepts in analysis of cognitive processes in contexts such as psychotherapy, neurotechnology, AI alignment, AI agent representation of individuals in autonomous negotiations, developing human-like AI systems, and other aspects of AI safety. [SEP] [HINT] human -> Neuroscience (Syns: human being, man, homo) | framework -> Bioinformatics (Syns: theoretical account, model, fabric) | theory -> Materials Science (Syns: possibility, hypothesis)",Neuroscience
"Spin current generation through non-relativistic spin splittings, found in uncompensated magnets and d-wave altermagnets, is desirable for low-power spintronics. Such spin currents, however, are symmetry forbidden in conventional collinear antiferromagnets and higher-order altermagnets. Using spin point group analysis, we demonstrate that finite spin currents can be induced in these materials via magnetoelectric, piezomagnetic, and piezomagnetoelectric-like couplings. We utilize electric fields, strain, and their combinations to drive symmetry-lowering phase transitions into uncompensated magnetic or d-wave altermagnetic states, thereby enabling finite spin conductivity in a broader class of magnetic materials. We further substantiate this framework using density functional theory and Boltzmann transport calculations on representative magnetic materials - KV2Se2O, RuF4 , Cr2O3 , FeS2 , and MnPSe3 - spanning these different cases. The charge-to-spin conversion ratio reaches up to almost 100% via uncompensated magnetism and about 40% via d-wave altermagnetism under realistic conditions, highlighting the effectiveness of this approach for efficient spin current generation.",Materials Science
"Spin current generation through non-relativistic spin splittings, found in uncompensated magnets and d-wave altermagnets, is desirable for low-power spintronics. Such spin currents, however, are symmetry forbidden in conventional collinear antiferromagnets and higher-order altermagnets. Using spin point group analysis, we demonstrate that finite spin currents can be induced in these materials via magnetoelectric, piezomagnetic, and piezomagnetoelectric-like couplings. We utilize electric fields, strain, and their combinations to drive symmetry-lowering phase transitions into uncompensated magnetic or d-wave altermagnetic states, thereby enabling finite spin conductivity in a broader class of magnetic materials. We further substantiate this framework using density functional theory and Boltzmann transport calculations on representative magnetic materials - KV2Se2O, RuF4 , Cr2O3 , FeS2 , and MnPSe3 - spanning these different cases. The charge-to-spin conversion ratio reaches up to almost 100% via uncompensated magnetism and about 40% via d-wave altermagnetism under realistic conditions, highlighting the effectiveness of this approach for efficient spin current generation. [SEP] [HINT] spin -> Materials Science (Syns: twisting, whirl, tailspin) | transport -> Materials Science (Syns: transferral, enthral, shipping) | functional -> Neuroscience (Syns: working, usable, running)",Materials Science
"Understanding how neuronal dynamics couple with stimuli space and how receptive fields emerge and organize within brain networks remains a fundamental challenge in neuroscience. Several models attempted to explain these phenomena, often by adjusting the network to empirical manifestations, but struggled to achieve biological plausibility. Here, we propose a physiologically grounded model in which receptive fields and population-level attractor dynamics emerge naturally from the effective hyperbolic geometry of scale-free networks. In particular, we associate stimulus space with the boundary of a hyperbolic embedding, and study the resulting neural dynamics in both rate-based and spiking implementations. The resulting localized attractors faithfully reflect the structure of the stimulus space and capture key properties of the receptive fields without fine-tuning of local connectivity, exhibiting a direct relation between a neuron's connectivity degree and the corresponding receptive field size. The model generalizes to stimulus spaces of arbitrary dimensionality and scale, encompassing various modalities, such as orientation and place selectivity. We also provide direct experimental evidence in support of these results, based on analyses of hippocampal place fields recorded on a linear track. Overall, our framework offers a novel organizing principle for receptive field formation and establishes a direct link between network structure, stimulus space encoding, and neural dynamics.",Neuroscience
"Understanding how neuronal dynamics couple with stimuli space and how receptive fields emerge and organize within brain networks remains a fundamental challenge in neuroscience. Several models attempted to explain these phenomena, often by adjusting the network to empirical manifestations, but struggled to achieve biological plausibility. Here, we propose a physiologically grounded model in which receptive fields and population-level attractor dynamics emerge naturally from the effective hyperbolic geometry of scale-free networks. In particular, we associate stimulus space with the boundary of a hyperbolic embedding, and study the resulting neural dynamics in both rate-based and spiking implementations. The resulting localized attractors faithfully reflect the structure of the stimulus space and capture key properties of the receptive fields without fine-tuning of local connectivity, exhibiting a direct relation between a neuron's connectivity degree and the corresponding receptive field size. The model generalizes to stimulus spaces of arbitrary dimensionality and scale, encompassing various modalities, such as orientation and place selectivity. We also provide direct experimental evidence in support of these results, based on analyses of hippocampal place fields recorded on a linear track. Overall, our framework offers a novel organizing principle for receptive field formation and establishes a direct link between network structure, stimulus space encoding, and neural dynamics. [SEP] [HINT] field -> Materials Science (Syns: field of honor, line of business, orbit) | connectivity -> Neuroscience (Syns: ) | based -> Bioinformatics (Syns: ground, free-base, base)",Neuroscience
"Opposing the theory that Helium (He) cannot be inserted into AB-type ionic compounds due to the Madelung energy increase, our crystal structure search and first-principles calculations found that He can form stable compounds with sodium halides (NaX, X=Cl, Br, I) under high-pressure. These reactions are driven by the non-local chemistry arising from the cation-anion size disparity, distinctly different from the He insertion reaction with A2B-type compounds. The large size differences between Na+ and X- enable structures that can effectively host He insertions through volume and inter-atomic distance disproportionation. Furthermore, the insertion of He atoms can significantly relieve the elevated Madelung energy that builds up in NaX under high pressure. This energy increase arises from structural transitions driven by cation-anion size disparity, which are necessary for reducing volume under pressure. The insertion of He allows the reduction of the total volume under high pressure without increasing the Madelung energy. Our predicted compounds and stability analysis reveal a new example of He reactivity governed not by local chemical bond formation, but by long-range electrostatic interactions.",Materials Science
"Opposing the theory that Helium (He) cannot be inserted into AB-type ionic compounds due to the Madelung energy increase, our crystal structure search and first-principles calculations found that He can form stable compounds with sodium halides (NaX, X=Cl, Br, I) under high-pressure. These reactions are driven by the non-local chemistry arising from the cation-anion size disparity, distinctly different from the He insertion reaction with A2B-type compounds. The large size differences between Na+ and X- enable structures that can effectively host He insertions through volume and inter-atomic distance disproportionation. Furthermore, the insertion of He atoms can significantly relieve the elevated Madelung energy that builds up in NaX under high pressure. This energy increase arises from structural transitions driven by cation-anion size disparity, which are necessary for reducing volume under pressure. The insertion of He allows the reduction of the total volume under high pressure without increasing the Madelung energy. Our predicted compounds and stability analysis reveal a new example of He reactivity governed not by local chemical bond formation, but by long-range electrostatic interactions. [SEP] [HINT] structure -> Bioinformatics (Syns: social system, complex body part, social structure) | different -> Neuroscience (Syns: unlike, dissimilar) | crystal -> Materials Science (Syns: crystallization, quartz, lechatelierite)",Materials Science
"Background and objective: Spatial transcriptomics provides rich spatial context but lacks sufficient resolution for large-scale causal inference. We developed SpeF-Phixer, a spatially extended phi-mixing framework integrating whole-slide image (WSI)-derived spatial cell distributions with mapped scRNA-seq expression fields to infer directed gene regulatory triplets with spatial coherence. Methods: Using CD103/CD8-immunostained colorectal cancer WSIs and publicly available scRNA-seq datasets, spatial gene fields were constructed around mapped cells and discretized for signed phi-mixing computation. Pairwise dependencies, directional signs, and triplet structures were evaluated through kNN-based neighborhood screening and bootstrap consensus inference. Mediation and convergence were distinguished using generalized additive models (GAMs), with spatial validity assessed by real-null comparisons and database-backed direction checks. Results: Across tissue patches, the pipeline reduced approximately 3.6x10^4 triplet candidates to a reproducible consensus set (approximately 3x10^2 per patch). The downstream edge (Y to Z) showed significant directional bias consistent with curated regulatory databases. Spatial path tracing demonstrated markedly higher coherence for real triplets than for null controls, indicating that inferred chains represent biologically instantiated regulatory flows. Conclusion: SpeF-Phixer extracts spatially coherent, directionally consistent gene regulatory triplets from histological images. This framework bridges single-cell molecular profiles with microenvironmental organization and provides a scalable foundation for constructing spatially informed causal gene networks.",Bioinformatics
"Background and objective: Spatial transcriptomics provides rich spatial context but lacks sufficient resolution for large-scale causal inference. We developed SpeF-Phixer, a spatially extended phi-mixing framework integrating whole-slide image (WSI)-derived spatial cell distributions with mapped scRNA-seq expression fields to infer directed gene regulatory triplets with spatial coherence. Methods: Using CD103/CD8-immunostained colorectal cancer WSIs and publicly available scRNA-seq datasets, spatial gene fields were constructed around mapped cells and discretized for signed phi-mixing computation. Pairwise dependencies, directional signs, and triplet structures were evaluated through kNN-based neighborhood screening and bootstrap consensus inference. Mediation and convergence were distinguished using generalized additive models (GAMs), with spatial validity assessed by real-null comparisons and database-backed direction checks. Results: Across tissue patches, the pipeline reduced approximately 3.6x10^4 triplet candidates to a reproducible consensus set (approximately 3x10^2 per patch). The downstream edge (Y to Z) showed significant directional bias consistent with curated regulatory databases. Spatial path tracing demonstrated markedly higher coherence for real triplets than for null controls, indicating that inferred chains represent biologically instantiated regulatory flows. Conclusion: SpeF-Phixer extracts spatially coherent, directionally consistent gene regulatory triplets from histological images. This framework bridges single-cell molecular profiles with microenvironmental organization and provides a scalable foundation for constructing spatially informed causal gene networks. [SEP] [HINT] tissue -> Bioinformatics (Syns: tissue paper, weave) | molecular -> Bioinformatics (Syns: ) | framework -> Bioinformatics (Syns: theoretical account, model, fabric)",Bioinformatics
"Predicting future brain state from a baseline magnetic resonance image (MRI) is a central challenge in neuroimaging and has important implications for studying neurodegenerative diseases such as Alzheimer's disease (AD). Most existing approaches predict future cognitive scores or clinical outcomes, such as conversion from mild cognitive impairment to dementia. Instead, here we investigate longitudinal MRI image-to-image prediction that forecasts a participant's entire brain MRI several years into the future, intrinsically modeling complex, spatially distributed neurodegenerative patterns. We implement and evaluate five deep learning architectures (UNet, U2-Net, UNETR, Time-Embedding UNet, and ODE-UNet) on two longitudinal cohorts (ADNI and AIBL). Predicted follow-up MRIs are directly compared with the actual follow-up scans using metrics that capture global similarity and local differences. The best performing models achieve high-fidelity predictions, and all models generalize well to an independent external dataset, demonstrating robust cross-cohort performance. Our results indicate that deep learning can reliably predict participant-specific brain MRI at the voxel level, offering new opportunities for individualized prognosis.",Neuroscience
"Predicting future brain state from a baseline magnetic resonance image (MRI) is a central challenge in neuroimaging and has important implications for studying neurodegenerative diseases such as Alzheimer's disease (AD). Most existing approaches predict future cognitive scores or clinical outcomes, such as conversion from mild cognitive impairment to dementia. Instead, here we investigate longitudinal MRI image-to-image prediction that forecasts a participant's entire brain MRI several years into the future, intrinsically modeling complex, spatially distributed neurodegenerative patterns. We implement and evaluate five deep learning architectures (UNet, U2-Net, UNETR, Time-Embedding UNet, and ODE-UNet) on two longitudinal cohorts (ADNI and AIBL). Predicted follow-up MRIs are directly compared with the actual follow-up scans using metrics that capture global similarity and local differences. The best performing models achieve high-fidelity predictions, and all models generalize well to an independent external dataset, demonstrating robust cross-cohort performance. Our results indicate that deep learning can reliably predict participant-specific brain MRI at the voxel level, offering new opportunities for individualized prognosis. [SEP] [HINT] clinical -> Bioinformatics (Syns: ) | learning -> Bioinformatics (Syns: take, teach, acquire) | results -> Bioinformatics (Syns: final result, consequence, resultant role)",Neuroscience
"High-resolution imaging provides dense trajectories of migrating cells, flocking animals, and synthetic active particles, from which interaction laws can be determined with a wide variety of methods. Yet, distinguishing whether front-back or lateral biases seen in such data reflect intrinsic anisotropy in the interaction kernel or emergent correlations that are nevertheless produced by isotropic pairwise interaction forces remains an open challenge. We resolve this ambiguity by deriving a linear partial differential equation that connects measurable two-point velocity correlations to an unknown, distance- and angle-dependent interaction kernel. Turing-like instabilities can occur which allows for dipolar or quadrupolar patterns to arise even when agents interact according to an underlying attraction-repulsion law that is angle-independent. We then show that incorporating a weak velocity-alignment force can interfere with anisotropic pattern formation by suppressing dipolar patterns. We validate these predictions with agent-based simulations and provide design guidance for experiments that seek to discriminate intrinsic anisotropy from emergent effects.",Bioinformatics
"High-resolution imaging provides dense trajectories of migrating cells, flocking animals, and synthetic active particles, from which interaction laws can be determined with a wide variety of methods. Yet, distinguishing whether front-back or lateral biases seen in such data reflect intrinsic anisotropy in the interaction kernel or emergent correlations that are nevertheless produced by isotropic pairwise interaction forces remains an open challenge. We resolve this ambiguity by deriving a linear partial differential equation that connects measurable two-point velocity correlations to an unknown, distance- and angle-dependent interaction kernel. Turing-like instabilities can occur which allows for dipolar or quadrupolar patterns to arise even when agents interact according to an underlying attraction-repulsion law that is angle-independent. We then show that incorporating a weak velocity-alignment force can interfere with anisotropic pattern formation by suppressing dipolar patterns. We validate these predictions with agent-based simulations and provide design guidance for experiments that seek to discriminate intrinsic anisotropy from emergent effects. [SEP] [HINT] imaging -> Bioinformatics (Syns: imagery, imagination, visualise) | design -> Bioinformatics (Syns: aim, invention, pattern) | data -> Bioinformatics (Syns: data point, information, datum)",Bioinformatics
"Nd$_{2}$Fe$_{14}$B -- a widely used permanent magnet -- has magnetocrystalline anisotropy constants that differ between the bulk and interface regions. This study explores the effects of lattice distortion on the magnetocrystalline anisotropy ($K_{\rm u}$) and magnetization of (Nd$_{1-x}$Pr$_x$)$_2$Fe$_{14}$B. Nd$_2$Fe$_{14}$B alloys were fabricated; scanning transmission electron microscopy revealed a compressive strain of up to 25% near grain boundaries. Using the full-potential Korringa--Kohn--Rostoker method, we calculated the strain dependence of $K_{\rm u}$, showing that although $K_{\rm u}$ is 4.2 MJ/m$^3$ under strain-free conditions at 0 K, it becomes negative in regions with 25% compressive strain. Additionally, Pr$_{2}$Fe$_{14}$B exhibits a larger $K_{\rm u}$ than Pr$_{2}$Fe$_{14}$B under undistorted conditions, whereas Pr-rich alloys exhibit a more pronounced reduction in $K_{\rm u}$ under strain. These findings highlight the critical influence of lattice distortions on magnetic properties. The calculated strain-dependent magnetic anisotropy parameters provide valuable inputs for future micromagnetic simulations, aiding the design of advanced magnetic materials.",Materials Science
"Nd$_{2}$Fe$_{14}$B -- a widely used permanent magnet -- has magnetocrystalline anisotropy constants that differ between the bulk and interface regions. This study explores the effects of lattice distortion on the magnetocrystalline anisotropy ($K_{\rm u}$) and magnetization of (Nd$_{1-x}$Pr$_x$)$_2$Fe$_{14}$B. Nd$_2$Fe$_{14}$B alloys were fabricated; scanning transmission electron microscopy revealed a compressive strain of up to 25% near grain boundaries. Using the full-potential Korringa--Kohn--Rostoker method, we calculated the strain dependence of $K_{\rm u}$, showing that although $K_{\rm u}$ is 4.2 MJ/m$^3$ under strain-free conditions at 0 K, it becomes negative in regions with 25% compressive strain. Additionally, Pr$_{2}$Fe$_{14}$B exhibits a larger $K_{\rm u}$ than Pr$_{2}$Fe$_{14}$B under undistorted conditions, whereas Pr-rich alloys exhibit a more pronounced reduction in $K_{\rm u}$ under strain. These findings highlight the critical influence of lattice distortions on magnetic properties. The calculated strain-dependent magnetic anisotropy parameters provide valuable inputs for future micromagnetic simulations, aiding the design of advanced magnetic materials. [SEP] [HINT] used -> Bioinformatics (Syns: utilize, ill-used, apply) | electron -> Materials Science (Syns: negatron) | using -> Bioinformatics (Syns: utilize, exploitation, apply)",Materials Science
"The tunability of covalent organic frameworks (COFs) opens opportunities to engineer topological electronic phases, including topological insulators (TIs) and higher-order topological insulators (HOTIs)--materials that host in-gap states localized at their edges, hinges, or corners. Here we explore how chemically feasible perturbations can drive triazine-based COFs (CTFs) into topological regimes. Using a tight-binding model on the Honeycomb lattice inspired by the frontier electronic states of CTFs, we show that introducing an effective uniaxial strain--implemented as a modulation of electron hopping on a subset of bonds--can generate a series of distinct topological band structures. This effect can be realized in practice through chemical substitution of linkers along the strained bonds. First-principles calculations demonstrate that replacing biphenyl with pyrene linkers drives a CTF to the brink of a HOTI phase, suggesting a viable route toward topological band-structure engineering in COFs.",Materials Science
"The tunability of covalent organic frameworks (COFs) opens opportunities to engineer topological electronic phases, including topological insulators (TIs) and higher-order topological insulators (HOTIs)--materials that host in-gap states localized at their edges, hinges, or corners. Here we explore how chemically feasible perturbations can drive triazine-based COFs (CTFs) into topological regimes. Using a tight-binding model on the Honeycomb lattice inspired by the frontier electronic states of CTFs, we show that introducing an effective uniaxial strain--implemented as a modulation of electron hopping on a subset of bonds--can generate a series of distinct topological band structures. This effect can be realized in practice through chemical substitution of linkers along the strained bonds. First-principles calculations demonstrate that replacing biphenyl with pyrene linkers drives a CTF to the brink of a HOTI phase, suggesting a viable route toward topological band-structure engineering in COFs. [SEP] [HINT] electronic -> Materials Science (Syns: ) | electron -> Materials Science (Syns: negatron) | including -> Bioinformatics (Syns: admit, include, let in)",Materials Science
"Analysing biological spiking neural network models with synaptic plasticity has proven to be challenging both theoretically and numerically. In a network with N all-to-all connected neurons, the number of synaptic connections is on the order of $N^2$, making these models computationally demanding. Furthermore, the intricate coupling between neuron and synapse dynamics, along with the heterogeneity generated by plasticity, hinder the use of classic theoretical tools such as mean-field or slow-fast analyses. To address these challenges, we introduce a new variable which we term a typical neuron X. Viewed as a post-synaptic neuron, X is composed of the activity state V , the time since its last spike S, and the empirical distribution $ξ$ of the triplet V , S and W (incoming weight) associated to the pre-synaptic neurons. In particular, we study a stochastic spike-timing-dependent plasticity (STDP) model of connection in a probabilistic Wilson-Cowan spiking neural network model, which features binary neural activity. Taking the large N limit, we obtain from the empirical distribution of the typical neuron a simplified yet accurate representation of the original spiking network. This mean-field limit is a piecewise deterministic Markov process (PDMP) of McKean-Vlasov type, where the typical neuron dynamics depends on its own distribution. We term this analysis McKean-Vlasov mean-field (MKV-MF). Our approach not only reduces computational complexity but also provides insights into the dynamics of this spiking neural network with plasticity. The model obtained is mathematically exact and capable of tracking transient changes. This analysis marks the first exploration of MKV-MF dynamics in a network of spiking neurons interacting with STDP.",Neuroscience
"Analysing biological spiking neural network models with synaptic plasticity has proven to be challenging both theoretically and numerically. In a network with N all-to-all connected neurons, the number of synaptic connections is on the order of $N^2$, making these models computationally demanding. Furthermore, the intricate coupling between neuron and synapse dynamics, along with the heterogeneity generated by plasticity, hinder the use of classic theoretical tools such as mean-field or slow-fast analyses. To address these challenges, we introduce a new variable which we term a typical neuron X. Viewed as a post-synaptic neuron, X is composed of the activity state V , the time since its last spike S, and the empirical distribution $ξ$ of the triplet V , S and W (incoming weight) associated to the pre-synaptic neurons. In particular, we study a stochastic spike-timing-dependent plasticity (STDP) model of connection in a probabilistic Wilson-Cowan spiking neural network model, which features binary neural activity. Taking the large N limit, we obtain from the empirical distribution of the typical neuron a simplified yet accurate representation of the original spiking network. This mean-field limit is a piecewise deterministic Markov process (PDMP) of McKean-Vlasov type, where the typical neuron dynamics depends on its own distribution. We term this analysis McKean-Vlasov mean-field (MKV-MF). Our approach not only reduces computational complexity but also provides insights into the dynamics of this spiking neural network with plasticity. The model obtained is mathematically exact and capable of tracking transient changes. This analysis marks the first exploration of MKV-MF dynamics in a network of spiking neurons interacting with STDP. [SEP] [HINT] computational -> Neuroscience (Syns: ) | features -> Bioinformatics (Syns: characteristic, lineament, feature of speech) | order -> Materials Science (Syns: enjoin, dictate, social club)",Neuroscience
"The observation of reversible de-mixing phenomena in mixed-halide perovskites under illumination is one of the most challenging as well as intriguing aspects of this class of materials. On the one hand, it poses critical constraints to the compositional space that allows reliable design of absorbers for perovskite photovoltaics. On the other hand, it holds potential for the development of novel optoionic devices where an ionic response is triggered via optical stimuli. Funda-mental questions about the origin of such photo de-mixing process remain unanswered, both in terms of its mechanism as well as thermodynamic description. Here, we relate in-situ measurements of ionic and electronic transport of mixed bromide-iodide perovskite thin films performed during photo de-mixing with the evolution of their optical and morpho-logical properties. The results point to the definition of different stages of the de-mixing process which, based on micros-copy and spectroscopic measurements, we assign to regimes of spinodal decomposition and nucleation of quasi-equilibrium iodide- and bromide-rich phases. Combined with density functional theory calculations, we explore the role of dimensionality in the mechanism and reversibility of photo de-mixing and dark re-mixing processes, referring to elec-tronic and ionic contributions to the de-mixing driving force. Additionally, our data emphasizes the role of the surface, as significantly different de-mixing dynamics, in terms of extent and reversibility, are observed for films with or without encapsulation. Our comprehensive analysis of transport, phase and optical properties of mixed-halide perovskites pro-vides guidelines for future materials design as well as for the more general fundamental understanding of light-induced ionic phenomena.",Materials Science
"The observation of reversible de-mixing phenomena in mixed-halide perovskites under illumination is one of the most challenging as well as intriguing aspects of this class of materials. On the one hand, it poses critical constraints to the compositional space that allows reliable design of absorbers for perovskite photovoltaics. On the other hand, it holds potential for the development of novel optoionic devices where an ionic response is triggered via optical stimuli. Funda-mental questions about the origin of such photo de-mixing process remain unanswered, both in terms of its mechanism as well as thermodynamic description. Here, we relate in-situ measurements of ionic and electronic transport of mixed bromide-iodide perovskite thin films performed during photo de-mixing with the evolution of their optical and morpho-logical properties. The results point to the definition of different stages of the de-mixing process which, based on micros-copy and spectroscopic measurements, we assign to regimes of spinodal decomposition and nucleation of quasi-equilibrium iodide- and bromide-rich phases. Combined with density functional theory calculations, we explore the role of dimensionality in the mechanism and reversibility of photo de-mixing and dark re-mixing processes, referring to elec-tronic and ionic contributions to the de-mixing driving force. Additionally, our data emphasizes the role of the surface, as significantly different de-mixing dynamics, in terms of extent and reversibility, are observed for films with or without encapsulation. Our comprehensive analysis of transport, phase and optical properties of mixed-halide perovskites pro-vides guidelines for future materials design as well as for the more general fundamental understanding of light-induced ionic phenomena. [SEP] [HINT] based -> Bioinformatics (Syns: ground, free-base, base) | perovskite -> Materials Science (Syns: ) | understanding -> Neuroscience (Syns: savvy, intellect, sympathy)",Materials Science
"Born effective charge (BEC), a fundamental quantity in lattice dynamics and ferroelectric theory, provides a quantitative measure of linear polarization response to ionic displacements. However, it does not account for higher-order effects, which can play a significant role in certain materials, such as fluorite HfO$_2$. In this letter, we extend the BEC framework by introducing the concept of second-order dynamical charge and mode effective charge. Using first-principles calculations, we demonstrate that specific combinations of nonpolar phonon modes in many oxides can induce substantial second-order polarizations, reaching magnitudes comparable to those of intrinsically polar modes. Through a symmetry-based analysis of the charge density, we elucidate the microscopic origin of these effects, tracing them to variations in bond covalency and local electronic rearrangements. We also demonstrate large second-order mode effective charge in well-studied perovskites such as SrTiO$_3$, highlighting the generality of these phenomena. Our results reveal a previously unrecognized mechanism that drives polarization in crystalline solids, offering new insights into the design principles of next-generation ferroelectric, piezoelectric and multifunctional materials.",Materials Science
"Born effective charge (BEC), a fundamental quantity in lattice dynamics and ferroelectric theory, provides a quantitative measure of linear polarization response to ionic displacements. However, it does not account for higher-order effects, which can play a significant role in certain materials, such as fluorite HfO$_2$. In this letter, we extend the BEC framework by introducing the concept of second-order dynamical charge and mode effective charge. Using first-principles calculations, we demonstrate that specific combinations of nonpolar phonon modes in many oxides can induce substantial second-order polarizations, reaching magnitudes comparable to those of intrinsically polar modes. Through a symmetry-based analysis of the charge density, we elucidate the microscopic origin of these effects, tracing them to variations in bond covalency and local electronic rearrangements. We also demonstrate large second-order mode effective charge in well-studied perovskites such as SrTiO$_3$, highlighting the generality of these phenomena. Our results reveal a previously unrecognized mechanism that drives polarization in crystalline solids, offering new insights into the design principles of next-generation ferroelectric, piezoelectric and multifunctional materials. [SEP] [HINT] phonon -> Materials Science (Syns: ) | charge -> Materials Science (Syns: tear, bearing, burster) | electronic -> Materials Science (Syns: )",Materials Science
"In recent years, Electroencephalographic analysis has gained prominence in stress research when combined with AI and Machine Learning models for validation. In this study, a lightweight dynamic brain connectivity framework based on Time Varying Directed Transfer Function is proposed, where TV DTF features were validated through ML based stress classification. TV DTF estimates the directional information flow between brain regions across distinct EEG frequency bands, thereby capturing temporal and causal influences that are often overlooked by static functional connectivity measures. EEG recordings from the 32 channel SAM 40 dataset were employed, focusing on mental arithmetic task trials. The dynamic EEG-based TV-DTF features were validated through ML classifiers such as Support Vector Machine, Random Forest, Gradient Boosting, Adaptive Boosting, and Extreme Gradient Boosting. Experimental results show that alpha-TV-DTF provided the strongest discriminative power, with SVM achieving 89.73% accuracy in 3-class classification and with XGBoost achieving 93.69% accuracy in 2 class classification. Relative to absolute power and phase locking based functional connectivity features, alpha TV DTF and beta TV DTF achieved higher performance across the ML models, highlighting the advantages of dynamic over static measures. Feature importance analysis further highlighted dominant long-range frontal parietal and frontal occipital informational influences, emphasizing the regulatory role of frontal regions under stress. These findings validate the lightweight TV-DTF as a robust framework, revealing spatiotemporal brain dynamics and directional influences across different stress levels.",Neuroscience
"In recent years, Electroencephalographic analysis has gained prominence in stress research when combined with AI and Machine Learning models for validation. In this study, a lightweight dynamic brain connectivity framework based on Time Varying Directed Transfer Function is proposed, where TV DTF features were validated through ML based stress classification. TV DTF estimates the directional information flow between brain regions across distinct EEG frequency bands, thereby capturing temporal and causal influences that are often overlooked by static functional connectivity measures. EEG recordings from the 32 channel SAM 40 dataset were employed, focusing on mental arithmetic task trials. The dynamic EEG-based TV-DTF features were validated through ML classifiers such as Support Vector Machine, Random Forest, Gradient Boosting, Adaptive Boosting, and Extreme Gradient Boosting. Experimental results show that alpha-TV-DTF provided the strongest discriminative power, with SVM achieving 89.73% accuracy in 3-class classification and with XGBoost achieving 93.69% accuracy in 2 class classification. Relative to absolute power and phase locking based functional connectivity features, alpha TV DTF and beta TV DTF achieved higher performance across the ML models, highlighting the advantages of dynamic over static measures. Feature importance analysis further highlighted dominant long-range frontal parietal and frontal occipital informational influences, emphasizing the regulatory role of frontal regions under stress. These findings validate the lightweight TV-DTF as a robust framework, revealing spatiotemporal brain dynamics and directional influences across different stress levels. [SEP] [HINT] task -> Neuroscience (Syns: tax, project, chore) | connectivity -> Neuroscience (Syns: ) | based -> Bioinformatics (Syns: ground, free-base, base)",Neuroscience
"Computational antibody design holds immense promise for therapeutic discovery, yet existing generative models are fundamentally limited by two core challenges: (i) a lack of dynamical consistency, which yields physically implausible structures, and (ii) poor generalization due to data scarcity and structural bias. We introduce FP-AbDiff, the first antibody generator to enforce Fokker-Planck Equation (FPE) physics along the entire generative trajectory. Our method minimizes a novel FPE residual loss over the mixed manifold of CDR geometries (R^3 x SO(3)), compelling locally-learned denoising scores to assemble into a globally coherent probability flow. This physics-informed regularizer is synergistically integrated with deep biological priors within a state-of-the-art SE(3)-equivariant diffusion framework. Rigorous evaluation on the RAbD benchmark confirms that FP-AbDiff establishes a new state-of-the-art. In de novo CDR-H3 design, it achieves a mean Root Mean Square Deviation of 0.99 Å when superposing on the variable region, a 25% improvement over the previous state-of-the-art model, AbX, and the highest reported Contact Amino Acid Recovery of 39.91%. This superiority is underscored in the more challenging six-CDR co-design task, where our model delivers consistently superior geometric precision, cutting the average full-chain Root Mean Square Deviation by ~15%, and crucially, achieves the highest full-chain Amino Acid Recovery on the functionally dominant CDR-H3 loop (45.67%). By aligning generative dynamics with physical laws, FP-AbDiff enhances robustness and generalizability, establishing a principled approach for physically faithful and functionally viable antibody design.",Bioinformatics
"Computational antibody design holds immense promise for therapeutic discovery, yet existing generative models are fundamentally limited by two core challenges: (i) a lack of dynamical consistency, which yields physically implausible structures, and (ii) poor generalization due to data scarcity and structural bias. We introduce FP-AbDiff, the first antibody generator to enforce Fokker-Planck Equation (FPE) physics along the entire generative trajectory. Our method minimizes a novel FPE residual loss over the mixed manifold of CDR geometries (R^3 x SO(3)), compelling locally-learned denoising scores to assemble into a globally coherent probability flow. This physics-informed regularizer is synergistically integrated with deep biological priors within a state-of-the-art SE(3)-equivariant diffusion framework. Rigorous evaluation on the RAbD benchmark confirms that FP-AbDiff establishes a new state-of-the-art. In de novo CDR-H3 design, it achieves a mean Root Mean Square Deviation of 0.99 Å when superposing on the variable region, a 25% improvement over the previous state-of-the-art model, AbX, and the highest reported Contact Amino Acid Recovery of 39.91%. This superiority is underscored in the more challenging six-CDR co-design task, where our model delivers consistently superior geometric precision, cutting the average full-chain Root Mean Square Deviation by ~15%, and crucially, achieves the highest full-chain Amino Acid Recovery on the functionally dominant CDR-H3 loop (45.67%). By aligning generative dynamics with physical laws, FP-AbDiff enhances robustness and generalizability, establishing a principled approach for physically faithful and functionally viable antibody design. [SEP] [HINT] computational -> Neuroscience (Syns: ) | existing -> Bioinformatics (Syns: subsist, existent, survive) | method -> Bioinformatics (Syns: method acting)",Bioinformatics
"Molecular property prediction is fundamental to chemical engineering applications such as solvent screening. We present Socrates-Mol, a framework that transforms language models into empirical Bayesian reasoners through context engineering, addressing cold start problems without model fine-tuning. The system implements a reflective-prediction cycle where initial outputs serve as priors, retrieved molecular cases provide evidence, and refined predictions form posteriors, extracting reusable chemical rules from sparse data. We introduce ranking tasks aligned with industrial screening priorities and employ cross-model self-consistency across five language models to reduce variance. Experiments on amine solvent LogP prediction reveal task-dependent patterns: regression achieves 72% MAE reduction and 112% R-squared improvement through self-consistency, while ranking tasks show limited gains due to systematic multi-model biases. The framework reduces deployment costs by over 70% compared to full fine-tuning, providing a scalable solution for molecular property prediction while elucidating the task-adaptive nature of self-consistency mechanisms.",Bioinformatics
"Molecular property prediction is fundamental to chemical engineering applications such as solvent screening. We present Socrates-Mol, a framework that transforms language models into empirical Bayesian reasoners through context engineering, addressing cold start problems without model fine-tuning. The system implements a reflective-prediction cycle where initial outputs serve as priors, retrieved molecular cases provide evidence, and refined predictions form posteriors, extracting reusable chemical rules from sparse data. We introduce ranking tasks aligned with industrial screening priorities and employ cross-model self-consistency across five language models to reduce variance. Experiments on amine solvent LogP prediction reveal task-dependent patterns: regression achieves 72% MAE reduction and 112% R-squared improvement through self-consistency, while ranking tasks show limited gains due to systematic multi-model biases. The framework reduces deployment costs by over 70% compared to full fine-tuning, providing a scalable solution for molecular property prediction while elucidating the task-adaptive nature of self-consistency mechanisms. [SEP] [HINT] tasks -> Neuroscience (Syns: tax, task, project) | language -> Neuroscience (Syns: linguistic process, linguistic communication, spoken communication) | molecular -> Bioinformatics (Syns: )",Bioinformatics
"Neurodevelopmental disorders such as Fragile X Syndrome (FXS) and Autism Spectrum Disorder (ASD) are characterized by disrupted cortical oscillatory activity, particularly in the alpha and gamma frequency bands. These abnormalities are linked to deficits in attention, sensory processing, and cognitive function. In this work, we present an adaptive machine learning-based brain-computer interface (BCI) system designed to modulate neural oscillations through frequency-specific auditory stimulation to enhance cognitive readiness in individuals with FXS. EEG data were recorded from 38 participants using a 128-channel system under a stimulation paradigm consisting of a 30-second baseline (no stimulus) followed by 60-second auditory entrainment episodes at 7Hz, 9Hz, 11Hz, and 13Hz. A comprehensive analysis of power spectral features (Alpha, Gamma, Delta, Theta, Beta) and cross-frequency coupling metrics (Alpha-Gamma, Alpha-Beta, etc.) was conducted. The results identified Peak Alpha Power, Peak Gamma Power, and Alpha Power per second per channel as the most discriminative biomarkers. The 13Hz stimulation condition consistently elicited a significant increase in Alpha activity and suppression of Gamma activity, aligning with our optimization objective. A supervised machine learning framework was developed to predict EEG responses and dynamically adjust stimulation parameters, enabling real-time, subject-specific adaptation. This work establishes a novel EEG-driven optimization framework for cognitive neuromodulation, providing a foundational model for next-generation AI-integrated BCI systems aimed at personalized neurorehabilitation in FXS and related disorders.",Neuroscience
"Neurodevelopmental disorders such as Fragile X Syndrome (FXS) and Autism Spectrum Disorder (ASD) are characterized by disrupted cortical oscillatory activity, particularly in the alpha and gamma frequency bands. These abnormalities are linked to deficits in attention, sensory processing, and cognitive function. In this work, we present an adaptive machine learning-based brain-computer interface (BCI) system designed to modulate neural oscillations through frequency-specific auditory stimulation to enhance cognitive readiness in individuals with FXS. EEG data were recorded from 38 participants using a 128-channel system under a stimulation paradigm consisting of a 30-second baseline (no stimulus) followed by 60-second auditory entrainment episodes at 7Hz, 9Hz, 11Hz, and 13Hz. A comprehensive analysis of power spectral features (Alpha, Gamma, Delta, Theta, Beta) and cross-frequency coupling metrics (Alpha-Gamma, Alpha-Beta, etc.) was conducted. The results identified Peak Alpha Power, Peak Gamma Power, and Alpha Power per second per channel as the most discriminative biomarkers. The 13Hz stimulation condition consistently elicited a significant increase in Alpha activity and suppression of Gamma activity, aligning with our optimization objective. A supervised machine learning framework was developed to predict EEG responses and dynamically adjust stimulation parameters, enabling real-time, subject-specific adaptation. This work establishes a novel EEG-driven optimization framework for cognitive neuromodulation, providing a foundational model for next-generation AI-integrated BCI systems aimed at personalized neurorehabilitation in FXS and related disorders. [SEP] [HINT] features -> Bioinformatics (Syns: characteristic, lineament, feature of speech) | cortical -> Neuroscience (Syns: ) | learning -> Bioinformatics (Syns: take, teach, acquire)",Neuroscience
"The electron flux diverts electrons from optimal hydrogen production pathways to competitive pathways, which overall reduces the efficiency of the photo fermentation hydrogen production (PFHP) system. For tackling electron flux and metabolic pathway regulation, a hybrid material (nano-capattery (NC)) was developed based on cobalt-iron-nitrogen doped biochar (Co-Fe-NBC). The NC possessed both the capacitor property (287.91 F/g) and battery-like charge storage 38.3 mC/g with the highest energy density of 159.95 mWh/g. These properties existed due to its Fe2+/Fe3+ and Co2+/Co3+ redox cycle ability, a highly porous surface (291.81 m2/g BET surface area) caused by the defects (AD/AG 3.13) and abundant oxygen vacancies (OVs) observed through electro paramagnetic resonance. During PFHP, there is an 85% reduction in propionic acid, a 65.3% record electron management efficiency, an improved 1.34 NAD+/NADH ratio, along with a 87% increase in dehydrogenase activity, confirming the superior role of NC in efficient regulation of the metabolic pathway and electron flux management. These exceptional properties of biochar-based NC raised the cumulative hydrogen production from 151.03 mL (control) to 589.54 mL, which was an enormous increase of 367%.",Materials Science
"The electron flux diverts electrons from optimal hydrogen production pathways to competitive pathways, which overall reduces the efficiency of the photo fermentation hydrogen production (PFHP) system. For tackling electron flux and metabolic pathway regulation, a hybrid material (nano-capattery (NC)) was developed based on cobalt-iron-nitrogen doped biochar (Co-Fe-NBC). The NC possessed both the capacitor property (287.91 F/g) and battery-like charge storage 38.3 mC/g with the highest energy density of 159.95 mWh/g. These properties existed due to its Fe2+/Fe3+ and Co2+/Co3+ redox cycle ability, a highly porous surface (291.81 m2/g BET surface area) caused by the defects (AD/AG 3.13) and abundant oxygen vacancies (OVs) observed through electro paramagnetic resonance. During PFHP, there is an 85% reduction in propionic acid, a 65.3% record electron management efficiency, an improved 1.34 NAD+/NADH ratio, along with a 87% increase in dehydrogenase activity, confirming the superior role of NC in efficient regulation of the metabolic pathway and electron flux management. These exceptional properties of biochar-based NC raised the cumulative hydrogen production from 151.03 mL (control) to 589.54 mL, which was an enormous increase of 367%. [SEP] [HINT] based -> Bioinformatics (Syns: ground, free-base, base) | charge -> Materials Science (Syns: tear, bearing, burster) | electron -> Materials Science (Syns: negatron)",Materials Science
"Autism spectrum disorder (ASD) is most often diagnosed using behavioral evaluations, which can vary between clinicians. Brain imaging, combined with machine learning, may help identify more objective patterns linked to ASD. This project used magnetic resonance imaging (MRI) data from the publicly available ABIDE I dataset (n = 1,112) to test two approaches for classifying ASD and control participants. The first was a 3D convolutional neural network (CNN) trained end-to-end. The second was a hybrid approach that used the CNN as a feature extractor and then applied a support vector machine (SVM) classifier. The baseline CNN reached moderate performance (accuracy = 0.66, AUC = 0.70), while the hybrid CNN + SVM achieved higher overall accuracy (0.76) and AUC (0.80). The hybrid model also produced more balanced results between ASD and control groups. Separating feature extraction and classification improved performance and reduced bias between diagnostic groups. These findings suggest that combining deep learning and traditional machine learning methods could enhance the reliability of MRI-based research on ASD.",Neuroscience
"Autism spectrum disorder (ASD) is most often diagnosed using behavioral evaluations, which can vary between clinicians. Brain imaging, combined with machine learning, may help identify more objective patterns linked to ASD. This project used magnetic resonance imaging (MRI) data from the publicly available ABIDE I dataset (n = 1,112) to test two approaches for classifying ASD and control participants. The first was a 3D convolutional neural network (CNN) trained end-to-end. The second was a hybrid approach that used the CNN as a feature extractor and then applied a support vector machine (SVM) classifier. The baseline CNN reached moderate performance (accuracy = 0.66, AUC = 0.70), while the hybrid CNN + SVM achieved higher overall accuracy (0.76) and AUC (0.80). The hybrid model also produced more balanced results between ASD and control groups. Separating feature extraction and classification improved performance and reduced bias between diagnostic groups. These findings suggest that combining deep learning and traditional machine learning methods could enhance the reliability of MRI-based research on ASD. [SEP] [HINT] used -> Bioinformatics (Syns: utilize, ill-used, apply) | learning -> Bioinformatics (Syns: take, teach, acquire) | performance -> Bioinformatics (Syns: functioning, operation, carrying out)",Neuroscience
"Metal-organic framework (MOF) databases have grown rapidly through experimental deposition and large-scale literature extraction, but recent analyses show that nearly half of their entries contain substantial structural errors. These inaccuracies propagate through high-throughput screening and machine-learning workflows, limiting the reliability of data-driven MOF discovery. Correcting such errors is exceptionally difficult because true repairs require integrating crystallographic files, synthesis descriptions, and contextual evidence scattered across the literature. Here we introduce LitMOF, a large language model-driven multi-agent framework that validates crystallographic information directly from the original literature and cross-validates it with database entries to repair structural errors. Applying LitMOF to the experimental MOF database (the CSD MOF Subset), we constructed LitMOF-DB, a curated set 118,464 computation-ready structures, including corrections of 69% (6,161 MOFs) of the invalid MOFs in the latest CoRE MOF database. Additionally, the system uncovered 12,646 experimentally reported MOFs absent from existing resources, substantially expanding the known experimental design space. This work establishes a scalable pathway toward self-correcting scientific databases and a generalizable paradigm for LLM-driven curation in materials science.",Materials Science
"Metal-organic framework (MOF) databases have grown rapidly through experimental deposition and large-scale literature extraction, but recent analyses show that nearly half of their entries contain substantial structural errors. These inaccuracies propagate through high-throughput screening and machine-learning workflows, limiting the reliability of data-driven MOF discovery. Correcting such errors is exceptionally difficult because true repairs require integrating crystallographic files, synthesis descriptions, and contextual evidence scattered across the literature. Here we introduce LitMOF, a large language model-driven multi-agent framework that validates crystallographic information directly from the original literature and cross-validates it with database entries to repair structural errors. Applying LitMOF to the experimental MOF database (the CSD MOF Subset), we constructed LitMOF-DB, a curated set 118,464 computation-ready structures, including corrections of 69% (6,161 MOFs) of the invalid MOFs in the latest CoRE MOF database. Additionally, the system uncovered 12,646 experimentally reported MOFs absent from existing resources, substantially expanding the known experimental design space. This work establishes a scalable pathway toward self-correcting scientific databases and a generalizable paradigm for LLM-driven curation in materials science. [SEP] [HINT] language -> Neuroscience (Syns: linguistic process, linguistic communication, spoken communication) | information -> Bioinformatics (Syns: entropy, data, info) | work -> Bioinformatics (Syns: work out, process, bring)",Materials Science
"Deterministic Lateral Displacement (DLD) devices are widely used in microfluidics for label-free, size-based separation of particles and cells, with particular promise in isolating circulating tumor cells (CTCs) for early cancer diagnostics. This study focuses on the optimization of DLD design parameters, such as row shift fraction, post size, and gap distance, to enhance the selective isolation of lung cancer cells based on their physical properties. To overcome the challenges of rare CTC detection and reduce reliance on computationally intensive simulations, machine learning models including gradient boosting, k-nearest neighbors, random forest, and multilayer perceptron (MLP) regressors are employed. Trained on a large, numerically validated dataset, these models predict particle trajectories and identify optimal device configurations, enabling high-throughput and cost-effective DLD design. Beyond trajectory prediction, the models aid in isolating critical design variables, offering a systematic, data-driven framework for automated DLD optimization. This integrative approach advances the development of scalable and precise microfluidic systems for cancer diagnostics, contributing to the broader goals of early detection and personalized medicine.",Bioinformatics
"Deterministic Lateral Displacement (DLD) devices are widely used in microfluidics for label-free, size-based separation of particles and cells, with particular promise in isolating circulating tumor cells (CTCs) for early cancer diagnostics. This study focuses on the optimization of DLD design parameters, such as row shift fraction, post size, and gap distance, to enhance the selective isolation of lung cancer cells based on their physical properties. To overcome the challenges of rare CTC detection and reduce reliance on computationally intensive simulations, machine learning models including gradient boosting, k-nearest neighbors, random forest, and multilayer perceptron (MLP) regressors are employed. Trained on a large, numerically validated dataset, these models predict particle trajectories and identify optimal device configurations, enabling high-throughput and cost-effective DLD design. Beyond trajectory prediction, the models aid in isolating critical design variables, offering a systematic, data-driven framework for automated DLD optimization. This integrative approach advances the development of scalable and precise microfluidic systems for cancer diagnostics, contributing to the broader goals of early detection and personalized medicine. [SEP] [HINT] used -> Bioinformatics (Syns: utilize, ill-used, apply) | based -> Bioinformatics (Syns: ground, free-base, base) | learning -> Bioinformatics (Syns: take, teach, acquire)",Bioinformatics
"Graphene has emerged as a promising material for next-generation electronic and thermal devices owing to its exceptional charge transport and thermal conductivity. However, high-quality samples are predominantly obtained via mechanical exfoliation from graphite crystals, a process that inherently lacks scalability. Despite extensive efforts toward large-area synthesis, cost-effective approaches for producing high-quality, large-area, single-crystalline graphene with fast turnaround time remain limited. Here, we report the design, fabrication, and performance benchmarking of a rapid thermal chemical vapor deposition (RTCVD) system capable of synthesizing epitaxial monolayer graphene under atmospheric pressure. The entire growth process, from sample loading to unloading, is achieved within $25$ minutes with a temperature ramp rate exceeding $23^\circ\mathrm{C}/s$. Growth at atmospheric pressure eliminates the need for vacuum components, thereby reducing both system complexity and operational costs. The structural and electronic quality of epitaxial graphene is comprehensively characterized using Raman spectroscopy, selected area electron diffraction (SAED), and magnetotransport measurements, which reveal signatures of quantum Hall effect in synthesized graphene samples. Furthermore, we demonstrate van der Waals epitaxial growth of palladium (Pd) thin films on graphene transferred to Si/SiO$_{2}$ substrates, establishing its single-crystalline nature over a large area and its potential as a versatile platform for subsequent heteroepitaxial growth.",Materials Science
"Graphene has emerged as a promising material for next-generation electronic and thermal devices owing to its exceptional charge transport and thermal conductivity. However, high-quality samples are predominantly obtained via mechanical exfoliation from graphite crystals, a process that inherently lacks scalability. Despite extensive efforts toward large-area synthesis, cost-effective approaches for producing high-quality, large-area, single-crystalline graphene with fast turnaround time remain limited. Here, we report the design, fabrication, and performance benchmarking of a rapid thermal chemical vapor deposition (RTCVD) system capable of synthesizing epitaxial monolayer graphene under atmospheric pressure. The entire growth process, from sample loading to unloading, is achieved within $25$ minutes with a temperature ramp rate exceeding $23^\circ\mathrm{C}/s$. Growth at atmospheric pressure eliminates the need for vacuum components, thereby reducing both system complexity and operational costs. The structural and electronic quality of epitaxial graphene is comprehensively characterized using Raman spectroscopy, selected area electron diffraction (SAED), and magnetotransport measurements, which reveal signatures of quantum Hall effect in synthesized graphene samples. Furthermore, we demonstrate van der Waals epitaxial growth of palladium (Pd) thin films on graphene transferred to Si/SiO$_{2}$ substrates, establishing its single-crystalline nature over a large area and its potential as a versatile platform for subsequent heteroepitaxial growth. [SEP] [HINT] transport -> Materials Science (Syns: transferral, enthral, shipping) | charge -> Materials Science (Syns: tear, bearing, burster) | electronic -> Materials Science (Syns: )",Materials Science
"The key to successful drug design lies in the correct comprehension of protein-ligand interactions. Within the current knowledge paragm, these interactions can be described from both thermodynamic and kinetic perspectives. In recent years, many deep learning models have emerged for predicting the thermodynamic properties of protein-ligand interactions. However, there is currently no mature model for predicting kinetic properties, primarily due to lack of kinetic data. To tackle this problem, we have developed a graph neural network model called STELLAR-koff (Structure-based TransfEr Learning for Ligand Activity Regression) to predict protein-ligand dissociation rate constant. Unlike traditional protein-ligand property prediction models, which typically use a single complex conformation as input, STELLAR-koff employs transfer learning to transform multiple ligand conformations within the protein into a protein ligand interaction landscape, and uses this landscape as the primary input for the model. In addition, we expanded the PDBbind koff dataset from 680 to 1,197 entries and employed the augmented dataset for model training and testing. When tested through five-fold cross-validation, STELLAR-koff achieved Pearson correlation coefficient of 0.729 surpassing or being on pair with most of the published prediction methods. Tested on external set, STELLAR-koff demonstrated strong predictive performance on unseen protein, achieving a Pearson of 0.838 on the focal adhesion kinase in particular. Experimental validation on cyclin-dependent kinase also demonstrated the effectiveness of STELLAR-koff in real drug discovering scenarios. We believe this study provides an effective tool for predicting protein-ligand dissociation rate constant and offers new insight for the future development of this field.",Bioinformatics
"The key to successful drug design lies in the correct comprehension of protein-ligand interactions. Within the current knowledge paragm, these interactions can be described from both thermodynamic and kinetic perspectives. In recent years, many deep learning models have emerged for predicting the thermodynamic properties of protein-ligand interactions. However, there is currently no mature model for predicting kinetic properties, primarily due to lack of kinetic data. To tackle this problem, we have developed a graph neural network model called STELLAR-koff (Structure-based TransfEr Learning for Ligand Activity Regression) to predict protein-ligand dissociation rate constant. Unlike traditional protein-ligand property prediction models, which typically use a single complex conformation as input, STELLAR-koff employs transfer learning to transform multiple ligand conformations within the protein into a protein ligand interaction landscape, and uses this landscape as the primary input for the model. In addition, we expanded the PDBbind koff dataset from 680 to 1,197 entries and employed the augmented dataset for model training and testing. When tested through five-fold cross-validation, STELLAR-koff achieved Pearson correlation coefficient of 0.729 surpassing or being on pair with most of the published prediction methods. Tested on external set, STELLAR-koff demonstrated strong predictive performance on unseen protein, achieving a Pearson of 0.838 on the focal adhesion kinase in particular. Experimental validation on cyclin-dependent kinase also demonstrated the effectiveness of STELLAR-koff in real drug discovering scenarios. We believe this study provides an effective tool for predicting protein-ligand dissociation rate constant and offers new insight for the future development of this field. [SEP] [HINT] learning -> Bioinformatics (Syns: take, teach, acquire) | complex -> Bioinformatics (Syns: building complex, coordination compound, composite) | performance -> Bioinformatics (Syns: functioning, operation, carrying out)",Bioinformatics
"A combinatorial neural code is a subset of the power set $2^{[n]}$ on $[n]=\{1,\dots, n\}$, in which each $1\leq i\leq n$ represents a neuron and each element (codeword) represents the co-firing event of some neurons. Consider a space $X\subseteq\mathbb{R}^d$, simulating an animal's environment, and a collection $\mathcal{U}=\{U_1,\dots,U_n\}$ of open subsets of $X$. Each $U_i\subseteq X$ simulates a place field which is a specific region where a place cell $i$ is active. Then, the code of $\mathcal{U}$ in $X$ is defined as $\text{code}(\mathcal{U},X)=\left\{σ\subseteq[n]\bigg|\bigcap_{i\inσ} U_i\setminus\bigcup_{j\notinσ}U_j\neq\varnothing\right\}$. If a neural code $\mathcal{C}=\text{code}(\mathcal{U},X)$ for some $X$ and $\mathcal{U}$, we say $\mathcal{C}$ has a realization of open subsets of some space $X$. Although every combinatorial neural code obviously has a realization by some open subsets, determining whether it has a realization by some open convex subsets remains unsolved. Many studies attempted to tackle this decision problem, but only partial results were achieved. In fact, a previous study showed that the decision problem of convex neural codes is NP-hard. Furthermore, the authors of this study conjectured that every convex neural code can be realized as a minor of a neural code arising from a representable oriented matroid, which can lead to an equivalence between convex and polytope convex neural codes. Even though this conjecture has been confirmed in dimension two, its validity in higher dimensions is still unknown. To advance the investigation of this conjecture, we provide a complete characterization of the covering relations within the poset $\mathbf{P_{Code}}$ of neural codes.",Neuroscience
"A combinatorial neural code is a subset of the power set $2^{[n]}$ on $[n]=\{1,\dots, n\}$, in which each $1\leq i\leq n$ represents a neuron and each element (codeword) represents the co-firing event of some neurons. Consider a space $X\subseteq\mathbb{R}^d$, simulating an animal's environment, and a collection $\mathcal{U}=\{U_1,\dots,U_n\}$ of open subsets of $X$. Each $U_i\subseteq X$ simulates a place field which is a specific region where a place cell $i$ is active. Then, the code of $\mathcal{U}$ in $X$ is defined as $\text{code}(\mathcal{U},X)=\left\{σ\subseteq[n]\bigg|\bigcap_{i\inσ} U_i\setminus\bigcup_{j\notinσ}U_j\neq\varnothing\right\}$. If a neural code $\mathcal{C}=\text{code}(\mathcal{U},X)$ for some $X$ and $\mathcal{U}$, we say $\mathcal{C}$ has a realization of open subsets of some space $X$. Although every combinatorial neural code obviously has a realization by some open subsets, determining whether it has a realization by some open convex subsets remains unsolved. Many studies attempted to tackle this decision problem, but only partial results were achieved. In fact, a previous study showed that the decision problem of convex neural codes is NP-hard. Furthermore, the authors of this study conjectured that every convex neural code can be realized as a minor of a neural code arising from a representable oriented matroid, which can lead to an equivalence between convex and polytope convex neural codes. Even though this conjecture has been confirmed in dimension two, its validity in higher dimensions is still unknown. To advance the investigation of this conjecture, we provide a complete characterization of the covering relations within the poset $\mathbf{P_{Code}}$ of neural codes. [SEP] [HINT] field -> Materials Science (Syns: field of honor, line of business, orbit) | space -> Neuroscience (Syns: distance, place, outer space) | results -> Bioinformatics (Syns: final result, consequence, resultant role)",Neuroscience
"As clinical data are becoming increasingly available, machine learning methods have been employed to extract knowledge from them and predict clinical events. While promising, approaches suffer from at least two main issues: low availability of labelled data and data heterogeneity leading to missing values. This work proposes the use of self-supervised auto-encoders to efficiently address these challenges. We apply our methodology to a clinical dataset from patients with ischaemic heart disease. Patient data is embedded in a latent space, built using unlabelled data, which is then used to train a neural network classifier to predict cardiovascular death. Results show improved balanced accuracy compared to applying the classifier directly to the raw data, demonstrating that this solution is promising, especially in conditions where availability of unlabelled data could increase.",Bioinformatics
"As clinical data are becoming increasingly available, machine learning methods have been employed to extract knowledge from them and predict clinical events. While promising, approaches suffer from at least two main issues: low availability of labelled data and data heterogeneity leading to missing values. This work proposes the use of self-supervised auto-encoders to efficiently address these challenges. We apply our methodology to a clinical dataset from patients with ischaemic heart disease. Patient data is embedded in a latent space, built using unlabelled data, which is then used to train a neural network classifier to predict cardiovascular death. Results show improved balanced accuracy compared to applying the classifier directly to the raw data, demonstrating that this solution is promising, especially in conditions where availability of unlabelled data could increase. [SEP] [HINT] used -> Bioinformatics (Syns: utilize, ill-used, apply) | low -> Materials Science (Syns: low-spirited, scurvy, depressed) | clinical -> Bioinformatics (Syns: )",Bioinformatics
"Spontaneous parametric downconversion (SPDC) and four-wave mixing in $χ^{(2)}$ and $χ^{(3)}$ media underpin most entangled-photon sources, but direct generation of higher-order entangled multiphoton states by $n$-th order parametric downconversion remains extremely challenging because conventional materials exhibit tiny high-order nonlinearities. Here we show that single-layer Nb$_3$Cl$_8$, an excitonic Mott insulator on a breathing Kagome lattice, supports exceptionally large nonlinear susceptibilities up to seventh order. Many-body GW--Bethe--Salpeter and time-dependent BSE / Kadanoff--Baym simulations yield resonant $χ^{(2)}$--$χ^{(7)}$ for monolayer Nb$_3$Cl$_8$, with $|χ^{(4)}|$ and $|χ^{(5)}|$ surpassing values in prototypical transition metal dichalcogenides by 5--9 orders of magnitude. We trace this enhancement to flat bands and strongly bound Frenkel excitons with ferroelectrically aligned out-of-plane dipoles. Building on experimentally demonstrated 1$\times N$ integrated beam splitters with arbitrary power ratios, we propose an on-chip architecture where each output arm hosts an Nb$_3$Cl$_8$ patch, optionally gated by graphene to tune the complex $n$-photon amplitudes. Using the ab-initio $χ^{(3)}$ and $χ^{(4)}$ values, we predict that three-photon GHZ$_3$ and four-photon cluster-state sources in this platform can achieve $n$-photon generation rates up to $\sim 10^8$ and $\sim 10^6$ times larger, respectively, than silica-fiber- and MoS$_2$-based implementations with comparable geometry. We derive the quantum Hamiltonian and explicit $n$-photon generation rates for this platform, and show how suitable interferometric networks enable electrically and spectrally tunable GHZ, $W$, and cluster states based on genuine high-order nonlinear processes in a 2D excitonic Mott insulator.",Materials Science
"Spontaneous parametric downconversion (SPDC) and four-wave mixing in $χ^{(2)}$ and $χ^{(3)}$ media underpin most entangled-photon sources, but direct generation of higher-order entangled multiphoton states by $n$-th order parametric downconversion remains extremely challenging because conventional materials exhibit tiny high-order nonlinearities. Here we show that single-layer Nb$_3$Cl$_8$, an excitonic Mott insulator on a breathing Kagome lattice, supports exceptionally large nonlinear susceptibilities up to seventh order. Many-body GW--Bethe--Salpeter and time-dependent BSE / Kadanoff--Baym simulations yield resonant $χ^{(2)}$--$χ^{(7)}$ for monolayer Nb$_3$Cl$_8$, with $|χ^{(4)}|$ and $|χ^{(5)}|$ surpassing values in prototypical transition metal dichalcogenides by 5--9 orders of magnitude. We trace this enhancement to flat bands and strongly bound Frenkel excitons with ferroelectrically aligned out-of-plane dipoles. Building on experimentally demonstrated 1$\times N$ integrated beam splitters with arbitrary power ratios, we propose an on-chip architecture where each output arm hosts an Nb$_3$Cl$_8$ patch, optionally gated by graphene to tune the complex $n$-photon amplitudes. Using the ab-initio $χ^{(3)}$ and $χ^{(4)}$ values, we predict that three-photon GHZ$_3$ and four-photon cluster-state sources in this platform can achieve $n$-photon generation rates up to $\sim 10^8$ and $\sim 10^6$ times larger, respectively, than silica-fiber- and MoS$_2$-based implementations with comparable geometry. We derive the quantum Hamiltonian and explicit $n$-photon generation rates for this platform, and show how suitable interferometric networks enable electrically and spectrally tunable GHZ, $W$, and cluster states based on genuine high-order nonlinear processes in a 2D excitonic Mott insulator. [SEP] [HINT] transition -> Materials Science (Syns: passage, modulation, changeover) | based -> Bioinformatics (Syns: ground, free-base, base) | networks -> Neuroscience (Syns: network, meshwork, electronic network)",Materials Science
"The brain has evolved to effectively control the body, and in order to understand the relationship we need to model the sensorimotor transformations underlying embodied control. As part of a coordinated effort, we are developing a general-purpose platform for behavior-driven simulation modeling high fidelity behavioral dynamics, biomechanics, and neural circuit architectures underlying embodied control. We present a pipeline for taking kinematics data from the neuroscience lab and creating a pipeline for recapitulating those natural movements in a biomechanical model. We implement a imitation learning framework to perform a dexterous forelimb reaching task with a musculoskeletal model in a simulated physics environment. The mouse arm model is currently training at faster than 1 million training steps per second due to GPU acceleration with JAX and Mujoco-MJX. We present results that indicate that adding naturalistic constraints on energy and velocity lead to simulated musculoskeletal activity that better predict real EMG signals. This work provides evidence to suggest that energy and control constraints are critical to modeling musculoskeletal motor control.",Bioinformatics
"The brain has evolved to effectively control the body, and in order to understand the relationship we need to model the sensorimotor transformations underlying embodied control. As part of a coordinated effort, we are developing a general-purpose platform for behavior-driven simulation modeling high fidelity behavioral dynamics, biomechanics, and neural circuit architectures underlying embodied control. We present a pipeline for taking kinematics data from the neuroscience lab and creating a pipeline for recapitulating those natural movements in a biomechanical model. We implement a imitation learning framework to perform a dexterous forelimb reaching task with a musculoskeletal model in a simulated physics environment. The mouse arm model is currently training at faster than 1 million training steps per second due to GPU acceleration with JAX and Mujoco-MJX. We present results that indicate that adding naturalistic constraints on energy and velocity lead to simulated musculoskeletal activity that better predict real EMG signals. This work provides evidence to suggest that energy and control constraints are critical to modeling musculoskeletal motor control. [SEP] [HINT] task -> Neuroscience (Syns: tax, project, chore) | learning -> Bioinformatics (Syns: take, teach, acquire) | order -> Materials Science (Syns: enjoin, dictate, social club)",Bioinformatics
"Predicting species distributions using occupancy models accounting for imperfect detection is now commonplace in ecology. Recently, modelling spatial and temporal autocorrelation was proposed to alleviate the lack of replication in occupancy data, which often prevents model identifiability. However, how such models perform in highly heterogeneous datasets where missing or single-visit data dominates remains an open question. Motivated by an heterogeneous fine-scale butterfly occupancy dataset, we evaluate the performance of a multi-season occupancy model with spatial and temporal random effects to a skewed (Poisson) distribution of the number of surveys per site, overlap of covariates between occupancy and detection submodels, and spatiotemporal clustering of observations. Results showed that the model is robust to heterogeneous data and covariate overlap. However, when spatiotemporal gaps were added, site occupancy was biased towards the average occupancy, itself overestimated. Random effects did not correct the influence of gaps, due to identifiability issues of variance and autocorrelation parameters. Occupancy analysis of two butterfly species further confirmed these results. Overall, multi-season occupancy models with autocorrelation are robust to heterogeneous data and covariate overlap, but still present identifiability issues and are challenged by severe data gaps, which compromise predictions even in data-rich areas.",Bioinformatics
"Predicting species distributions using occupancy models accounting for imperfect detection is now commonplace in ecology. Recently, modelling spatial and temporal autocorrelation was proposed to alleviate the lack of replication in occupancy data, which often prevents model identifiability. However, how such models perform in highly heterogeneous datasets where missing or single-visit data dominates remains an open question. Motivated by an heterogeneous fine-scale butterfly occupancy dataset, we evaluate the performance of a multi-season occupancy model with spatial and temporal random effects to a skewed (Poisson) distribution of the number of surveys per site, overlap of covariates between occupancy and detection submodels, and spatiotemporal clustering of observations. Results showed that the model is robust to heterogeneous data and covariate overlap. However, when spatiotemporal gaps were added, site occupancy was biased towards the average occupancy, itself overestimated. Random effects did not correct the influence of gaps, due to identifiability issues of variance and autocorrelation parameters. Occupancy analysis of two butterfly species further confirmed these results. Overall, multi-season occupancy models with autocorrelation are robust to heterogeneous data and covariate overlap, but still present identifiability issues and are challenged by severe data gaps, which compromise predictions even in data-rich areas. [SEP] [HINT] datasets -> Bioinformatics (Syns: ) | performance -> Bioinformatics (Syns: functioning, operation, carrying out) | results -> Bioinformatics (Syns: final result, consequence, resultant role)",Bioinformatics
"The sharp rise in medical tomography examinations has created a demand for automated systems that can reliably extract informative features for downstream tasks such as tumor characterization. Although 3D volumes contain richer information than individual slices, effective 3D classification remains difficult: volumetric data encode complex spatial dependencies, and the scarcity of large-scale 3D datasets has constrained progress toward 3D foundation models. As a result, many recent approaches rely on 2D vision foundation models trained on natural images, repurposing them as feature extractors for medical scans with surprisingly strong performance. Despite their practical success, current methods that apply 2D foundation models to 3D scans via slice-based decomposition remain fundamentally limited. Standard slicing along axial, sagittal, and coronal planes often fails to capture the true spatial extent of a structure when its orientation does not align with these canonical views. More critically, most approaches aggregate slice features independently, ignoring the underlying 3D geometry and losing spatial coherence across slices. To overcome these limitations, we propose TomoGraphView, a novel framework that integrates omnidirectional volume slicing with spherical graph-based feature aggregation. Instead of restricting the model to axial, sagittal, or coronal planes, our method samples both canonical and non-canonical cross-sections generated from uniformly distributed points on a sphere enclosing the volume. We publicly share our accessible code base at http://github.com/compai-lab/2025-MedIA-kiechle and provide a user-friendly library for omnidirectional volume slicing at https://pypi.org/project/OmniSlicer.",Bioinformatics
"The sharp rise in medical tomography examinations has created a demand for automated systems that can reliably extract informative features for downstream tasks such as tumor characterization. Although 3D volumes contain richer information than individual slices, effective 3D classification remains difficult: volumetric data encode complex spatial dependencies, and the scarcity of large-scale 3D datasets has constrained progress toward 3D foundation models. As a result, many recent approaches rely on 2D vision foundation models trained on natural images, repurposing them as feature extractors for medical scans with surprisingly strong performance. Despite their practical success, current methods that apply 2D foundation models to 3D scans via slice-based decomposition remain fundamentally limited. Standard slicing along axial, sagittal, and coronal planes often fails to capture the true spatial extent of a structure when its orientation does not align with these canonical views. More critically, most approaches aggregate slice features independently, ignoring the underlying 3D geometry and losing spatial coherence across slices. To overcome these limitations, we propose TomoGraphView, a novel framework that integrates omnidirectional volume slicing with spherical graph-based feature aggregation. Instead of restricting the model to axial, sagittal, or coronal planes, our method samples both canonical and non-canonical cross-sections generated from uniformly distributed points on a sphere enclosing the volume. We publicly share our accessible code base at http://github.com/compai-lab/2025-MedIA-kiechle and provide a user-friendly library for omnidirectional volume slicing at https://pypi.org/project/OmniSlicer. [SEP] [HINT] tasks -> Neuroscience (Syns: tax, task, project) | features -> Bioinformatics (Syns: characteristic, lineament, feature of speech) | structure -> Bioinformatics (Syns: social system, complex body part, social structure)",Bioinformatics
"Surgical video datasets are essential for scene understanding, enabling procedural modeling and intra-operative support. However, these datasets are often heavily imbalanced, with rare actions and tools under-represented, which limits the robustness of downstream models. We address this challenge with $SurgiFlowVid$, a sparse and controllable video diffusion framework for generating surgical videos of under-represented classes. Our approach introduces a dual-prediction diffusion module that jointly denoises RGB frames and optical flow, providing temporal inductive biases to improve motion modeling from limited samples. In addition, a sparse visual encoder conditions the generation process on lightweight signals (e.g., sparse segmentation masks or RGB frames), enabling controllability without dense annotations. We validate our approach on three surgical datasets across tasks including action recognition, tool presence detection, and laparoscope motion prediction. Synthetic data generated by our method yields consistent gains of 10-20% over competitive baselines, establishing $SurgiFlowVid$ as a promising strategy to mitigate data imbalance and advance surgical video understanding methods.",Bioinformatics
"Surgical video datasets are essential for scene understanding, enabling procedural modeling and intra-operative support. However, these datasets are often heavily imbalanced, with rare actions and tools under-represented, which limits the robustness of downstream models. We address this challenge with $SurgiFlowVid$, a sparse and controllable video diffusion framework for generating surgical videos of under-represented classes. Our approach introduces a dual-prediction diffusion module that jointly denoises RGB frames and optical flow, providing temporal inductive biases to improve motion modeling from limited samples. In addition, a sparse visual encoder conditions the generation process on lightweight signals (e.g., sparse segmentation masks or RGB frames), enabling controllability without dense annotations. We validate our approach on three surgical datasets across tasks including action recognition, tool presence detection, and laparoscope motion prediction. Synthetic data generated by our method yields consistent gains of 10-20% over competitive baselines, establishing $SurgiFlowVid$ as a promising strategy to mitigate data imbalance and advance surgical video understanding methods. [SEP] [HINT] tasks -> Neuroscience (Syns: tax, task, project) | understanding -> Neuroscience (Syns: savvy, intellect, sympathy) | datasets -> Bioinformatics (Syns: )",Bioinformatics
"Monolithic perovskite-silicon tandem solar cells experienced a significant increase in efficiency, making them viable for industrial applications. Among the various scalable and industry-compatible metal halide perovskite deposition techniques, co-evaporation stands out as particularly well-suited for perovskite-silicon tandem solar cells due to its ability to conformally cover textured silicon bottom cells. Solution-processed [2-(3,6-Dimethoxy-9H-carbazol-9-yl)ethyl]phosphonic acid (MeO-2PACz) is commonly used as a hole-transporting material for co-evaporated metal halide perovskites. However, we show that it covers the textured surface of silicon bottom cells unevenly, impacting the film growth and leading to the formation of residual PbI2 at the buried interface. The present study reveals via X-ray photoemission electron microscopy (XPEEM) and infrared scattering-type scanning near-field optical microscope (IR s-SNOM) that a CsCl seed layer fosters organic precursor incorporation across the MeO-2PACz/perovskite interface, even in the areas with a thin MeO-2PACz layer, thereby preventing the formation of interfacial PbI2 and leading to larger apparent grains. The improvement of the metal halide perovskite film quality on the MeO-2PACz/perovskite interface and the bulk perovskite film led to 30.3% (29.7% certified) efficient perovskite-silicon tandem solar cell. The present work highlights the importance of a seed layer for a robust growth of co-evaporated metal halide perovskite and represents an important milestone for the transfer of perovskite-silicon tandem solar cells from laboratory to industry.",Materials Science
"Monolithic perovskite-silicon tandem solar cells experienced a significant increase in efficiency, making them viable for industrial applications. Among the various scalable and industry-compatible metal halide perovskite deposition techniques, co-evaporation stands out as particularly well-suited for perovskite-silicon tandem solar cells due to its ability to conformally cover textured silicon bottom cells. Solution-processed [2-(3,6-Dimethoxy-9H-carbazol-9-yl)ethyl]phosphonic acid (MeO-2PACz) is commonly used as a hole-transporting material for co-evaporated metal halide perovskites. However, we show that it covers the textured surface of silicon bottom cells unevenly, impacting the film growth and leading to the formation of residual PbI2 at the buried interface. The present study reveals via X-ray photoemission electron microscopy (XPEEM) and infrared scattering-type scanning near-field optical microscope (IR s-SNOM) that a CsCl seed layer fosters organic precursor incorporation across the MeO-2PACz/perovskite interface, even in the areas with a thin MeO-2PACz layer, thereby preventing the formation of interfacial PbI2 and leading to larger apparent grains. The improvement of the metal halide perovskite film quality on the MeO-2PACz/perovskite interface and the bulk perovskite film led to 30.3% (29.7% certified) efficient perovskite-silicon tandem solar cell. The present work highlights the importance of a seed layer for a robust growth of co-evaporated metal halide perovskite and represents an important milestone for the transfer of perovskite-silicon tandem solar cells from laboratory to industry. [SEP] [HINT] used -> Bioinformatics (Syns: utilize, ill-used, apply) | perovskite -> Materials Science (Syns: ) | electron -> Materials Science (Syns: negatron)",Materials Science
"In-context learners like TabPFN are promising for biomolecule efficacy prediction, where established molecular feature sets and relevant experimental results can serve as powerful contextual examples. However, their performance is highly sensitive to the provided context, making strategies like post-hoc ensembling of models trained on different data subsets a viable approach. An open question is how to select the best models for the ensemble without access to ground truth labels. In this study, we investigate an uncertainty-guided strategy for model selection. We demonstrate on an siRNA knockdown efficacy task that a TabPFN model using straightforward sequence-based features can surpass specialized state-of-the-art predictors. We also show that the model's predicted inter-quantile range (IQR), a measure of its uncertainty, has a negative correlation with true prediction error. We developed the OligoICP method, which selects and averages an ensemble of models with the lowest mean IQR for siRNA efficacy prediction, achieving superior performance compared to naive ensembling or using a single model trained on all available data. This finding highlights model uncertainty as a powerful, label-free heuristic for optimizing biomolecule efficacy predictions.",Bioinformatics
"In-context learners like TabPFN are promising for biomolecule efficacy prediction, where established molecular feature sets and relevant experimental results can serve as powerful contextual examples. However, their performance is highly sensitive to the provided context, making strategies like post-hoc ensembling of models trained on different data subsets a viable approach. An open question is how to select the best models for the ensemble without access to ground truth labels. In this study, we investigate an uncertainty-guided strategy for model selection. We demonstrate on an siRNA knockdown efficacy task that a TabPFN model using straightforward sequence-based features can surpass specialized state-of-the-art predictors. We also show that the model's predicted inter-quantile range (IQR), a measure of its uncertainty, has a negative correlation with true prediction error. We developed the OligoICP method, which selects and averages an ensemble of models with the lowest mean IQR for siRNA efficacy prediction, achieving superior performance compared to naive ensembling or using a single model trained on all available data. This finding highlights model uncertainty as a powerful, label-free heuristic for optimizing biomolecule efficacy predictions. [SEP] [HINT] task -> Neuroscience (Syns: tax, project, chore) | features -> Bioinformatics (Syns: characteristic, lineament, feature of speech) | molecular -> Bioinformatics (Syns: )",Bioinformatics
"Despite growing reference libraries and advanced computational tools, progress in the field of metabolomics remains constrained by low rates of annotating measured spectra. The recent developments of large language models (LLMs) have led to strong performance across a wide range of generation and reasoning tasks, spurring increased interest in LLMs' application to domain-specific scientific challenges, such as mass spectra annotation. Here, we present a novel framework, General Intelligence-based Fragmentation (GIF), that guides pretrained LLMs through spectra simulation using structured prompting and reasoning. GIF utilizes tagging, structured inputs/outputs, system prompts, instruction-based prompts, and iterative refinement. Indeed, GIF offers a structured alternative to ad hoc prompting, underscoring the need for systematic guidance of LLMs on complex scientific tasks. Using GIF, we evaluate current generalist LLMs' ability to use reasoning towards fragmentation and to perform intensity prediction after fine-tuning. We benchmark performance on a novel QA dataset, the MassSpecGym QA-sim dataset, that we derive from the MassSpecGym dataset. Through these implementations of GIF, we find that GPT-4o and GPT-4o-mini achieve a cosine similarity of 0.36 and 0.35 between the simulated and true spectra, respectively, outperforming other pretrained models including GPT-5, Llama-3.1, and ChemDFM, despite GPT-5's recency and ChemDFM's domain specialization. GIF outperforms several deep learning baselines. Our evaluation of GIF highlights the value of using LLMs not only for spectra simulation but for enabling human-in-the-loop workflows and structured, explainable reasoning in molecular fragmentation.",Bioinformatics
"Despite growing reference libraries and advanced computational tools, progress in the field of metabolomics remains constrained by low rates of annotating measured spectra. The recent developments of large language models (LLMs) have led to strong performance across a wide range of generation and reasoning tasks, spurring increased interest in LLMs' application to domain-specific scientific challenges, such as mass spectra annotation. Here, we present a novel framework, General Intelligence-based Fragmentation (GIF), that guides pretrained LLMs through spectra simulation using structured prompting and reasoning. GIF utilizes tagging, structured inputs/outputs, system prompts, instruction-based prompts, and iterative refinement. Indeed, GIF offers a structured alternative to ad hoc prompting, underscoring the need for systematic guidance of LLMs on complex scientific tasks. Using GIF, we evaluate current generalist LLMs' ability to use reasoning towards fragmentation and to perform intensity prediction after fine-tuning. We benchmark performance on a novel QA dataset, the MassSpecGym QA-sim dataset, that we derive from the MassSpecGym dataset. Through these implementations of GIF, we find that GPT-4o and GPT-4o-mini achieve a cosine similarity of 0.36 and 0.35 between the simulated and true spectra, respectively, outperforming other pretrained models including GPT-5, Llama-3.1, and ChemDFM, despite GPT-5's recency and ChemDFM's domain specialization. GIF outperforms several deep learning baselines. Our evaluation of GIF highlights the value of using LLMs not only for spectra simulation but for enabling human-in-the-loop workflows and structured, explainable reasoning in molecular fragmentation. [SEP] [HINT] field -> Materials Science (Syns: field of honor, line of business, orbit) | low -> Materials Science (Syns: low-spirited, scurvy, depressed) | language -> Neuroscience (Syns: linguistic process, linguistic communication, spoken communication)",Bioinformatics
"The extent to which different neural or artificial neural networks (models) rely on equivalent representations to support similar tasks remains a central question in neuroscience and machine learning. Prior work has typically compared systems using a single representational similarity metric, yet each captures only one facet of representational structure. To address this, we leverage a suite of representational similarity metrics-each capturing a distinct facet of representational correspondence, such as geometry, unit-level tuning, or linear decodability-and assess brain region or model separability using multiple complementary measures. Metrics that preserve geometric or tuning structure (e.g., RSA, Soft Matching) yield stronger region-based discrimination, whereas more flexible mappings such as Linear Predictivity show weaker separation. These findings suggest that geometry and tuning encode brain-region- or model-family-specific signatures, while linearly decodable information tends to be more globally shared across regions or models. To integrate these complementary representational facets, we adapt Similarity Network Fusion (SNF), a framework originally developed for multi-omics data integration. SNF produces substantially sharper regional and model family-level separation than any single metric and yields robust composite similarity profiles. Moreover, clustering cortical regions using SNF-derived similarity scores reveals a clearer hierarchical organization that aligns closely with established anatomical and functional hierarchies of the visual cortex-surpassing the correspondence achieved by individual metrics.",Neuroscience
"The extent to which different neural or artificial neural networks (models) rely on equivalent representations to support similar tasks remains a central question in neuroscience and machine learning. Prior work has typically compared systems using a single representational similarity metric, yet each captures only one facet of representational structure. To address this, we leverage a suite of representational similarity metrics-each capturing a distinct facet of representational correspondence, such as geometry, unit-level tuning, or linear decodability-and assess brain region or model separability using multiple complementary measures. Metrics that preserve geometric or tuning structure (e.g., RSA, Soft Matching) yield stronger region-based discrimination, whereas more flexible mappings such as Linear Predictivity show weaker separation. These findings suggest that geometry and tuning encode brain-region- or model-family-specific signatures, while linearly decodable information tends to be more globally shared across regions or models. To integrate these complementary representational facets, we adapt Similarity Network Fusion (SNF), a framework originally developed for multi-omics data integration. SNF produces substantially sharper regional and model family-level separation than any single metric and yields robust composite similarity profiles. Moreover, clustering cortical regions using SNF-derived similarity scores reveals a clearer hierarchical organization that aligns closely with established anatomical and functional hierarchies of the visual cortex-surpassing the correspondence achieved by individual metrics. [SEP] [HINT] tasks -> Neuroscience (Syns: tax, task, project) | cortical -> Neuroscience (Syns: ) | networks -> Neuroscience (Syns: network, meshwork, electronic network)",Neuroscience
"The relationship between Integrated Information Theory (IIT) and the Free-Energy Principle (FEP) remains unresolved, particularly with respect to how integrated information, proposed as the intrinsic substrate of consciousness, behaves within variational Bayesian inference. We investigated this issue using dissociated neuronal cultures, previously shown to perform perceptual inference consistent with the FEP. Repeated stimulation from hidden sources induced robust source selectivity: variational free energy (VFE) decreased across sessions, whereas accuracy and Bayesian surprise (complexity) increased. Network-level analyses revealed that a proxy measure of integrated information and the size of the main complex followed a hill-shaped trajectory, with informational cores organizing diverse neuronal activity. Across experiments, integrated information correlated strongly and positively with Bayesian surprise, modestly and heterogeneously with accuracy, and showed no significant relationship with VFE. The positive coupling between Φ and Bayesian surprise likely reflects the diversity of activity observed in critical dynamics. These findings suggest that integrated information increases specifically during belief updating, when sensory inputs are most informative, rather than tracking model efficiency. The hill-shaped trajectory of Φ during inference can be functionally interpreted as a transition from exploration to exploitation. This work provides empirical evidence linking the physical account of consciousness advanced by IIT with the functional perspective offered by the FEP, contributing to a unified framework for the mechanisms and adaptive roles of phenomenology.",Neuroscience
"The relationship between Integrated Information Theory (IIT) and the Free-Energy Principle (FEP) remains unresolved, particularly with respect to how integrated information, proposed as the intrinsic substrate of consciousness, behaves within variational Bayesian inference. We investigated this issue using dissociated neuronal cultures, previously shown to perform perceptual inference consistent with the FEP. Repeated stimulation from hidden sources induced robust source selectivity: variational free energy (VFE) decreased across sessions, whereas accuracy and Bayesian surprise (complexity) increased. Network-level analyses revealed that a proxy measure of integrated information and the size of the main complex followed a hill-shaped trajectory, with informational cores organizing diverse neuronal activity. Across experiments, integrated information correlated strongly and positively with Bayesian surprise, modestly and heterogeneously with accuracy, and showed no significant relationship with VFE. The positive coupling between Φ and Bayesian surprise likely reflects the diversity of activity observed in critical dynamics. These findings suggest that integrated information increases specifically during belief updating, when sensory inputs are most informative, rather than tracking model efficiency. The hill-shaped trajectory of Φ during inference can be functionally interpreted as a transition from exploration to exploitation. This work provides empirical evidence linking the physical account of consciousness advanced by IIT with the functional perspective offered by the FEP, contributing to a unified framework for the mechanisms and adaptive roles of phenomenology. [SEP] [HINT] transition -> Materials Science (Syns: passage, modulation, changeover) | functional -> Neuroscience (Syns: working, usable, running) | information -> Bioinformatics (Syns: entropy, data, info)",Neuroscience
"Neural network models capable of storing memory have been extensively studied in computer science and computational neuroscience. The Hopfield network is a prototypical example of a model designed for associative, or content-addressable, memory and has been analyzed in many forms. Further, ideas and methods from complex network theory have been incorporated into artificial neural networks and learning, emphasizing their structural properties. Nevertheless, the temporal dynamics also play a vital role in biological neural networks, whose temporal structure is a crucial feature to examine. Biological neural networks display complex intermittency and, thus, can be studied through the lens of the temporal complexity (TC) theory. The TC approach look at the metastability of self-organized states, characterized by a power-law decay in the inter-event time distribution and in the total activity distribution or a scaling behavior in the corresponding event-driven diffusion processes. In this study, we present a temporal complexity (TC) analysis of a biologically-inspired Hopfield-type neural network model. We conducted a comparative assessment between scale-free and random network topologies, with particular emphasis on their global activation patterns. Our parametric analysis revealed comparable dynamical behaviors across both neural network architectures. Furthermore, our investigation into temporal complexity characteristics uncovered that seemingly distinct dynamical patterns exhibit similar temporal complexity behaviors. In particular, similar power-law decay in the activity distribution and similar complexity levels are observed in both topologies, but with a much reduced noise in the scale-free topology. Notably, most of the complex dynamical profiles were consistently observed in scale-free network configurations, thus confirming the crucial role of hubs in neural network dynamics.",Neuroscience
"Neural network models capable of storing memory have been extensively studied in computer science and computational neuroscience. The Hopfield network is a prototypical example of a model designed for associative, or content-addressable, memory and has been analyzed in many forms. Further, ideas and methods from complex network theory have been incorporated into artificial neural networks and learning, emphasizing their structural properties. Nevertheless, the temporal dynamics also play a vital role in biological neural networks, whose temporal structure is a crucial feature to examine. Biological neural networks display complex intermittency and, thus, can be studied through the lens of the temporal complexity (TC) theory. The TC approach look at the metastability of self-organized states, characterized by a power-law decay in the inter-event time distribution and in the total activity distribution or a scaling behavior in the corresponding event-driven diffusion processes. In this study, we present a temporal complexity (TC) analysis of a biologically-inspired Hopfield-type neural network model. We conducted a comparative assessment between scale-free and random network topologies, with particular emphasis on their global activation patterns. Our parametric analysis revealed comparable dynamical behaviors across both neural network architectures. Furthermore, our investigation into temporal complexity characteristics uncovered that seemingly distinct dynamical patterns exhibit similar temporal complexity behaviors. In particular, similar power-law decay in the activity distribution and similar complexity levels are observed in both topologies, but with a much reduced noise in the scale-free topology. Notably, most of the complex dynamical profiles were consistently observed in scale-free network configurations, thus confirming the crucial role of hubs in neural network dynamics. [SEP] [HINT] computational -> Neuroscience (Syns: ) | networks -> Neuroscience (Syns: network, meshwork, electronic network) | structure -> Bioinformatics (Syns: social system, complex body part, social structure)",Neuroscience
"Radiology is essential to modern healthcare, yet rising demand and staffing shortages continue to pose major challenges. Recent advances in artificial intelligence have the potential to support radiologists and help address these challenges. Given its widespread use and clinical importance, chest X-ray classification is well suited to augment radiologists' workflows. However, most existing approaches rely solely on single-view, image-level inputs, ignoring the structured clinical information and multi-image studies available at the time of reporting. In this work, we introduce CaMCheX, a multimodal transformer-based framework that aligns multi-view chest X-ray studies with structured clinical data to better reflect how clinicians make diagnostic decisions. Our architecture employs view-specific ConvNeXt encoders for frontal and lateral chest radiographs, whose features are fused with clinical indications, history, and vital signs using a transformer fusion module. This design enables the model to generate context-aware representations that mirror reasoning in clinical practice. Our results exceed the state of the art for both the original MIMIC-CXR dataset and the more recent CXR-LT benchmarks, highlighting the value of clinically grounded multimodal alignment for advancing chest X-ray classification.",Bioinformatics
"Radiology is essential to modern healthcare, yet rising demand and staffing shortages continue to pose major challenges. Recent advances in artificial intelligence have the potential to support radiologists and help address these challenges. Given its widespread use and clinical importance, chest X-ray classification is well suited to augment radiologists' workflows. However, most existing approaches rely solely on single-view, image-level inputs, ignoring the structured clinical information and multi-image studies available at the time of reporting. In this work, we introduce CaMCheX, a multimodal transformer-based framework that aligns multi-view chest X-ray studies with structured clinical data to better reflect how clinicians make diagnostic decisions. Our architecture employs view-specific ConvNeXt encoders for frontal and lateral chest radiographs, whose features are fused with clinical indications, history, and vital signs using a transformer fusion module. This design enables the model to generate context-aware representations that mirror reasoning in clinical practice. Our results exceed the state of the art for both the original MIMIC-CXR dataset and the more recent CXR-LT benchmarks, highlighting the value of clinically grounded multimodal alignment for advancing chest X-ray classification. [SEP] [HINT] clinical -> Bioinformatics (Syns: ) | features -> Bioinformatics (Syns: characteristic, lineament, feature of speech) | information -> Bioinformatics (Syns: entropy, data, info)",Bioinformatics
"Linearly transforming stimulus representations of deep neural networks yields high-performing models of behavioral and neural responses to complex stimuli. But does the test accuracy of such predictions identify genuine representational alignment? We addressed this question through a large-scale model-recovery study. Twenty diverse vision models were linearly aligned to 4.5 million behavioral judgments from the THINGS odd-one-out dataset and calibrated to reproduce human response variability. For each model in turn, we sampled synthetic responses from its probabilistic predictions, fitted all candidate models to the synthetic data, and tested whether the data-generating model would re-emerge as the best predictor of the simulated data. Model recovery accuracy improved with training-set size but plateaued below 80%, even at millions of simulated trials. Regression analyses linked misidentification primarily to shifts in representational geometry induced by the linear transformation, as well as to the effective dimensionality of the transformed features. These findings demonstrate that, even with massive behavioral data, overly flexible alignment metrics may fail to guide us toward artificial representations that are genuinely more human-aligned. Model comparison experiments must be designed to balance the trade-off between predictive accuracy and identifiability-ensuring that the best-fitting model is also the right one.",Neuroscience
"Linearly transforming stimulus representations of deep neural networks yields high-performing models of behavioral and neural responses to complex stimuli. But does the test accuracy of such predictions identify genuine representational alignment? We addressed this question through a large-scale model-recovery study. Twenty diverse vision models were linearly aligned to 4.5 million behavioral judgments from the THINGS odd-one-out dataset and calibrated to reproduce human response variability. For each model in turn, we sampled synthetic responses from its probabilistic predictions, fitted all candidate models to the synthetic data, and tested whether the data-generating model would re-emerge as the best predictor of the simulated data. Model recovery accuracy improved with training-set size but plateaued below 80%, even at millions of simulated trials. Regression analyses linked misidentification primarily to shifts in representational geometry induced by the linear transformation, as well as to the effective dimensionality of the transformed features. These findings demonstrate that, even with massive behavioral data, overly flexible alignment metrics may fail to guide us toward artificial representations that are genuinely more human-aligned. Model comparison experiments must be designed to balance the trade-off between predictive accuracy and identifiability-ensuring that the best-fitting model is also the right one. [SEP] [HINT] networks -> Neuroscience (Syns: network, meshwork, electronic network) | complex -> Bioinformatics (Syns: building complex, coordination compound, composite) | human -> Neuroscience (Syns: human being, man, homo)",Neuroscience
"The turn of the millennium has seen a growing interest in the study of live cells by infrared (IR) spectroscopy, driven by the versatility, wealth of molecular information, and potential for high-throughput screening of the technique. Measurements on individual cells, either isolated or within a multi-cellular structure, provide information that is not available from ensemble samples. The present review discusses the use of infrared (IR) microscopy to analyse live single cells from a biochemical perspective, seeking information on real-time processes. The emphasis is on the use of the technique to quantify metabolic turnover, with the aim of providing a complementary method for metabolomics, and for toxicological and pharmacological studies. The work highlights the methodological advances and proof-of-concept experiments that took place over the past few years in this direction. It discusses current advantages and limitations of the technique, including the possibility of detecting specific biomolecules and their reactivity, and it concludes with a brief outline of future perspectives.",Bioinformatics
"The turn of the millennium has seen a growing interest in the study of live cells by infrared (IR) spectroscopy, driven by the versatility, wealth of molecular information, and potential for high-throughput screening of the technique. Measurements on individual cells, either isolated or within a multi-cellular structure, provide information that is not available from ensemble samples. The present review discusses the use of infrared (IR) microscopy to analyse live single cells from a biochemical perspective, seeking information on real-time processes. The emphasis is on the use of the technique to quantify metabolic turnover, with the aim of providing a complementary method for metabolomics, and for toxicological and pharmacological studies. The work highlights the methodological advances and proof-of-concept experiments that took place over the past few years in this direction. It discusses current advantages and limitations of the technique, including the possibility of detecting specific biomolecules and their reactivity, and it concludes with a brief outline of future perspectives. [SEP] [HINT] information -> Bioinformatics (Syns: entropy, data, info) | molecular -> Bioinformatics (Syns: ) | work -> Bioinformatics (Syns: work out, process, bring)",Bioinformatics
"The global demand for sustainable protein sources is driving increasing interest in edible insects, with Acheta domesticus (house cricket) identified as one of the most suitable species for industrial production. Current farming practices typically rear crickets in mixed-sex populations without automated sex sorting, despite potential benefits such as selective breeding, optimized reproduction ratios, and nutritional differentiation. This work presents a low-cost, real-time system for automated sex-based sorting of Acheta domesticus, combining computer vision and physical actuation. The device integrates a Raspberry Pi 5 with the official Raspberry AI Camera and a custom YOLOv8 nano object detection model, together with a servo-actuated sorting arm. The model reached a mean Average Precision at IoU 0.5 (mAP@0.5) of 0.977 during testing, and real-world experiments with groups of crickets achieved an overall sorting accuracy of 86.8%. These results demonstrate the feasibility of deploying lightweight deep learning models on resource-constrained devices for insect farming applications, offering a practical solution to improve efficiency and sustainability in cricket production.",Bioinformatics
"The global demand for sustainable protein sources is driving increasing interest in edible insects, with Acheta domesticus (house cricket) identified as one of the most suitable species for industrial production. Current farming practices typically rear crickets in mixed-sex populations without automated sex sorting, despite potential benefits such as selective breeding, optimized reproduction ratios, and nutritional differentiation. This work presents a low-cost, real-time system for automated sex-based sorting of Acheta domesticus, combining computer vision and physical actuation. The device integrates a Raspberry Pi 5 with the official Raspberry AI Camera and a custom YOLOv8 nano object detection model, together with a servo-actuated sorting arm. The model reached a mean Average Precision at IoU 0.5 (mAP@0.5) of 0.977 during testing, and real-world experiments with groups of crickets achieved an overall sorting accuracy of 86.8%. These results demonstrate the feasibility of deploying lightweight deep learning models on resource-constrained devices for insect farming applications, offering a practical solution to improve efficiency and sustainability in cricket production. [SEP] [HINT] learning -> Bioinformatics (Syns: take, teach, acquire) | work -> Bioinformatics (Syns: work out, process, bring) | results -> Bioinformatics (Syns: final result, consequence, resultant role)",Bioinformatics
"The objective of this paper is to review physiological and computational aspects of the responsiveness of the cerebral cortex to stimulation, and how responsiveness depends on the state of the system. This correspondence between brain state and brain responsiveness (state-dependent responses) is outlined at different scales from the cellular and circuit level, to the mesoscale and macroscale level. At each scale, we review how quantitative methods can be used to characterize network states based on brain responses, such as the Perturbational Complexity Index (PCI). This description will compare data and models, systematically and at multiple scales, with a focus on the mechanisms that explain how brain responses depend on brain states.",Neuroscience
"The objective of this paper is to review physiological and computational aspects of the responsiveness of the cerebral cortex to stimulation, and how responsiveness depends on the state of the system. This correspondence between brain state and brain responsiveness (state-dependent responses) is outlined at different scales from the cellular and circuit level, to the mesoscale and macroscale level. At each scale, we review how quantitative methods can be used to characterize network states based on brain responses, such as the Perturbational Complexity Index (PCI). This description will compare data and models, systematically and at multiple scales, with a focus on the mechanisms that explain how brain responses depend on brain states. [SEP] [HINT] used -> Bioinformatics (Syns: utilize, ill-used, apply) | network -> Bioinformatics (Syns: meshwork, electronic network, mesh) | different -> Neuroscience (Syns: unlike, dissimilar)",Neuroscience
"Traditional non-biological storage media, such as hard drives, face limitations in both storage density and lifespan due to the rapid growth of data in the big data era. Mirror-image peptides composed of D-amino acids have emerged as a promising biological storage medium due to their high storage density, structural stability, and long lifespan. The sequencing of mirror-image peptides relies on \textit{de-novo} technology. However, its accuracy is limited by the scarcity of tandem mass spectrometry datasets and the challenges that current algorithms encounter when processing these peptides directly. This study is the first to propose improving sequencing accuracy indirectly by optimizing the design of mirror-image peptide sequences. In this work, we introduce DBond, a deep neural network based model that integrates sequence features, precursor ion properties, and mass spectrometry environmental factors for the prediction of mirror-image peptide bond cleavage. In this process, sequences with a high peptide bond cleavage ratio, which are easy to sequence, are selected. The main contributions of this study are as follows. First, we constructed MiPD513, a tandem mass spectrometry dataset containing 513 mirror-image peptides. Second, we developed the peptide bond cleavage labeling algorithm (PBCLA), which generated approximately 12.5 million labeled data based on MiPD513. Third, we proposed a dual prediction strategy that combines multi-label and single-label classification. On an independent test set, the single-label classification strategy outperformed other methods in both single and multiple peptide bond cleavage prediction tasks, offering a strong foundation for sequence optimization.",Bioinformatics
"Traditional non-biological storage media, such as hard drives, face limitations in both storage density and lifespan due to the rapid growth of data in the big data era. Mirror-image peptides composed of D-amino acids have emerged as a promising biological storage medium due to their high storage density, structural stability, and long lifespan. The sequencing of mirror-image peptides relies on \textit{de-novo} technology. However, its accuracy is limited by the scarcity of tandem mass spectrometry datasets and the challenges that current algorithms encounter when processing these peptides directly. This study is the first to propose improving sequencing accuracy indirectly by optimizing the design of mirror-image peptide sequences. In this work, we introduce DBond, a deep neural network based model that integrates sequence features, precursor ion properties, and mass spectrometry environmental factors for the prediction of mirror-image peptide bond cleavage. In this process, sequences with a high peptide bond cleavage ratio, which are easy to sequence, are selected. The main contributions of this study are as follows. First, we constructed MiPD513, a tandem mass spectrometry dataset containing 513 mirror-image peptides. Second, we developed the peptide bond cleavage labeling algorithm (PBCLA), which generated approximately 12.5 million labeled data based on MiPD513. Third, we proposed a dual prediction strategy that combines multi-label and single-label classification. On an independent test set, the single-label classification strategy outperformed other methods in both single and multiple peptide bond cleavage prediction tasks, offering a strong foundation for sequence optimization. [SEP] [HINT] based -> Bioinformatics (Syns: ground, free-base, base) | processing -> Neuroscience (Syns: work, process, march) | datasets -> Bioinformatics (Syns: )",Bioinformatics
"We formulate the tight-binding model for cubic $α$-Sn based on the DFT calculations. In the model, we incorporate a variable bond angle, which allows us to simulate the effect of the in-plane strain. In the bulk, we demonstrate the presence of the $\mathbb{Z}_2$ topological invariant and a non-zero mirror Chern number, making $α$-Sn one of the rare cases where dual topology can be observed. We calculate the topological phase diagram of multi-layer $α$-Sn as a function of strain and number of layers. We find that a non-trivial quantum spin Hall state appears only for compressive strain above five layers of thickness. Quite surprisingly, both in the trivial and non-trivial phases, we find a plethora of edge-states with energies inside the bulk gap of the system. Some of these states are localized at the side surfaces of the slab, some of them prefer top/bottom surfaces and some are localized in the hinges. We trace the microscopic origin of these states back to a minimal model that supports chiral symmetry and multiple one-dimensional winding numbers that take different values in different directions in the Brillouin zone.",Materials Science
"We formulate the tight-binding model for cubic $α$-Sn based on the DFT calculations. In the model, we incorporate a variable bond angle, which allows us to simulate the effect of the in-plane strain. In the bulk, we demonstrate the presence of the $\mathbb{Z}_2$ topological invariant and a non-zero mirror Chern number, making $α$-Sn one of the rare cases where dual topology can be observed. We calculate the topological phase diagram of multi-layer $α$-Sn as a function of strain and number of layers. We find that a non-trivial quantum spin Hall state appears only for compressive strain above five layers of thickness. Quite surprisingly, both in the trivial and non-trivial phases, we find a plethora of edge-states with energies inside the bulk gap of the system. Some of these states are localized at the side surfaces of the slab, some of them prefer top/bottom surfaces and some are localized in the hinges. We trace the microscopic origin of these states back to a minimal model that supports chiral symmetry and multiple one-dimensional winding numbers that take different values in different directions in the Brillouin zone. [SEP] [HINT] based -> Bioinformatics (Syns: ground, free-base, base) | dft -> Materials Science (Syns: ) | spin -> Materials Science (Syns: twisting, whirl, tailspin)",Materials Science
"We report an experimental study of the magnetic-field dependence of the optically pumped valley polarization in an epitaxial tungsten diselenide (WSe$_2$) monolayer grown by molecular-beam epitaxy (MBE) on a hexagonal boron nitride (hBN) substrate. Circularly polarized photoluminescence (PL) measurements reveal that applying a weak out-of-plane magnetic field, on the order of 0.1 T, dramatically increases the effectiveness of the optical orientation of the emission associated with defect-bound localized excitons. We compare the obtained results with the earlier studies on the reference exfoliated monolayers, discussing both qualitative similarity as well as quantitative differences. Our observations are further supplemented by the results of time-resolved PL measurements, which confirm the pseudospin relaxation time of approximately 25 ps, a value significantly shorter than the $\approx$100 ps previously reported for mechanically exfoliated samples.",Materials Science
"We report an experimental study of the magnetic-field dependence of the optically pumped valley polarization in an epitaxial tungsten diselenide (WSe$_2$) monolayer grown by molecular-beam epitaxy (MBE) on a hexagonal boron nitride (hBN) substrate. Circularly polarized photoluminescence (PL) measurements reveal that applying a weak out-of-plane magnetic field, on the order of 0.1 T, dramatically increases the effectiveness of the optical orientation of the emission associated with defect-bound localized excitons. We compare the obtained results with the earlier studies on the reference exfoliated monolayers, discussing both qualitative similarity as well as quantitative differences. Our observations are further supplemented by the results of time-resolved PL measurements, which confirm the pseudospin relaxation time of approximately 25 ps, a value significantly shorter than the $\approx$100 ps previously reported for mechanically exfoliated samples. [SEP] [HINT] order -> Materials Science (Syns: enjoin, dictate, social club) | results -> Bioinformatics (Syns: final result, consequence, resultant role) | optical -> Materials Science (Syns: ocular, opthalmic, optic)",Materials Science
"Transcranial magnetic stimulation (TMS) with asymmetric electric field pulses, such as monophasic, offers directional selectivity for neural activation but requires excessive energy. Previous pulse shape optimisation has been limited to symmetric pulses or heavily constrained variations of conventional waveforms without achieving general optimality in energy efficiency or neural selectivity. We implemented an optimisation framework that incorporates neuron model activation constraints and flexible control of pulse asymmetry. The optimised electric field waveforms achieved up to 92 % and 88 % reduction in energy loss and thus coil heating respectively compared to conventional monophasic pulses and previously improved monophasic-equivalent pulses. In the human experiments, OUR pulses showed similar motor thresholds to monophasic pulses in both AP and PA directions with significantly lower energy loss, particularly in the AP direction. Moreover, there was a significant MEP latency difference of (1.79 +/- 0.41) ms between AP and PA direction with OUR pulses, which suggests directional selectivity. Our framework successfully identified highly energy-efficient asymmetric pulses for directionally-selective neural engagement. These pulses can enable selective rapid-rate repetitive TMS protocols with reduced power consumption and coil heating, with potential benefits for precision and potency of neuro-modulation.",Neuroscience
"Transcranial magnetic stimulation (TMS) with asymmetric electric field pulses, such as monophasic, offers directional selectivity for neural activation but requires excessive energy. Previous pulse shape optimisation has been limited to symmetric pulses or heavily constrained variations of conventional waveforms without achieving general optimality in energy efficiency or neural selectivity. We implemented an optimisation framework that incorporates neuron model activation constraints and flexible control of pulse asymmetry. The optimised electric field waveforms achieved up to 92 % and 88 % reduction in energy loss and thus coil heating respectively compared to conventional monophasic pulses and previously improved monophasic-equivalent pulses. In the human experiments, OUR pulses showed similar motor thresholds to monophasic pulses in both AP and PA directions with significantly lower energy loss, particularly in the AP direction. Moreover, there was a significant MEP latency difference of (1.79 +/- 0.41) ms between AP and PA direction with OUR pulses, which suggests directional selectivity. Our framework successfully identified highly energy-efficient asymmetric pulses for directionally-selective neural engagement. These pulses can enable selective rapid-rate repetitive TMS protocols with reduced power consumption and coil heating, with potential benefits for precision and potency of neuro-modulation. [SEP] [HINT] field -> Materials Science (Syns: field of honor, line of business, orbit) | human -> Neuroscience (Syns: human being, man, homo) | framework -> Bioinformatics (Syns: theoretical account, model, fabric)",Neuroscience
"Traumatic brain injury (TBI) is intrinsically heterogeneous, and typical clinical outcome measures like the Glasgow Coma Scale complicate this diversity. The large variability in severity and patient outcomes render it difficult to link structural damage to functional deficits. The Federal Interagency Traumatic Brain Injury Research (FITBIR) repository contains large-scale multi-site magnetic resonance imaging data of varying resolutions and acquisition parameters (25 shared studies with 7,693 sessions that have age, sex and TBI status defined - 5,811 TBI and 1,882 controls). To reveal shared pathways of injury of TBI through imaging, we analyzed T1-weighted images from these sessions by first harmonizing to a local dataset and segmenting 132 regions of interest (ROIs) in the brain. After running quality assurance, calculating the volumes of the ROIs, and removing outliers, we calculated the z-scores of volumes for all participants relative to the mean and standard deviation of the controls. We regressed out sex, age, and total brain volume with a multivariate linear regression, and we found significant differences in 37 ROIs between subjects with TBI and controls (p < 0.05 with independent t-tests with false discovery rate correction). We found that differences originated in 1) the brainstem, occipital pole and structures posterior to the orbit, 2) subcortical gray matter and insular cortex, and 3) cerebral and cerebellar white matter using independent component analysis and clustering the component loadings of those with TBI.",Bioinformatics
"Traumatic brain injury (TBI) is intrinsically heterogeneous, and typical clinical outcome measures like the Glasgow Coma Scale complicate this diversity. The large variability in severity and patient outcomes render it difficult to link structural damage to functional deficits. The Federal Interagency Traumatic Brain Injury Research (FITBIR) repository contains large-scale multi-site magnetic resonance imaging data of varying resolutions and acquisition parameters (25 shared studies with 7,693 sessions that have age, sex and TBI status defined - 5,811 TBI and 1,882 controls). To reveal shared pathways of injury of TBI through imaging, we analyzed T1-weighted images from these sessions by first harmonizing to a local dataset and segmenting 132 regions of interest (ROIs) in the brain. After running quality assurance, calculating the volumes of the ROIs, and removing outliers, we calculated the z-scores of volumes for all participants relative to the mean and standard deviation of the controls. We regressed out sex, age, and total brain volume with a multivariate linear regression, and we found significant differences in 37 ROIs between subjects with TBI and controls (p < 0.05 with independent t-tests with false discovery rate correction). We found that differences originated in 1) the brainstem, occipital pole and structures posterior to the orbit, 2) subcortical gray matter and insular cortex, and 3) cerebral and cerebellar white matter using independent component analysis and clustering the component loadings of those with TBI. [SEP] [HINT] clinical -> Bioinformatics (Syns: ) | functional -> Neuroscience (Syns: working, usable, running) | quality -> Bioinformatics (Syns: lineament, tone, calibre)",Bioinformatics
"Biological learning unfolds continuously in time, yet most algorithmic models rely on discrete updates and separate inference and learning phases. We study a continuous-time neural model that unifies several biologically plausible learning algorithms and removes the need for phase separation. Rules including stochastic gradient descent (SGD), feedback alignment (FA), direct feedback alignment (DFA), and Kolen-Pollack (KP) emerge naturally as limiting cases of the dynamics. Simulations show that these continuous-time networks stably learn at biological timescales, even under temporal mismatches and integration noise. Through analysis and simulation, we show that learning depends on temporal overlap: a synapse updates correctly only when its input and the corresponding error signal coincide in time. When inputs are held constant, learning strength declines linearly as the delay between input and error approaches the stimulus duration, explaining observed robustness and failure across network depths. Critically, robust learning requires the synaptic plasticity timescale to exceed the stimulus duration by one to two orders of magnitude. For typical cortical stimuli (tens of milliseconds), this places the functional plasticity window in the few-second range, a testable prediction that identifies seconds-scale eligibility traces as necessary for error-driven learning in biological circuits.",Neuroscience
"Biological learning unfolds continuously in time, yet most algorithmic models rely on discrete updates and separate inference and learning phases. We study a continuous-time neural model that unifies several biologically plausible learning algorithms and removes the need for phase separation. Rules including stochastic gradient descent (SGD), feedback alignment (FA), direct feedback alignment (DFA), and Kolen-Pollack (KP) emerge naturally as limiting cases of the dynamics. Simulations show that these continuous-time networks stably learn at biological timescales, even under temporal mismatches and integration noise. Through analysis and simulation, we show that learning depends on temporal overlap: a synapse updates correctly only when its input and the corresponding error signal coincide in time. When inputs are held constant, learning strength declines linearly as the delay between input and error approaches the stimulus duration, explaining observed robustness and failure across network depths. Critically, robust learning requires the synaptic plasticity timescale to exceed the stimulus duration by one to two orders of magnitude. For typical cortical stimuli (tens of milliseconds), this places the functional plasticity window in the few-second range, a testable prediction that identifies seconds-scale eligibility traces as necessary for error-driven learning in biological circuits. [SEP] [HINT] learning -> Bioinformatics (Syns: take, teach, acquire) | cortical -> Neuroscience (Syns: ) | networks -> Neuroscience (Syns: network, meshwork, electronic network)",Neuroscience
"We introduce HAMscope, a compact, snapshot hyperspectral autofluorescence miniscope that enables real-time, label-free molecular imaging in a wide range of biological systems. By integrating a thin polymer diffuser into a widefield miniscope, HAMscope spectrally encodes each frame and employs a probabilistic deep learning framework to reconstruct 30-channel hyperspectral stacks (452 to 703 nm) or directly infer molecular composition maps from single images. A scalable multi-pass U-Net architecture with transformer-based attention and per-pixel uncertainty estimation enables high spatio-spectral fidelity (mean absolute error ~ 0.0048) at video rates. While initially demonstrated in plant systems, including lignin, chlorophyll, and suberin imaging in intact poplar and cork tissues, the platform is readily adaptable to other applications such as neural activity mapping, metabolic profiling, and histopathology. We show that the system generalizes to out-of-distribution tissue types and supports direct molecular mapping without the need for spectral unmixing. HAMscope establishes a general framework for compact, uncertainty-aware spectral imaging that combines minimal optics with advanced deep learning, offering broad utility for real-time biochemical imaging across neuroscience, environmental monitoring, and biomedicine.",Bioinformatics
"We introduce HAMscope, a compact, snapshot hyperspectral autofluorescence miniscope that enables real-time, label-free molecular imaging in a wide range of biological systems. By integrating a thin polymer diffuser into a widefield miniscope, HAMscope spectrally encodes each frame and employs a probabilistic deep learning framework to reconstruct 30-channel hyperspectral stacks (452 to 703 nm) or directly infer molecular composition maps from single images. A scalable multi-pass U-Net architecture with transformer-based attention and per-pixel uncertainty estimation enables high spatio-spectral fidelity (mean absolute error ~ 0.0048) at video rates. While initially demonstrated in plant systems, including lignin, chlorophyll, and suberin imaging in intact poplar and cork tissues, the platform is readily adaptable to other applications such as neural activity mapping, metabolic profiling, and histopathology. We show that the system generalizes to out-of-distribution tissue types and supports direct molecular mapping without the need for spectral unmixing. HAMscope establishes a general framework for compact, uncertainty-aware spectral imaging that combines minimal optics with advanced deep learning, offering broad utility for real-time biochemical imaging across neuroscience, environmental monitoring, and biomedicine. [SEP] [HINT] tissue -> Bioinformatics (Syns: tissue paper, weave) | learning -> Bioinformatics (Syns: take, teach, acquire) | molecular -> Bioinformatics (Syns: )",Bioinformatics
"Fingerprint analysis and fingerprint identification have been the most widely used tools for human identification. To this day, various models have been proposed to explain how fingerprints are formed, ranging from the fibroblast model, which focuses on cell-collagen interactions, to the buckling of thin layers model, both yielding significant results. In this work, we present a reaction-diffusion model of Schnakenberg type, featuring an anisotropic diffusion matrix that follows the ridge orientations supplied by other traditional fingerprint-generation models, and notably yet allows minutiae -- i.e. characteristic microstructures embedded in fingerprints -- to emerge. The statistical analysis of the minutiae distribution in a randomly generated fingerprint collection is consistent with observations in real fingerprints. The model can numerically generate fingerprint-like patterns corresponding to the four basic classifications -- arches, ulnar loops, radial loops, and whorls -- as well as a variety of derived forms. The generated patterns emerge on a convex domain that mimics the geometry of a fingertip, exhibiting the diverse types of minutiae typically analyzed in fingerprint identification and showing strong agreement with those observed in human fingerprints. This model also provides insight into how levels of certainty in human identification can be achieved when based on minutiae positions. All the algorithms are implemented in an open source software named GenCHSin.",Bioinformatics
"Fingerprint analysis and fingerprint identification have been the most widely used tools for human identification. To this day, various models have been proposed to explain how fingerprints are formed, ranging from the fibroblast model, which focuses on cell-collagen interactions, to the buckling of thin layers model, both yielding significant results. In this work, we present a reaction-diffusion model of Schnakenberg type, featuring an anisotropic diffusion matrix that follows the ridge orientations supplied by other traditional fingerprint-generation models, and notably yet allows minutiae -- i.e. characteristic microstructures embedded in fingerprints -- to emerge. The statistical analysis of the minutiae distribution in a randomly generated fingerprint collection is consistent with observations in real fingerprints. The model can numerically generate fingerprint-like patterns corresponding to the four basic classifications -- arches, ulnar loops, radial loops, and whorls -- as well as a variety of derived forms. The generated patterns emerge on a convex domain that mimics the geometry of a fingertip, exhibiting the diverse types of minutiae typically analyzed in fingerprint identification and showing strong agreement with those observed in human fingerprints. This model also provides insight into how levels of certainty in human identification can be achieved when based on minutiae positions. All the algorithms are implemented in an open source software named GenCHSin. [SEP] [HINT] used -> Bioinformatics (Syns: utilize, ill-used, apply) | based -> Bioinformatics (Syns: ground, free-base, base) | human -> Neuroscience (Syns: human being, man, homo)",Bioinformatics
"Oysters in Virginia Chesapeake Bay oyster reefs are ""age-truncated"", possibly due to a combination of historical overfishing, disease epizootics, environmental degradation, and climate change. Research has suggested that oysters exhibit resilience to environmental stressors; however, that evidence is based on the current limited understanding of oyster lifespan. Until this paper, the Virginia Oyster Stock Assessment and Replenishment Archive (VOSARA), a spatially and temporally expansive dataset (222 reefs across 2003-2023) of shell lengths (SL, mm), had yet to be examined comprehensively in the context of resilience. We develop a novel method using Gaussian mixture modeling (GMM) to identify the age groups in each reef using yearly SL data and then link those age groups over time to identify cohorts and estimate their lifespan. Sixty-four reefs (29%) are deemed to have sufficient data (at least 300 oysters sampled for a minimum of 8 consecutive years) for this analysis. We fit univariate GMMs for each year ($t$) and reef ($r$) for each of the seven river strata ($R$) to estimate 1) the mean and standard deviation of SL for each $a_{Rrt}$th age group, and 2) the mixture percentage of each $a_{Rrt}$th age group. We link age groups across time to infer age cohorts by developing a mechanistic algorithm that prevents the shrinking of shell length when an $a_{Rrt}$th group becomes an ($a_{R,r,t+1}$)th group. Our method shows promise in identifying oyster cohorts and estimating lifespan solely using SL data. Our results show signals of resiliency in almost all river systems: oyster cohorts live longer and grow larger in the mid-to-late 2010s compared to the early 2000s.",Bioinformatics
"Oysters in Virginia Chesapeake Bay oyster reefs are ""age-truncated"", possibly due to a combination of historical overfishing, disease epizootics, environmental degradation, and climate change. Research has suggested that oysters exhibit resilience to environmental stressors; however, that evidence is based on the current limited understanding of oyster lifespan. Until this paper, the Virginia Oyster Stock Assessment and Replenishment Archive (VOSARA), a spatially and temporally expansive dataset (222 reefs across 2003-2023) of shell lengths (SL, mm), had yet to be examined comprehensively in the context of resilience. We develop a novel method using Gaussian mixture modeling (GMM) to identify the age groups in each reef using yearly SL data and then link those age groups over time to identify cohorts and estimate their lifespan. Sixty-four reefs (29%) are deemed to have sufficient data (at least 300 oysters sampled for a minimum of 8 consecutive years) for this analysis. We fit univariate GMMs for each year ($t$) and reef ($r$) for each of the seven river strata ($R$) to estimate 1) the mean and standard deviation of SL for each $a_{Rrt}$th age group, and 2) the mixture percentage of each $a_{Rrt}$th age group. We link age groups across time to infer age cohorts by developing a mechanistic algorithm that prevents the shrinking of shell length when an $a_{Rrt}$th group becomes an ($a_{R,r,t+1}$)th group. Our method shows promise in identifying oyster cohorts and estimating lifespan solely using SL data. Our results show signals of resiliency in almost all river systems: oyster cohorts live longer and grow larger in the mid-to-late 2010s compared to the early 2000s. [SEP] [HINT] based -> Bioinformatics (Syns: ground, free-base, base) | understanding -> Neuroscience (Syns: savvy, intellect, sympathy) | results -> Bioinformatics (Syns: final result, consequence, resultant role)",Bioinformatics
"Psycholinguistics and neurolinguistics are two complementary disciplines that study language from different perspectives. Psycholinguistics focuses on the cognitive processes involved in language production and comprehension, while neurolinguistics investigates the brain bases of these mechanisms. Brain imaging techniques make it possible to identify the regions and networks involved in various psycholinguistic processes, and to better understand the effects of brain lesions on language abilities. By integrating psycholinguistic and neurolinguistic approaches, research provides a deeper understanding of language processing, whether intact or impaired. This knowledge paves the way for more targeted and effective rehabilitation strategies.",Neuroscience
"Psycholinguistics and neurolinguistics are two complementary disciplines that study language from different perspectives. Psycholinguistics focuses on the cognitive processes involved in language production and comprehension, while neurolinguistics investigates the brain bases of these mechanisms. Brain imaging techniques make it possible to identify the regions and networks involved in various psycholinguistic processes, and to better understand the effects of brain lesions on language abilities. By integrating psycholinguistic and neurolinguistic approaches, research provides a deeper understanding of language processing, whether intact or impaired. This knowledge paves the way for more targeted and effective rehabilitation strategies. [SEP] [HINT] imaging -> Bioinformatics (Syns: imagery, imagination, visualise) | different -> Neuroscience (Syns: unlike, dissimilar) | cognitive -> Neuroscience (Syns: )",Neuroscience
"The ability to continually learn, retain and deploy skills to accomplish goals is a key feature of intelligent and efficient behavior. However, the neural mechanisms facilitating the continual learning and flexible (re-)composition of skills remain elusive. Here, we study continual learning and the compositional reuse of learned computations in recurrent neural network (RNN) models using a novel two-system approach: one system that infers what computation to perform, and one that implements how to perform it. We focus on a set of compositional cognitive tasks commonly studied in neuroscience. To construct the what system, we first show that a large family of tasks can be systematically described by a probabilistic generative model, where compositionality stems from a shared underlying vocabulary of discrete task epochs. The shared epoch structure makes these tasks inherently compositional. We first show that this compositionality can be systematically described by a probabilistic generative model. Furthermore, We develop an unsupervised online learning approach that can learn this model on a single-trial basis, building its vocabulary incrementally as it is exposed to new tasks, and inferring the latent epoch structure as a time-varying computational context within a trial. We implement the how system as an RNN whose low-rank components are composed according to the context inferred by the what system. Contextual inference facilitates the creation, learning, and reuse of low-rank RNN components as new tasks are introduced sequentially, enabling continual learning without catastrophic forgetting. Using an example task set, we demonstrate the efficacy and competitive performance of this two-system learning framework, its potential for forward and backward transfer, as well as fast compositional generalization to unseen tasks.",Neuroscience
"The ability to continually learn, retain and deploy skills to accomplish goals is a key feature of intelligent and efficient behavior. However, the neural mechanisms facilitating the continual learning and flexible (re-)composition of skills remain elusive. Here, we study continual learning and the compositional reuse of learned computations in recurrent neural network (RNN) models using a novel two-system approach: one system that infers what computation to perform, and one that implements how to perform it. We focus on a set of compositional cognitive tasks commonly studied in neuroscience. To construct the what system, we first show that a large family of tasks can be systematically described by a probabilistic generative model, where compositionality stems from a shared underlying vocabulary of discrete task epochs. The shared epoch structure makes these tasks inherently compositional. We first show that this compositionality can be systematically described by a probabilistic generative model. Furthermore, We develop an unsupervised online learning approach that can learn this model on a single-trial basis, building its vocabulary incrementally as it is exposed to new tasks, and inferring the latent epoch structure as a time-varying computational context within a trial. We implement the how system as an RNN whose low-rank components are composed according to the context inferred by the what system. Contextual inference facilitates the creation, learning, and reuse of low-rank RNN components as new tasks are introduced sequentially, enabling continual learning without catastrophic forgetting. Using an example task set, we demonstrate the efficacy and competitive performance of this two-system learning framework, its potential for forward and backward transfer, as well as fast compositional generalization to unseen tasks. [SEP] [HINT] task -> Neuroscience (Syns: tax, project, chore) | tasks -> Neuroscience (Syns: tax, task, project) | computational -> Neuroscience (Syns: )",Neuroscience
"Spin space groups (SSGs) impose fundamentally different constraints on magnetic configurations in real and reciprocal spaces. As a consequence, the correspondence between real-space and momentum-space spin arrangements is far richer than traditionally assumed. Building on the complete enumeration of SSGs, we develop a systematic, symmetry-based framework that classifies all possible spin arrangements allowed by these groups. This unified approach naturally incorporates conventional magnetic orders, altermagnetism, and p-wave magnetism as distinct symmetry classes. Crucially, our classification predicts a variety of novel magnetic phases, highlighted by the discovery of the coplanar even-wave magnet: a state that is non-collinear in real space but hosts a collinear even-wave spin polarization in k-space. Analysis of a minimal model reveals that this phase is characterized by non-quantized spin polarization and exhibits a novel mechanism for symmetry-enforced zero polarization on non-degenerate bands. Extending the framework from bulk crystals to layer SSGs appropriate for two-dimensional systems, we further predict layered counterparts and provide symmetry guidelines for designing bilayer coplanar p-wave and even-wave magnets. We further validate this finding through first-principles calculations and propose CoCrO4 as a promising candidate for its experimental realization, thereby demonstrating the completeness and predictive power of the SSG-based classification of magnetic orders.",Materials Science
"Spin space groups (SSGs) impose fundamentally different constraints on magnetic configurations in real and reciprocal spaces. As a consequence, the correspondence between real-space and momentum-space spin arrangements is far richer than traditionally assumed. Building on the complete enumeration of SSGs, we develop a systematic, symmetry-based framework that classifies all possible spin arrangements allowed by these groups. This unified approach naturally incorporates conventional magnetic orders, altermagnetism, and p-wave magnetism as distinct symmetry classes. Crucially, our classification predicts a variety of novel magnetic phases, highlighted by the discovery of the coplanar even-wave magnet: a state that is non-collinear in real space but hosts a collinear even-wave spin polarization in k-space. Analysis of a minimal model reveals that this phase is characterized by non-quantized spin polarization and exhibits a novel mechanism for symmetry-enforced zero polarization on non-degenerate bands. Extending the framework from bulk crystals to layer SSGs appropriate for two-dimensional systems, we further predict layered counterparts and provide symmetry guidelines for designing bilayer coplanar p-wave and even-wave magnets. We further validate this finding through first-principles calculations and propose CoCrO4 as a promising candidate for its experimental realization, thereby demonstrating the completeness and predictive power of the SSG-based classification of magnetic orders. [SEP] [HINT] spin -> Materials Science (Syns: twisting, whirl, tailspin) | space -> Neuroscience (Syns: distance, place, outer space) | different -> Neuroscience (Syns: unlike, dissimilar)",Materials Science
"Inferring who infected whom in an outbreak is essential for characterising transmission dynamics and guiding public health interventions. However, this task is challenging due to limited surveillance data and the complexity of immunological and social interactions. Instead of a single definitive transmission tree, epidemiologists often consider multiple plausible trees forming \textit{epidemic forests}. Various inference methods and assumptions can yield different epidemic forests, yet no formal test exists to assess whether these differences are statistically significant. We propose such a framework using a chi-square test and permutational multivariate analysis of variance (PERMANOVA). We assessed each method's ability to distinguish simulated epidemic forests generated under different offspring distributions. While both methods achieved perfect specificity for forests with 100+ trees, PERMANOVA consistently outperformed the chi-square test in sensitivity across all epidemic and forest sizes. Implemented in the R package \textit{mixtree}, we provide the first statistical framework to robustly compare epidemic forests.",Bioinformatics
"Inferring who infected whom in an outbreak is essential for characterising transmission dynamics and guiding public health interventions. However, this task is challenging due to limited surveillance data and the complexity of immunological and social interactions. Instead of a single definitive transmission tree, epidemiologists often consider multiple plausible trees forming \textit{epidemic forests}. Various inference methods and assumptions can yield different epidemic forests, yet no formal test exists to assess whether these differences are statistically significant. We propose such a framework using a chi-square test and permutational multivariate analysis of variance (PERMANOVA). We assessed each method's ability to distinguish simulated epidemic forests generated under different offspring distributions. While both methods achieved perfect specificity for forests with 100+ trees, PERMANOVA consistently outperformed the chi-square test in sensitivity across all epidemic and forest sizes. Implemented in the R package \textit{mixtree}, we provide the first statistical framework to robustly compare epidemic forests. [SEP] [HINT] task -> Neuroscience (Syns: tax, project, chore) | different -> Neuroscience (Syns: unlike, dissimilar) | framework -> Bioinformatics (Syns: theoretical account, model, fabric)",Bioinformatics
"The magnetic properties of the compound Fe$_5$Si$_{1-x}$P$_{x}$B$_2$ have been studied, with a focus on the Curie temperature $T_\textrm{C}$, saturation magnetization $M_\textrm{S}$, and magnetocrystalline anisotropy. Field and temperature dependent magnetization measurements were used to determine $T_\textrm{C}\left(x\right)$ and $M_\textrm{S}\left(x\right)$. The saturation magnetization at 10 K (300 K) is found to monotonically decrease from $1.11~\mathrm{MA/m}$ ($1.03~\mathrm{MA/m}$) to $0.97~\mathrm{MA/m}$ ($0.87~\mathrm{MA/m}$), as $x$ increases from zero to one. The Curie temperature is determined to be 810 K and 615 K in Fe$_5$SiB$_2$ and Fe$_5$PB$_2$, respectively. The highest $T_\textrm{C}$ is observed for $x=0.1$, while it decreases monotonically for larger $x$. The Curie temperatures have also been theoretically determined to be 700 K and 660 K for Fe$_5$SiB$_2$ and Fe$_5$PB$_2$, respectively, using a combination of density functional theory and Monte Carlo simulations. The magnitude of the effective magnetocrystalline anisotropy was extracted using the law of approach to saturation, revealing an increase with increasing phosphorus concentration. Low--field magnetization vs. temperature results for $x = 0, 0.1, 0.2$ indicate that there is a transition from easy--axis to easy--plane anisotropy with decreasing temperature.",Materials Science
"The magnetic properties of the compound Fe$_5$Si$_{1-x}$P$_{x}$B$_2$ have been studied, with a focus on the Curie temperature $T_\textrm{C}$, saturation magnetization $M_\textrm{S}$, and magnetocrystalline anisotropy. Field and temperature dependent magnetization measurements were used to determine $T_\textrm{C}\left(x\right)$ and $M_\textrm{S}\left(x\right)$. The saturation magnetization at 10 K (300 K) is found to monotonically decrease from $1.11~\mathrm{MA/m}$ ($1.03~\mathrm{MA/m}$) to $0.97~\mathrm{MA/m}$ ($0.87~\mathrm{MA/m}$), as $x$ increases from zero to one. The Curie temperature is determined to be 810 K and 615 K in Fe$_5$SiB$_2$ and Fe$_5$PB$_2$, respectively. The highest $T_\textrm{C}$ is observed for $x=0.1$, while it decreases monotonically for larger $x$. The Curie temperatures have also been theoretically determined to be 700 K and 660 K for Fe$_5$SiB$_2$ and Fe$_5$PB$_2$, respectively, using a combination of density functional theory and Monte Carlo simulations. The magnitude of the effective magnetocrystalline anisotropy was extracted using the law of approach to saturation, revealing an increase with increasing phosphorus concentration. Low--field magnetization vs. temperature results for $x = 0, 0.1, 0.2$ indicate that there is a transition from easy--axis to easy--plane anisotropy with decreasing temperature. [SEP] [HINT] used -> Bioinformatics (Syns: utilize, ill-used, apply) | field -> Materials Science (Syns: field of honor, line of business, orbit) | transition -> Materials Science (Syns: passage, modulation, changeover)",Materials Science
"Functional brain graphs are often characterized with separate graph-theoretic or spectral descriptors, overlooking how these properties covary and partially overlap across brains and conditions. We anticipate that dense, weighted functional connectivity graphs occupy a low-dimensional latent geometry along which both topological and spectral structures display graded variations. Here, we estimated this unified graph representation and enabled generation of dense functional brain graphs through a graph transformer autoencoder with latent diffusion, with spectral geometry providing an inductive bias to guide learning. This geometry-aware latent representation, although unsupervised, meaningfully separated working-memory states and decoded visual stimuli, with performance further enhanced by incorporating neural dynamics. From the diffusion modeled distribution, we were able to sample biologically plausible and structurally grounded synthetic dense graphs.",Neuroscience
"Functional brain graphs are often characterized with separate graph-theoretic or spectral descriptors, overlooking how these properties covary and partially overlap across brains and conditions. We anticipate that dense, weighted functional connectivity graphs occupy a low-dimensional latent geometry along which both topological and spectral structures display graded variations. Here, we estimated this unified graph representation and enabled generation of dense functional brain graphs through a graph transformer autoencoder with latent diffusion, with spectral geometry providing an inductive bias to guide learning. This geometry-aware latent representation, although unsupervised, meaningfully separated working-memory states and decoded visual stimuli, with performance further enhanced by incorporating neural dynamics. From the diffusion modeled distribution, we were able to sample biologically plausible and structurally grounded synthetic dense graphs. [SEP] [HINT] connectivity -> Neuroscience (Syns: ) | functional -> Neuroscience (Syns: working, usable, running) | performance -> Bioinformatics (Syns: functioning, operation, carrying out)",Neuroscience
"The dynamics of tumor-immune interactions within a complex tumor microenvironment are typically modeled using a system of ordinary differential equations or partial differential equations. These models introduce some unknown parameters that need to be estimated accurately and efficiently from the limited and noisy experimental data. Moreover, due to the intricate biological complexity and limitations in experimental measurements, tumor-immune dynamics are not fully understood, and therefore, only partial knowledge of the underlying physics may be available, resulting in unknown or missing terms within the system of equations. In this study, we develop a cancer biology-informed neural network model(CBINN) to infer the unknown parameters in the system of equations as well as to discover the missing physics from sparse and noisy measurements. We test the performance of the CBINN model on three distinct nonlinear compartmental tumor-immune models and evaluate its robustness across multiple synthetic noise levels. By harnessing these highly nonlinear dynamics, our CBINN framework effectively estimates the unknown model parameters and uncovers the underlying physical laws or mathematical structures that govern these biological systems, even from scattered and noisy measurements. The models chosen here represent the dynamic patterns commonly observed in compartmental models of tumor-immune interactions, thereby validating the generalizability and efficacy of our methodology.",Bioinformatics
"The dynamics of tumor-immune interactions within a complex tumor microenvironment are typically modeled using a system of ordinary differential equations or partial differential equations. These models introduce some unknown parameters that need to be estimated accurately and efficiently from the limited and noisy experimental data. Moreover, due to the intricate biological complexity and limitations in experimental measurements, tumor-immune dynamics are not fully understood, and therefore, only partial knowledge of the underlying physics may be available, resulting in unknown or missing terms within the system of equations. In this study, we develop a cancer biology-informed neural network model(CBINN) to infer the unknown parameters in the system of equations as well as to discover the missing physics from sparse and noisy measurements. We test the performance of the CBINN model on three distinct nonlinear compartmental tumor-immune models and evaluate its robustness across multiple synthetic noise levels. By harnessing these highly nonlinear dynamics, our CBINN framework effectively estimates the unknown model parameters and uncovers the underlying physical laws or mathematical structures that govern these biological systems, even from scattered and noisy measurements. The models chosen here represent the dynamic patterns commonly observed in compartmental models of tumor-immune interactions, thereby validating the generalizability and efficacy of our methodology. [SEP] [HINT] complex -> Bioinformatics (Syns: building complex, coordination compound, composite) | performance -> Bioinformatics (Syns: functioning, operation, carrying out) | framework -> Bioinformatics (Syns: theoretical account, model, fabric)",Bioinformatics
"Prompt-driven vision foundation models, such as the Segment Anything Model, have recently demonstrated remarkable adaptability in computer vision. However, their direct application to medical imaging remains challenging due to heterogeneous tissue structures, imaging artefacts, and low-contrast boundaries, particularly in tumours and cancer primaries leading to suboptimal segmentation in ambiguous or overlapping lesion regions. Here, we present Segment Any Tumour 3D (SAT3D), a lightweight volumetric foundation model designed to enable robust and generalisable tumour segmentation across diverse medical imaging modalities. SAT3D integrates a shifted-window vision transformer for hierarchical volumetric representation with an uncertainty-aware training pipeline that explicitly incorporates uncertainty estimates as prompts to guide reliable boundary prediction in low-contrast regions. Adversarial learning further enhances model performance for the ambiguous pathological regions. We benchmark SAT3D against three recent vision foundation models and nnUNet across 11 publicly available datasets, encompassing 3,884 tumour and cancer cases for training and 694 cases for in-distribution evaluation. Trained on 17,075 3D volume-mask pairs across multiple modalities and cancer primaries, SAT3D demonstrates strong generalisation and robustness. To facilitate practical use and clinical translation, we developed a 3D Slicer plugin that enables interactive, prompt-driven segmentation and visualisation using the trained SAT3D model. Extensive experiments highlight its effectiveness in improving segmentation accuracy under challenging and out-of-distribution scenarios, underscoring its potential as a scalable foundation model for medical image analysis.",Bioinformatics
"Prompt-driven vision foundation models, such as the Segment Anything Model, have recently demonstrated remarkable adaptability in computer vision. However, their direct application to medical imaging remains challenging due to heterogeneous tissue structures, imaging artefacts, and low-contrast boundaries, particularly in tumours and cancer primaries leading to suboptimal segmentation in ambiguous or overlapping lesion regions. Here, we present Segment Any Tumour 3D (SAT3D), a lightweight volumetric foundation model designed to enable robust and generalisable tumour segmentation across diverse medical imaging modalities. SAT3D integrates a shifted-window vision transformer for hierarchical volumetric representation with an uncertainty-aware training pipeline that explicitly incorporates uncertainty estimates as prompts to guide reliable boundary prediction in low-contrast regions. Adversarial learning further enhances model performance for the ambiguous pathological regions. We benchmark SAT3D against three recent vision foundation models and nnUNet across 11 publicly available datasets, encompassing 3,884 tumour and cancer cases for training and 694 cases for in-distribution evaluation. Trained on 17,075 3D volume-mask pairs across multiple modalities and cancer primaries, SAT3D demonstrates strong generalisation and robustness. To facilitate practical use and clinical translation, we developed a 3D Slicer plugin that enables interactive, prompt-driven segmentation and visualisation using the trained SAT3D model. Extensive experiments highlight its effectiveness in improving segmentation accuracy under challenging and out-of-distribution scenarios, underscoring its potential as a scalable foundation model for medical image analysis. [SEP] [HINT] tissue -> Bioinformatics (Syns: tissue paper, weave) | clinical -> Bioinformatics (Syns: ) | learning -> Bioinformatics (Syns: take, teach, acquire)",Bioinformatics
"This book introduces the new research area of Geometric Data Science, where data can represent any real objects through geometric measurements.   The first part of the book focuses on finite point sets. The most important result is a complete and continuous classification of all finite clouds of unordered points under rigid motion in any Euclidean space. The key challenge was to avoid the exponential complexity arising from permutations of the given unordered points. For a fixed dimension of the ambient Euclidean space, the times of all algorithms for the resulting invariants and distance metrics depend polynomially on the number of points.   The second part of the book advances a similar classification in the much more difficult case of periodic point sets, which model all periodic crystals at the atomic scale. The most significant result is the hierarchy of invariants from the ultra-fast to complete ones. The key challenge was to resolve the discontinuity of crystal representations that break down under almost any noise. Experimental validation on all major materials databases confirmed the Crystal Isometry Principle: any real periodic crystal has a unique location in a common moduli space of all periodic structures under rigid motion. The resulting moduli space contains all known and not yet discovered periodic crystals and hence continuously extends Mendeleev's table to the full crystal universe.",Materials Science
"This book introduces the new research area of Geometric Data Science, where data can represent any real objects through geometric measurements.   The first part of the book focuses on finite point sets. The most important result is a complete and continuous classification of all finite clouds of unordered points under rigid motion in any Euclidean space. The key challenge was to avoid the exponential complexity arising from permutations of the given unordered points. For a fixed dimension of the ambient Euclidean space, the times of all algorithms for the resulting invariants and distance metrics depend polynomially on the number of points.   The second part of the book advances a similar classification in the much more difficult case of periodic point sets, which model all periodic crystals at the atomic scale. The most significant result is the hierarchy of invariants from the ultra-fast to complete ones. The key challenge was to resolve the discontinuity of crystal representations that break down under almost any noise. Experimental validation on all major materials databases confirmed the Crystal Isometry Principle: any real periodic crystal has a unique location in a common moduli space of all periodic structures under rigid motion. The resulting moduli space contains all known and not yet discovered periodic crystals and hence continuously extends Mendeleev's table to the full crystal universe. [SEP] [HINT] space -> Neuroscience (Syns: distance, place, outer space) | crystal -> Materials Science (Syns: crystallization, quartz, lechatelierite) | materials -> Materials Science (Syns: stuff, cloth, material)",Materials Science
"Feature selection is a combinatorial optimization problem that is NP-hard. Conventional approaches often employ heuristic or greedy strategies, which are prone to premature convergence and may fail to capture subtle yet informative features. This limitation becomes especially critical in high-dimensional datasets, where complex and interdependent feature relationships prevail. We introduce the HeFS (Helper-Enhanced Feature Selection) framework to refine feature subsets produced by existing algorithms. HeFS systematically searches the residual feature space to identify a Helper Set - features that complement the original subset and improve classification performance. The approach employs a biased initialization scheme and a ratio-guided mutation mechanism within a genetic algorithm, coupled with Pareto-based multi-objective optimization to jointly maximize predictive accuracy and feature complementarity. Experiments on 18 benchmark datasets demonstrate that HeFS consistently identifies overlooked yet informative features and achieves superior performance over state-of-the-art methods, including in challenging domains such as gastric cancer classification, drug toxicity prediction, and computer science applications. The code and datasets are available at https://healthinformaticslab.org/supp/.",Bioinformatics
"Feature selection is a combinatorial optimization problem that is NP-hard. Conventional approaches often employ heuristic or greedy strategies, which are prone to premature convergence and may fail to capture subtle yet informative features. This limitation becomes especially critical in high-dimensional datasets, where complex and interdependent feature relationships prevail. We introduce the HeFS (Helper-Enhanced Feature Selection) framework to refine feature subsets produced by existing algorithms. HeFS systematically searches the residual feature space to identify a Helper Set - features that complement the original subset and improve classification performance. The approach employs a biased initialization scheme and a ratio-guided mutation mechanism within a genetic algorithm, coupled with Pareto-based multi-objective optimization to jointly maximize predictive accuracy and feature complementarity. Experiments on 18 benchmark datasets demonstrate that HeFS consistently identifies overlooked yet informative features and achieves superior performance over state-of-the-art methods, including in challenging domains such as gastric cancer classification, drug toxicity prediction, and computer science applications. The code and datasets are available at https://healthinformaticslab.org/supp/. [SEP] [HINT] features -> Bioinformatics (Syns: characteristic, lineament, feature of speech) | space -> Neuroscience (Syns: distance, place, outer space) | complex -> Bioinformatics (Syns: building complex, coordination compound, composite)",Bioinformatics
"Accurate measures of musculoskeletal forces are critical for clinicians, biomechanists, and engineers, yet direct measurement is highly invasive and current estimation methods remain limited in accuracy. Here, we demonstrate the application of ultra-wideband radar to non-invasively estimate musculoskeletal forces by measuring changes in the electromagnetic properties of contracting muscles, in muscles with different structural properties, during various static and dynamic conditions, and in the presence of fatigue. First, we show that ultra-wideband radar scans of muscle can reliably track isometric force in a unipennate knee extensor (vastus lateralis) and a bipennate ankle dorsiflexor (tibialis anterior). Next, we integrate radar signals within machine-learning and linear models to estimate musculoskeletal forces during fatiguing isometric, and dynamic knee extension contractions, with exceptional accuracy (test R2>0.984; errors<3.3%). Finally, we identify frequency-dependent effects of musculoskeletal forces on ultra-wideband radar signals, that are independent of physiological and structural features known to influence muscle force. Together, these findings establish ultra-wideband radar as a powerful, non-invasive approach for quantifying in vivo musculoskeletal forces, with transformative potential for wearable assistive technologies, biomechanics, and rehabilitation.",Bioinformatics
"Accurate measures of musculoskeletal forces are critical for clinicians, biomechanists, and engineers, yet direct measurement is highly invasive and current estimation methods remain limited in accuracy. Here, we demonstrate the application of ultra-wideband radar to non-invasively estimate musculoskeletal forces by measuring changes in the electromagnetic properties of contracting muscles, in muscles with different structural properties, during various static and dynamic conditions, and in the presence of fatigue. First, we show that ultra-wideband radar scans of muscle can reliably track isometric force in a unipennate knee extensor (vastus lateralis) and a bipennate ankle dorsiflexor (tibialis anterior). Next, we integrate radar signals within machine-learning and linear models to estimate musculoskeletal forces during fatiguing isometric, and dynamic knee extension contractions, with exceptional accuracy (test R2>0.984; errors<3.3%). Finally, we identify frequency-dependent effects of musculoskeletal forces on ultra-wideband radar signals, that are independent of physiological and structural features known to influence muscle force. Together, these findings establish ultra-wideband radar as a powerful, non-invasive approach for quantifying in vivo musculoskeletal forces, with transformative potential for wearable assistive technologies, biomechanics, and rehabilitation. [SEP] [HINT] features -> Bioinformatics (Syns: characteristic, lineament, feature of speech) | different -> Neuroscience (Syns: unlike, dissimilar) | structural -> Materials Science (Syns: geomorphologic, morphologic, morphological)",Bioinformatics
"The rapid generation of whole-slide images (WSIs) in dermatopathology necessitates automated methods for efficient processing and accurate classification. This study evaluates the performance of two foundation models, UNI and Virchow2, as feature extractors for classifying WSIs into three diagnostic categories: melanocytic, basaloid, and squamous lesions. Patch-level embeddings were aggregated into slide-level features using a mean-aggregation strategy and subsequently used to train multiple machine learning classifiers, including logistic regression, gradient-boosted trees, and random forest models. Performance was assessed using precision, recall, true positive rate, false positive rate, and the area under the receiver operating characteristic curve (AUROC) on the test set. Results demonstrate that patch-level features extracted using Virchow2 outperformed those extracted via UNI across most slide-level classifiers, with logistic regression achieving the highest accuracy (90%) for Virchow2, though the difference was not statistically significant. The study also explored data augmentation techniques and image normalization to enhance model robustness and generalizability. The mean-aggregation approach provided reliable slide-level feature representations. All experimental results and metrics were tracked and visualized using WandB.ai, facilitating reproducibility and interpretability. This research highlights the potential of foundation models for automated WSI classification, providing a scalable and effective approach for dermatopathological diagnosis while paving the way for future advancements in slide-level representation learning.",Bioinformatics
"The rapid generation of whole-slide images (WSIs) in dermatopathology necessitates automated methods for efficient processing and accurate classification. This study evaluates the performance of two foundation models, UNI and Virchow2, as feature extractors for classifying WSIs into three diagnostic categories: melanocytic, basaloid, and squamous lesions. Patch-level embeddings were aggregated into slide-level features using a mean-aggregation strategy and subsequently used to train multiple machine learning classifiers, including logistic regression, gradient-boosted trees, and random forest models. Performance was assessed using precision, recall, true positive rate, false positive rate, and the area under the receiver operating characteristic curve (AUROC) on the test set. Results demonstrate that patch-level features extracted using Virchow2 outperformed those extracted via UNI across most slide-level classifiers, with logistic regression achieving the highest accuracy (90%) for Virchow2, though the difference was not statistically significant. The study also explored data augmentation techniques and image normalization to enhance model robustness and generalizability. The mean-aggregation approach provided reliable slide-level feature representations. All experimental results and metrics were tracked and visualized using WandB.ai, facilitating reproducibility and interpretability. This research highlights the potential of foundation models for automated WSI classification, providing a scalable and effective approach for dermatopathological diagnosis while paving the way for future advancements in slide-level representation learning. [SEP] [HINT] used -> Bioinformatics (Syns: utilize, ill-used, apply) | features -> Bioinformatics (Syns: characteristic, lineament, feature of speech) | learning -> Bioinformatics (Syns: take, teach, acquire)",Bioinformatics
"The present investigation reports on the fabrication and characterization of heterojunctions based on in situ Eu doped CdO layers, which were deposited on p-type silicon using the plasma assisted molecular beam epitaxy (PA MBE) method. The structural and optical properties of the cadmium oxide (CdO) films were investigated using X ray diffraction and Fourier transform infrared spectroscopy (FTIR). The CdO Eu films are polycrystalline. The electrical properties of the p n heterojunction composed of transparent n CdO Eu and p Si semiconductors were investigated by current voltage and electron beam-induced current (EBIC) measurements. Current voltage measurements demonstrate good junction characteristics with a rectifying ratio of 20 . EBIC measurements allowed us to calculate the diffusion length of minority carriers and the precise location of the depleted area at the CdO and Si interfaces.",Materials Science
"The present investigation reports on the fabrication and characterization of heterojunctions based on in situ Eu doped CdO layers, which were deposited on p-type silicon using the plasma assisted molecular beam epitaxy (PA MBE) method. The structural and optical properties of the cadmium oxide (CdO) films were investigated using X ray diffraction and Fourier transform infrared spectroscopy (FTIR). The CdO Eu films are polycrystalline. The electrical properties of the p n heterojunction composed of transparent n CdO Eu and p Si semiconductors were investigated by current voltage and electron beam-induced current (EBIC) measurements. Current voltage measurements demonstrate good junction characteristics with a rectifying ratio of 20 . EBIC measurements allowed us to calculate the diffusion length of minority carriers and the precise location of the depleted area at the CdO and Si interfaces. [SEP] [HINT] based -> Bioinformatics (Syns: ground, free-base, base) | molecular -> Bioinformatics (Syns: ) | electron -> Materials Science (Syns: negatron)",Materials Science
"Medical image segmentation using deep learning (DL) has enabled the development of automated analysis pipelines for large-scale population studies. However, state-of-the-art DL methods are prone to hallucinations, which can result in anatomically implausible segmentations. With manual correction impractical at scale, automated quality control (QC) techniques have to address the challenge. While promising, existing QC methods are organ-specific, limiting their generalizability and usability beyond their original intended task. To overcome this limitation, we propose no-new Quality Control (nnQC), a robust QC framework based on a diffusion-generative paradigm that self-adapts to any input organ dataset. Central to nnQC is a novel Team of Experts (ToE) architecture, where two specialized experts independently encode 3D spatial awareness, represented by the relative spatial position of an axial slice, and anatomical information derived from visual features from the original image. A weighted conditional module dynamically combines the pair of independent embeddings, or opinions to condition the sampling mechanism within a diffusion process, enabling the generation of a spatially aware pseudo-ground truth for predicting QC scores. Within its framework, nnQC integrates fingerprint adaptation to ensure adaptability across organs, datasets, and imaging modalities. We evaluated nnQC on seven organs using twelve publicly available datasets. Our results demonstrate that nnQC consistently outperforms state-of-the-art methods across all experiments, including cases where segmentation masks are highly degraded or completely missing, confirming its versatility and effectiveness across different organs.",Bioinformatics
"Medical image segmentation using deep learning (DL) has enabled the development of automated analysis pipelines for large-scale population studies. However, state-of-the-art DL methods are prone to hallucinations, which can result in anatomically implausible segmentations. With manual correction impractical at scale, automated quality control (QC) techniques have to address the challenge. While promising, existing QC methods are organ-specific, limiting their generalizability and usability beyond their original intended task. To overcome this limitation, we propose no-new Quality Control (nnQC), a robust QC framework based on a diffusion-generative paradigm that self-adapts to any input organ dataset. Central to nnQC is a novel Team of Experts (ToE) architecture, where two specialized experts independently encode 3D spatial awareness, represented by the relative spatial position of an axial slice, and anatomical information derived from visual features from the original image. A weighted conditional module dynamically combines the pair of independent embeddings, or opinions to condition the sampling mechanism within a diffusion process, enabling the generation of a spatially aware pseudo-ground truth for predicting QC scores. Within its framework, nnQC integrates fingerprint adaptation to ensure adaptability across organs, datasets, and imaging modalities. We evaluated nnQC on seven organs using twelve publicly available datasets. Our results demonstrate that nnQC consistently outperforms state-of-the-art methods across all experiments, including cases where segmentation masks are highly degraded or completely missing, confirming its versatility and effectiveness across different organs. [SEP] [HINT] based -> Bioinformatics (Syns: ground, free-base, base) | features -> Bioinformatics (Syns: characteristic, lineament, feature of speech) | learning -> Bioinformatics (Syns: take, teach, acquire)",Bioinformatics
"Two-dimensional semiconductors, such as monolayer transition metal dichalcogenides (TMDC), exhibit strong excitonic transitions at room temperature and offer a unique platform for exploring light-matter interactions in nanoscale photonic systems. In this work, we demonstrate a compact and polarization-invariant photonic metasurface, fabricated from hexagonal boron-nitride (hBN) and based on radial bound states in the continuum (BIC), which are formed by radially distributed pairs of structurally asymmetric resonators. The metasurface employs multiple symmetry-breaking perturbations to support high quality-(Q-)factor resonances within a footprint smaller than 8 x 8 $μm^2$ - one-sixth of the area of previous approaches. Compared to established hBN metasurface designs, the radial geometry furthermore achieves significantly higher Q-factors with a reduced footprint. By integrating the hBN photonic structure with a WS$_2$ monolayer, we observe enhanced photoluminescence when its resonance is spectrally aligned with the exciton resonance, accompanied by signatures of discrete momentum-space patterns that identify the orbital-angular-momentum-carrying ring eigenmodes. These features persist over a wide range of excitation powers and show minimal linewidth broadening, indicating robust and spatially modulated exciton-photon coupling. This work establishes a scalable approach for generating hybrid photonic-excitonic states with momentum-space structure, offering new opportunities for exciton localization, valley emission, spatially programmable light-matter interaction in two-dimensional material platforms and compact luminescent devices based on 2D material-integrated metasurfaces.",Materials Science
"Two-dimensional semiconductors, such as monolayer transition metal dichalcogenides (TMDC), exhibit strong excitonic transitions at room temperature and offer a unique platform for exploring light-matter interactions in nanoscale photonic systems. In this work, we demonstrate a compact and polarization-invariant photonic metasurface, fabricated from hexagonal boron-nitride (hBN) and based on radial bound states in the continuum (BIC), which are formed by radially distributed pairs of structurally asymmetric resonators. The metasurface employs multiple symmetry-breaking perturbations to support high quality-(Q-)factor resonances within a footprint smaller than 8 x 8 $μm^2$ - one-sixth of the area of previous approaches. Compared to established hBN metasurface designs, the radial geometry furthermore achieves significantly higher Q-factors with a reduced footprint. By integrating the hBN photonic structure with a WS$_2$ monolayer, we observe enhanced photoluminescence when its resonance is spectrally aligned with the exciton resonance, accompanied by signatures of discrete momentum-space patterns that identify the orbital-angular-momentum-carrying ring eigenmodes. These features persist over a wide range of excitation powers and show minimal linewidth broadening, indicating robust and spatially modulated exciton-photon coupling. This work establishes a scalable approach for generating hybrid photonic-excitonic states with momentum-space structure, offering new opportunities for exciton localization, valley emission, spatially programmable light-matter interaction in two-dimensional material platforms and compact luminescent devices based on 2D material-integrated metasurfaces. [SEP] [HINT] transition -> Materials Science (Syns: passage, modulation, changeover) | based -> Bioinformatics (Syns: ground, free-base, base) | features -> Bioinformatics (Syns: characteristic, lineament, feature of speech)",Materials Science
"Electrogastrography is the recording of changes in electric potential caused by the stomach's pacemaker region, typically through several cutaneous sensors placed on the abdomen. It is a worthwhile technique in medical and psychological research, but also relatively niche. Here we present a tutorial on the acquisition and analysis of the human electrogastrogram. Because dedicated equipment and software can be prohibitively expensive, we demonstrate how data can be acquired using a low-cost OpenBCI Ganglion amplifier. We also present a processing pipeline that minimises attrition, which is particularly helpful for low-cost equipment but also applicable to top-of-the-line hardware. Our approach comprises outlier rejection, frequency filtering, movement filtering, and noise reduction using independent component analysis. Where traditional approaches include a subjective step in which only one channel is manually selected for further analysis, our pipeline recomposes the electrogastrogram from all recorded channels after automatic rejection of nuisance components. The main benefits of this approach are reduced attrition, retention of data from all recorded channels, and reduced influence of researcher bias. In addition to our tutorial on the method, we offer a proof-of-principle in which our approach leads to reduced data rejection compared to established methods. We aimed to describe each step in sufficient detail to be implemented in any programming language. In addition, we made an open-source Python package freely available for ease of use.",Neuroscience
"Electrogastrography is the recording of changes in electric potential caused by the stomach's pacemaker region, typically through several cutaneous sensors placed on the abdomen. It is a worthwhile technique in medical and psychological research, but also relatively niche. Here we present a tutorial on the acquisition and analysis of the human electrogastrogram. Because dedicated equipment and software can be prohibitively expensive, we demonstrate how data can be acquired using a low-cost OpenBCI Ganglion amplifier. We also present a processing pipeline that minimises attrition, which is particularly helpful for low-cost equipment but also applicable to top-of-the-line hardware. Our approach comprises outlier rejection, frequency filtering, movement filtering, and noise reduction using independent component analysis. Where traditional approaches include a subjective step in which only one channel is manually selected for further analysis, our pipeline recomposes the electrogastrogram from all recorded channels after automatic rejection of nuisance components. The main benefits of this approach are reduced attrition, retention of data from all recorded channels, and reduced influence of researcher bias. In addition to our tutorial on the method, we offer a proof-of-principle in which our approach leads to reduced data rejection compared to established methods. We aimed to describe each step in sufficient detail to be implemented in any programming language. In addition, we made an open-source Python package freely available for ease of use. [SEP] [HINT] processing -> Neuroscience (Syns: work, process, march) | human -> Neuroscience (Syns: human being, man, homo) | using -> Bioinformatics (Syns: utilize, exploitation, apply)",Neuroscience
"We present the measurement, characterization, and calibration procedures used to produce a series of datasets for various conductive and semiconductive materials. The data, provided, include emission yields as a function of incident electron energy together with surface composition obtained from X-Ray Photoelectron Spectroscopy or Auger Electron Spectroscopy analyses. Initial datasets cover copper and gold, with additional materials to be released on arXiv.",Materials Science
"We present the measurement, characterization, and calibration procedures used to produce a series of datasets for various conductive and semiconductive materials. The data, provided, include emission yields as a function of incident electron energy together with surface composition obtained from X-Ray Photoelectron Spectroscopy or Auger Electron Spectroscopy analyses. Initial datasets cover copper and gold, with additional materials to be released on arXiv. [SEP] [HINT] used -> Bioinformatics (Syns: utilize, ill-used, apply) | electron -> Materials Science (Syns: negatron) | datasets -> Bioinformatics (Syns: )",Materials Science
"Working memory requires the brain to maintain information from the recent past to guide ongoing behavior. Neurons can contribute to this capacity by slowly integrating their inputs over time, creating persistent activity that outlasts the original stimulus. However, when these slowly integrating neurons are organized hierarchically, they introduce cumulative delays that create a fundamental challenge for learning: teaching signals that indicate whether behavior was correct or incorrect arrive out-of-sync with the neural activity they are meant to instruct. Here, we demonstrate that neurons enhanced with an adaptive current can compensate for these delays by responding to external stimuli prospectively -- effectively predicting future inputs to synchronize with them. First, we show that such prospective neurons enable teaching signal synchronization across a range of learning algorithms that propagate error signals through hierarchical networks. Second, we demonstrate that this successfully guides learning in slowly integrating neurons, enabling the formation and retrieval of memories over extended timescales. We support our findings with a mathematical analysis of the prospective coding mechanism and learning experiments on motor control tasks. Together, our results reveal how neural adaptation could solve a critical timing problem and enable efficient learning in dynamic environments.",Neuroscience
"Working memory requires the brain to maintain information from the recent past to guide ongoing behavior. Neurons can contribute to this capacity by slowly integrating their inputs over time, creating persistent activity that outlasts the original stimulus. However, when these slowly integrating neurons are organized hierarchically, they introduce cumulative delays that create a fundamental challenge for learning: teaching signals that indicate whether behavior was correct or incorrect arrive out-of-sync with the neural activity they are meant to instruct. Here, we demonstrate that neurons enhanced with an adaptive current can compensate for these delays by responding to external stimuli prospectively -- effectively predicting future inputs to synchronize with them. First, we show that such prospective neurons enable teaching signal synchronization across a range of learning algorithms that propagate error signals through hierarchical networks. Second, we demonstrate that this successfully guides learning in slowly integrating neurons, enabling the formation and retrieval of memories over extended timescales. We support our findings with a mathematical analysis of the prospective coding mechanism and learning experiments on motor control tasks. Together, our results reveal how neural adaptation could solve a critical timing problem and enable efficient learning in dynamic environments. [SEP] [HINT] learning -> Bioinformatics (Syns: take, teach, acquire) | information -> Bioinformatics (Syns: entropy, data, info) | results -> Bioinformatics (Syns: final result, consequence, resultant role)",Neuroscience
"Mathematical oncology is a rapidly evolving interdisciplinary field that uses mathematical models to enhance our understanding of cancer dynamics, including tumor growth, metastasis, and treatment response. Tumor-immune interactions play a crucial role in cancer biology, influencing tumor progression and the effectiveness of immunotherapy and targeted treatments. However, studying tumor dynamics in isolation often fails to capture the complex interplay between cancer cells and the immune system, which is critical to disease progression and therapeutic efficacy. Mathematical models that incorporate tumor-immune interactions offer valuable insights into these processes, providing a framework for analyzing immune escape, treatment response, and resistance mechanisms. In this review, we provide an overview of mathematical models that describe tumor-immune dynamics, highlighting their applications in understanding tumor growth, evaluating treatment strategies, and predicting immune responses. We also discuss the strengths and limitations of current modeling approaches and propose future directions for the development of more comprehensive and predictive models of tumor-immune interactions. We aim to offer a comprehensive guide to the state of mathematical modeling in tumor immunology, emphasizing its potential to inform clinical decision-making and improve cancer therapies.",Bioinformatics
"Mathematical oncology is a rapidly evolving interdisciplinary field that uses mathematical models to enhance our understanding of cancer dynamics, including tumor growth, metastasis, and treatment response. Tumor-immune interactions play a crucial role in cancer biology, influencing tumor progression and the effectiveness of immunotherapy and targeted treatments. However, studying tumor dynamics in isolation often fails to capture the complex interplay between cancer cells and the immune system, which is critical to disease progression and therapeutic efficacy. Mathematical models that incorporate tumor-immune interactions offer valuable insights into these processes, providing a framework for analyzing immune escape, treatment response, and resistance mechanisms. In this review, we provide an overview of mathematical models that describe tumor-immune dynamics, highlighting their applications in understanding tumor growth, evaluating treatment strategies, and predicting immune responses. We also discuss the strengths and limitations of current modeling approaches and propose future directions for the development of more comprehensive and predictive models of tumor-immune interactions. We aim to offer a comprehensive guide to the state of mathematical modeling in tumor immunology, emphasizing its potential to inform clinical decision-making and improve cancer therapies. [SEP] [HINT] field -> Materials Science (Syns: field of honor, line of business, orbit) | clinical -> Bioinformatics (Syns: ) | understanding -> Neuroscience (Syns: savvy, intellect, sympathy)",Bioinformatics
"Increasing climate change and habitat loss are driving unprecedented shifts in species distributions. Conservation professionals urgently need timely, high-resolution predictions of biodiversity risks, especially in ecologically diverse regions like Africa. We propose EcoCast, a spatio-temporal model designed for continual biodiversity and climate risk forecasting. Utilizing multisource satellite imagery, climate data, and citizen science occurrence records, EcoCast predicts near-term (monthly to seasonal) shifts in species distributions through sequence-based transformers that model spatio-temporal environmental dependencies. The architecture is designed with support for continual learning to enable future operational deployment with new data streams. Our pilot study in Africa shows promising improvements in forecasting distributions of selected bird species compared to a Random Forest baseline, highlighting EcoCast's potential to inform targeted conservation policies. By demonstrating an end-to-end pipeline from multi-modal data ingestion to operational forecasting, EcoCast bridges the gap between cutting-edge machine learning and biodiversity management, ultimately guiding data-driven strategies for climate resilience and ecosystem conservation throughout Africa.",Bioinformatics
"Increasing climate change and habitat loss are driving unprecedented shifts in species distributions. Conservation professionals urgently need timely, high-resolution predictions of biodiversity risks, especially in ecologically diverse regions like Africa. We propose EcoCast, a spatio-temporal model designed for continual biodiversity and climate risk forecasting. Utilizing multisource satellite imagery, climate data, and citizen science occurrence records, EcoCast predicts near-term (monthly to seasonal) shifts in species distributions through sequence-based transformers that model spatio-temporal environmental dependencies. The architecture is designed with support for continual learning to enable future operational deployment with new data streams. Our pilot study in Africa shows promising improvements in forecasting distributions of selected bird species compared to a Random Forest baseline, highlighting EcoCast's potential to inform targeted conservation policies. By demonstrating an end-to-end pipeline from multi-modal data ingestion to operational forecasting, EcoCast bridges the gap between cutting-edge machine learning and biodiversity management, ultimately guiding data-driven strategies for climate resilience and ecosystem conservation throughout Africa. [SEP] [HINT] learning -> Bioinformatics (Syns: take, teach, acquire) | potential -> Bioinformatics (Syns: voltage, potential difference, electric potential) | study -> Bioinformatics (Syns: sketch, meditate, take)",Bioinformatics
"Delafossites (ABC2, where A and B are metals and C is a chalcogen) are a versatile family of quantum materials and layered oxides/chalcogenides whose properties are highly sensitive to atomic composition and stacking geometry. Their broad chemical tunability makes them an ideal platform for large-scale combinatorial exploration and high-throughput computational screening with desirable quantum properties. In this work, we employ a Concept Whitening Graph Neural Network, a gray-box AI model, to classify delafossite structures by stacking sequence and magnetic states. By aligning learned representations with human-interpretable physical concepts, this gray-box approach enables both accurate prediction and insight into the structural and chemical features driving magnetic behavior. The magnetic-ordering models achieved validation accuracies exceeding 80 percent, with a further slight uptick observed in the model incorporating the largest number of concepts. Concept alignment analysis revealed measurable learning across nine physically meaningful descriptors, with coefficients of determination ranging from approximately 0.6 for the d-shell valence-electron concepts to 0.4-0.5 for the magnetic coupling parameters. Furthermore, we mapped the concept importances onto the material graph representation, elucidating interpretable physical trends and the progression of stable concept-aligned regions across training. These results demonstrate the potential of interpretable graph-based learning to capture the underlying physics of complex materials systems and provide an interpretable framework for accelerating the discovery and understanding of delafossites and related crystalline materials.",Materials Science
"Delafossites (ABC2, where A and B are metals and C is a chalcogen) are a versatile family of quantum materials and layered oxides/chalcogenides whose properties are highly sensitive to atomic composition and stacking geometry. Their broad chemical tunability makes them an ideal platform for large-scale combinatorial exploration and high-throughput computational screening with desirable quantum properties. In this work, we employ a Concept Whitening Graph Neural Network, a gray-box AI model, to classify delafossite structures by stacking sequence and magnetic states. By aligning learned representations with human-interpretable physical concepts, this gray-box approach enables both accurate prediction and insight into the structural and chemical features driving magnetic behavior. The magnetic-ordering models achieved validation accuracies exceeding 80 percent, with a further slight uptick observed in the model incorporating the largest number of concepts. Concept alignment analysis revealed measurable learning across nine physically meaningful descriptors, with coefficients of determination ranging from approximately 0.6 for the d-shell valence-electron concepts to 0.4-0.5 for the magnetic coupling parameters. Furthermore, we mapped the concept importances onto the material graph representation, elucidating interpretable physical trends and the progression of stable concept-aligned regions across training. These results demonstrate the potential of interpretable graph-based learning to capture the underlying physics of complex materials systems and provide an interpretable framework for accelerating the discovery and understanding of delafossites and related crystalline materials. [SEP] [HINT] computational -> Neuroscience (Syns: ) | features -> Bioinformatics (Syns: characteristic, lineament, feature of speech) | understanding -> Neuroscience (Syns: savvy, intellect, sympathy)",Materials Science
"We present BIOMERO 2.0, a major evolution of the BIOMERO framework that transforms OMERO into a FAIR-compliant (findable, accessible, interoperable, and reusable), provenance-aware bioimaging platform. BIOMERO 2.0 integrates data import, preprocessing, analysis, and workflow monitoring through an OMERO.web plugin and containerized components. The importer subsystem facilitates in-place import using containerized preprocessing and metadata enrichment via forms, while the analyzer subsystem coordinates and tracks containerized analyses on high-performance computing systems via the BIOMERO Python library. All imports and analyses are recorded with parameters, versions, and results, ensuring real-time provenance accessible through integrated dashboards. This dual approach places OMERO at the heart of the bioimaging analysis process: the importer ensures provenance from image acquisition through preprocessing and import into OMERO, while the analyzer records it for downstream processing. These integrated layers enhance OMEROs FAIRification, supporting traceable, reusable workflows for image analysis that bridge the gap between data import, analysis, and sharing.",Bioinformatics
"We present BIOMERO 2.0, a major evolution of the BIOMERO framework that transforms OMERO into a FAIR-compliant (findable, accessible, interoperable, and reusable), provenance-aware bioimaging platform. BIOMERO 2.0 integrates data import, preprocessing, analysis, and workflow monitoring through an OMERO.web plugin and containerized components. The importer subsystem facilitates in-place import using containerized preprocessing and metadata enrichment via forms, while the analyzer subsystem coordinates and tracks containerized analyses on high-performance computing systems via the BIOMERO Python library. All imports and analyses are recorded with parameters, versions, and results, ensuring real-time provenance accessible through integrated dashboards. This dual approach places OMERO at the heart of the bioimaging analysis process: the importer ensures provenance from image acquisition through preprocessing and import into OMERO, while the analyzer records it for downstream processing. These integrated layers enhance OMEROs FAIRification, supporting traceable, reusable workflows for image analysis that bridge the gap between data import, analysis, and sharing. [SEP] [HINT] systems -> Bioinformatics (Syns: organization, organisation, system) | framework -> Bioinformatics (Syns: theoretical account, model, fabric) | using -> Bioinformatics (Syns: utilize, exploitation, apply)",Bioinformatics
"III-V colloidal quantum dots are widely studied for their applications as detectors and emitters from visible to short-wave infrared. They might also be used in the mid-infrared if they can be stably n-doped to access their intraband transitions. Mid-infrared intraband transitions are therefore studied for InAs, InAs/InP, and InAs/ZnSe colloidal quantum dots with an energy gap at 1.4 micron. Using electrochemistry, the quantum dot films show state-resolved mobility, state-resolved electron filling, and intraband absorption in the 3-8 micron range. The InAs/ZnSe films need a more reducing potential than InAs, but the InAs/InP films need a lower reduction potential. As a result, we found that dry films of InAs/InP dots show stable n-doping of the 1Se state, with a steady-state intraband absorption in the 3-5 micron range, and intraband luminescence at 5 micron. low-toxicity, high thermal stability, and stable n-doping, InAs quantum dots become an interesting material for mid-infrared applications.",Materials Science
"III-V colloidal quantum dots are widely studied for their applications as detectors and emitters from visible to short-wave infrared. They might also be used in the mid-infrared if they can be stably n-doped to access their intraband transitions. Mid-infrared intraband transitions are therefore studied for InAs, InAs/InP, and InAs/ZnSe colloidal quantum dots with an energy gap at 1.4 micron. Using electrochemistry, the quantum dot films show state-resolved mobility, state-resolved electron filling, and intraband absorption in the 3-8 micron range. The InAs/ZnSe films need a more reducing potential than InAs, but the InAs/InP films need a lower reduction potential. As a result, we found that dry films of InAs/InP dots show stable n-doping of the 1Se state, with a steady-state intraband absorption in the 3-5 micron range, and intraband luminescence at 5 micron. low-toxicity, high thermal stability, and stable n-doping, InAs quantum dots become an interesting material for mid-infrared applications. [SEP] [HINT] used -> Bioinformatics (Syns: utilize, ill-used, apply) | electron -> Materials Science (Syns: negatron) | using -> Bioinformatics (Syns: utilize, exploitation, apply)",Materials Science
"Cells within biological tissue are constantly subjected to dynamic mechanical forces. Measuring the internal stress of tissues has proven crucial for our understanding of the role of mechanical forces in fundamental biological processes like morphogenesis, collective migration, cell division or cell elimination and death. Previously, we have introduced Bayesian Inversion Stress Microscopy (BISM), which is relying on measuring cell-generated traction forces in vitro and has proven particularly useful to measure absolute stresses in confined cell monolayers. We further demonstrate the applicability and robustness of BISM across various experimental settings with different boundary conditions, ranging from confined tissues of arbitrary shape to monolayers composed of different cell types. Importantly, BISM does not require assumptions on cell rheology. Therefore, it can be applied to complex heterogeneous tissues consisting of different cell types, as long as they can be grown on a flat substrate. Finally, we compare BISM to other common stress measurement techniques using a coherent experimental setup, followed by a discussion on its limitations and further perspectives.",Bioinformatics
"Cells within biological tissue are constantly subjected to dynamic mechanical forces. Measuring the internal stress of tissues has proven crucial for our understanding of the role of mechanical forces in fundamental biological processes like morphogenesis, collective migration, cell division or cell elimination and death. Previously, we have introduced Bayesian Inversion Stress Microscopy (BISM), which is relying on measuring cell-generated traction forces in vitro and has proven particularly useful to measure absolute stresses in confined cell monolayers. We further demonstrate the applicability and robustness of BISM across various experimental settings with different boundary conditions, ranging from confined tissues of arbitrary shape to monolayers composed of different cell types. Importantly, BISM does not require assumptions on cell rheology. Therefore, it can be applied to complex heterogeneous tissues consisting of different cell types, as long as they can be grown on a flat substrate. Finally, we compare BISM to other common stress measurement techniques using a coherent experimental setup, followed by a discussion on its limitations and further perspectives. [SEP] [HINT] tissue -> Bioinformatics (Syns: tissue paper, weave) | understanding -> Neuroscience (Syns: savvy, intellect, sympathy) | complex -> Bioinformatics (Syns: building complex, coordination compound, composite)",Bioinformatics
"Recordings of increasingly large neural populations have revealed that the firing of individual neurons is highly coordinated. When viewed in the space of all possible patterns, the collective activity forms non-linear structures called neural manifolds. Because such structures are observed even at rest or during sleep, an important hypothesis is that activity manifolds may correspond to continuous attractors shaped by recurrent connectivity between neurons. Classical models of recurrent networks have shown that continuous attractors can be generated by specific symmetries in the connectivity. Although a variety of attractor network models have been studied, general principles linking network connectivity and the geometry of attractors remain to be formulated. Here, we address this question by using group representation theory to formalize the relationship between the symmetries in recurrent connectivity and the resulting fixed-point manifolds. We start by revisiting the classical ring model, a continuous attractor network generating a circular manifold. Interpreting its connectivity as a circular convolution, we draw a parallel with feed-forward CNNs. Building on principles of geometric deep learning, we then generalize this architecture to a broad range of symmetries using group representation theory. Specifically, we introduce a new class of equivariant RNNs, where the connectivity is based on group convolution. Using the group Fourier transform, we reduce such networks to low-rank models, giving us a low-dimensional description that can be fully analyzed to determine the symmetry, dimensionality and stability of fixed-point manifolds. Our results underline the importance of stability considerations: for a connectivity with a given symmetry, depending on parameters, several manifolds with different symmetry subgroups can coexist, some stable and others consisting of saddle points.",Neuroscience
"Recordings of increasingly large neural populations have revealed that the firing of individual neurons is highly coordinated. When viewed in the space of all possible patterns, the collective activity forms non-linear structures called neural manifolds. Because such structures are observed even at rest or during sleep, an important hypothesis is that activity manifolds may correspond to continuous attractors shaped by recurrent connectivity between neurons. Classical models of recurrent networks have shown that continuous attractors can be generated by specific symmetries in the connectivity. Although a variety of attractor network models have been studied, general principles linking network connectivity and the geometry of attractors remain to be formulated. Here, we address this question by using group representation theory to formalize the relationship between the symmetries in recurrent connectivity and the resulting fixed-point manifolds. We start by revisiting the classical ring model, a continuous attractor network generating a circular manifold. Interpreting its connectivity as a circular convolution, we draw a parallel with feed-forward CNNs. Building on principles of geometric deep learning, we then generalize this architecture to a broad range of symmetries using group representation theory. Specifically, we introduce a new class of equivariant RNNs, where the connectivity is based on group convolution. Using the group Fourier transform, we reduce such networks to low-rank models, giving us a low-dimensional description that can be fully analyzed to determine the symmetry, dimensionality and stability of fixed-point manifolds. Our results underline the importance of stability considerations: for a connectivity with a given symmetry, depending on parameters, several manifolds with different symmetry subgroups can coexist, some stable and others consisting of saddle points. [SEP] [HINT] connectivity -> Neuroscience (Syns: ) | based -> Bioinformatics (Syns: ground, free-base, base) | networks -> Neuroscience (Syns: network, meshwork, electronic network)",Neuroscience
"Reconstructing images seen by people from their fMRI brain recordings provides a non-invasive window into the human brain. Despite recent progress enabled by diffusion models, current methods often lack faithfulness to the actual seen images. We present ""Brain-IT"", a brain-inspired approach that addresses this challenge through a Brain Interaction Transformer (BIT), allowing effective interactions between clusters of functionally-similar brain-voxels. These functional-clusters are shared by all subjects, serving as building blocks for integrating information both within and across brains. All model components are shared by all clusters & subjects, allowing efficient training with a limited amount of data. To guide the image reconstruction, BIT predicts two complementary localized patch-level image features: (i)high-level semantic features which steer the diffusion model toward the correct semantic content of the image; and (ii)low-level structural features which help to initialize the diffusion process with the correct coarse layout of the image. BIT's design enables direct flow of information from brain-voxel clusters to localized image features. Through these principles, our method achieves image reconstructions from fMRI that faithfully reconstruct the seen images, and surpass current SotA approaches both visually and by standard objective metrics. Moreover, with only 1-hour of fMRI data from a new subject, we achieve results comparable to current methods trained on full 40-hour recordings.",Neuroscience
"Reconstructing images seen by people from their fMRI brain recordings provides a non-invasive window into the human brain. Despite recent progress enabled by diffusion models, current methods often lack faithfulness to the actual seen images. We present ""Brain-IT"", a brain-inspired approach that addresses this challenge through a Brain Interaction Transformer (BIT), allowing effective interactions between clusters of functionally-similar brain-voxels. These functional-clusters are shared by all subjects, serving as building blocks for integrating information both within and across brains. All model components are shared by all clusters & subjects, allowing efficient training with a limited amount of data. To guide the image reconstruction, BIT predicts two complementary localized patch-level image features: (i)high-level semantic features which steer the diffusion model toward the correct semantic content of the image; and (ii)low-level structural features which help to initialize the diffusion process with the correct coarse layout of the image. BIT's design enables direct flow of information from brain-voxel clusters to localized image features. Through these principles, our method achieves image reconstructions from fMRI that faithfully reconstruct the seen images, and surpass current SotA approaches both visually and by standard objective metrics. Moreover, with only 1-hour of fMRI data from a new subject, we achieve results comparable to current methods trained on full 40-hour recordings. [SEP] [HINT] features -> Bioinformatics (Syns: characteristic, lineament, feature of speech) | information -> Bioinformatics (Syns: entropy, data, info) | human -> Neuroscience (Syns: human being, man, homo)",Neuroscience
"Understanding how the primate brain transforms complex visual scenes into coherent perceptual experiences remains a central challenge in neuroscience. Here, we present a comprehensive framework for interpreting monkey visual processing by integrating encoding and decoding approaches applied to two large-scale spiking datasets recorded from macaque using THINGS images (THINGS macaque IT Dataset (TITD) and THINGS Ventral Stream Spiking Dataset (TVSD)). We leverage multi-electrode array recordings from the ventral visual stream--including V1, V4, and inferotemporal (IT) cortex--to investigate how distributed neural populations encode and represent visual information. Our approach employs linear models to decode spiking activity into multiple latent visual spaces (including CLIP and VDVAE embeddings) and reconstruct images using state-of-the-art generative models. We further utilize encoding models to map visual features back to neural activity, enabling visualization of the ""preferred stimuli"" that drive specific neural ensembles. Analyses of both datasets reveal that it is possible to reconstruct both low-level (e.g., color, texture) and high-level (e.g., semantic category) features of visual stimuli from population activity, with reconstructions preserving key perceptual attributes as quantified by feature-based similarity metrics. The spatiotemporal spike patterns reflect the ventral stream's hierarchical organization with anterior regions representing complex objects and categories. Functional clustering identifies feature-specific neural ensembles, with temporal dynamics show evolving feature selectivity post-stimulus. Our findings demonstrate feasible, generalizable perceptual reconstruction from large-scale monkey neural recordings, linking neural activity to perception.",Neuroscience
"Understanding how the primate brain transforms complex visual scenes into coherent perceptual experiences remains a central challenge in neuroscience. Here, we present a comprehensive framework for interpreting monkey visual processing by integrating encoding and decoding approaches applied to two large-scale spiking datasets recorded from macaque using THINGS images (THINGS macaque IT Dataset (TITD) and THINGS Ventral Stream Spiking Dataset (TVSD)). We leverage multi-electrode array recordings from the ventral visual stream--including V1, V4, and inferotemporal (IT) cortex--to investigate how distributed neural populations encode and represent visual information. Our approach employs linear models to decode spiking activity into multiple latent visual spaces (including CLIP and VDVAE embeddings) and reconstruct images using state-of-the-art generative models. We further utilize encoding models to map visual features back to neural activity, enabling visualization of the ""preferred stimuli"" that drive specific neural ensembles. Analyses of both datasets reveal that it is possible to reconstruct both low-level (e.g., color, texture) and high-level (e.g., semantic category) features of visual stimuli from population activity, with reconstructions preserving key perceptual attributes as quantified by feature-based similarity metrics. The spatiotemporal spike patterns reflect the ventral stream's hierarchical organization with anterior regions representing complex objects and categories. Functional clustering identifies feature-specific neural ensembles, with temporal dynamics show evolving feature selectivity post-stimulus. Our findings demonstrate feasible, generalizable perceptual reconstruction from large-scale monkey neural recordings, linking neural activity to perception. [SEP] [HINT] decoding -> Neuroscience (Syns: decrypt, decipherment, decryption) | features -> Bioinformatics (Syns: characteristic, lineament, feature of speech) | understanding -> Neuroscience (Syns: savvy, intellect, sympathy)",Neuroscience
"We characterize the grain boundary (GB) susceptibility to hydrogen-assisted intergranular cracking in pure nickel as a function of coincident site lattice value ($Σ$-n), over a wide range of hydrogen concentrations (4 to 14 wppm). Cracks on the surface and within the bulk material were identified across the entire gauge region of the specimens. The susceptibility of GBs to crack initiation and propagation was evaluated by separating cracks containing single GB or multiple GBs. A larger loss in fracture strain, a smaller reduction in area, and an increase in the percentage of intergranular fracture indicated a higher degree of embrittlement at elevated hydrogen concentrations. The number of cracks was significantly higher on the surface than in the bulk for the most severe hydrogen charging conditions ($\geq$ 8 wppm), while a similar number was observed for lower concentrations. The propensity for hydrogen-assisted intergranular cracking at different types of GBs on the surface and in the bulk material was consistent, indicating that while cathodic charging can promote surface cracks, it does not significantly impact the GBs relative susceptibility. The $Σ$-3 boundaries were the most resistant to cracking, as evidenced by the considerably lower fraction of these GBs exhibiting intergranular cracking at all hydrogen concentrations considered. This contrasts literature findings for Ni alloys and can be explained by the segregation energies and reductions in the cohesive strength with hydrogen, with less favorable trapping at the $Σ$-3 boundaries. No evidence of plasticity-mediated cracking initiation was observed.",Materials Science
"We characterize the grain boundary (GB) susceptibility to hydrogen-assisted intergranular cracking in pure nickel as a function of coincident site lattice value ($Σ$-n), over a wide range of hydrogen concentrations (4 to 14 wppm). Cracks on the surface and within the bulk material were identified across the entire gauge region of the specimens. The susceptibility of GBs to crack initiation and propagation was evaluated by separating cracks containing single GB or multiple GBs. A larger loss in fracture strain, a smaller reduction in area, and an increase in the percentage of intergranular fracture indicated a higher degree of embrittlement at elevated hydrogen concentrations. The number of cracks was significantly higher on the surface than in the bulk for the most severe hydrogen charging conditions ($\geq$ 8 wppm), while a similar number was observed for lower concentrations. The propensity for hydrogen-assisted intergranular cracking at different types of GBs on the surface and in the bulk material was consistent, indicating that while cathodic charging can promote surface cracks, it does not significantly impact the GBs relative susceptibility. The $Σ$-3 boundaries were the most resistant to cracking, as evidenced by the considerably lower fraction of these GBs exhibiting intergranular cracking at all hydrogen concentrations considered. This contrasts literature findings for Ni alloys and can be explained by the segregation energies and reductions in the cohesive strength with hydrogen, with less favorable trapping at the $Σ$-3 boundaries. No evidence of plasticity-mediated cracking initiation was observed. [SEP] [HINT] different -> Neuroscience (Syns: unlike, dissimilar) | material -> Materials Science (Syns: stuff, cloth, real) | lattice -> Materials Science (Syns: grille, fretwork, latticework)",Materials Science
"The Adaptive Exponential Integrate-and-Fire (AdEx) model is a simplified framework that effectively characterizes neuronal electrical activity. The aim of this paper is to employ phase plane analysis to systematically investigate diverse firing patterns generated by the AdEx model under varying parametric conditions. We first introduce the fundamental equations and parameter configurations of the AdEx model to numerically simulate the six representative firing patterns in the AdEx model. And then we use phase plane analysis to explore the dynamic mechanism of these firing patterns under different input currents and parametric conditions. Our findings demonstrate that the AdEx model can simulate multiple firing patterns, including Tonic Spiking, Adapting, Initial Bursting, Busting, Transient Spiking and Delayed Spiking firing patterns. These results not only advance the understanding of complex electrophysiological phenomena in neurons but also provide theoretical foundations for applications in many fields like neuromorphic computing and brain-computer interfaces.",Neuroscience
"The Adaptive Exponential Integrate-and-Fire (AdEx) model is a simplified framework that effectively characterizes neuronal electrical activity. The aim of this paper is to employ phase plane analysis to systematically investigate diverse firing patterns generated by the AdEx model under varying parametric conditions. We first introduce the fundamental equations and parameter configurations of the AdEx model to numerically simulate the six representative firing patterns in the AdEx model. And then we use phase plane analysis to explore the dynamic mechanism of these firing patterns under different input currents and parametric conditions. Our findings demonstrate that the AdEx model can simulate multiple firing patterns, including Tonic Spiking, Adapting, Initial Bursting, Busting, Transient Spiking and Delayed Spiking firing patterns. These results not only advance the understanding of complex electrophysiological phenomena in neurons but also provide theoretical foundations for applications in many fields like neuromorphic computing and brain-computer interfaces. [SEP] [HINT] understanding -> Neuroscience (Syns: savvy, intellect, sympathy) | complex -> Bioinformatics (Syns: building complex, coordination compound, composite) | results -> Bioinformatics (Syns: final result, consequence, resultant role)",Neuroscience
"In the past decade a surge in the amount of electronic health record (EHR) data in the United States, attributed to a favorable policy environment created by the Health Information Technology for Economic and Clinical Health (HITECH) Act of 2009 and the 21st Century Cures Act of 2016. Clinical notes for patients' assessments, diagnoses, and treatments are captured in these EHRs in free-form text by physicians, who spend a considerable amount of time entering and editing them. Manually writing clinical notes takes a considerable amount of a doctor's valuable time, increasing the patient's waiting time and possibly delaying diagnoses. Large language models (LLMs) possess the ability to generate news articles that closely resemble human-written ones. We investigate the usage of Chain-of-Thought (CoT) prompt engineering to improve the LLM's response in clinical note generation. In our prompts, we use as input International Classification of Diseases (ICD) codes and basic patient information. We investigate a strategy that combines the traditional CoT with semantic search results to improve the quality of generated clinical notes. Additionally, we infuse a knowledge graph (KG) built from clinical ontology to further enrich the domain-specific knowledge of generated clinical notes. We test our prompting technique on six clinical cases from the CodiEsp test dataset using GPT-4 and our results show that it outperformed the clinical notes generated by standard one-shot prompts.",Bioinformatics
"In the past decade a surge in the amount of electronic health record (EHR) data in the United States, attributed to a favorable policy environment created by the Health Information Technology for Economic and Clinical Health (HITECH) Act of 2009 and the 21st Century Cures Act of 2016. Clinical notes for patients' assessments, diagnoses, and treatments are captured in these EHRs in free-form text by physicians, who spend a considerable amount of time entering and editing them. Manually writing clinical notes takes a considerable amount of a doctor's valuable time, increasing the patient's waiting time and possibly delaying diagnoses. Large language models (LLMs) possess the ability to generate news articles that closely resemble human-written ones. We investigate the usage of Chain-of-Thought (CoT) prompt engineering to improve the LLM's response in clinical note generation. In our prompts, we use as input International Classification of Diseases (ICD) codes and basic patient information. We investigate a strategy that combines the traditional CoT with semantic search results to improve the quality of generated clinical notes. Additionally, we infuse a knowledge graph (KG) built from clinical ontology to further enrich the domain-specific knowledge of generated clinical notes. We test our prompting technique on six clinical cases from the CodiEsp test dataset using GPT-4 and our results show that it outperformed the clinical notes generated by standard one-shot prompts. [SEP] [HINT] clinical -> Bioinformatics (Syns: ) | language -> Neuroscience (Syns: linguistic process, linguistic communication, spoken communication) | electronic -> Materials Science (Syns: )",Bioinformatics
"Brain-computer interfaces (BCIs) allow direct communication between the brain and external devices, frequently using electroencephalography (EEG) to record neural activity. Dimensionality reduction and structured regularization are essential for effectively classifying task-related brain signals, including event-related potentials (ERPs) and motor imagery (MI) rhythms. Current tensor-based approaches, such as Tucker and PARAFAC decompositions, often lack the flexibility needed to fully capture the complexity of EEG data. This study introduces Block-Term Tensor Discriminant Analysis (BTTDA): a novel tensor-based and supervised feature extraction method designed to enhance classification accuracy by providing flexible multilinear dimensionality reduction. Extending Higher Order Discriminant Analysis (HODA), BTTDA uses a novel and interpretable forward model for HODA combined with a deflation scheme to iteratively extract discriminant block terms, improving feature representation for classification. BTTDA and a sum-of-rank-1-terms variant PARAFACDA were evaluated on publicly available ERP (second-order tensors) and MI (third-order tensors) EEG datasets from the MOABB benchmarking framework. Benchmarking revealed that BTTDA and PARAFACDA significantly outperform the traditional HODA method in ERP decoding, resulting in state-of-the art performance (ROC-AUC = 91.25%). For MI, decoding results of HODA, BTTDA and PARAFACDA were subpar, but BTTDA still significantly outperformed HODA (64.52% > 61.00%). The block-term structure of BTTDA enables interpretable and more efficient dimensionality reduction without compromising discriminative power. This offers a promising and adaptable approach for feature extraction in BCI and broader neuroimaging applications.",Neuroscience
"Brain-computer interfaces (BCIs) allow direct communication between the brain and external devices, frequently using electroencephalography (EEG) to record neural activity. Dimensionality reduction and structured regularization are essential for effectively classifying task-related brain signals, including event-related potentials (ERPs) and motor imagery (MI) rhythms. Current tensor-based approaches, such as Tucker and PARAFAC decompositions, often lack the flexibility needed to fully capture the complexity of EEG data. This study introduces Block-Term Tensor Discriminant Analysis (BTTDA): a novel tensor-based and supervised feature extraction method designed to enhance classification accuracy by providing flexible multilinear dimensionality reduction. Extending Higher Order Discriminant Analysis (HODA), BTTDA uses a novel and interpretable forward model for HODA combined with a deflation scheme to iteratively extract discriminant block terms, improving feature representation for classification. BTTDA and a sum-of-rank-1-terms variant PARAFACDA were evaluated on publicly available ERP (second-order tensors) and MI (third-order tensors) EEG datasets from the MOABB benchmarking framework. Benchmarking revealed that BTTDA and PARAFACDA significantly outperform the traditional HODA method in ERP decoding, resulting in state-of-the art performance (ROC-AUC = 91.25%). For MI, decoding results of HODA, BTTDA and PARAFACDA were subpar, but BTTDA still significantly outperformed HODA (64.52% > 61.00%). The block-term structure of BTTDA enables interpretable and more efficient dimensionality reduction without compromising discriminative power. This offers a promising and adaptable approach for feature extraction in BCI and broader neuroimaging applications. [SEP] [HINT] decoding -> Neuroscience (Syns: decrypt, decipherment, decryption) | structure -> Bioinformatics (Syns: social system, complex body part, social structure) | order -> Materials Science (Syns: enjoin, dictate, social club)",Neuroscience
"Object binding, the brain's ability to bind the many features that collectively represent an object into a coherent whole, is central to human cognition. It groups low-level perceptual features into high-level object representations, stores those objects efficiently and compositionally in memory, and supports human reasoning about individual object instances. While prior work often imposes object-centric attention (e.g., Slot Attention) explicitly to probe these benefits, it remains unclear whether this ability naturally emerges in pre-trained Vision Transformers (ViTs). Intuitively, they could: recognizing which patches belong to the same object should be useful for downstream prediction and thus guide attention. Motivated by the quadratic nature of self-attention, we hypothesize that ViTs represent whether two patches belong to the same object, a property we term IsSameObject. We decode IsSameObject from patch embeddings across ViT layers using a similarity probe, which reaches over 90% accuracy. Crucially, this object-binding capability emerges reliably in self-supervised ViTs (DINO, MAE, CLIP), but markedly weaker in ImageNet-supervised models, suggesting that binding is not a trivial architectural artifact, but an ability acquired through specific pretraining objectives. We further discover that IsSameObject is encoded in a low-dimensional subspace on top of object features, and that this signal actively guides attention. Ablating IsSameObject from model activations degrades downstream performance and works against the learning objective, implying that emergent object binding naturally serves the pretraining objective. Our findings challenge the view that ViTs lack object binding and highlight how symbolic knowledge of ""which parts belong together"" emerges naturally in a connectionist system.",Neuroscience
"Object binding, the brain's ability to bind the many features that collectively represent an object into a coherent whole, is central to human cognition. It groups low-level perceptual features into high-level object representations, stores those objects efficiently and compositionally in memory, and supports human reasoning about individual object instances. While prior work often imposes object-centric attention (e.g., Slot Attention) explicitly to probe these benefits, it remains unclear whether this ability naturally emerges in pre-trained Vision Transformers (ViTs). Intuitively, they could: recognizing which patches belong to the same object should be useful for downstream prediction and thus guide attention. Motivated by the quadratic nature of self-attention, we hypothesize that ViTs represent whether two patches belong to the same object, a property we term IsSameObject. We decode IsSameObject from patch embeddings across ViT layers using a similarity probe, which reaches over 90% accuracy. Crucially, this object-binding capability emerges reliably in self-supervised ViTs (DINO, MAE, CLIP), but markedly weaker in ImageNet-supervised models, suggesting that binding is not a trivial architectural artifact, but an ability acquired through specific pretraining objectives. We further discover that IsSameObject is encoded in a low-dimensional subspace on top of object features, and that this signal actively guides attention. Ablating IsSameObject from model activations degrades downstream performance and works against the learning objective, implying that emergent object binding naturally serves the pretraining objective. Our findings challenge the view that ViTs lack object binding and highlight how symbolic knowledge of ""which parts belong together"" emerges naturally in a connectionist system. [SEP] [HINT] features -> Bioinformatics (Syns: characteristic, lineament, feature of speech) | learning -> Bioinformatics (Syns: take, teach, acquire) | work -> Bioinformatics (Syns: work out, process, bring)",Neuroscience
"Neuromorphic computing aspires to overcome the intrinsic inefficiencies of von Neumann architectures by co-locating memory and computation in physical devices that emulate biological neurons and synapses. Memristive materials stand at the core of this paradigm, enabling non-volatile, history-dependent electronic responses. While inorganic oxides currently dominate the field, molecular and polymeric systems can offer untapped advantages in terms of chemical tunability, structural flexibility, low-cost processing, and biocompatibility. However, progress has been hindered by the absence of a theoretical framework able to rationalize how molecular structure translates into memristive function. Here, a multiscale computational perspective is presented, outlining how quantum chemistry and molecular dynamics, among other approaches, can be integrated into a coherent methodology to design next-generation organic memristors. Three mechanisms, ionic migration, redox-driven switching, and conduction interplay in chiral molecules are examined as representative routes toward molecular neuromorphic hardware. The opportunities and challenges associated with each mechanism are discussed, together with a view on how a theoretically guided roadmap can accelerate the emergence of chemically engineered synaptic materials.",Materials Science
"Neuromorphic computing aspires to overcome the intrinsic inefficiencies of von Neumann architectures by co-locating memory and computation in physical devices that emulate biological neurons and synapses. Memristive materials stand at the core of this paradigm, enabling non-volatile, history-dependent electronic responses. While inorganic oxides currently dominate the field, molecular and polymeric systems can offer untapped advantages in terms of chemical tunability, structural flexibility, low-cost processing, and biocompatibility. However, progress has been hindered by the absence of a theoretical framework able to rationalize how molecular structure translates into memristive function. Here, a multiscale computational perspective is presented, outlining how quantum chemistry and molecular dynamics, among other approaches, can be integrated into a coherent methodology to design next-generation organic memristors. Three mechanisms, ionic migration, redox-driven switching, and conduction interplay in chiral molecules are examined as representative routes toward molecular neuromorphic hardware. The opportunities and challenges associated with each mechanism are discussed, together with a view on how a theoretically guided roadmap can accelerate the emergence of chemically engineered synaptic materials. [SEP] [HINT] computational -> Neuroscience (Syns: ) | electronic -> Materials Science (Syns: ) | structure -> Bioinformatics (Syns: social system, complex body part, social structure)",Materials Science
"Heat transfer in semiconductor devices is dominated by chip and substrate assemblies, where heat generated within a finite chip layer dissipates into a semi-infinite substrate with much higher thermophysical properties. This mismatch produces steep interfacial temperature gradients, making the transient thermal response highly sensitive to the interface. Conventional numerical solvers require excessive discretization to resolve these dynamics, while physics-informed neural networks (PINNs) often exhibit unstable convergence and loss of physical consistency near the material interface. To address these challenges, we introduce HeatTransFormer, a physics-guided Transformer architecture for interface-dominated diffusion problems. The framework integrates physically informed spatiotemporal sampling, a Laplace-based activation emulating analytical diffusion solutions, and a mask-free attention mechanism supporting bidirectional spatiotemporal coupling. These components enable the model to resolve steep gradients, maintain physical consistency, and remain stable where PINNs typically fail. HeatTransFormer produces coherent temperature fields across the interface when applied to a finite layer and semi-infinite substrate configuration. Coupled with a physics-constrained inverse strategy, it further enables reliable identification of three unknown thermal properties simultaneously using only external measurements. Overall, this work demonstrates that physics-guided Transformer architectures provide a unified framework for forward and inverse modeling in interface-dominated thermal systems.",Materials Science
"Heat transfer in semiconductor devices is dominated by chip and substrate assemblies, where heat generated within a finite chip layer dissipates into a semi-infinite substrate with much higher thermophysical properties. This mismatch produces steep interfacial temperature gradients, making the transient thermal response highly sensitive to the interface. Conventional numerical solvers require excessive discretization to resolve these dynamics, while physics-informed neural networks (PINNs) often exhibit unstable convergence and loss of physical consistency near the material interface. To address these challenges, we introduce HeatTransFormer, a physics-guided Transformer architecture for interface-dominated diffusion problems. The framework integrates physically informed spatiotemporal sampling, a Laplace-based activation emulating analytical diffusion solutions, and a mask-free attention mechanism supporting bidirectional spatiotemporal coupling. These components enable the model to resolve steep gradients, maintain physical consistency, and remain stable where PINNs typically fail. HeatTransFormer produces coherent temperature fields across the interface when applied to a finite layer and semi-infinite substrate configuration. Coupled with a physics-constrained inverse strategy, it further enables reliable identification of three unknown thermal properties simultaneously using only external measurements. Overall, this work demonstrates that physics-guided Transformer architectures provide a unified framework for forward and inverse modeling in interface-dominated thermal systems. [SEP] [HINT] networks -> Neuroscience (Syns: network, meshwork, electronic network) | work -> Bioinformatics (Syns: work out, process, bring) | framework -> Bioinformatics (Syns: theoretical account, model, fabric)",Materials Science
"In obstructed atomic insulators, fractional charges appear at the corners of the crystals in the shapes of vertex-transitive polyhedra, and are given by the filling anomaly divided by the number of corners. Recent studies reveal that the filling anomaly for the cases with genus $0$ is universally given by the total charge at the Wyckoff position $1a$. In this study, we rewrite the formula in terms of the degree of sharpness of the corner, and show that the corner charge formula also holds for cases with arbitrary genus. We also extend our formula to vertex-transitive shell polyhedra, which are closed or open polyhedra without the bulk region, with all the vertices related by symmetry. Then, we show that the corner charges of such shell polyhedra are equal to the two-dimensional disclination charges of the corresponding disclinations. By identifying it with the disclination charge under the Wen-Zee action, we show that the coupling constant of the Wen-Zee action for a crystalline insulator is given by the total charge at the Wyckoff position at the disclination core.",Materials Science
"In obstructed atomic insulators, fractional charges appear at the corners of the crystals in the shapes of vertex-transitive polyhedra, and are given by the filling anomaly divided by the number of corners. Recent studies reveal that the filling anomaly for the cases with genus $0$ is universally given by the total charge at the Wyckoff position $1a$. In this study, we rewrite the formula in terms of the degree of sharpness of the corner, and show that the corner charge formula also holds for cases with arbitrary genus. We also extend our formula to vertex-transitive shell polyhedra, which are closed or open polyhedra without the bulk region, with all the vertices related by symmetry. Then, we show that the corner charges of such shell polyhedra are equal to the two-dimensional disclination charges of the corresponding disclinations. By identifying it with the disclination charge under the Wen-Zee action, we show that the coupling constant of the Wen-Zee action for a crystalline insulator is given by the total charge at the Wyckoff position at the disclination core. [SEP] [HINT] charge -> Materials Science (Syns: tear, bearing, burster)",Materials Science
"The rapid development of two-dimensional (2D) materials has reshaped modern nanoscience, offering properties that differ fundamentally from their bulk counterparts. As experimental discovery accelerates, the need for reliable computational techniques has become increas- ingly important. Within the framework of density functional theory, this review explores the critical role of exchange-correlation functionals in predicting key material properties such as structural, optoelectronic, magnetic, and thermal. We examine the challenges posed by quantum confinement, anisotropic screening, and van der Waals interactions, which conventional functionals often fail to describe. Advanced approaches, including meta-GGA, hybrid functionals, and many-body perturbation theory (e.g., GW and Bethe-Salpeter equation), are assessed for their improved accuracy in capturing electronic structure and excitonic effects. We further discuss the non-universality of functionals across different 2D material families and the emerging role of machine learning to enhance computational efficiency. Finally, the review outlines current limitations and emerging strategies, providing a roadmap for advancing exchange-correlation functionals and beyond, to enable the practical design and application of 2D materials.",Materials Science
"The rapid development of two-dimensional (2D) materials has reshaped modern nanoscience, offering properties that differ fundamentally from their bulk counterparts. As experimental discovery accelerates, the need for reliable computational techniques has become increas- ingly important. Within the framework of density functional theory, this review explores the critical role of exchange-correlation functionals in predicting key material properties such as structural, optoelectronic, magnetic, and thermal. We examine the challenges posed by quantum confinement, anisotropic screening, and van der Waals interactions, which conventional functionals often fail to describe. Advanced approaches, including meta-GGA, hybrid functionals, and many-body perturbation theory (e.g., GW and Bethe-Salpeter equation), are assessed for their improved accuracy in capturing electronic structure and excitonic effects. We further discuss the non-universality of functionals across different 2D material families and the emerging role of machine learning to enhance computational efficiency. Finally, the review outlines current limitations and emerging strategies, providing a roadmap for advancing exchange-correlation functionals and beyond, to enable the practical design and application of 2D materials. [SEP] [HINT] computational -> Neuroscience (Syns: ) | learning -> Bioinformatics (Syns: take, teach, acquire) | electronic -> Materials Science (Syns: )",Materials Science
"We introduce DeepFHT, a survival-analysis framework that couples deep neural networks with first hitting time (FHT) distributions from stochastic process theory. Time to event is represented as the first passage of a latent diffusion process to an absorbing boundary. A neural network maps input variables to physically meaningful parameters including initial condition, drift, and diffusion, within a chosen FHT process such as Brownian motion, both with drift and driftless. This yields closed- form survival and hazard functions and captures time-varying risk without assuming proportional- hazards. We compare DeepFHT with Cox regression using synthetic and real-world datasets. The method achieves predictive accuracy on par with the state-of-the-art approach, while maintaining a physics- based interpretable parameterization that elucidates the relation between input features and risk. This combination of stochastic process theory and deep learning provides a principled avenue for modeling survival phenomena in complex systems",Bioinformatics
"We introduce DeepFHT, a survival-analysis framework that couples deep neural networks with first hitting time (FHT) distributions from stochastic process theory. Time to event is represented as the first passage of a latent diffusion process to an absorbing boundary. A neural network maps input variables to physically meaningful parameters including initial condition, drift, and diffusion, within a chosen FHT process such as Brownian motion, both with drift and driftless. This yields closed- form survival and hazard functions and captures time-varying risk without assuming proportional- hazards. We compare DeepFHT with Cox regression using synthetic and real-world datasets. The method achieves predictive accuracy on par with the state-of-the-art approach, while maintaining a physics- based interpretable parameterization that elucidates the relation between input features and risk. This combination of stochastic process theory and deep learning provides a principled avenue for modeling survival phenomena in complex systems [SEP] [HINT] based -> Bioinformatics (Syns: ground, free-base, base) | features -> Bioinformatics (Syns: characteristic, lineament, feature of speech) | learning -> Bioinformatics (Syns: take, teach, acquire)",Bioinformatics
"This study presents an unsupervised method to infer discreteness, syntax and temporal structures of fruit-bats vocalizations, as a case study of graded vocal systems, and evaluates the complexity of communication patterns in relation with behavioral context. The method improved the baseline for unsupervised labeling of vocal units (i.e. syllables) through manifold learning, by investigating how dimen- sionality reduction on mel-spectrograms affects labeling, and comparing it with unsupervised labels based on acoustic similarity. We then encoded vocalizations as syllabic sequences to analyze the type of syntax, and extracted the Maximal Repetitions (MRs) to evaluate syntactical structures. We found evidence for: i) associative syntax, rather than combinatorial (context classification is unaffected by permutation of sequences, F 1 > 0.9); ii) context-dependent use of syllables (Wilcoxon rank-sum tests, p-value < 0.05); iii) heavy-tail distribution of MRs (truncated power-law, exponent α < 2), indicative of mechanism encoding com- binatorial complexity. Analysis of MRs and syllabic transition networks revealed that mother-pupil interactions were characterized by repetitions, while commu- nication in conflict-contexts exhibited higher complexity (longer MRs and more interconnected vocal sequences) than non-agonistic contexts. We propose that communicative complexity is higher in scenarios of disagreement, reflecting lower compressibility of information.",Bioinformatics
"This study presents an unsupervised method to infer discreteness, syntax and temporal structures of fruit-bats vocalizations, as a case study of graded vocal systems, and evaluates the complexity of communication patterns in relation with behavioral context. The method improved the baseline for unsupervised labeling of vocal units (i.e. syllables) through manifold learning, by investigating how dimen- sionality reduction on mel-spectrograms affects labeling, and comparing it with unsupervised labels based on acoustic similarity. We then encoded vocalizations as syllabic sequences to analyze the type of syntax, and extracted the Maximal Repetitions (MRs) to evaluate syntactical structures. We found evidence for: i) associative syntax, rather than combinatorial (context classification is unaffected by permutation of sequences, F 1 > 0.9); ii) context-dependent use of syllables (Wilcoxon rank-sum tests, p-value < 0.05); iii) heavy-tail distribution of MRs (truncated power-law, exponent α < 2), indicative of mechanism encoding com- binatorial complexity. Analysis of MRs and syllabic transition networks revealed that mother-pupil interactions were characterized by repetitions, while commu- nication in conflict-contexts exhibited higher complexity (longer MRs and more interconnected vocal sequences) than non-agonistic contexts. We propose that communicative complexity is higher in scenarios of disagreement, reflecting lower compressibility of information. [SEP] [HINT] transition -> Materials Science (Syns: passage, modulation, changeover) | based -> Bioinformatics (Syns: ground, free-base, base) | networks -> Neuroscience (Syns: network, meshwork, electronic network)",Bioinformatics
"Contemporary ML separates the static structure of parameters from the dynamic flow of inference, yielding systems that lack the sample efficiency and thermodynamic frugality of biological cognition. In this theoretical work, we propose \textbf{Memory-Amortized Inference (MAI)}, a formal framework rooted in algebraic topology that unifies learning and memory as phase transitions of a single geometric substrate. Central to our theory is the \textbf{Homological Parity Principle}, which posits a fundamental dichotomy: even-dimensional homology ($H_{even}$) physically instantiates stable \textbf{Content} (stable scaffolds or ``what''), while odd-dimensional homology ($H_{odd}$) instantiates dynamic \textbf{Context} (dynamic flows or ``where''). We derive the logical flow of MAI as a topological trinity transformation: \textbf{Search $\to$ Closure $\to$ Structure}. Specifically, we demonstrate that cognition operates by converting high-complexity recursive search (modeled by \textit{Savitch's Theorem} in NPSPACE) into low-complexity lookup (modeled by \textit{Dynamic Programming} in P) via the mechanism of \textbf{Topological Cycle Closure}. We further show that this consolidation process is governed by a topological generalization of the Wake-Sleep algorithm, functioning as a coordinate descent that alternates between optimizing the $H_{odd}$ flow (inference/wake) and condensing persistent cycles into the $H_{even}$ scaffold (learning/sleep). This framework offers a rigorous explanation for the emergence of fast-thinking (intuition) from slow-thinking (reasoning) and provides a blueprint for post-Turing architectures that compute via topological resonance.",Neuroscience
"Contemporary ML separates the static structure of parameters from the dynamic flow of inference, yielding systems that lack the sample efficiency and thermodynamic frugality of biological cognition. In this theoretical work, we propose \textbf{Memory-Amortized Inference (MAI)}, a formal framework rooted in algebraic topology that unifies learning and memory as phase transitions of a single geometric substrate. Central to our theory is the \textbf{Homological Parity Principle}, which posits a fundamental dichotomy: even-dimensional homology ($H_{even}$) physically instantiates stable \textbf{Content} (stable scaffolds or ``what''), while odd-dimensional homology ($H_{odd}$) instantiates dynamic \textbf{Context} (dynamic flows or ``where''). We derive the logical flow of MAI as a topological trinity transformation: \textbf{Search $\to$ Closure $\to$ Structure}. Specifically, we demonstrate that cognition operates by converting high-complexity recursive search (modeled by \textit{Savitch's Theorem} in NPSPACE) into low-complexity lookup (modeled by \textit{Dynamic Programming} in P) via the mechanism of \textbf{Topological Cycle Closure}. We further show that this consolidation process is governed by a topological generalization of the Wake-Sleep algorithm, functioning as a coordinate descent that alternates between optimizing the $H_{odd}$ flow (inference/wake) and condensing persistent cycles into the $H_{even}$ scaffold (learning/sleep). This framework offers a rigorous explanation for the emergence of fast-thinking (intuition) from slow-thinking (reasoning) and provides a blueprint for post-Turing architectures that compute via topological resonance. [SEP] [HINT] learning -> Bioinformatics (Syns: take, teach, acquire) | structure -> Bioinformatics (Syns: social system, complex body part, social structure) | systems -> Bioinformatics (Syns: organization, organisation, system)",Neuroscience
"High-dimensional neural activity often reside in a low-dimensional subspace, referred to as neural manifolds. Grid cells in the medial entorhinal cortex provide a periodic spatial code that are organized near a toroidal manifold, independent of the spatial environment. Due to the periodic nature of its code, it is unclear how the brain utilizes the toroidal manifold to understand its state in a spatial environment. We introduce a novel framework that decodes spatial information from grid cell activity using topology. Our approach uses topological data analysis to extract toroidal coordinates from grid cell population activity and employs path-lifting to reconstruct trajectories in physical space. The reconstructed paths differ from the original by an affine transformation. We validated the method on both continuous attractor network simulations and experimental recordings of grid cells, demonstrating that local trajectories can be reliably reconstructed from a single grid cell module without external position information or training data. These results suggest that co-modular grid cells contain sufficient information for path integration and suggest a potential computational mechanism for spatial navigation.",Neuroscience
"High-dimensional neural activity often reside in a low-dimensional subspace, referred to as neural manifolds. Grid cells in the medial entorhinal cortex provide a periodic spatial code that are organized near a toroidal manifold, independent of the spatial environment. Due to the periodic nature of its code, it is unclear how the brain utilizes the toroidal manifold to understand its state in a spatial environment. We introduce a novel framework that decodes spatial information from grid cell activity using topology. Our approach uses topological data analysis to extract toroidal coordinates from grid cell population activity and employs path-lifting to reconstruct trajectories in physical space. The reconstructed paths differ from the original by an affine transformation. We validated the method on both continuous attractor network simulations and experimental recordings of grid cells, demonstrating that local trajectories can be reliably reconstructed from a single grid cell module without external position information or training data. These results suggest that co-modular grid cells contain sufficient information for path integration and suggest a potential computational mechanism for spatial navigation. [SEP] [HINT] computational -> Neuroscience (Syns: ) | information -> Bioinformatics (Syns: entropy, data, info) | results -> Bioinformatics (Syns: final result, consequence, resultant role)",Neuroscience
"The role of additives such as FEC in extending the calendar life of silicon anodes beyond the cycling benefits is still not fully understood. Herein, the calendar life of high-loading Si (80 wt%) using baseline 1.2 M LiPF6 in EC-EMC electrolyte versus adding 10 wt% FEC is investigated over months. Over 8 days of aging, FEC leads to a 13-fold reduction in irreversible capacity loss in Si-LiFePO4 full cells. Cells without FEC are projected to fall below 80% of their initial capacity within approx. 22 days versus approx. 279 days with FEC. Symmetric Si-Si cells from harvested electrodes show greater increase in interphase resistance without FEC, whereby an increase of 10.81 Ohms is measured for 0 wt% FEC vs. only 3.37 Ohms for 10 wt% FEC over 2 months. Power law modeling of this long-term interphase resistance finds mixed transport-reaction growth behavior in FEC-free cells, suggesting significant dissolution, whereas cells with 10 wt% FEC added display a diffusion-controlled impedance growth behavior, suggesting a robust surface passivation film. Post-mortem FTIR and XPS confirm polycarbonate enrichment of the SEI, which was discovered to predominantly emerge from FEC self-polymerization during the idle aging. When the Si electrodes aged with and without FEC are harvested and reassembled into full cells with the same electrolytes used at aging, the first-cycle coulombic efficiency is 71% for 0 wt% FEC versus 97% for 10 wt% FEC. Subsequent cycling maintains over 99.7% CE with 10 wt% FEC, surpassing the pre-aging CE of 98.8%. This elevated CE indicates better passivation provided by the polymer fragments formed during aging compared to electrochemically formed SEI where no strong polymer FTIR signal is found. The self-polymerization during idle aging with additives such as FEC is therefore an opportune in situ mechanism to further engineer in extending the life of Si-based batteries.",Materials Science
"The role of additives such as FEC in extending the calendar life of silicon anodes beyond the cycling benefits is still not fully understood. Herein, the calendar life of high-loading Si (80 wt%) using baseline 1.2 M LiPF6 in EC-EMC electrolyte versus adding 10 wt% FEC is investigated over months. Over 8 days of aging, FEC leads to a 13-fold reduction in irreversible capacity loss in Si-LiFePO4 full cells. Cells without FEC are projected to fall below 80% of their initial capacity within approx. 22 days versus approx. 279 days with FEC. Symmetric Si-Si cells from harvested electrodes show greater increase in interphase resistance without FEC, whereby an increase of 10.81 Ohms is measured for 0 wt% FEC vs. only 3.37 Ohms for 10 wt% FEC over 2 months. Power law modeling of this long-term interphase resistance finds mixed transport-reaction growth behavior in FEC-free cells, suggesting significant dissolution, whereas cells with 10 wt% FEC added display a diffusion-controlled impedance growth behavior, suggesting a robust surface passivation film. Post-mortem FTIR and XPS confirm polycarbonate enrichment of the SEI, which was discovered to predominantly emerge from FEC self-polymerization during the idle aging. When the Si electrodes aged with and without FEC are harvested and reassembled into full cells with the same electrolytes used at aging, the first-cycle coulombic efficiency is 71% for 0 wt% FEC versus 97% for 10 wt% FEC. Subsequent cycling maintains over 99.7% CE with 10 wt% FEC, surpassing the pre-aging CE of 98.8%. This elevated CE indicates better passivation provided by the polymer fragments formed during aging compared to electrochemically formed SEI where no strong polymer FTIR signal is found. The self-polymerization during idle aging with additives such as FEC is therefore an opportune in situ mechanism to further engineer in extending the life of Si-based batteries. [SEP] [HINT] used -> Bioinformatics (Syns: utilize, ill-used, apply) | using -> Bioinformatics (Syns: utilize, exploitation, apply) | si -> Materials Science (Syns: te, Systeme International d'Unites, Systeme International)",Materials Science
"We develop a first-principles many-body framework to describe the dynamics of photocarriers and phonons in semiconductors following ultrafast excitation. Our approach incorporates explicit ab initio light-matter coupling and first-principles collision integrals for carrier-carrier, carrier-phonon, and phonon-phonon scattering. It also yields time-dependent quasiparticle and phonon frequency renormalizations, along with light-induced coherent atomic motion. The equations of motion are solved in a maximally localized Wannier basis, ensuring gauge-consistent scattering integrals and ultradense momentum sampling, thereby enabling direct comparison with pump-probe experiments. The method can be coupled to constrained density-functional theory to access light-induced structural phase transitions at longer times after the light pulse. We showcase the capabilities and predictive power of this framework on MoS$_2$ and h-BN monolayers. For MoS$_2$, we resolve photoinduced renormalizations of electronic and lattice properties, ultrafast carrier relaxation, hot-phonon dynamics, and displacive coherent atomic motion. Including carrier-carrier scattering is crucial to obtain realistic photocarrier equilibration times, while omitting phonon-phonon scattering leads to incorrect long-time lattice thermalization and a factor of two larger A$_{1g}$ coherent phonon damping time. For h-BN, we quantify photoinduced changes in the electronic, optical, and lattice responses in quasi-equilibrium, demonstrating a fluence-dependent enhancement of screening and melting of excitonic features.",Materials Science
"We develop a first-principles many-body framework to describe the dynamics of photocarriers and phonons in semiconductors following ultrafast excitation. Our approach incorporates explicit ab initio light-matter coupling and first-principles collision integrals for carrier-carrier, carrier-phonon, and phonon-phonon scattering. It also yields time-dependent quasiparticle and phonon frequency renormalizations, along with light-induced coherent atomic motion. The equations of motion are solved in a maximally localized Wannier basis, ensuring gauge-consistent scattering integrals and ultradense momentum sampling, thereby enabling direct comparison with pump-probe experiments. The method can be coupled to constrained density-functional theory to access light-induced structural phase transitions at longer times after the light pulse. We showcase the capabilities and predictive power of this framework on MoS$_2$ and h-BN monolayers. For MoS$_2$, we resolve photoinduced renormalizations of electronic and lattice properties, ultrafast carrier relaxation, hot-phonon dynamics, and displacive coherent atomic motion. Including carrier-carrier scattering is crucial to obtain realistic photocarrier equilibration times, while omitting phonon-phonon scattering leads to incorrect long-time lattice thermalization and a factor of two larger A$_{1g}$ coherent phonon damping time. For h-BN, we quantify photoinduced changes in the electronic, optical, and lattice responses in quasi-equilibrium, demonstrating a fluence-dependent enhancement of screening and melting of excitonic features. [SEP] [HINT] phonon -> Materials Science (Syns: ) | electronic -> Materials Science (Syns: ) | including -> Bioinformatics (Syns: admit, include, let in)",Materials Science
"Altermagnets are characterized by anisotropic band/spin splittings in momentum space, dictated by their spin-space group symmetries. However, the real-space modulations of altermagnetism are often neglected and have not been explored experimentally. Here we combine neutron diffraction, angle-resolved photoemission spectroscopy (ARPES), spin-resolved ARPES and density functional theory to demonstrate that Cs$_{1-δ}$V$_2$Te$_2$O realizes a spatially modulated form of altermagnetism, i.e., hidden altermagnetism. Such a state in Cs$_{1-δ}$V$_2$Te$_2$O results from its G-type antiferromagnetism and two-dimensional electronic states, allowing for the development of spatially alternating altermagnetic layers, whose local spin polarizations are directly verified by spin-resolved ARPES measurements. Our experimental discovery of hidden altermagnetism broadens the scope of unconventional magnetism and opens routes to exploring emergent phenomena from real-space modulations of altermagnetic order.",Materials Science
"Altermagnets are characterized by anisotropic band/spin splittings in momentum space, dictated by their spin-space group symmetries. However, the real-space modulations of altermagnetism are often neglected and have not been explored experimentally. Here we combine neutron diffraction, angle-resolved photoemission spectroscopy (ARPES), spin-resolved ARPES and density functional theory to demonstrate that Cs$_{1-δ}$V$_2$Te$_2$O realizes a spatially modulated form of altermagnetism, i.e., hidden altermagnetism. Such a state in Cs$_{1-δ}$V$_2$Te$_2$O results from its G-type antiferromagnetism and two-dimensional electronic states, allowing for the development of spatially alternating altermagnetic layers, whose local spin polarizations are directly verified by spin-resolved ARPES measurements. Our experimental discovery of hidden altermagnetism broadens the scope of unconventional magnetism and opens routes to exploring emergent phenomena from real-space modulations of altermagnetic order. [SEP] [HINT] spin -> Materials Science (Syns: twisting, whirl, tailspin) | electronic -> Materials Science (Syns: ) | functional -> Neuroscience (Syns: working, usable, running)",Materials Science
"Neurodegeneration, characterized by the progressive loss of neuronal structure or function, is commonly assessed in clinical practice through reductions in cortical thickness or brain volume, as visualized by structural MRI. While informative, these conventional approaches lack the statistical sophistication required to fully capture the spatially correlated and heterogeneous nature of neurodegeneration, which manifests both in healthy aging and in neurological disorders. To address these limitations, brain age gap has emerged as a promising data-driven biomarker of brain health. The brain age gap prediction (BAGP) models estimate the difference between a person's predicted brain age from neuroimaging data and their chronological age. The resulting brain age gap serves as a compact biomarker of brain health, with recent studies demonstrating its predictive utility for disease progression and severity. However, practical adoption of BAGP models is hindered by their methodological obscurities and limited generalizability across diverse clinical populations. This tutorial article provides an overview of BAGP and introduces a principled framework for this application based on recent advancements in graph signal processing (GSP). In particular, we focus on graph neural networks (GNNs) and introduce the coVariance neural network (VNN), which leverages the anatomical covariance matrices derived from structural MRI. VNNs offer strong theoretical grounding and operational interpretability, enabling robust estimation of brain age gap predictions. By integrating perspectives from GSP, machine learning, and network neuroscience, this work clarifies the path forward for reliable and interpretable BAGP models and outlines future research directions in personalized medicine.",Bioinformatics
"Neurodegeneration, characterized by the progressive loss of neuronal structure or function, is commonly assessed in clinical practice through reductions in cortical thickness or brain volume, as visualized by structural MRI. While informative, these conventional approaches lack the statistical sophistication required to fully capture the spatially correlated and heterogeneous nature of neurodegeneration, which manifests both in healthy aging and in neurological disorders. To address these limitations, brain age gap has emerged as a promising data-driven biomarker of brain health. The brain age gap prediction (BAGP) models estimate the difference between a person's predicted brain age from neuroimaging data and their chronological age. The resulting brain age gap serves as a compact biomarker of brain health, with recent studies demonstrating its predictive utility for disease progression and severity. However, practical adoption of BAGP models is hindered by their methodological obscurities and limited generalizability across diverse clinical populations. This tutorial article provides an overview of BAGP and introduces a principled framework for this application based on recent advancements in graph signal processing (GSP). In particular, we focus on graph neural networks (GNNs) and introduce the coVariance neural network (VNN), which leverages the anatomical covariance matrices derived from structural MRI. VNNs offer strong theoretical grounding and operational interpretability, enabling robust estimation of brain age gap predictions. By integrating perspectives from GSP, machine learning, and network neuroscience, this work clarifies the path forward for reliable and interpretable BAGP models and outlines future research directions in personalized medicine. [SEP] [HINT] based -> Bioinformatics (Syns: ground, free-base, base) | clinical -> Bioinformatics (Syns: ) | cortical -> Neuroscience (Syns: )",Bioinformatics
"This thesis delves into the world of non-invasive electrophysiological brain signals like electroencephalography (EEG) and magnetoencephalography (MEG), focusing on modelling and decoding such data. The research aims to investigate what happens in the brain when we perceive visual stimuli or engage in covert speech (inner speech) and enhance the decoding performance of such stimuli. The thesis is divided into two main sections, methodological and experimental work. A central concern in both sections is the large variability present in electrophysiological recordings, whether it be within-subject or between-subject variability, and to a certain extent between-dataset variability. In the methodological sections, we explore the potential of deep learning for brain decoding. We present advancements in decoding visual stimuli using linear models at the individual subject level. We then explore how deep learning techniques can be employed for group decoding, introducing new methods to deal with between-subject variability. Finally, we also explores novel forecasting models of MEG data based on convolutional and Transformer-based architectures. In particular, Transformer-based models demonstrate superior capabilities in generating signals that closely match real brain data, thereby enhancing the accuracy and reliability of modelling the brain's electrophysiology. In the experimental section, we present a unique dataset containing high-trial inner speech EEG, MEG, and preliminary optically pumped magnetometer (OPM) data. Our aim is to investigate different types of inner speech and push decoding performance by collecting a high number of trials and sessions from a few participants. However, the decoding results are found to be mostly negative, underscoring the difficulty of decoding inner speech.",Neuroscience
"This thesis delves into the world of non-invasive electrophysiological brain signals like electroencephalography (EEG) and magnetoencephalography (MEG), focusing on modelling and decoding such data. The research aims to investigate what happens in the brain when we perceive visual stimuli or engage in covert speech (inner speech) and enhance the decoding performance of such stimuli. The thesis is divided into two main sections, methodological and experimental work. A central concern in both sections is the large variability present in electrophysiological recordings, whether it be within-subject or between-subject variability, and to a certain extent between-dataset variability. In the methodological sections, we explore the potential of deep learning for brain decoding. We present advancements in decoding visual stimuli using linear models at the individual subject level. We then explore how deep learning techniques can be employed for group decoding, introducing new methods to deal with between-subject variability. Finally, we also explores novel forecasting models of MEG data based on convolutional and Transformer-based architectures. In particular, Transformer-based models demonstrate superior capabilities in generating signals that closely match real brain data, thereby enhancing the accuracy and reliability of modelling the brain's electrophysiology. In the experimental section, we present a unique dataset containing high-trial inner speech EEG, MEG, and preliminary optically pumped magnetometer (OPM) data. Our aim is to investigate different types of inner speech and push decoding performance by collecting a high number of trials and sessions from a few participants. However, the decoding results are found to be mostly negative, underscoring the difficulty of decoding inner speech. [SEP] [HINT] decoding -> Neuroscience (Syns: decrypt, decipherment, decryption) | based -> Bioinformatics (Syns: ground, free-base, base) | learning -> Bioinformatics (Syns: take, teach, acquire)",Neuroscience
"Moiré superlattices in two-dimensional materials provide a versatile platform to explore strongly correlated and topological phases. This work presents a practical theoretical workflow for studying the correlated and topological states in moiré systems, combining continuum modeling, Hartree-Fock mean-field approximations, many-body perturbation theory, and exact diagonalizations. We focus on the numerical implementation of these methods, emphasizing subtleties such as remote band effects, inhomogeneous and dynamical screening, double counting problem, etc., which are often swept under the rug in theoretical works. The workflow enables a systematic investigation of symmetry-breaking ground state properties, quasiparticle excitation properties and fractional Chern insulator phases emerging from moiré superlattices, providing insights that are directly relevant to experimental observations. By bridging technical details and physical interpretations, this work aims to guide both theorists and experimentalists in understanding and predicting correlated phenomena in moiré materials.",Materials Science
"Moiré superlattices in two-dimensional materials provide a versatile platform to explore strongly correlated and topological phases. This work presents a practical theoretical workflow for studying the correlated and topological states in moiré systems, combining continuum modeling, Hartree-Fock mean-field approximations, many-body perturbation theory, and exact diagonalizations. We focus on the numerical implementation of these methods, emphasizing subtleties such as remote band effects, inhomogeneous and dynamical screening, double counting problem, etc., which are often swept under the rug in theoretical works. The workflow enables a systematic investigation of symmetry-breaking ground state properties, quasiparticle excitation properties and fractional Chern insulator phases emerging from moiré superlattices, providing insights that are directly relevant to experimental observations. By bridging technical details and physical interpretations, this work aims to guide both theorists and experimentalists in understanding and predicting correlated phenomena in moiré materials. [SEP] [HINT] understanding -> Neuroscience (Syns: savvy, intellect, sympathy) | work -> Bioinformatics (Syns: work out, process, bring) | band -> Materials Science (Syns: set, stria, dance orchestra)",Materials Science
"The combination of semiconducting properties and synthetically tunable chirality in chiral metal halide semiconductors (CMHS) offer a compelling platform for room temperature control over electronic spin properties, leveraging effects such as chirality-induced spin selectivity (CISS) for the development of new opto-spintronic functionalities. We report room-temperature CISS-induced magnetoresistance (CISS-MR) exceeding 100% for spin valves in a configuration consisting of a ferromagnet (FM), tunneling barrier, and CMHS. The high CISS-MR is attributed to interfacial spin-selective tunneling barrier induced by the chirality, which can produce current dissymmetry factors that surpass the limit imposed by the Jullière model governed by the intrinsic spin polarization of the adjacent FM contact. The CISS-MR exhibits a strong dependence on the CMHS composition, revealing a structure-property relationship between CISS and structural chirality. The observed exceptionally large tunneling MR response differentiates from a subtle anisotropic MR arising from the proximity effect at the FM/CMHS interface in the absence of a tunneling barrier. Our study provides insights into charge-to-spin interconversion in chiral semiconductors, offering materials design principles to control and enhance CISS response and utilize it in functional platforms.",Materials Science
"The combination of semiconducting properties and synthetically tunable chirality in chiral metal halide semiconductors (CMHS) offer a compelling platform for room temperature control over electronic spin properties, leveraging effects such as chirality-induced spin selectivity (CISS) for the development of new opto-spintronic functionalities. We report room-temperature CISS-induced magnetoresistance (CISS-MR) exceeding 100% for spin valves in a configuration consisting of a ferromagnet (FM), tunneling barrier, and CMHS. The high CISS-MR is attributed to interfacial spin-selective tunneling barrier induced by the chirality, which can produce current dissymmetry factors that surpass the limit imposed by the Jullière model governed by the intrinsic spin polarization of the adjacent FM contact. The CISS-MR exhibits a strong dependence on the CMHS composition, revealing a structure-property relationship between CISS and structural chirality. The observed exceptionally large tunneling MR response differentiates from a subtle anisotropic MR arising from the proximity effect at the FM/CMHS interface in the absence of a tunneling barrier. Our study provides insights into charge-to-spin interconversion in chiral semiconductors, offering materials design principles to control and enhance CISS response and utilize it in functional platforms. [SEP] [HINT] spin -> Materials Science (Syns: twisting, whirl, tailspin) | electronic -> Materials Science (Syns: ) | functional -> Neuroscience (Syns: working, usable, running)",Materials Science
"Predictive coding is a framework for understanding the formation of low-dimensional internal representations mirroring the environment's latent structure. The conditions under which such representations emerge remain unclear. In this work, we investigate how the prediction horizon and network depth shape the solutions of predictive coding tasks. Using a minimal abstract setting inspired by prior work, we show empirically and theoretically that sufficiently deep networks trained with multi-step prediction horizons consistently recover the underlying latent structure, a phenomenon explained through the Ordinary Least Squares estimator structure and biases in learning dynamics. We then extend these insights to nonlinear networks and complex datasets, including piecewise linear functions, MNIST, multiple latent states and higher dimensional state geometries. Our results provide a principled understanding of when and why predictive coding induces structured representations, bridging the gap between empirical observations and theoretical foundations.",Neuroscience
"Predictive coding is a framework for understanding the formation of low-dimensional internal representations mirroring the environment's latent structure. The conditions under which such representations emerge remain unclear. In this work, we investigate how the prediction horizon and network depth shape the solutions of predictive coding tasks. Using a minimal abstract setting inspired by prior work, we show empirically and theoretically that sufficiently deep networks trained with multi-step prediction horizons consistently recover the underlying latent structure, a phenomenon explained through the Ordinary Least Squares estimator structure and biases in learning dynamics. We then extend these insights to nonlinear networks and complex datasets, including piecewise linear functions, MNIST, multiple latent states and higher dimensional state geometries. Our results provide a principled understanding of when and why predictive coding induces structured representations, bridging the gap between empirical observations and theoretical foundations. [SEP] [HINT] understanding -> Neuroscience (Syns: savvy, intellect, sympathy) | learning -> Bioinformatics (Syns: take, teach, acquire) | networks -> Neuroscience (Syns: network, meshwork, electronic network)",Neuroscience
"Despite remarkable technological advances, AI systems may still benefit from biological principles, such as recurrent connectivity and energy-efficient mechanisms. Drawing inspiration from the brain, we present a biologically plausible extension of the eligibility propagation (e-prop) learning rule for recurrent spiking networks. By translating the time-driven update scheme into an event-driven one, we integrate the learning rule into a simulation platform for large-scale spiking neural networks and demonstrate its applicability to tasks such as neuromorphic MNIST. We extend the model with prominent biological features such as continuous dynamics and weight updates, strict locality, and sparse connectivity. Our results show that biologically grounded constraints can inform the design of computationally efficient AI algorithms, offering scalability to millions of neurons without compromising learning performance. This work bridges machine learning and computational neuroscience, paving the way for sustainable, biologically inspired AI systems while advancing our understanding of brain-like learning.",Neuroscience
"Despite remarkable technological advances, AI systems may still benefit from biological principles, such as recurrent connectivity and energy-efficient mechanisms. Drawing inspiration from the brain, we present a biologically plausible extension of the eligibility propagation (e-prop) learning rule for recurrent spiking networks. By translating the time-driven update scheme into an event-driven one, we integrate the learning rule into a simulation platform for large-scale spiking neural networks and demonstrate its applicability to tasks such as neuromorphic MNIST. We extend the model with prominent biological features such as continuous dynamics and weight updates, strict locality, and sparse connectivity. Our results show that biologically grounded constraints can inform the design of computationally efficient AI algorithms, offering scalability to millions of neurons without compromising learning performance. This work bridges machine learning and computational neuroscience, paving the way for sustainable, biologically inspired AI systems while advancing our understanding of brain-like learning. [SEP] [HINT] connectivity -> Neuroscience (Syns: ) | tasks -> Neuroscience (Syns: tax, task, project) | computational -> Neuroscience (Syns: )",Neuroscience
"The State of Brain Emulation Report 2025 provides a comprehensive reassessment of the field's progress since Sandberg and Bostrom's 2008 Whole Brain Emulation roadmap. The report is organized around three core capabilities required for brain emulation: recording brain function (Neural Dynamics), mapping brain structure (Connectomics), and emulation and embodiment (Computational Neuroscience). It also identifies ongoing challenges and outlines strategic priorities to help the field move forward.",Neuroscience
"The State of Brain Emulation Report 2025 provides a comprehensive reassessment of the field's progress since Sandberg and Bostrom's 2008 Whole Brain Emulation roadmap. The report is organized around three core capabilities required for brain emulation: recording brain function (Neural Dynamics), mapping brain structure (Connectomics), and emulation and embodiment (Computational Neuroscience). It also identifies ongoing challenges and outlines strategic priorities to help the field move forward. [SEP] [HINT] field -> Materials Science (Syns: field of honor, line of business, orbit) | brain -> Neuroscience (Syns: learning ability, mentality, brainiac) | state -> Bioinformatics (Syns: posit, put forward, express)",Neuroscience
"Machine learning models of vastly different modalities and architectures are being trained to predict the behavior of molecules, materials, and proteins. However, it remains unclear whether they learn similar internal representations of matter. Understanding their latent structure is essential for building scientific foundation models that generalize reliably beyond their training domains. Although representational convergence has been observed in language and vision, its counterpart in the sciences has not been systematically explored. Here, we show that representations learned by nearly sixty scientific models, spanning string-, graph-, 3D atomistic, and protein-based modalities, are highly aligned across a wide range of chemical systems. Models trained on different datasets have highly similar representations of small molecules, and machine learning interatomic potentials converge in representation space as they improve in performance, suggesting that foundation models learn a common underlying representation of physical reality. We then show two distinct regimes of scientific models: on inputs similar to those seen during training, high-performing models align closely and weak models diverge into local sub-optima in representation space; on vastly different structures from those seen during training, nearly all models collapse onto a low-information representation, indicating that today's models remain limited by training data and inductive bias and do not yet encode truly universal structure. Our findings establish representational alignment as a quantitative benchmark for foundation-level generality in scientific models. More broadly, our work can track the emergence of universal representations of matter as models scale, and for selecting and distilling models whose learned representations transfer best across modalities, domains of matter, and scientific tasks.",Materials Science
"Machine learning models of vastly different modalities and architectures are being trained to predict the behavior of molecules, materials, and proteins. However, it remains unclear whether they learn similar internal representations of matter. Understanding their latent structure is essential for building scientific foundation models that generalize reliably beyond their training domains. Although representational convergence has been observed in language and vision, its counterpart in the sciences has not been systematically explored. Here, we show that representations learned by nearly sixty scientific models, spanning string-, graph-, 3D atomistic, and protein-based modalities, are highly aligned across a wide range of chemical systems. Models trained on different datasets have highly similar representations of small molecules, and machine learning interatomic potentials converge in representation space as they improve in performance, suggesting that foundation models learn a common underlying representation of physical reality. We then show two distinct regimes of scientific models: on inputs similar to those seen during training, high-performing models align closely and weak models diverge into local sub-optima in representation space; on vastly different structures from those seen during training, nearly all models collapse onto a low-information representation, indicating that today's models remain limited by training data and inductive bias and do not yet encode truly universal structure. Our findings establish representational alignment as a quantitative benchmark for foundation-level generality in scientific models. More broadly, our work can track the emergence of universal representations of matter as models scale, and for selecting and distilling models whose learned representations transfer best across modalities, domains of matter, and scientific tasks. [SEP] [HINT] language -> Neuroscience (Syns: linguistic process, linguistic communication, spoken communication) | understanding -> Neuroscience (Syns: savvy, intellect, sympathy) | learning -> Bioinformatics (Syns: take, teach, acquire)",Materials Science
"Sparse autoencoders (SAEs) are a mechanistic interpretability technique that have been used to provide insight into learned concepts within large protein language models. Here, we employ TopK and Ordered SAEs to investigate an autoregressive antibody language model, p-IgGen, and steer its generation. We show that TopK SAEs can reveal biologically meaningful latent features, but high feature concept correlation does not guarantee causal control over generation. In contrast, Ordered SAEs impose an hierarchical structure that reliably identifies steerable features, but at the expense of more complex and less interpretable activation patterns. These findings advance the mechanistic interpretability of domain-specific protein language models and suggest that, while TopK SAEs are sufficient for mapping latent features to concepts, Ordered SAEs are preferable when precise generative steering is required.",Bioinformatics
"Sparse autoencoders (SAEs) are a mechanistic interpretability technique that have been used to provide insight into learned concepts within large protein language models. Here, we employ TopK and Ordered SAEs to investigate an autoregressive antibody language model, p-IgGen, and steer its generation. We show that TopK SAEs can reveal biologically meaningful latent features, but high feature concept correlation does not guarantee causal control over generation. In contrast, Ordered SAEs impose an hierarchical structure that reliably identifies steerable features, but at the expense of more complex and less interpretable activation patterns. These findings advance the mechanistic interpretability of domain-specific protein language models and suggest that, while TopK SAEs are sufficient for mapping latent features to concepts, Ordered SAEs are preferable when precise generative steering is required. [SEP] [HINT] used -> Bioinformatics (Syns: utilize, ill-used, apply) | language -> Neuroscience (Syns: linguistic process, linguistic communication, spoken communication) | features -> Bioinformatics (Syns: characteristic, lineament, feature of speech)",Bioinformatics
"Accurately predicting experimentally-realizable 3D molecular crystal structures from their 2D chemical graphs is a long-standing open challenge in computational chemistry called crystal structure prediction (CSP). Efficiently solving this problem has implications ranging from pharmaceuticals to organic semiconductors, as crystal packing directly governs the physical and chemical properties of organic solids. In this paper, we introduce OXtal, a large-scale 100M parameter all-atom diffusion model that directly learns the conditional joint distribution over intramolecular conformations and periodic packing. To efficiently scale OXtal, we abandon explicit equivariant architectures imposing inductive bias arising from crystal symmetries in favor of data augmentation strategies. We further propose a novel crystallization-inspired lattice-free training scheme, Stoichiometric Stochastic Shell Sampling ($S^4$), that efficiently captures long-range interactions while sidestepping explicit lattice parametrization -- thus enabling more scalable architectural choices at all-atom resolution. By leveraging a large dataset of 600K experimentally validated crystal structures (including rigid and flexible molecules, co-crystals, and solvates), OXtal achieves orders-of-magnitude improvements over prior ab initio machine learning CSP methods, while remaining orders of magnitude cheaper than traditional quantum-chemical approaches. Specifically, OXtal recovers experimental structures with conformer $\text{RMSD}_1<0.5$ Å and attains over 80\% packing similarity rate, demonstrating its ability to model both thermodynamic and kinetic regularities of molecular crystallization.",Materials Science
"Accurately predicting experimentally-realizable 3D molecular crystal structures from their 2D chemical graphs is a long-standing open challenge in computational chemistry called crystal structure prediction (CSP). Efficiently solving this problem has implications ranging from pharmaceuticals to organic semiconductors, as crystal packing directly governs the physical and chemical properties of organic solids. In this paper, we introduce OXtal, a large-scale 100M parameter all-atom diffusion model that directly learns the conditional joint distribution over intramolecular conformations and periodic packing. To efficiently scale OXtal, we abandon explicit equivariant architectures imposing inductive bias arising from crystal symmetries in favor of data augmentation strategies. We further propose a novel crystallization-inspired lattice-free training scheme, Stoichiometric Stochastic Shell Sampling ($S^4$), that efficiently captures long-range interactions while sidestepping explicit lattice parametrization -- thus enabling more scalable architectural choices at all-atom resolution. By leveraging a large dataset of 600K experimentally validated crystal structures (including rigid and flexible molecules, co-crystals, and solvates), OXtal achieves orders-of-magnitude improvements over prior ab initio machine learning CSP methods, while remaining orders of magnitude cheaper than traditional quantum-chemical approaches. Specifically, OXtal recovers experimental structures with conformer $\text{RMSD}_1<0.5$ Å and attains over 80\% packing similarity rate, demonstrating its ability to model both thermodynamic and kinetic regularities of molecular crystallization. [SEP] [HINT] computational -> Neuroscience (Syns: ) | learning -> Bioinformatics (Syns: take, teach, acquire) | structure -> Bioinformatics (Syns: social system, complex body part, social structure)",Materials Science
"The majority of research in both training Artificial Neural Networks (ANNs) and modeling learning in biological brains focuses on synaptic plasticity, where learning equates to changing the strength of existing connections. However, in biological brains, structural plasticity - where new connections are created and others removed - is also vital, not only for effective learning but also for recovery from damage and optimal resource usage. Inspired by structural plasticity, pruning is often used in machine learning to remove weak connections from trained models to reduce the computational requirements of inference. However, the machine learning frameworks typically used for backpropagation-based training of both ANNs and Spiking Neural Networks (SNNs) are optimized for dense connectivity, meaning that pruning does not help reduce the training costs of ever-larger models. The GeNN simulator already supports efficient GPU-accelerated simulation of sparse SNNs for computational neuroscience and machine learning. Here, we present a new flexible framework for implementing GPU-accelerated structural plasticity rules and demonstrate this first using the e-prop supervised learning rule and DEEP R to train efficient, sparse SNN classifiers and then, in an unsupervised learning context, to learn topographic maps. Compared to baseline dense models, our sparse classifiers reduce training time by up to 10x while the DEEP R rewiring enables them to perform as well as the original models. We demonstrate topographic map formation in faster-than-realtime simulations, provide insights into the connectivity evolution, and measure simulation speed versus network size. The proposed framework will enable further research into achieving and maintaining sparsity in network structure and neural communication, as well as exploring the computational benefits of sparsity in a range of neuromorphic applications.",Neuroscience
"The majority of research in both training Artificial Neural Networks (ANNs) and modeling learning in biological brains focuses on synaptic plasticity, where learning equates to changing the strength of existing connections. However, in biological brains, structural plasticity - where new connections are created and others removed - is also vital, not only for effective learning but also for recovery from damage and optimal resource usage. Inspired by structural plasticity, pruning is often used in machine learning to remove weak connections from trained models to reduce the computational requirements of inference. However, the machine learning frameworks typically used for backpropagation-based training of both ANNs and Spiking Neural Networks (SNNs) are optimized for dense connectivity, meaning that pruning does not help reduce the training costs of ever-larger models. The GeNN simulator already supports efficient GPU-accelerated simulation of sparse SNNs for computational neuroscience and machine learning. Here, we present a new flexible framework for implementing GPU-accelerated structural plasticity rules and demonstrate this first using the e-prop supervised learning rule and DEEP R to train efficient, sparse SNN classifiers and then, in an unsupervised learning context, to learn topographic maps. Compared to baseline dense models, our sparse classifiers reduce training time by up to 10x while the DEEP R rewiring enables them to perform as well as the original models. We demonstrate topographic map formation in faster-than-realtime simulations, provide insights into the connectivity evolution, and measure simulation speed versus network size. The proposed framework will enable further research into achieving and maintaining sparsity in network structure and neural communication, as well as exploring the computational benefits of sparsity in a range of neuromorphic applications. [SEP] [HINT] used -> Bioinformatics (Syns: utilize, ill-used, apply) | connectivity -> Neuroscience (Syns: ) | computational -> Neuroscience (Syns: )",Neuroscience
"Hidden hearing loss, or cochlear neural degeneration (CND), disrupts suprathreshold auditory coding without affecting clinical thresholds, making it difficult to diagnose. We present an information-theoretic framework to evaluate speech stimuli that maximally reveal CND by quantifying mutual information (MI) loss between inner hair cell (IHC) receptor potentials and auditory nerve fiber (ANF) responses and acoustic input and ANF responses. Using a phenomenological auditory model, we simulated responses to 50 CVC words under clean, time-compressed, reverberant, and combined conditions across different presentation levels, with systematically varied survival of low-, medium-, and high-spontaneous-rate fibers. MI was computed channel-wise between IHC and ANF responses and integrated across characteristic frequencies. Information loss was defined relative to a normal-hearing baseline. Results demonstrate progressive MI loss with increasing CND, most pronounced for time-compressed speech, while reverberation produced comparatively smaller effects. These findings identify rapid, temporally dense speech as optimal probes for CND, informing the design of objective clinical diagnostics while revealing problems associated with reverberation as a probe.",Neuroscience
"Hidden hearing loss, or cochlear neural degeneration (CND), disrupts suprathreshold auditory coding without affecting clinical thresholds, making it difficult to diagnose. We present an information-theoretic framework to evaluate speech stimuli that maximally reveal CND by quantifying mutual information (MI) loss between inner hair cell (IHC) receptor potentials and auditory nerve fiber (ANF) responses and acoustic input and ANF responses. Using a phenomenological auditory model, we simulated responses to 50 CVC words under clean, time-compressed, reverberant, and combined conditions across different presentation levels, with systematically varied survival of low-, medium-, and high-spontaneous-rate fibers. MI was computed channel-wise between IHC and ANF responses and integrated across characteristic frequencies. Information loss was defined relative to a normal-hearing baseline. Results demonstrate progressive MI loss with increasing CND, most pronounced for time-compressed speech, while reverberation produced comparatively smaller effects. These findings identify rapid, temporally dense speech as optimal probes for CND, informing the design of objective clinical diagnostics while revealing problems associated with reverberation as a probe. [SEP] [HINT] clinical -> Bioinformatics (Syns: ) | information -> Bioinformatics (Syns: entropy, data, info) | results -> Bioinformatics (Syns: final result, consequence, resultant role)",Neuroscience
"It is generally assumed that the carbon atoms of graphitic samples and their finite analogs have sizable quadrupole moments, with the out-of-plane component ($Q^{\rm C}_{20}$ in traceless spherical coordinates) being the dominate contribution.   However, there is no consensus on what the quantity is for such carbon-based systems and values reported in the literature range from $Q^{\rm C}_{20} \sim -1.14$ to $+0.79$ a.u.   In this work we propose a theoretical framework in which well-defined statements can be made about properties of atoms-in-a-molecule (AIMs) even when these properties are not experimentally observable.   Using this framework and the distributed multipole method basis-space iterated Stockholder atoms (BS-ISA), we show that the atomic quadrupole moment of a carbon atom in graphene is essentially zero within the limits of precision of the numerical method used.   We explain how the experimentally measured atomic quadrupole moment of a graphite sample determined by Whitehouse \& Buckingham likely originated almost entirely from edge dipoles, and we propose a more realistic electrostatic model for finite graphene nanoflakes.",Materials Science
"It is generally assumed that the carbon atoms of graphitic samples and their finite analogs have sizable quadrupole moments, with the out-of-plane component ($Q^{\rm C}_{20}$ in traceless spherical coordinates) being the dominate contribution.   However, there is no consensus on what the quantity is for such carbon-based systems and values reported in the literature range from $Q^{\rm C}_{20} \sim -1.14$ to $+0.79$ a.u.   In this work we propose a theoretical framework in which well-defined statements can be made about properties of atoms-in-a-molecule (AIMs) even when these properties are not experimentally observable.   Using this framework and the distributed multipole method basis-space iterated Stockholder atoms (BS-ISA), we show that the atomic quadrupole moment of a carbon atom in graphene is essentially zero within the limits of precision of the numerical method used.   We explain how the experimentally measured atomic quadrupole moment of a graphite sample determined by Whitehouse \& Buckingham likely originated almost entirely from edge dipoles, and we propose a more realistic electrostatic model for finite graphene nanoflakes. [SEP] [HINT] work -> Bioinformatics (Syns: work out, process, bring) | systems -> Bioinformatics (Syns: organization, organisation, system) | framework -> Bioinformatics (Syns: theoretical account, model, fabric)",Materials Science
"Active inference proposes expected free energy as an objective for planning and decision-making to adequately balance exploitative and explorative drives in learning agents. The exploitative drive, or what an agent wants to achieve, is formalised as the Kullback-Leibler divergence between a variational probability distribution, updated at each inference step, and a preference probability distribution that indicates what states or observations are more likely for the agent, hence determining the agent's goal in a certain environment. In the literature, the questions of how the preference distribution should be specified and of how a certain specification impacts inference and learning in an active inference agent have been given hardly any attention. In this work, we consider four possible ways of defining the preference distribution, either providing the agents with hard or soft goals and either involving or not goal shaping (i.e., intermediate goals). We compare the performances of four agents, each given one of the possible preference distributions, in a grid world navigation task. Our results show that goal shaping enables the best performance overall (i.e., it promotes exploitation) while sacrificing learning about the environment's transition dynamics (i.e., it hampers exploration).",Neuroscience
"Active inference proposes expected free energy as an objective for planning and decision-making to adequately balance exploitative and explorative drives in learning agents. The exploitative drive, or what an agent wants to achieve, is formalised as the Kullback-Leibler divergence between a variational probability distribution, updated at each inference step, and a preference probability distribution that indicates what states or observations are more likely for the agent, hence determining the agent's goal in a certain environment. In the literature, the questions of how the preference distribution should be specified and of how a certain specification impacts inference and learning in an active inference agent have been given hardly any attention. In this work, we consider four possible ways of defining the preference distribution, either providing the agents with hard or soft goals and either involving or not goal shaping (i.e., intermediate goals). We compare the performances of four agents, each given one of the possible preference distributions, in a grid world navigation task. Our results show that goal shaping enables the best performance overall (i.e., it promotes exploitation) while sacrificing learning about the environment's transition dynamics (i.e., it hampers exploration). [SEP] [HINT] transition -> Materials Science (Syns: passage, modulation, changeover) | learning -> Bioinformatics (Syns: take, teach, acquire) | performance -> Bioinformatics (Syns: functioning, operation, carrying out)",Neuroscience
"Accurate diagnosis of spitzoid tumors (ST) is critical to ensure a favorable prognosis and to avoid both under- and over-treatment. Epigenetic data, particularly DNA methylation, provide a valuable source of information for this task. However, prior studies assume complete data, an unrealistic setting as methylation profiles frequently contain missing entries due to limited coverage and experimental artifacts. Our work challenges these favorable scenarios and introduces ReMAC, an extension of ReMasker designed to tackle classification tasks on high-dimensional data under complete and incomplete regimes. Evaluation on real clinical data demonstrates that ReMAC achieves strong and robust performance compared to competing classification methods in the stratification of ST. Code is available: https://github.com/roshni-mahtani/ReMAC.",Bioinformatics
"Accurate diagnosis of spitzoid tumors (ST) is critical to ensure a favorable prognosis and to avoid both under- and over-treatment. Epigenetic data, particularly DNA methylation, provide a valuable source of information for this task. However, prior studies assume complete data, an unrealistic setting as methylation profiles frequently contain missing entries due to limited coverage and experimental artifacts. Our work challenges these favorable scenarios and introduces ReMAC, an extension of ReMasker designed to tackle classification tasks on high-dimensional data under complete and incomplete regimes. Evaluation on real clinical data demonstrates that ReMAC achieves strong and robust performance compared to competing classification methods in the stratification of ST. Code is available: https://github.com/roshni-mahtani/ReMAC. [SEP] [HINT] tasks -> Neuroscience (Syns: tax, task, project) | clinical -> Bioinformatics (Syns: ) | information -> Bioinformatics (Syns: entropy, data, info)",Bioinformatics
"Adverse drug reactions (ADRs) are a major barrier to safe and effective pharmacotherapy and increasingly reflect higher order interactions between drugs, genetic background, and clinical phenotypes. Existing graph based approaches usually predict ADRs as properties of drugs or drug pairs, leaving the causal gene implicit and limiting their value for pharmacogenomic decision making. We introduce HyperADRs, a hierarchical hypergraph framework that predicts ADR risk at the level of drug-gene-ADR triads. Starting from curated pharmacogenomic annotations in PharmGKB and the pharmacogenomics subdatabase of DrugBank, we construct high confidence triplets and integrate them with auxiliary molecular, functional, and disease relations from precision-medicine-oriented knowledge graphs. Drugs, genes, and ADR concepts are embedded with modality appropriate pretrained models (UniMol, ESM2, SapBERT) and propagated through a hypergraph convolutional network. A FiLM based, query conditioned contrastive learning module learns context specific representations so that, given any two entities, the model retrieves the correct third entity against many candidates. To improve robustness and interpretability, we propose a nine category ADR macro system scheme that reduces large heterogeneous ""other"" bins while aligning with organ system reasoning in clinical pharmacology. Across drug-, gene-, and ADR-held-out evaluations on PharmGKB, HyperADRs matches or exceeds strong baselines on ranking based metrics. When trained on PharmGKB and tested on unseen DrugBank triplets, HyperADRs maintains its ranking advantage, indicating that the learned representations capture transferable biological mechanisms and can support mechanistically grounded pharmacogenomic hypothesis generation.",Bioinformatics
"Adverse drug reactions (ADRs) are a major barrier to safe and effective pharmacotherapy and increasingly reflect higher order interactions between drugs, genetic background, and clinical phenotypes. Existing graph based approaches usually predict ADRs as properties of drugs or drug pairs, leaving the causal gene implicit and limiting their value for pharmacogenomic decision making. We introduce HyperADRs, a hierarchical hypergraph framework that predicts ADR risk at the level of drug-gene-ADR triads. Starting from curated pharmacogenomic annotations in PharmGKB and the pharmacogenomics subdatabase of DrugBank, we construct high confidence triplets and integrate them with auxiliary molecular, functional, and disease relations from precision-medicine-oriented knowledge graphs. Drugs, genes, and ADR concepts are embedded with modality appropriate pretrained models (UniMol, ESM2, SapBERT) and propagated through a hypergraph convolutional network. A FiLM based, query conditioned contrastive learning module learns context specific representations so that, given any two entities, the model retrieves the correct third entity against many candidates. To improve robustness and interpretability, we propose a nine category ADR macro system scheme that reduces large heterogeneous ""other"" bins while aligning with organ system reasoning in clinical pharmacology. Across drug-, gene-, and ADR-held-out evaluations on PharmGKB, HyperADRs matches or exceeds strong baselines on ranking based metrics. When trained on PharmGKB and tested on unseen DrugBank triplets, HyperADRs maintains its ranking advantage, indicating that the learned representations capture transferable biological mechanisms and can support mechanistically grounded pharmacogenomic hypothesis generation. [SEP] [HINT] based -> Bioinformatics (Syns: ground, free-base, base) | clinical -> Bioinformatics (Syns: ) | learning -> Bioinformatics (Syns: take, teach, acquire)",Bioinformatics
"Pnictogen chalcohalides (MChX) have recently emerged as promising nontoxic and environmentally friendly photovoltaic absorbers, combining strong light absorption coefficients with favorable low-temperature synthesis conditions. Despite these advantages and reported optimized morphologies, device efficiencies remain below 10%, far from their ideal radiative limit. To uncover the origin of these performance losses, we present a systematic and fully consistent first-principles investigation of the defect chemistry across the Bi-based chalcohalide family. Our results reveal a complex defect landscape dominated by chalcogen vacancies of low formation energy, which act as deep nonradiative recombination centers. Despite their moderate charge-carrier capture coefficients, the high equilibrium concentrations of these defects reduce the theoretical maximum efficiencies by 6% in BiSeI and by 10% in BiSeBr. In contrast, sulfur vacancies in BiSI and BiSBr are comparatively benign, presenting smaller capture coefficients due to weaker electron-phonon coupling. Interestingly, despite its huge nonradiative charge-carrier recombination rate, BiSeI presents the best conversion efficiency among all four compounds owing to its most suitable bandgap for outdoor photovoltaic applications. Our findings identify defect chemistry as a critical bottleneck in MChX solar cells and proposes chalcogen-rich synthesis conditions and targeted anion substitutions as effective strategies for mitigation of detrimental vacancies.",Materials Science
"Pnictogen chalcohalides (MChX) have recently emerged as promising nontoxic and environmentally friendly photovoltaic absorbers, combining strong light absorption coefficients with favorable low-temperature synthesis conditions. Despite these advantages and reported optimized morphologies, device efficiencies remain below 10%, far from their ideal radiative limit. To uncover the origin of these performance losses, we present a systematic and fully consistent first-principles investigation of the defect chemistry across the Bi-based chalcohalide family. Our results reveal a complex defect landscape dominated by chalcogen vacancies of low formation energy, which act as deep nonradiative recombination centers. Despite their moderate charge-carrier capture coefficients, the high equilibrium concentrations of these defects reduce the theoretical maximum efficiencies by 6% in BiSeI and by 10% in BiSeBr. In contrast, sulfur vacancies in BiSI and BiSBr are comparatively benign, presenting smaller capture coefficients due to weaker electron-phonon coupling. Interestingly, despite its huge nonradiative charge-carrier recombination rate, BiSeI presents the best conversion efficiency among all four compounds owing to its most suitable bandgap for outdoor photovoltaic applications. Our findings identify defect chemistry as a critical bottleneck in MChX solar cells and proposes chalcogen-rich synthesis conditions and targeted anion substitutions as effective strategies for mitigation of detrimental vacancies. [SEP] [HINT] low -> Materials Science (Syns: low-spirited, scurvy, depressed) | defect -> Materials Science (Syns: mar, shortcoming, fault) | complex -> Bioinformatics (Syns: building complex, coordination compound, composite)",Materials Science
"High-resolution spatial transcriptomics (HR-ST) technologies offer unprecedented insights into tissue architecture but lack standardized frameworks for histological annotation. We present ST2HE, a cross-platform generative framework that synthesizes virtual hematoxylin and eosin (H&E) images directly from HR-ST data. ST2HE integrates nuclei morphology and spatial transcript coordinates using a one-step diffusion model, enabling histologically faithful image generation across diverse tissue types and HR-ST platforms. Conditional and tissue-independent variants support both known and novel tissue contexts. Evaluations on breast cancer, non-small cell lung cancer, and Kaposi's sarcoma demonstrate ST2HE's ability to preserve morphological features and support downstream annotations of tissue histology and phenotype classification. Ablation studies reveal that larger context windows, balanced loss functions, and multi-colored transcript visualization enhance image fidelity. ST2HE bridges molecular and histological domains, enabling interpretable, scalable annotation of HR-ST data and advancing computational pathology.",Bioinformatics
"High-resolution spatial transcriptomics (HR-ST) technologies offer unprecedented insights into tissue architecture but lack standardized frameworks for histological annotation. We present ST2HE, a cross-platform generative framework that synthesizes virtual hematoxylin and eosin (H&E) images directly from HR-ST data. ST2HE integrates nuclei morphology and spatial transcript coordinates using a one-step diffusion model, enabling histologically faithful image generation across diverse tissue types and HR-ST platforms. Conditional and tissue-independent variants support both known and novel tissue contexts. Evaluations on breast cancer, non-small cell lung cancer, and Kaposi's sarcoma demonstrate ST2HE's ability to preserve morphological features and support downstream annotations of tissue histology and phenotype classification. Ablation studies reveal that larger context windows, balanced loss functions, and multi-colored transcript visualization enhance image fidelity. ST2HE bridges molecular and histological domains, enabling interpretable, scalable annotation of HR-ST data and advancing computational pathology. [SEP] [HINT] tissue -> Bioinformatics (Syns: tissue paper, weave) | computational -> Neuroscience (Syns: ) | features -> Bioinformatics (Syns: characteristic, lineament, feature of speech)",Bioinformatics
"Generative modeling becomes increasingly data-intensive in high-dimensional spaces. In molecular science, where data collection is expensive and important events are rare, compression to lower-dimensional manifolds is especially important for various downstream tasks, including generation. We combine a time-lagged information bottleneck designed to characterize molecular important representations and a diffusion model in one joint training objective. The resulting protocol, which we term Diffusive State Predictive Information Bottleneck (D-SPIB), enables the balancing of representation learning and generation aims in one flexible architecture. Additionally, the model is capable of combining temperature information from different molecular simulation trajectories to learn a coherent and useful internal representation of thermodynamics. We benchmark D-SPIB on multiple molecular tasks and showcase its potential for exploring physical conditions outside the training set.",Bioinformatics
"Generative modeling becomes increasingly data-intensive in high-dimensional spaces. In molecular science, where data collection is expensive and important events are rare, compression to lower-dimensional manifolds is especially important for various downstream tasks, including generation. We combine a time-lagged information bottleneck designed to characterize molecular important representations and a diffusion model in one joint training objective. The resulting protocol, which we term Diffusive State Predictive Information Bottleneck (D-SPIB), enables the balancing of representation learning and generation aims in one flexible architecture. Additionally, the model is capable of combining temperature information from different molecular simulation trajectories to learn a coherent and useful internal representation of thermodynamics. We benchmark D-SPIB on multiple molecular tasks and showcase its potential for exploring physical conditions outside the training set. [SEP] [HINT] tasks -> Neuroscience (Syns: tax, task, project) | learning -> Bioinformatics (Syns: take, teach, acquire) | information -> Bioinformatics (Syns: entropy, data, info)",Bioinformatics
"Discovering the neural mechanisms underpinning cognition is one of the grand challenges of neuroscience. However, previous approaches for building models of RNN dynamics that explain behaviour required iterative refinement of architectures and/or optimisation objectives, resulting in a piecemeal, and mostly heuristic, human-in-the-loop process. Here, we offer an alternative approach that automates the discovery of viable RNN mechanisms by explicitly training RNNs to reproduce behaviour, including the same characteristic errors and suboptimalities, that humans and animals produce in a cognitive task. Achieving this required two main innovations. First, as the amount of behavioural data that can be collected in experiments is often too limited to train RNNs, we use a non-parametric generative model of behavioural responses to produce surrogate data for training RNNs. Second, to capture all relevant statistical aspects of the data, we developed a novel diffusion model-based approach for training RNNs. To showcase the potential of our approach, we chose a visual working memory task as our test-bed, as behaviour in this task is well known to produce response distributions that are patently multimodal (due to swap errors). The resulting network dynamics correctly qualitative features of macaque neural data. Importantly, these results were not possible to obtain with more traditional approaches, i.e., when only a limited set of behavioural signatures (rather than the full richness of behavioural response distributions) were fitted, or when RNNs were trained for task optimality (instead of reproducing behaviour). Our approach also yields novel predictions about the mechanism of swap errors, which can be readily tested in experiments. These results suggest that fitting RNNs to rich patterns of behaviour provides a powerful way to automatically discover mechanisms of important cognitive functions.",Neuroscience
"Discovering the neural mechanisms underpinning cognition is one of the grand challenges of neuroscience. However, previous approaches for building models of RNN dynamics that explain behaviour required iterative refinement of architectures and/or optimisation objectives, resulting in a piecemeal, and mostly heuristic, human-in-the-loop process. Here, we offer an alternative approach that automates the discovery of viable RNN mechanisms by explicitly training RNNs to reproduce behaviour, including the same characteristic errors and suboptimalities, that humans and animals produce in a cognitive task. Achieving this required two main innovations. First, as the amount of behavioural data that can be collected in experiments is often too limited to train RNNs, we use a non-parametric generative model of behavioural responses to produce surrogate data for training RNNs. Second, to capture all relevant statistical aspects of the data, we developed a novel diffusion model-based approach for training RNNs. To showcase the potential of our approach, we chose a visual working memory task as our test-bed, as behaviour in this task is well known to produce response distributions that are patently multimodal (due to swap errors). The resulting network dynamics correctly qualitative features of macaque neural data. Importantly, these results were not possible to obtain with more traditional approaches, i.e., when only a limited set of behavioural signatures (rather than the full richness of behavioural response distributions) were fitted, or when RNNs were trained for task optimality (instead of reproducing behaviour). Our approach also yields novel predictions about the mechanism of swap errors, which can be readily tested in experiments. These results suggest that fitting RNNs to rich patterns of behaviour provides a powerful way to automatically discover mechanisms of important cognitive functions. [SEP] [HINT] task -> Neuroscience (Syns: tax, project, chore) | features -> Bioinformatics (Syns: characteristic, lineament, feature of speech) | results -> Bioinformatics (Syns: final result, consequence, resultant role)",Neuroscience
"Art has long played a profound role in shaping human emotion, cognition, and behavior. While visual arts such as painting and architecture have been studied through eye tracking, revealing distinct gaze patterns between experts and novices, analogous methods for auditory art forms remain underdeveloped. Music, despite being a pervasive component of modern life and culture, still lacks objective tools to quantify listeners' attention and perceptual focus during natural listening experiences. To our knowledge, this is the first attempt to decode selective attention to musical elements using naturalistic, studio-produced songs and a lightweight consumer-grade EEG device with only four electrodes. By analyzing neural responses during real world like music listening, we test whether decoding is feasible under conditions that minimize participant burden and preserve the authenticity of the musical experience. Our contributions are fourfold: (i) decoding music attention in real studio-produced songs, (ii) demonstrating feasibility with a four-channel consumer EEG, (iii) providing insights for music attention decoding, and (iv) demonstrating improved model ability over prior work. Our findings suggest that musical attention can be decoded not only for novel songs but also across new subjects, showing performance improvements compared to existing approaches under our tested conditions. These findings show that consumer-grade devices can reliably capture signals, and that neural decoding in music could be feasible in real-world settings. This paves the way for applications in education, personalized music technologies, and therapeutic interventions.",Neuroscience
"Art has long played a profound role in shaping human emotion, cognition, and behavior. While visual arts such as painting and architecture have been studied through eye tracking, revealing distinct gaze patterns between experts and novices, analogous methods for auditory art forms remain underdeveloped. Music, despite being a pervasive component of modern life and culture, still lacks objective tools to quantify listeners' attention and perceptual focus during natural listening experiences. To our knowledge, this is the first attempt to decode selective attention to musical elements using naturalistic, studio-produced songs and a lightweight consumer-grade EEG device with only four electrodes. By analyzing neural responses during real world like music listening, we test whether decoding is feasible under conditions that minimize participant burden and preserve the authenticity of the musical experience. Our contributions are fourfold: (i) decoding music attention in real studio-produced songs, (ii) demonstrating feasibility with a four-channel consumer EEG, (iii) providing insights for music attention decoding, and (iv) demonstrating improved model ability over prior work. Our findings suggest that musical attention can be decoded not only for novel songs but also across new subjects, showing performance improvements compared to existing approaches under our tested conditions. These findings show that consumer-grade devices can reliably capture signals, and that neural decoding in music could be feasible in real-world settings. This paves the way for applications in education, personalized music technologies, and therapeutic interventions. [SEP] [HINT] decoding -> Neuroscience (Syns: decrypt, decipherment, decryption) | performance -> Bioinformatics (Syns: functioning, operation, carrying out) | human -> Neuroscience (Syns: human being, man, homo)",Neuroscience
"The first experiments in dynamic rotational diamond anvil cell (dRDAC) on severe plastic deformation (SPD) and BCC<->HCP phase transformation (PT) at pressure up to 27.6 GPa, rotation rates up to 1,500 RPM, and strain rates up to 2,094 /s are performed considering Fe-%7Mn alloy as an example. The BCC-HCP PT initiates at 11.4 GPa under hydrostatic loading while it is 3.2 GPa under plastic compression. Strong effect of plastic straining leads to unique kinetics with simultaneous direct and reverse PTs, not studied for any material. For quasi-static loading, parameters in the kinetics for the strain-induced direct-reverse PTs and stationary volume fraction versus pressure are found. During torsion with 1,000 and 1,500 RPM, volume fraction of the HCP phase does not change. After torsion stops, it increases by 30% within a few minutes after 1,000 RPM and HCP phase disappears after 1,500 RPM. These findings contradict general wisdom that strain-induced PTs occur only during straining, time is not a governing parameter, and kinetics is determined by plastic strain instead of time. Thus, nuclei of the HCP phase are generated during straining at high strain rate, but growth/disappearance occur under stresses at much longer time scales. Consequently, a new theory of combined strain- and stress-induced PTs is required. The following important rule is revealed: crystallite size of 30 nm, microstrain ~0.004, and dislocation density ~1.1 x $10^{15}$/$m^2$ in the HCP phase are steady during static compression and dynamic torsion, during and after the PT and after torsion. These parameters are independent of pressure, plastic strain tensor, its path, strain rates, and volume fraction of the HCP phase. Obtained results open fundamental research on combined strain- and stress-induced PTs and microstructure evolution under dynamic SPD and high pressure.",Materials Science
"The first experiments in dynamic rotational diamond anvil cell (dRDAC) on severe plastic deformation (SPD) and BCC<->HCP phase transformation (PT) at pressure up to 27.6 GPa, rotation rates up to 1,500 RPM, and strain rates up to 2,094 /s are performed considering Fe-%7Mn alloy as an example. The BCC-HCP PT initiates at 11.4 GPa under hydrostatic loading while it is 3.2 GPa under plastic compression. Strong effect of plastic straining leads to unique kinetics with simultaneous direct and reverse PTs, not studied for any material. For quasi-static loading, parameters in the kinetics for the strain-induced direct-reverse PTs and stationary volume fraction versus pressure are found. During torsion with 1,000 and 1,500 RPM, volume fraction of the HCP phase does not change. After torsion stops, it increases by 30% within a few minutes after 1,000 RPM and HCP phase disappears after 1,500 RPM. These findings contradict general wisdom that strain-induced PTs occur only during straining, time is not a governing parameter, and kinetics is determined by plastic strain instead of time. Thus, nuclei of the HCP phase are generated during straining at high strain rate, but growth/disappearance occur under stresses at much longer time scales. Consequently, a new theory of combined strain- and stress-induced PTs is required. The following important rule is revealed: crystallite size of 30 nm, microstrain ~0.004, and dislocation density ~1.1 x $10^{15}$/$m^2$ in the HCP phase are steady during static compression and dynamic torsion, during and after the PT and after torsion. These parameters are independent of pressure, plastic strain tensor, its path, strain rates, and volume fraction of the HCP phase. Obtained results open fundamental research on combined strain- and stress-induced PTs and microstructure evolution under dynamic SPD and high pressure. [SEP] [HINT] results -> Bioinformatics (Syns: final result, consequence, resultant role) | strain -> Materials Science (Syns: air, stock, form) | theory -> Materials Science (Syns: possibility, hypothesis)",Materials Science
"A probabilistic clustering algorithm is proposed for the analysis of forensic DNA mixtures in which individual cells are isolated and short tandem repeats are amplified using the polymerase chain reaction to generate single cell electropherograms. The task of the algorithm is to use the peak height information in the electropherograms to group the cells according to their contributors. Using a recently developed experimental set of individual cell electropherograms, a large set of simulations shows that the proposed clustering algorithm has excellent performance in correctly grouping single cells, and for assigning likelihood ratios for persons of interest (of known genotype).",Bioinformatics
"A probabilistic clustering algorithm is proposed for the analysis of forensic DNA mixtures in which individual cells are isolated and short tandem repeats are amplified using the polymerase chain reaction to generate single cell electropherograms. The task of the algorithm is to use the peak height information in the electropherograms to group the cells according to their contributors. Using a recently developed experimental set of individual cell electropherograms, a large set of simulations shows that the proposed clustering algorithm has excellent performance in correctly grouping single cells, and for assigning likelihood ratios for persons of interest (of known genotype). [SEP] [HINT] experimental -> Materials Science (Syns: data-based, observational) | task -> Neuroscience (Syns: tax, project, chore) | performance -> Bioinformatics (Syns: functioning, operation, carrying out)",Bioinformatics
"In the last decade, there have been major advances in clusterless decoding algorithms for neural data analysis. These algorithms use the theory of marked point processes to describe the joint activity of many neurons simultaneously, without the need for spike sorting. In this study, we examine information-theoretic metrics to analyze the information extracted from each observed spike under such clusterless models. In an analysis of spatial coding in the rat hippocampus, we compared the entropy reduction between spike-sorted and clusterless models for both individual spikes observed in isolation and when the prior information from all previously observed spikes is accounted for. Our analysis demonstrates that low-amplitude spikes, which are difficult to cluster and often left out of spike sorting, provide reduced information compared to sortable, high-amplitude spikes when considered in isolation, but the two provide similar levels of information when considering all the prior information available from past spiking. These findings demonstrate the value of combining information measures with state-space modeling and yield new insights into the underlying mechanisms of neural computation.",Bioinformatics
"In the last decade, there have been major advances in clusterless decoding algorithms for neural data analysis. These algorithms use the theory of marked point processes to describe the joint activity of many neurons simultaneously, without the need for spike sorting. In this study, we examine information-theoretic metrics to analyze the information extracted from each observed spike under such clusterless models. In an analysis of spatial coding in the rat hippocampus, we compared the entropy reduction between spike-sorted and clusterless models for both individual spikes observed in isolation and when the prior information from all previously observed spikes is accounted for. Our analysis demonstrates that low-amplitude spikes, which are difficult to cluster and often left out of spike sorting, provide reduced information compared to sortable, high-amplitude spikes when considered in isolation, but the two provide similar levels of information when considering all the prior information available from past spiking. These findings demonstrate the value of combining information measures with state-space modeling and yield new insights into the underlying mechanisms of neural computation. [SEP] [HINT] decoding -> Neuroscience (Syns: decrypt, decipherment, decryption) | information -> Bioinformatics (Syns: entropy, data, info) | theory -> Materials Science (Syns: possibility, hypothesis)",Bioinformatics
"Understanding the evolution of cellular microenvironments in spatiotemporal data is essential for deciphering tissue development and disease progression. While experimental techniques like spatial transcriptomics now enable high-resolution mapping of tissue organization across space and time, current methods that model cellular evolution operate at the single-cell level, overlooking the coordinated development of cellular states in a tissue. We introduce NicheFlow, a flow-based generative model that infers the temporal trajectory of cellular microenvironments across sequential spatial slides. By representing local cell neighborhoods as point clouds, NicheFlow jointly models the evolution of cell states and spatial coordinates using optimal transport and Variational Flow Matching. Our approach successfully recovers both global spatial architecture and local microenvironment composition across diverse spatiotemporal datasets, from embryonic to brain development.",Bioinformatics
"Understanding the evolution of cellular microenvironments in spatiotemporal data is essential for deciphering tissue development and disease progression. While experimental techniques like spatial transcriptomics now enable high-resolution mapping of tissue organization across space and time, current methods that model cellular evolution operate at the single-cell level, overlooking the coordinated development of cellular states in a tissue. We introduce NicheFlow, a flow-based generative model that infers the temporal trajectory of cellular microenvironments across sequential spatial slides. By representing local cell neighborhoods as point clouds, NicheFlow jointly models the evolution of cell states and spatial coordinates using optimal transport and Variational Flow Matching. Our approach successfully recovers both global spatial architecture and local microenvironment composition across diverse spatiotemporal datasets, from embryonic to brain development. [SEP] [HINT] tissue -> Bioinformatics (Syns: tissue paper, weave) | understanding -> Neuroscience (Syns: savvy, intellect, sympathy) | transport -> Materials Science (Syns: transferral, enthral, shipping)",Bioinformatics
"Robust decoding and classification of brain patterns measured with electroencephalography (EEG) remains a major challenge for real-world (i.e. outside scientific lab and medical facilities) brain-computer interface (BCI) applications due to well documented inter- and intra-participant variability. Here, we present a large-scale benchmark evaluating over 340,000+ unique combinations of spatial and nonlinear EEG classification. Our methodological pipeline consists in combinations of Common Spatial Patterns (CSP), Riemannian geometry, functional connectivity, and fractal- or entropy-based features across three open-access EEG datasets. Unlike prior studies, our analysis operates at the per-participant level and across multiple frequency bands (8-15 Hz and 8-30 Hz), enabling direct assessment of both group-level performance and individual variability. Covariance tangent space projection (cov-tgsp) and CSP consistently achieved the highest average classification accuracies. However, their effectiveness was strongly dataset-dependent, and marked participant-level differences persisted, particularly in the most heterogeneous of the datasets. Importantly, nonlinear methods outperformed spatial approaches for specific individuals, underscoring the need for personalized pipeline selection. Our findings highlight that no universal 'one-size-fits-all' method can optimally decode EEG motor imagery patterns across all users or datasets. Future work will require adaptive, multimodal, and possibly novel approaches to fully address neurophysiological variability in practical BCI applications where the system can automatically adapt to what makes each user unique.",Neuroscience
"Robust decoding and classification of brain patterns measured with electroencephalography (EEG) remains a major challenge for real-world (i.e. outside scientific lab and medical facilities) brain-computer interface (BCI) applications due to well documented inter- and intra-participant variability. Here, we present a large-scale benchmark evaluating over 340,000+ unique combinations of spatial and nonlinear EEG classification. Our methodological pipeline consists in combinations of Common Spatial Patterns (CSP), Riemannian geometry, functional connectivity, and fractal- or entropy-based features across three open-access EEG datasets. Unlike prior studies, our analysis operates at the per-participant level and across multiple frequency bands (8-15 Hz and 8-30 Hz), enabling direct assessment of both group-level performance and individual variability. Covariance tangent space projection (cov-tgsp) and CSP consistently achieved the highest average classification accuracies. However, their effectiveness was strongly dataset-dependent, and marked participant-level differences persisted, particularly in the most heterogeneous of the datasets. Importantly, nonlinear methods outperformed spatial approaches for specific individuals, underscoring the need for personalized pipeline selection. Our findings highlight that no universal 'one-size-fits-all' method can optimally decode EEG motor imagery patterns across all users or datasets. Future work will require adaptive, multimodal, and possibly novel approaches to fully address neurophysiological variability in practical BCI applications where the system can automatically adapt to what makes each user unique. [SEP] [HINT] decoding -> Neuroscience (Syns: decrypt, decipherment, decryption) | features -> Bioinformatics (Syns: characteristic, lineament, feature of speech) | space -> Neuroscience (Syns: distance, place, outer space)",Neuroscience
"Self-supervised learning (SSL) holds a great deal of promise for applications in neuroscience, due to the lack of large-scale, consistently labeled neural datasets. However, most neural datasets contain heterogeneous populations that mix stable, predictable cells with highly stochastic, stimulus-contingent ones, which has made it hard to identify consistent activity patterns during SSL. As a result, self-supervised pretraining has yet to show clear signs of benefits from scale on neural data. Here, we present a novel approach to self-supervised pretraining, POYO-SSL that exploits the heterogeneity of neural data to improve pre-training and achieve benefits of scale. Specifically, in POYO-SSL we pretrain only on predictable (statistically regular) neurons-identified on the pretraining split via simple higher-order statistics (skewness and kurtosis)-then we fine-tune on the unpredictable population for downstream tasks. On the Allen Brain Observatory dataset, this strategy yields approximately 12-13% relative gains over from-scratch training and exhibits smooth, monotonic scaling with model size. In contrast, existing state-of-the-art baselines plateau or destabilize as model size increases. By making predictability an explicit metric for crafting the data diet, POYO-SSL turns heterogeneity from a liability into an asset, providing a robust, biologically grounded recipe for scalable neural decoding and a path toward foundation models of neural dynamics.",Neuroscience
"Self-supervised learning (SSL) holds a great deal of promise for applications in neuroscience, due to the lack of large-scale, consistently labeled neural datasets. However, most neural datasets contain heterogeneous populations that mix stable, predictable cells with highly stochastic, stimulus-contingent ones, which has made it hard to identify consistent activity patterns during SSL. As a result, self-supervised pretraining has yet to show clear signs of benefits from scale on neural data. Here, we present a novel approach to self-supervised pretraining, POYO-SSL that exploits the heterogeneity of neural data to improve pre-training and achieve benefits of scale. Specifically, in POYO-SSL we pretrain only on predictable (statistically regular) neurons-identified on the pretraining split via simple higher-order statistics (skewness and kurtosis)-then we fine-tune on the unpredictable population for downstream tasks. On the Allen Brain Observatory dataset, this strategy yields approximately 12-13% relative gains over from-scratch training and exhibits smooth, monotonic scaling with model size. In contrast, existing state-of-the-art baselines plateau or destabilize as model size increases. By making predictability an explicit metric for crafting the data diet, POYO-SSL turns heterogeneity from a liability into an asset, providing a robust, biologically grounded recipe for scalable neural decoding and a path toward foundation models of neural dynamics. [SEP] [HINT] decoding -> Neuroscience (Syns: decrypt, decipherment, decryption) | learning -> Bioinformatics (Syns: take, teach, acquire) | datasets -> Bioinformatics (Syns: )",Neuroscience
"We study tribological granite-granite contacts as a model for tectonic faulting, combining experiments, theory, and molecular dynamics simulations. The high friction in this system is not dominated by particulate wear or plowing, as frequently assumed, but by cold welding within plastically deformed asperity junctions. We base this conclusion on the observation that wear is repeatedly high after cleaning contacts but decreases as gouge accumulates, while friction shows the opposite trend. Moreover, adding water reduces wear by a factor of ten but barely decreases friction. Thermal and rate-dependent effects - central to most earthquake models-are negligible: friction remains unchanged between -40°C and 20°C, across abrupt velocity steps, and after hours of stationary contact. The absence of rate-state effects in our macroscopic samples is rationalized by the scale-dependence of pre-slip. The evolution of surface topography shows that quartz grains become locally smooth, with height spectra isotropic for wavelength below 10 microns but anisotropic at longer wavelengths, similar to natural faults. The resulting gouge particles have the usual characteristic sizes near 100 nm. Molecular dynamics simulations of a rigid, amorphous silica tip sliding on α-quartz reproduce not only similar friction coefficients near unity but also other experimentally observed features, including stress-introduced transitions to phases observed in post-mortem faults, as well as theoretical estimates of local flash temperatures. Additionally, they reveal a marked decrease of interfacial shear strength above 600°C. The overall correspondence between experiments, simulations, theory, and field observations indicates that our model system captures essential aspects of rock friction.",Materials Science
"We study tribological granite-granite contacts as a model for tectonic faulting, combining experiments, theory, and molecular dynamics simulations. The high friction in this system is not dominated by particulate wear or plowing, as frequently assumed, but by cold welding within plastically deformed asperity junctions. We base this conclusion on the observation that wear is repeatedly high after cleaning contacts but decreases as gouge accumulates, while friction shows the opposite trend. Moreover, adding water reduces wear by a factor of ten but barely decreases friction. Thermal and rate-dependent effects - central to most earthquake models-are negligible: friction remains unchanged between -40°C and 20°C, across abrupt velocity steps, and after hours of stationary contact. The absence of rate-state effects in our macroscopic samples is rationalized by the scale-dependence of pre-slip. The evolution of surface topography shows that quartz grains become locally smooth, with height spectra isotropic for wavelength below 10 microns but anisotropic at longer wavelengths, similar to natural faults. The resulting gouge particles have the usual characteristic sizes near 100 nm. Molecular dynamics simulations of a rigid, amorphous silica tip sliding on α-quartz reproduce not only similar friction coefficients near unity but also other experimentally observed features, including stress-introduced transitions to phases observed in post-mortem faults, as well as theoretical estimates of local flash temperatures. Additionally, they reveal a marked decrease of interfacial shear strength above 600°C. The overall correspondence between experiments, simulations, theory, and field observations indicates that our model system captures essential aspects of rock friction. [SEP] [HINT] field -> Materials Science (Syns: field of honor, line of business, orbit) | molecular -> Bioinformatics (Syns: ) | including -> Bioinformatics (Syns: admit, include, let in)",Materials Science
"High-throughput phenotypic screens generate vast microscopy image datasets that push the limits of generative models due to their large dimensionality. Despite the growing popularity of general-purpose models trained on natural images for microscopy data analysis, their suitability in this domain has not been quantitatively demonstrated. We present the first systematic evaluation of Stable Diffusion's variational autoencoder (SD-VAE) for reconstructing Cell Painting images, assessing performance across a large dataset with diverse molecular perturbations and cell types. We find that SD-VAE reconstructions preserve phenotypic signals with minimal loss, supporting its use in microscopy workflows. To benchmark reconstruction quality, we compare pixel-level, embedding-based, latent-space, and retrieval-based metrics for a biologically informed evaluation. We show that general-purpose feature extractors like InceptionV3 match or surpass publicly available bespoke models in retrieval tasks, simplifying future pipelines. Our findings offer practical guidelines for evaluating generative models on microscopy data and support the use of off-the-shelf models in phenotypic drug discovery.",Bioinformatics
"High-throughput phenotypic screens generate vast microscopy image datasets that push the limits of generative models due to their large dimensionality. Despite the growing popularity of general-purpose models trained on natural images for microscopy data analysis, their suitability in this domain has not been quantitatively demonstrated. We present the first systematic evaluation of Stable Diffusion's variational autoencoder (SD-VAE) for reconstructing Cell Painting images, assessing performance across a large dataset with diverse molecular perturbations and cell types. We find that SD-VAE reconstructions preserve phenotypic signals with minimal loss, supporting its use in microscopy workflows. To benchmark reconstruction quality, we compare pixel-level, embedding-based, latent-space, and retrieval-based metrics for a biologically informed evaluation. We show that general-purpose feature extractors like InceptionV3 match or surpass publicly available bespoke models in retrieval tasks, simplifying future pipelines. Our findings offer practical guidelines for evaluating generative models on microscopy data and support the use of off-the-shelf models in phenotypic drug discovery. [SEP] [HINT] molecular -> Bioinformatics (Syns: ) | datasets -> Bioinformatics (Syns: ) | performance -> Bioinformatics (Syns: functioning, operation, carrying out)",Bioinformatics
"We compute valley splittings in Si/SiGe superlattices using ab initio density functional theory (DFT). This first-principle approach is expected to provide an excellent description of interfaces, strains, and atomistic disorder without empirically fitted parameters. We benchmark atomistic tight- binding (TB) and the ``$2k_0$'' theory within the effective mass (EM) approximation against DFT. We show that DFT supports the main conclusions of the 2$k_0$ theory, but reveals some limitations of semi-empirical methods such as the EM and TB, in particular about the description of atomistic disorder. The DFT calculations also highlight the effects of strong valley-orbit mixing at large valley splittings. Nevertheless, TB and the 2$k_0$ theory shall provide reasonable valley splitting statistics in many heterostructures of interest for spin qubit devices.",Materials Science
"We compute valley splittings in Si/SiGe superlattices using ab initio density functional theory (DFT). This first-principle approach is expected to provide an excellent description of interfaces, strains, and atomistic disorder without empirically fitted parameters. We benchmark atomistic tight- binding (TB) and the ``$2k_0$'' theory within the effective mass (EM) approximation against DFT. We show that DFT supports the main conclusions of the 2$k_0$ theory, but reveals some limitations of semi-empirical methods such as the EM and TB, in particular about the description of atomistic disorder. The DFT calculations also highlight the effects of strong valley-orbit mixing at large valley splittings. Nevertheless, TB and the 2$k_0$ theory shall provide reasonable valley splitting statistics in many heterostructures of interest for spin qubit devices. [SEP] [HINT] dft -> Materials Science (Syns: ) | spin -> Materials Science (Syns: twisting, whirl, tailspin) | functional -> Neuroscience (Syns: working, usable, running)",Materials Science
"Despite their electronic dominance, cubic diamond structured Si and Ge, are optoelectronically deficient. Recent work indicates, however, that a volume-expanded hexagonal Ge modification can exhibit intensely sought, superior optoelectronic characteristics. If larger Sn could form a hexagonal solid solution with Ge, this would achieve this expansion. But this was not expected because Ge and Sn are unreactive at ambient conditions, Sn does not have an ambient hexagonal symmetry, and only cubic or tetragonal binary modifications could be prepared under any conditions including thin film processing. This state of affairs is categorically changed here by subjecting Ge and Sn to pressures of 9 and 10 GPa and temperatures up to 1500 K using large-volume press methods. Synchrotron angle-dispersive X-ray diffraction, precession electron diffraction and chemical analysis using electron microscopy reveal ambient pressure recovery of hexagonal 2H, 4H and 6H Ge-Sn solid solutions (P63/mmc). Formation of this new binary materials landscape is correlated with Sn uptake, with the hexagonal symmetry being accessible below 21 atom % Sn and the cubic diamond symmetry at or above this value. The findings form fertile routes to advanced materials, by in tandem creating reactivity with pressure and directing production of needed crystal symmetries with composition, as well as opportunity to tune properties based on crystal symmetry, composition, and stacking sequence for optoelectronic applications. PubMed Disclaimer",Materials Science
"Despite their electronic dominance, cubic diamond structured Si and Ge, are optoelectronically deficient. Recent work indicates, however, that a volume-expanded hexagonal Ge modification can exhibit intensely sought, superior optoelectronic characteristics. If larger Sn could form a hexagonal solid solution with Ge, this would achieve this expansion. But this was not expected because Ge and Sn are unreactive at ambient conditions, Sn does not have an ambient hexagonal symmetry, and only cubic or tetragonal binary modifications could be prepared under any conditions including thin film processing. This state of affairs is categorically changed here by subjecting Ge and Sn to pressures of 9 and 10 GPa and temperatures up to 1500 K using large-volume press methods. Synchrotron angle-dispersive X-ray diffraction, precession electron diffraction and chemical analysis using electron microscopy reveal ambient pressure recovery of hexagonal 2H, 4H and 6H Ge-Sn solid solutions (P63/mmc). Formation of this new binary materials landscape is correlated with Sn uptake, with the hexagonal symmetry being accessible below 21 atom % Sn and the cubic diamond symmetry at or above this value. The findings form fertile routes to advanced materials, by in tandem creating reactivity with pressure and directing production of needed crystal symmetries with composition, as well as opportunity to tune properties based on crystal symmetry, composition, and stacking sequence for optoelectronic applications. PubMed Disclaimer [SEP] [HINT] based -> Bioinformatics (Syns: ground, free-base, base) | electronic -> Materials Science (Syns: ) | electron -> Materials Science (Syns: negatron)",Materials Science
"Understanding the interactions between strain, interfacial mechanics, and electrical performance is critical for designing beyond silicon electronics based on hetero-integrated 2D materials. Through combined experiment and simulation, we demonstrated and analyzed the enhancement of hole mobility in p-type monolayer $WSe_{2}$ field effect transistors (FETs) under biaxial compression. We tracked FET performance versus strain by incrementing compressive strain to $WSe_{2}$ channels via sequential AlOx deposition and performing intermediate photoluminescence and transport measurements. The hole mobility factor increased at a rate of 340 $\pm$ 95 %/%$ε$, and the on-current factor increased at a rate of 460 $\pm$ 340 %/%$ε$. Simulation revealed that the enhancement under compression arises primarily from a reduction in inter-valley scattering between the $Γ$--K valence bands, and the rate is robust against variations in carrier density, impurity density, or dielectric environment. These findings show that compressive strain is a powerful technique for enhancing performance in 2D p-FETs and that it is multiplicative with defect and doping engineering.",Materials Science
"Understanding the interactions between strain, interfacial mechanics, and electrical performance is critical for designing beyond silicon electronics based on hetero-integrated 2D materials. Through combined experiment and simulation, we demonstrated and analyzed the enhancement of hole mobility in p-type monolayer $WSe_{2}$ field effect transistors (FETs) under biaxial compression. We tracked FET performance versus strain by incrementing compressive strain to $WSe_{2}$ channels via sequential AlOx deposition and performing intermediate photoluminescence and transport measurements. The hole mobility factor increased at a rate of 340 $\pm$ 95 %/%$ε$, and the on-current factor increased at a rate of 460 $\pm$ 340 %/%$ε$. Simulation revealed that the enhancement under compression arises primarily from a reduction in inter-valley scattering between the $Γ$--K valence bands, and the rate is robust against variations in carrier density, impurity density, or dielectric environment. These findings show that compressive strain is a powerful technique for enhancing performance in 2D p-FETs and that it is multiplicative with defect and doping engineering. [SEP] [HINT] field -> Materials Science (Syns: field of honor, line of business, orbit) | based -> Bioinformatics (Syns: ground, free-base, base) | understanding -> Neuroscience (Syns: savvy, intellect, sympathy)",Materials Science
"Atomically precise metal nanoclusters bridge the molecular and bulk regimes, but designing bimetallic motifs with targeted stability and reactivity remains challenging. Here we combine density functional theory (DFT) and physics-grounded predictive artificial intelligence to map the configurational landscape of 13-atom icosahedral nanoclusters X$_{12}$TM, with hosts X = (Ti, Zr, Hf), and Fe and a single transition--metal dopant spanning the 3$d$-5$d$ series. Spin-polarized DFT calculations on 240 bimetallic clusters reveal systematic trends in binding and formation energies, distortion penalties, effective coordination number, d-band centre, and HOMO-LUMO gap that govern the competition between core-shell (in) and surface-segregated (out) arrangements. We then pretrain a transformer architecture on a curated set of 2968 unary clusters from the Quantum Cluster Database and fine-tune it on bimetallic data to predict formation energies and in/out preference, achieving mean absolute errors of about $0.6-0.7$eV and calibrated uncertainty intervals. The resulting model rapidly adapts to an unseen Fe-host domain with only a handful of labelled examples. At the same time, attention patterns and Shapley attributions highlight size mismatch, $d$-electron count, and coordination environment as key descriptors. All data, code, and workflows follow FAIR/TRUE principles, enabling reproducible, interpretable screening of unexplored nanocluster chemistries for catalysis and energy conversion.",Materials Science
"Atomically precise metal nanoclusters bridge the molecular and bulk regimes, but designing bimetallic motifs with targeted stability and reactivity remains challenging. Here we combine density functional theory (DFT) and physics-grounded predictive artificial intelligence to map the configurational landscape of 13-atom icosahedral nanoclusters X$_{12}$TM, with hosts X = (Ti, Zr, Hf), and Fe and a single transition--metal dopant spanning the 3$d$-5$d$ series. Spin-polarized DFT calculations on 240 bimetallic clusters reveal systematic trends in binding and formation energies, distortion penalties, effective coordination number, d-band centre, and HOMO-LUMO gap that govern the competition between core-shell (in) and surface-segregated (out) arrangements. We then pretrain a transformer architecture on a curated set of 2968 unary clusters from the Quantum Cluster Database and fine-tune it on bimetallic data to predict formation energies and in/out preference, achieving mean absolute errors of about $0.6-0.7$eV and calibrated uncertainty intervals. The resulting model rapidly adapts to an unseen Fe-host domain with only a handful of labelled examples. At the same time, attention patterns and Shapley attributions highlight size mismatch, $d$-electron count, and coordination environment as key descriptors. All data, code, and workflows follow FAIR/TRUE principles, enabling reproducible, interpretable screening of unexplored nanocluster chemistries for catalysis and energy conversion. [SEP] [HINT] dft -> Materials Science (Syns: ) | functional -> Neuroscience (Syns: working, usable, running) | molecular -> Bioinformatics (Syns: )",Materials Science
"Artificial intelligence (AI) has drawn significant inspiration from neuroscience to develop artificial neural network (ANN) models. However, these models remain constrained by the Von Neumann architecture and struggle to capture the complexity of the biological brain. Quantum computing, with its foundational principles of superposition, entanglement, and unitary evolution, offers a promising alternative approach to modeling neural dynamics. This paper explores the possibility of a neuro-quantum model of the brain by introducing a stochastic quantum approach that incorporates random fluctuations of neuronal processing within a quantum framework. We propose a mathematical formalization of stochastic quantum neural networks (QNNS), where qubits evolve according to stochastic differential equations inspired by biological neuronal processes. We also discuss challenges related to decoherence, qubit stability, and implications for AI and computational neuroscience.",Neuroscience
"Artificial intelligence (AI) has drawn significant inspiration from neuroscience to develop artificial neural network (ANN) models. However, these models remain constrained by the Von Neumann architecture and struggle to capture the complexity of the biological brain. Quantum computing, with its foundational principles of superposition, entanglement, and unitary evolution, offers a promising alternative approach to modeling neural dynamics. This paper explores the possibility of a neuro-quantum model of the brain by introducing a stochastic quantum approach that incorporates random fluctuations of neuronal processing within a quantum framework. We propose a mathematical formalization of stochastic quantum neural networks (QNNS), where qubits evolve according to stochastic differential equations inspired by biological neuronal processes. We also discuss challenges related to decoherence, qubit stability, and implications for AI and computational neuroscience. [SEP] [HINT] computational -> Neuroscience (Syns: ) | networks -> Neuroscience (Syns: network, meshwork, electronic network) | processing -> Neuroscience (Syns: work, process, march)",Neuroscience
"Neural activity forecasting is central to understanding neural systems and enabling closed-loop control. While deep learning has recently advanced the state-of-the-art in the time series forecasting literature, its application to neural activity forecasting remains limited. To bridge this gap, we systematically evaluated eight probabilistic deep learning models, including two foundation models, that have demonstrated strong performance on general forecasting benchmarks. We compared them against four classical statistical models and two baseline methods on spontaneous neural activity recorded from mouse cortex via widefield imaging. Across prediction horizons, several deep learning models consistently outperformed classical approaches, with the best model producing informative forecasts up to 1.5 seconds into the future. Our findings point toward future control applications and open new avenues for probing the intrinsic temporal structure of neural activity.",Neuroscience
"Neural activity forecasting is central to understanding neural systems and enabling closed-loop control. While deep learning has recently advanced the state-of-the-art in the time series forecasting literature, its application to neural activity forecasting remains limited. To bridge this gap, we systematically evaluated eight probabilistic deep learning models, including two foundation models, that have demonstrated strong performance on general forecasting benchmarks. We compared them against four classical statistical models and two baseline methods on spontaneous neural activity recorded from mouse cortex via widefield imaging. Across prediction horizons, several deep learning models consistently outperformed classical approaches, with the best model producing informative forecasts up to 1.5 seconds into the future. Our findings point toward future control applications and open new avenues for probing the intrinsic temporal structure of neural activity. [SEP] [HINT] understanding -> Neuroscience (Syns: savvy, intellect, sympathy) | learning -> Bioinformatics (Syns: take, teach, acquire) | structure -> Bioinformatics (Syns: social system, complex body part, social structure)",Neuroscience
"Inspired by key neuroscience principles, deep learning has driven exponential breakthroughs in developing functional models of perception and other cognitive processes. A key to this success has been the implementation of crucial features found in biological neural networks: neurons as units of information transfer, non-linear activation functions that enable general function approximation, and complex architectures vital for attentional processes. However, standard deep learning models rely on biologically implausible error propagation algorithms and struggle to accumulate knowledge incrementally. While, the precise learning rule governing synaptic plasticity in biological systems remains unknown, recent discoveries in neuroscience could fuel further progress in AI. Here I examine successful implementations of brain-inspired principles in deep learning, current limitations, and promising avenues inspired by recent advances in neuroscience, including error computation, propagation, and integration via synaptic updates in biological neural networks.",Neuroscience
"Inspired by key neuroscience principles, deep learning has driven exponential breakthroughs in developing functional models of perception and other cognitive processes. A key to this success has been the implementation of crucial features found in biological neural networks: neurons as units of information transfer, non-linear activation functions that enable general function approximation, and complex architectures vital for attentional processes. However, standard deep learning models rely on biologically implausible error propagation algorithms and struggle to accumulate knowledge incrementally. While, the precise learning rule governing synaptic plasticity in biological systems remains unknown, recent discoveries in neuroscience could fuel further progress in AI. Here I examine successful implementations of brain-inspired principles in deep learning, current limitations, and promising avenues inspired by recent advances in neuroscience, including error computation, propagation, and integration via synaptic updates in biological neural networks. [SEP] [HINT] features -> Bioinformatics (Syns: characteristic, lineament, feature of speech) | learning -> Bioinformatics (Syns: take, teach, acquire) | functional -> Neuroscience (Syns: working, usable, running)",Neuroscience
"Integrated information theory (IIT) starts from the existence of consciousness and characterizes its essential properties: every experience is intrinsic, specific, unitary, definite, and structured. IIT then formulates existence and its essential properties operationally in terms of cause-effect power of a substrate of units. Here we address IIT's operational requirements for existence by considering that, to have cause-effect power, to have it intrinsically, and to have it specifically, substrate units in their actual state must both (i) ensure the intrinsic availability of a repertoire of cause-effect states, and (ii) increase the probability of a specific cause-effect state. We showed previously that requirement (ii) can be assessed by the intrinsic difference of a state's probability from maximal differentiation. Here we show that requirement (i) can be assessed by the intrinsic difference from maximal specification. These points and their consequences for integrated information are illustrated using simple systems of micro units. When applied to macro units and systems of macro units such as neural systems, a tradeoff between differentiation and specification is a necessary condition for intrinsic existence, i.e., for consciousness.",Neuroscience
"Integrated information theory (IIT) starts from the existence of consciousness and characterizes its essential properties: every experience is intrinsic, specific, unitary, definite, and structured. IIT then formulates existence and its essential properties operationally in terms of cause-effect power of a substrate of units. Here we address IIT's operational requirements for existence by considering that, to have cause-effect power, to have it intrinsically, and to have it specifically, substrate units in their actual state must both (i) ensure the intrinsic availability of a repertoire of cause-effect states, and (ii) increase the probability of a specific cause-effect state. We showed previously that requirement (ii) can be assessed by the intrinsic difference of a state's probability from maximal differentiation. Here we show that requirement (i) can be assessed by the intrinsic difference from maximal specification. These points and their consequences for integrated information are illustrated using simple systems of micro units. When applied to macro units and systems of macro units such as neural systems, a tradeoff between differentiation and specification is a necessary condition for intrinsic existence, i.e., for consciousness. [SEP] [HINT] information -> Bioinformatics (Syns: entropy, data, info) | systems -> Bioinformatics (Syns: organization, organisation, system) | using -> Bioinformatics (Syns: utilize, exploitation, apply)",Neuroscience
"Earth's gravity has fundamentally shaped human development by guiding the brain's integration of vestibular, visual, and proprioceptive inputs into an internal model of gravity: a dynamic neural representation enabling prediction and interpretation of gravitational forces. This work presents a dual computational framework to quantitatively model these adaptations. The first component is a lightweight Multi-Layer Perceptron (MLP) that predicts g-load-dependent changes in key electroencephalographic (EEG) frequency bands, representing the brain's cortical state. The second component utilizes a suite of independent Gaussian Processes (GPs) to model the body's broader physiological state, including Heart Rate Variability (HRV), Electrodermal Activity (EDA), and motor behavior. Both models were trained on data derived from a comprehensive review of parabolic flight literature, using published findings as anchor points to construct robust, continuous functions. To complement this quantitative analysis, we simulated subjective human experience under different gravitational loads, ranging from microgravity (0g) and partial gravity (Moon 0.17g, Mars 0.38g) to hypergravity associated with spacecraft launch and re-entry (1.8g), using a large language model (Claude 3.5 Sonnet). The model was prompted with physiological parameters to generate introspective narratives of alertness and self-awareness, which closely aligned with the quantitative findings from both the EEG and physiological models. This combined framework integrates quantitative physiological modeling with generative cognitive simulation, offering a novel approach to understanding and predicting human performance in altered gravity",Neuroscience
"Earth's gravity has fundamentally shaped human development by guiding the brain's integration of vestibular, visual, and proprioceptive inputs into an internal model of gravity: a dynamic neural representation enabling prediction and interpretation of gravitational forces. This work presents a dual computational framework to quantitatively model these adaptations. The first component is a lightweight Multi-Layer Perceptron (MLP) that predicts g-load-dependent changes in key electroencephalographic (EEG) frequency bands, representing the brain's cortical state. The second component utilizes a suite of independent Gaussian Processes (GPs) to model the body's broader physiological state, including Heart Rate Variability (HRV), Electrodermal Activity (EDA), and motor behavior. Both models were trained on data derived from a comprehensive review of parabolic flight literature, using published findings as anchor points to construct robust, continuous functions. To complement this quantitative analysis, we simulated subjective human experience under different gravitational loads, ranging from microgravity (0g) and partial gravity (Moon 0.17g, Mars 0.38g) to hypergravity associated with spacecraft launch and re-entry (1.8g), using a large language model (Claude 3.5 Sonnet). The model was prompted with physiological parameters to generate introspective narratives of alertness and self-awareness, which closely aligned with the quantitative findings from both the EEG and physiological models. This combined framework integrates quantitative physiological modeling with generative cognitive simulation, offering a novel approach to understanding and predicting human performance in altered gravity [SEP] [HINT] computational -> Neuroscience (Syns: ) | language -> Neuroscience (Syns: linguistic process, linguistic communication, spoken communication) | understanding -> Neuroscience (Syns: savvy, intellect, sympathy)",Neuroscience
"Current atlas-based approaches to brain network analysis rely heavily on standardized anatomical or connectivity-driven brain atlases. However, these fixed atlases often introduce significant limitations, such as spatial misalignment across individuals, functional heterogeneity within predefined regions, and atlas-selection biases, collectively undermining the reliability and interpretability of the derived brain networks. To address these challenges, we propose a novel atlas-free brain network transformer (atlas-free BNT) that leverages individualized brain parcellations derived directly from subject-specific resting-state fMRI data. Our approach computes ROI-to-voxel connectivity features in a standardized voxel-based feature space, which are subsequently processed using the BNT architecture to produce comparable subject-level embeddings. Experimental evaluations on sex classification and brain-connectome age prediction tasks demonstrate that our atlas-free BNT consistently outperforms state-of-the-art atlas-based methods, including elastic net, BrainGNN, Graphormer and the original BNT. Our atlas-free approach significantly improves the precision, robustness, and generalizability of brain network analyses. This advancement holds great potential to enhance neuroimaging biomarkers and clinical diagnostic tools for personalized precision medicine.",Neuroscience
"Current atlas-based approaches to brain network analysis rely heavily on standardized anatomical or connectivity-driven brain atlases. However, these fixed atlases often introduce significant limitations, such as spatial misalignment across individuals, functional heterogeneity within predefined regions, and atlas-selection biases, collectively undermining the reliability and interpretability of the derived brain networks. To address these challenges, we propose a novel atlas-free brain network transformer (atlas-free BNT) that leverages individualized brain parcellations derived directly from subject-specific resting-state fMRI data. Our approach computes ROI-to-voxel connectivity features in a standardized voxel-based feature space, which are subsequently processed using the BNT architecture to produce comparable subject-level embeddings. Experimental evaluations on sex classification and brain-connectome age prediction tasks demonstrate that our atlas-free BNT consistently outperforms state-of-the-art atlas-based methods, including elastic net, BrainGNN, Graphormer and the original BNT. Our atlas-free approach significantly improves the precision, robustness, and generalizability of brain network analyses. This advancement holds great potential to enhance neuroimaging biomarkers and clinical diagnostic tools for personalized precision medicine. [SEP] [HINT] connectivity -> Neuroscience (Syns: ) | tasks -> Neuroscience (Syns: tax, task, project) | clinical -> Bioinformatics (Syns: )",Neuroscience
"EEG-based Brain-Computer Interfaces (BCIs) frequently face spatial specificity limitations in detecting single-trial P300 potentials, a neurophysiological hallmark leveraged for both BCI control and neurodegenerative disease diagnostics. We present a novel framework combining eLORETA source localization with cross-subject functional connectivity to identify stable regions of interest (ROIs) across sessions. Analyzing 62-channel EEG data from 31 subjects (63 sessions, 2,520 trials), we demonstrate that phase-lagged connectivity metrics can reliably isolate task-relevant hubs in deeper cortical-subcortical structures like the insula and parietal regions - critical for Alzheimer's disease biomarkers. By integrating spatially stable ROIs with dynamic temporal agreement, our hybrid classification systematically outperforms whole-brain approaches in different frequency bands (up to 5.4% depending on the connectivity method and the spectral range) while maintaining millisecond-level temporal precision.   To the best of our knowledge, this is the first study to establish cross-subject ROI consensus through source-space connectivity, bypassing scalp EEG's depth constraints to probe Alzheimer's-relevant networks. The framework's robustness to noise and compatibility with portable systems offer significant potential for global deployment in early neurodegenerative disease detection. Future integration of individualized anatomical data or adaptive parameter optimization could refine this tool for clinical deployment, enhancing the current max accuracy of 81.57% in the 1-15 Hz range.",Bioinformatics
"EEG-based Brain-Computer Interfaces (BCIs) frequently face spatial specificity limitations in detecting single-trial P300 potentials, a neurophysiological hallmark leveraged for both BCI control and neurodegenerative disease diagnostics. We present a novel framework combining eLORETA source localization with cross-subject functional connectivity to identify stable regions of interest (ROIs) across sessions. Analyzing 62-channel EEG data from 31 subjects (63 sessions, 2,520 trials), we demonstrate that phase-lagged connectivity metrics can reliably isolate task-relevant hubs in deeper cortical-subcortical structures like the insula and parietal regions - critical for Alzheimer's disease biomarkers. By integrating spatially stable ROIs with dynamic temporal agreement, our hybrid classification systematically outperforms whole-brain approaches in different frequency bands (up to 5.4% depending on the connectivity method and the spectral range) while maintaining millisecond-level temporal precision.   To the best of our knowledge, this is the first study to establish cross-subject ROI consensus through source-space connectivity, bypassing scalp EEG's depth constraints to probe Alzheimer's-relevant networks. The framework's robustness to noise and compatibility with portable systems offer significant potential for global deployment in early neurodegenerative disease detection. Future integration of individualized anatomical data or adaptive parameter optimization could refine this tool for clinical deployment, enhancing the current max accuracy of 81.57% in the 1-15 Hz range. [SEP] [HINT] connectivity -> Neuroscience (Syns: ) | clinical -> Bioinformatics (Syns: ) | functional -> Neuroscience (Syns: working, usable, running)",Bioinformatics
"The objective of this work is to deconvolute the interaction of slip, twinning, and notch on the deformation response of an austenitic manganese (Hadfield) steel using detailed finite element simulations. The simulations employ a rate-dependent crystal plasticity constitutive model that incorporates both slip and twinning deformation mechanisms. The model accounts for the spatially non-uniform appearance of new twin-related orientations, hardening due to slip--twin interactions, and modified properties of the twinned crystal. Limited experiments on single-crystal dog-bone and single-edge notch specimens, with two crystal orientations, are also conducted to aid the simulation. Several features of the experimental observations are accurately captured in the simulations. For example, simulations accurately capture distinct stress--strain responses associated with different crystallographic orientations, including variations in initial hardening behavior followed by either decreasing or increasing hardening depending on the dominant deformation mechanisms. The simulation also captures the observed orientation-dependent asymmetric deformation of the notch in single-edge notch specimens. Additionally, by selectively activating deformation mechanisms, the role of twinning is isolated and its influence on both global and local response is clearly demonstrated. These results provide a mechanistic understanding of how deformation mode interactions and local geometry (i.e., notch) influence the response of these materials.",Materials Science
"The objective of this work is to deconvolute the interaction of slip, twinning, and notch on the deformation response of an austenitic manganese (Hadfield) steel using detailed finite element simulations. The simulations employ a rate-dependent crystal plasticity constitutive model that incorporates both slip and twinning deformation mechanisms. The model accounts for the spatially non-uniform appearance of new twin-related orientations, hardening due to slip--twin interactions, and modified properties of the twinned crystal. Limited experiments on single-crystal dog-bone and single-edge notch specimens, with two crystal orientations, are also conducted to aid the simulation. Several features of the experimental observations are accurately captured in the simulations. For example, simulations accurately capture distinct stress--strain responses associated with different crystallographic orientations, including variations in initial hardening behavior followed by either decreasing or increasing hardening depending on the dominant deformation mechanisms. The simulation also captures the observed orientation-dependent asymmetric deformation of the notch in single-edge notch specimens. Additionally, by selectively activating deformation mechanisms, the role of twinning is isolated and its influence on both global and local response is clearly demonstrated. These results provide a mechanistic understanding of how deformation mode interactions and local geometry (i.e., notch) influence the response of these materials. [SEP] [HINT] features -> Bioinformatics (Syns: characteristic, lineament, feature of speech) | understanding -> Neuroscience (Syns: savvy, intellect, sympathy) | work -> Bioinformatics (Syns: work out, process, bring)",Materials Science
"Trigonal solid-state defects are often subjects of spontaneous symmetry breaking driven by the $E\otimes e$ Jahn-Teller effect, reflecting strong electron-phonon coupling. These systems, particularly paramagnetic defect qubits in solids are central for quantum technology applications, where accurate knowledge of their fine-structure parameters $-$ shaped by the complex interplay of spin-orbit and electron-phonon interactions $-$ is essential. We introduce the $\mathtt{Exe.py}$ code part of the $\mathtt{jahn {\text -} teller {\text -} dynamics}$ package, a Python code that implements the first-principles approach of [Phys. Rev. X 8, 021063 (2018)] to accurately compute the spin-orbit-phonon entanglement in trigonal defects utilizing the output from density functional theory calculations (DFT). By employing $Δ$SCF calculations, the method extends naturally to excited states and predicts fine-structure parameters of zero-phonon lines (ZPLs), including Zeeman shifts under external magnetic fields. The approach is applicable not only to solid-state defects but also to Jahn-Teller active trigonal molecules such as the $X$CH$_3$ family. We demonstrate the capabilities of Exe.py through applications to negatively charged Group-IV$-$vacancy (G4V) defects in diamond: SiV$^-$, GeV$^-$, SnV$^-$, PbV$^-$ and the neutral N$_3$V$^0$ defect in diamond, and the CH$_3$O methoxy molecule.",Materials Science
"Trigonal solid-state defects are often subjects of spontaneous symmetry breaking driven by the $E\otimes e$ Jahn-Teller effect, reflecting strong electron-phonon coupling. These systems, particularly paramagnetic defect qubits in solids are central for quantum technology applications, where accurate knowledge of their fine-structure parameters $-$ shaped by the complex interplay of spin-orbit and electron-phonon interactions $-$ is essential. We introduce the $\mathtt{Exe.py}$ code part of the $\mathtt{jahn {\text -} teller {\text -} dynamics}$ package, a Python code that implements the first-principles approach of [Phys. Rev. X 8, 021063 (2018)] to accurately compute the spin-orbit-phonon entanglement in trigonal defects utilizing the output from density functional theory calculations (DFT). By employing $Δ$SCF calculations, the method extends naturally to excited states and predicts fine-structure parameters of zero-phonon lines (ZPLs), including Zeeman shifts under external magnetic fields. The approach is applicable not only to solid-state defects but also to Jahn-Teller active trigonal molecules such as the $X$CH$_3$ family. We demonstrate the capabilities of Exe.py through applications to negatively charged Group-IV$-$vacancy (G4V) defects in diamond: SiV$^-$, GeV$^-$, SnV$^-$, PbV$^-$ and the neutral N$_3$V$^0$ defect in diamond, and the CH$_3$O methoxy molecule. [SEP] [HINT] defect -> Materials Science (Syns: mar, shortcoming, fault) | functional -> Neuroscience (Syns: working, usable, running) | complex -> Bioinformatics (Syns: building complex, coordination compound, composite)",Materials Science
"Brain stimulation is a powerful tool for understanding cortical function and holds promise for therapeutic interventions in neuropsychiatric disorders. Initial visual prosthetics apply electric microstimulation to early visual cortex which can evoke percepts of simple symbols such as letters. However, these approaches are fundamentally limited by hardware constraints and the low-level representational properties of this cortical region. In contrast, higher-level visual areas encode more complex object representations and therefore constitute a promising target for stimulation - but determining representational targets that reliably evoke object-level percepts constitutes a major challenge. We here introduce a computational framework to causally model and guide stimulation of high-level cortex, comprising three key components: (1) a perturbation module that translates microstimulation parameters into spatial changes to neural activity, (2) topographic models that capture the spatial organization of cortical neurons and thus enable prototyping of stimulation experiments, and (3) a mapping procedure that links model-optimized stimulation sites back to primate cortex. Applying this framework in two macaque monkeys performing a visual recognition task, model-predicted stimulation experiments produced significant in-vivo changes in perceptual choices. Per-site model predictions and monkey behavior were strongly correlated, underscoring the promise of model-guided stimulation. Image generation further revealed a qualitative similarity between in-silico stimulation of face-selective sites and a patient's report of facephenes. This proof-of-principle establishes a foundation for model-guided microstimulation and points toward next-generation visual prosthetics capable of inducing more complex visual experiences.",Neuroscience
"Brain stimulation is a powerful tool for understanding cortical function and holds promise for therapeutic interventions in neuropsychiatric disorders. Initial visual prosthetics apply electric microstimulation to early visual cortex which can evoke percepts of simple symbols such as letters. However, these approaches are fundamentally limited by hardware constraints and the low-level representational properties of this cortical region. In contrast, higher-level visual areas encode more complex object representations and therefore constitute a promising target for stimulation - but determining representational targets that reliably evoke object-level percepts constitutes a major challenge. We here introduce a computational framework to causally model and guide stimulation of high-level cortex, comprising three key components: (1) a perturbation module that translates microstimulation parameters into spatial changes to neural activity, (2) topographic models that capture the spatial organization of cortical neurons and thus enable prototyping of stimulation experiments, and (3) a mapping procedure that links model-optimized stimulation sites back to primate cortex. Applying this framework in two macaque monkeys performing a visual recognition task, model-predicted stimulation experiments produced significant in-vivo changes in perceptual choices. Per-site model predictions and monkey behavior were strongly correlated, underscoring the promise of model-guided stimulation. Image generation further revealed a qualitative similarity between in-silico stimulation of face-selective sites and a patient's report of facephenes. This proof-of-principle establishes a foundation for model-guided microstimulation and points toward next-generation visual prosthetics capable of inducing more complex visual experiences. [SEP] [HINT] computational -> Neuroscience (Syns: ) | understanding -> Neuroscience (Syns: savvy, intellect, sympathy) | cortical -> Neuroscience (Syns: )",Neuroscience
"Functional brain networks exhibit topological structures that reflect neural organization; however, statistical comparison of these networks is challenging for several reasons. This paper introduces a topologically invariant permutation test for detecting topological inequivalence. Under topological equivalence, topological features can be permuted separately between groups without distorting individual network structures. The test statistic uses $2$-Wasserstein distances on persistent diagrams, computed in closed form. To reduce variability in brain connectivities while preserving topology, heat kernel expansion on the Hodge Laplacian is applied with bandwidth $t$ controlling diffusion intensity. Theoretical results guarantee variance reduction through optimal Hilbert space projection. Simulations across diverse network topologies show superior performance compared to conventional two-sample tests and alternative metrics. Applied to resting-state fMRI data from the Multimodal Treatment of ADHD study, the method detects significant topological differences between cannabis users and non-users.",Neuroscience
"Functional brain networks exhibit topological structures that reflect neural organization; however, statistical comparison of these networks is challenging for several reasons. This paper introduces a topologically invariant permutation test for detecting topological inequivalence. Under topological equivalence, topological features can be permuted separately between groups without distorting individual network structures. The test statistic uses $2$-Wasserstein distances on persistent diagrams, computed in closed form. To reduce variability in brain connectivities while preserving topology, heat kernel expansion on the Hodge Laplacian is applied with bandwidth $t$ controlling diffusion intensity. Theoretical results guarantee variance reduction through optimal Hilbert space projection. Simulations across diverse network topologies show superior performance compared to conventional two-sample tests and alternative metrics. Applied to resting-state fMRI data from the Multimodal Treatment of ADHD study, the method detects significant topological differences between cannabis users and non-users. [SEP] [HINT] features -> Bioinformatics (Syns: characteristic, lineament, feature of speech) | networks -> Neuroscience (Syns: network, meshwork, electronic network) | space -> Neuroscience (Syns: distance, place, outer space)",Neuroscience
"Transition metal oxides exhibit a wide range of tunable electronic properties arising from the complex interplay of charge, spin, and lattice degrees of freedom, governed by their $d$ orbital configurations, making them particularly interesting for oxide electronics and (electro)catalysis. Perovskite oxide heterointerfaces offer a promising route to engineer these orbital states. In this work, we tune the Co $3d$ orbital occupancy in LaCoO$_3$ from a partial $d^7$ to a partial $d^5$ state through interfacial engineering with LaTiO$_3$, LaMnO$_3$, LaAlO$_3$ and LaNiO$_3$. Using X-ray absorption spectroscopy combined with charge transfer multiplet calculations, we identify differences in the Co valence and spin state for the series of oxide heterostructures. LaTiO$_3$ and LaMnO$_3$ interfaces result in interfacial charge transfer towards LaCoO$_3$, resulting in a partial $d^7$ orbital occupancy, while a LaNiO$_3$ interface results in a partial Co $d^5$ occupancy. Strikingly, a LaAlO$_3$ spacer layer between LaNiO$_3$ and LaCoO$_3$ results in a Co $d^6$ low spin state. These results indicate that the Co spin state, like the valence state, is governed by the interfacial environment. High-resolution scanning transmission electron microscopy imaging reveals a clear connection between strain and spin configuration, emphasizing the importance of structural control at oxide interfaces. Overall, this work demonstrates that interfacial engineering simultaneously governs orbital occupancy and spin state in correlated oxides, advancing spin-engineering strategies in correlated oxides and offering new insights for the rational design of functional oxide heterostructures.",Materials Science
"Transition metal oxides exhibit a wide range of tunable electronic properties arising from the complex interplay of charge, spin, and lattice degrees of freedom, governed by their $d$ orbital configurations, making them particularly interesting for oxide electronics and (electro)catalysis. Perovskite oxide heterointerfaces offer a promising route to engineer these orbital states. In this work, we tune the Co $3d$ orbital occupancy in LaCoO$_3$ from a partial $d^7$ to a partial $d^5$ state through interfacial engineering with LaTiO$_3$, LaMnO$_3$, LaAlO$_3$ and LaNiO$_3$. Using X-ray absorption spectroscopy combined with charge transfer multiplet calculations, we identify differences in the Co valence and spin state for the series of oxide heterostructures. LaTiO$_3$ and LaMnO$_3$ interfaces result in interfacial charge transfer towards LaCoO$_3$, resulting in a partial $d^7$ orbital occupancy, while a LaNiO$_3$ interface results in a partial Co $d^5$ occupancy. Strikingly, a LaAlO$_3$ spacer layer between LaNiO$_3$ and LaCoO$_3$ results in a Co $d^6$ low spin state. These results indicate that the Co spin state, like the valence state, is governed by the interfacial environment. High-resolution scanning transmission electron microscopy imaging reveals a clear connection between strain and spin configuration, emphasizing the importance of structural control at oxide interfaces. Overall, this work demonstrates that interfacial engineering simultaneously governs orbital occupancy and spin state in correlated oxides, advancing spin-engineering strategies in correlated oxides and offering new insights for the rational design of functional oxide heterostructures. [SEP] [HINT] transition -> Materials Science (Syns: passage, modulation, changeover) | low -> Materials Science (Syns: low-spirited, scurvy, depressed) | spin -> Materials Science (Syns: twisting, whirl, tailspin)",Materials Science
"Foundation models have shown remarkable success in fitting biological visual systems; however, their black-box nature inherently limits their utility for understanding brain function. Here, we peek inside a SOTA foundation model of neural activity (Wang et al., 2025) as a physiologist might, characterizing each 'neuron' based on its temporal response properties to parametric stimuli. We analyze how different stimuli are represented in neural activity space by building decoding manifolds, and we analyze how different neurons are represented in stimulus-response space by building neural encoding manifolds. We find that the different processing stages of the model (i.e., the feedforward encoder, recurrent, and readout modules) each exhibit qualitatively different representational structures in these manifolds. The recurrent module shows a jump in capabilities over the encoder module by 'pushing apart' the representations of different temporal stimulus patterns; while the readout module achieves biological fidelity by using numerous specialized feature maps rather than biologically plausible mechanisms. Overall, we present this work as a study of the inner workings of a prominent neural foundation model, gaining insights into the biological relevance of its internals through the novel analysis of its neurons' joint temporal response patterns.",Neuroscience
"Foundation models have shown remarkable success in fitting biological visual systems; however, their black-box nature inherently limits their utility for understanding brain function. Here, we peek inside a SOTA foundation model of neural activity (Wang et al., 2025) as a physiologist might, characterizing each 'neuron' based on its temporal response properties to parametric stimuli. We analyze how different stimuli are represented in neural activity space by building decoding manifolds, and we analyze how different neurons are represented in stimulus-response space by building neural encoding manifolds. We find that the different processing stages of the model (i.e., the feedforward encoder, recurrent, and readout modules) each exhibit qualitatively different representational structures in these manifolds. The recurrent module shows a jump in capabilities over the encoder module by 'pushing apart' the representations of different temporal stimulus patterns; while the readout module achieves biological fidelity by using numerous specialized feature maps rather than biologically plausible mechanisms. Overall, we present this work as a study of the inner workings of a prominent neural foundation model, gaining insights into the biological relevance of its internals through the novel analysis of its neurons' joint temporal response patterns. [SEP] [HINT] decoding -> Neuroscience (Syns: decrypt, decipherment, decryption) | based -> Bioinformatics (Syns: ground, free-base, base) | understanding -> Neuroscience (Syns: savvy, intellect, sympathy)",Neuroscience
"We explore the recently introduced persistent reachability homology (PRH) of digraph data, i.e. data in the form of directed graphs. In particular, we study the effectiveness of PRH in network classification task in a key neuroscience problem: epilepsy detection. PRH is a variation of the persistent homology of digraphs, more traditionally based on the directed flag complex (DPH). A main advantage of PRH is that it considers the condensations of the digraphs appearing in the persistent filtration and thus is computed from smaller digraphs. We compare the effectiveness of PRH to that of DPH and we show that PRH outperforms DPH in the classification task. We use the Betti curves and their integrals as topological features and implement our pipeline on support vector machine.",Bioinformatics
"We explore the recently introduced persistent reachability homology (PRH) of digraph data, i.e. data in the form of directed graphs. In particular, we study the effectiveness of PRH in network classification task in a key neuroscience problem: epilepsy detection. PRH is a variation of the persistent homology of digraphs, more traditionally based on the directed flag complex (DPH). A main advantage of PRH is that it considers the condensations of the digraphs appearing in the persistent filtration and thus is computed from smaller digraphs. We compare the effectiveness of PRH to that of DPH and we show that PRH outperforms DPH in the classification task. We use the Betti curves and their integrals as topological features and implement our pipeline on support vector machine. [SEP] [HINT] complex -> Bioinformatics (Syns: building complex, coordination compound, composite) | network -> Bioinformatics (Syns: meshwork, electronic network, mesh) | task -> Neuroscience (Syns: tax, project, chore)",Bioinformatics
"Identifying the effects of mechanical ventilation strategies and protocols in critical care requires analyzing data from heterogeneous patient-ventilator systems within the context of the clinical decision-making environment. This research develops a framework to help understand the consequences of mechanical ventilation (MV) and adjunct care decisions on patient outcome from observations of critical care patients receiving MV. Developing an understanding of and improving critical care respiratory management requires the analysis of existing secondary-use clinical data to generate hypotheses about advantageous variations and adaptations of current care. This work introduces a perspective of the joint patient-ventilator-care systems (so-called J6) to develop a scalable method for analyzing data and trajectories of these complex systems. To that end, breath behaviors are analyzed using evolutionary game theory (EGT), which generates the necessary quantitative precursors for deeper analysis through probabilistic and stochastic machinery such as reinforcement learning. This result is one step along the pathway toward MV optimization and personalization. The EGT-based process is analytically validated on synthetic data to reveal potential caveats before proceeding to real-world ICU data applications that expose complexities of the data-generating process J6. The discussion includes potential developments toward a state transition model for the simulating effects of MV decision using empirical and game-theoretic elements.",Bioinformatics
"Identifying the effects of mechanical ventilation strategies and protocols in critical care requires analyzing data from heterogeneous patient-ventilator systems within the context of the clinical decision-making environment. This research develops a framework to help understand the consequences of mechanical ventilation (MV) and adjunct care decisions on patient outcome from observations of critical care patients receiving MV. Developing an understanding of and improving critical care respiratory management requires the analysis of existing secondary-use clinical data to generate hypotheses about advantageous variations and adaptations of current care. This work introduces a perspective of the joint patient-ventilator-care systems (so-called J6) to develop a scalable method for analyzing data and trajectories of these complex systems. To that end, breath behaviors are analyzed using evolutionary game theory (EGT), which generates the necessary quantitative precursors for deeper analysis through probabilistic and stochastic machinery such as reinforcement learning. This result is one step along the pathway toward MV optimization and personalization. The EGT-based process is analytically validated on synthetic data to reveal potential caveats before proceeding to real-world ICU data applications that expose complexities of the data-generating process J6. The discussion includes potential developments toward a state transition model for the simulating effects of MV decision using empirical and game-theoretic elements. [SEP] [HINT] transition -> Materials Science (Syns: passage, modulation, changeover) | clinical -> Bioinformatics (Syns: ) | understanding -> Neuroscience (Syns: savvy, intellect, sympathy)",Bioinformatics
"Lead-free vacancy-ordered perovskites (VOHPs) such as Cs2SnCl6 have emerged as promising materials for optoelectronic applications but typically suffer from wide band gaps and low photoluminescence quantum yields (PLQY). In this work, the electronic origins of broadband blue emission in Bi3+-doped Cs2SnCl6 are elucidated by combining density functional theory (DFT) calculations and ab initio molecular dynamics simulations. The study systematically explores the spatial configurations of Bi3+ dopants and Cl- vacancies, assessing their impact on structural and electronic properties. Results demonstrate that the formation of square pyramidal BiCl5(2-) units serves as efficient exciton traps, fundamentally enabling strong luminescence in an otherwise non-emitting host. The Bi3+ 6s2 lone pair in an asymmetric coordination environment drives second-order Jahn-Teller distortions, creating a highly polarizable local lattice. This softness, in contrast to the rigid SnCl6(2-) framework, produces heterogeneous distributions of bond lengths, bond angles, and band edges around dopant sites. Defect-induced states strongly localize charge carriers, while coupling to vibrational modes at 300 K dynamically broadens the band edges, accounting for the large Stokes shift and broadband photoluminescence. These results establish lone-pair-driven Jahn-Teller distortions and lattice heterogeneity as key design principles for efficient luminescence in lead-free perovskites.",Materials Science
"Lead-free vacancy-ordered perovskites (VOHPs) such as Cs2SnCl6 have emerged as promising materials for optoelectronic applications but typically suffer from wide band gaps and low photoluminescence quantum yields (PLQY). In this work, the electronic origins of broadband blue emission in Bi3+-doped Cs2SnCl6 are elucidated by combining density functional theory (DFT) calculations and ab initio molecular dynamics simulations. The study systematically explores the spatial configurations of Bi3+ dopants and Cl- vacancies, assessing their impact on structural and electronic properties. Results demonstrate that the formation of square pyramidal BiCl5(2-) units serves as efficient exciton traps, fundamentally enabling strong luminescence in an otherwise non-emitting host. The Bi3+ 6s2 lone pair in an asymmetric coordination environment drives second-order Jahn-Teller distortions, creating a highly polarizable local lattice. This softness, in contrast to the rigid SnCl6(2-) framework, produces heterogeneous distributions of bond lengths, bond angles, and band edges around dopant sites. Defect-induced states strongly localize charge carriers, while coupling to vibrational modes at 300 K dynamically broadens the band edges, accounting for the large Stokes shift and broadband photoluminescence. These results establish lone-pair-driven Jahn-Teller distortions and lattice heterogeneity as key design principles for efficient luminescence in lead-free perovskites. [SEP] [HINT] low -> Materials Science (Syns: low-spirited, scurvy, depressed) | charge -> Materials Science (Syns: tear, bearing, burster) | electronic -> Materials Science (Syns: )",Materials Science
"Vital to the creation of advanced materials is performing structural relaxations. Traditional approaches built on physics-derived first-principles calculations are computationally expensive, motivating the creation of machine-learning interatomic potentials (MLIPs). Traditional approaches to training MLIPs for structural relaxations involves training models to faithfully reproduce first-principles computed forces. We propose a fine-tuning method to be used on a pretrained MLIP in which we create a fully-differentiable end-to-end simulation loop that optimizes the predicted final structures directly. Trajectories are unrolled and gradients are tracked through the entire relaxation. We show that this method achieves substantial performance gains when applied to pretrained models, leading to a nearly $50\%$ reduction in test error across the sample datasets. Interestingly, we show the process is robust to substantial variation in the relaxation setup, achieving negligibly different results across varied hyperparameter and procedural modifications. Experimental results indicate this is due to a ``preference'' of BPTT to modify the MLIP rather than the other trainable parameters. Of particular interest to practitioners is that this approach lowers the data requirements for producing an effective domain-specific MLIP, addressing a common bottleneck in practical deployment.",Materials Science
"Vital to the creation of advanced materials is performing structural relaxations. Traditional approaches built on physics-derived first-principles calculations are computationally expensive, motivating the creation of machine-learning interatomic potentials (MLIPs). Traditional approaches to training MLIPs for structural relaxations involves training models to faithfully reproduce first-principles computed forces. We propose a fine-tuning method to be used on a pretrained MLIP in which we create a fully-differentiable end-to-end simulation loop that optimizes the predicted final structures directly. Trajectories are unrolled and gradients are tracked through the entire relaxation. We show that this method achieves substantial performance gains when applied to pretrained models, leading to a nearly $50\%$ reduction in test error across the sample datasets. Interestingly, we show the process is robust to substantial variation in the relaxation setup, achieving negligibly different results across varied hyperparameter and procedural modifications. Experimental results indicate this is due to a ``preference'' of BPTT to modify the MLIP rather than the other trainable parameters. Of particular interest to practitioners is that this approach lowers the data requirements for producing an effective domain-specific MLIP, addressing a common bottleneck in practical deployment. [SEP] [HINT] used -> Bioinformatics (Syns: utilize, ill-used, apply) | performance -> Bioinformatics (Syns: functioning, operation, carrying out) | results -> Bioinformatics (Syns: final result, consequence, resultant role)",Materials Science
"We report disorder-mediated first-order linear and higher-order nonlinear (magneto-)transport of Ta$_2$NiSe$_7$ (TNS) in the charge-density-wave (CDW) regime. CDW transition temperature ($T_{CDW}$) and carrier density are proportional and inversely proportional to residual resistance ratio of samples, respectively. Such relation helps to understand the unique CDW order therein. High-$T_{CDW}$ TNS exhibits negative first-harmonic magnetoresistance (MR$^{1ω}$) under a magnetic field ($B$) parallel to the direction of alternating current ($I^ω$), which may arise from the anomalous velocity induced by the Berry curvature of three-dimensional topological bands near the Fermi level. As $T_{CDW}$ drops, a positive-to-negative MR$^{1ω}$ transition is observed with decreasing perpendicular $B$, which is likely due to the contribution of Zeeman effect on current pathways in the disordered system. Moreover, interestingly, the second-harmonic nonlinear signals are suppressed, while the third-harmonic signals are significant and sensitive to both $B$ and $T_{CDW}$. Such observations, together with scaling analysis, suggest the quantum geometry quadrupole at play and the modulation of disorder on third-order nonlinearity. Our results pave an avenue for tailoring distinct-order magnetoresistive phases in disordered topological materials.",Materials Science
"We report disorder-mediated first-order linear and higher-order nonlinear (magneto-)transport of Ta$_2$NiSe$_7$ (TNS) in the charge-density-wave (CDW) regime. CDW transition temperature ($T_{CDW}$) and carrier density are proportional and inversely proportional to residual resistance ratio of samples, respectively. Such relation helps to understand the unique CDW order therein. High-$T_{CDW}$ TNS exhibits negative first-harmonic magnetoresistance (MR$^{1ω}$) under a magnetic field ($B$) parallel to the direction of alternating current ($I^ω$), which may arise from the anomalous velocity induced by the Berry curvature of three-dimensional topological bands near the Fermi level. As $T_{CDW}$ drops, a positive-to-negative MR$^{1ω}$ transition is observed with decreasing perpendicular $B$, which is likely due to the contribution of Zeeman effect on current pathways in the disordered system. Moreover, interestingly, the second-harmonic nonlinear signals are suppressed, while the third-harmonic signals are significant and sensitive to both $B$ and $T_{CDW}$. Such observations, together with scaling analysis, suggest the quantum geometry quadrupole at play and the modulation of disorder on third-order nonlinearity. Our results pave an avenue for tailoring distinct-order magnetoresistive phases in disordered topological materials. [SEP] [HINT] field -> Materials Science (Syns: field of honor, line of business, orbit) | transition -> Materials Science (Syns: passage, modulation, changeover) | order -> Materials Science (Syns: enjoin, dictate, social club)",Materials Science
"Neurons process information in ways that depend on their cell type, connectivity, and the brain region in which they are embedded. However, inferring these factors from neural activity remains a significant challenge. To build general-purpose representations that allow for resolving information about a neuron's identity, we introduce NuCLR, a self-supervised framework that aims to learn representations of neural activity that allow for differentiating one neuron from the rest. NuCLR brings together views of the same neuron observed at different times and across different stimuli and uses a contrastive objective to pull these representations together. To capture population context without assuming any fixed neuron ordering, we build a spatiotemporal transformer that integrates activity in a permutation-equivariant manner. Across multiple electrophysiology and calcium imaging datasets, a linear decoding evaluation on top of NuCLR representations achieves a new state-of-the-art for both cell type and brain region decoding tasks, and demonstrates strong zero-shot generalization to unseen animals. We present the first systematic scaling analysis for neuron-level representation learning, showing that increasing the number of animals used during pretraining consistently improves downstream performance. The learned representations are also label-efficient, requiring only a small fraction of labeled samples to achieve competitive performance. These results highlight how large, diverse neural datasets enable models to recover information about neuron identity that generalize across animals. Code is available at https://github.com/nerdslab/nuclr.",Neuroscience
"Neurons process information in ways that depend on their cell type, connectivity, and the brain region in which they are embedded. However, inferring these factors from neural activity remains a significant challenge. To build general-purpose representations that allow for resolving information about a neuron's identity, we introduce NuCLR, a self-supervised framework that aims to learn representations of neural activity that allow for differentiating one neuron from the rest. NuCLR brings together views of the same neuron observed at different times and across different stimuli and uses a contrastive objective to pull these representations together. To capture population context without assuming any fixed neuron ordering, we build a spatiotemporal transformer that integrates activity in a permutation-equivariant manner. Across multiple electrophysiology and calcium imaging datasets, a linear decoding evaluation on top of NuCLR representations achieves a new state-of-the-art for both cell type and brain region decoding tasks, and demonstrates strong zero-shot generalization to unseen animals. We present the first systematic scaling analysis for neuron-level representation learning, showing that increasing the number of animals used during pretraining consistently improves downstream performance. The learned representations are also label-efficient, requiring only a small fraction of labeled samples to achieve competitive performance. These results highlight how large, diverse neural datasets enable models to recover information about neuron identity that generalize across animals. Code is available at https://github.com/nerdslab/nuclr. [SEP] [HINT] used -> Bioinformatics (Syns: utilize, ill-used, apply) | decoding -> Neuroscience (Syns: decrypt, decipherment, decryption) | information -> Bioinformatics (Syns: entropy, data, info)",Neuroscience
"Current models treat physiological signals as noise corrupting neural computation. Previously, we showed that removing these ""artifacts"" eliminates 70% of predictive correlation, suggesting body signals functionally drive cognition. Here, we investigate the mechanism using high-density EEG (64 channels, 10 subjects, 500+ trials) during P300 target recognition.   Phase Slope Index revealed zero-lag synchrony (PSI=0.000044, p=0.061) with high coherence (0.316, p<0.0001). Ridge-regularized Granger causality showed massive bidirectional coupling (F=100.53 brain-to-body, F=62.76 body-to-brain) peaking simultaneously at 78.1ms, consistent with mutually coupled resonance pairs.   Time-resolved entropy analysis (200ms windows, 25ms steps) revealed triphasic dynamics: (1) constraint accumulation (0-78ms) building causal drive without entropy change (delta-S=-0.002 bits, p=0.75); (2) supercritical transition (100-600ms) triggering state expansion (58% directional increase, binomial p=0.002); (3) sustained metastability. Critically, transition magnitude was uncorrelated with resonance strength (r=-0.044, p=0.327), indicating binary threshold dynamics.   Understanding emerges through a thermodynamic sequence: brain-body resonance acts as a discrete gate triggering non-linear information integration. This architecture may fundamentally distinguish biological from artificial intelligence.   Keywords: embodied cognition, phase transitions, Granger causality, thermodynamics, neuromorphic computing, resonance dynamics, EEG artifacts",Neuroscience
"Current models treat physiological signals as noise corrupting neural computation. Previously, we showed that removing these ""artifacts"" eliminates 70% of predictive correlation, suggesting body signals functionally drive cognition. Here, we investigate the mechanism using high-density EEG (64 channels, 10 subjects, 500+ trials) during P300 target recognition.   Phase Slope Index revealed zero-lag synchrony (PSI=0.000044, p=0.061) with high coherence (0.316, p<0.0001). Ridge-regularized Granger causality showed massive bidirectional coupling (F=100.53 brain-to-body, F=62.76 body-to-brain) peaking simultaneously at 78.1ms, consistent with mutually coupled resonance pairs.   Time-resolved entropy analysis (200ms windows, 25ms steps) revealed triphasic dynamics: (1) constraint accumulation (0-78ms) building causal drive without entropy change (delta-S=-0.002 bits, p=0.75); (2) supercritical transition (100-600ms) triggering state expansion (58% directional increase, binomial p=0.002); (3) sustained metastability. Critically, transition magnitude was uncorrelated with resonance strength (r=-0.044, p=0.327), indicating binary threshold dynamics.   Understanding emerges through a thermodynamic sequence: brain-body resonance acts as a discrete gate triggering non-linear information integration. This architecture may fundamentally distinguish biological from artificial intelligence.   Keywords: embodied cognition, phase transitions, Granger causality, thermodynamics, neuromorphic computing, resonance dynamics, EEG artifacts [SEP] [HINT] transition -> Materials Science (Syns: passage, modulation, changeover) | understanding -> Neuroscience (Syns: savvy, intellect, sympathy) | information -> Bioinformatics (Syns: entropy, data, info)",Neuroscience
"Research increasingly relies on computational methods to analyze experimental data and predict molecular properties. Current approaches often require researchers to use a variety of tools for statistical analysis and machine learning, creating workflow inefficiencies. We present an integrated platform that combines classical statistical methods with Random Forest classification for comprehensive data analysis that can be used in the biological sciences. The platform implements automated hyperparameter optimization, feature importance analysis, and a suite of statistical tests including t tests, ANOVA, and Pearson correlation analysis. Our methodology addresses the gap between traditional statistical software, modern machine learning frameworks and biology, by providing a unified interface accessible to researchers without extensive programming experience. The system achieves this through automatic data preprocessing, categorical encoding, and adaptive model configuration based on dataset characteristics. Initial testing protocols are designed to evaluate classification accuracy across diverse chemical datasets with varying feature distributions. This work demonstrates that integrating statistical rigor with machine learning interpretability can accelerate biological discovery workflows while maintaining methodological soundness. The platform's modular architecture enables future extensions to additional machine learning algorithms and statistical procedures relevant to bioinformatics.",Bioinformatics
"Research increasingly relies on computational methods to analyze experimental data and predict molecular properties. Current approaches often require researchers to use a variety of tools for statistical analysis and machine learning, creating workflow inefficiencies. We present an integrated platform that combines classical statistical methods with Random Forest classification for comprehensive data analysis that can be used in the biological sciences. The platform implements automated hyperparameter optimization, feature importance analysis, and a suite of statistical tests including t tests, ANOVA, and Pearson correlation analysis. Our methodology addresses the gap between traditional statistical software, modern machine learning frameworks and biology, by providing a unified interface accessible to researchers without extensive programming experience. The system achieves this through automatic data preprocessing, categorical encoding, and adaptive model configuration based on dataset characteristics. Initial testing protocols are designed to evaluate classification accuracy across diverse chemical datasets with varying feature distributions. This work demonstrates that integrating statistical rigor with machine learning interpretability can accelerate biological discovery workflows while maintaining methodological soundness. The platform's modular architecture enables future extensions to additional machine learning algorithms and statistical procedures relevant to bioinformatics. [SEP] [HINT] used -> Bioinformatics (Syns: utilize, ill-used, apply) | based -> Bioinformatics (Syns: ground, free-base, base) | computational -> Neuroscience (Syns: )",Bioinformatics
"Perovskite ruthenates are fascinating playgrounds for exploring topological spin textures, but generally rely on extrinsic mechanisms to trigger the noncoplanar states. Here we report the discovery of an emergent chiral spin crystal phase in (111) SrRuO3 epitaxial films, characterized by a significant topological Hall effect and noncoplanar spin arrangements with different propagation vectors along two orthogonal directions. Instead of driven by the enhanced Dzyaloshinskii-Moriya interaction due to broken inversion symmetry at heterointerfaces, this emergent state arises intrinsically from the interplay of dipolar interactions and magnetic frustration, leading to the stabilization of topological phases in much thicker films. These findings open a new pathway for creating and controlling the topological spin states in perovskites, with broad implications for spintronic device design.",Materials Science
"Perovskite ruthenates are fascinating playgrounds for exploring topological spin textures, but generally rely on extrinsic mechanisms to trigger the noncoplanar states. Here we report the discovery of an emergent chiral spin crystal phase in (111) SrRuO3 epitaxial films, characterized by a significant topological Hall effect and noncoplanar spin arrangements with different propagation vectors along two orthogonal directions. Instead of driven by the enhanced Dzyaloshinskii-Moriya interaction due to broken inversion symmetry at heterointerfaces, this emergent state arises intrinsically from the interplay of dipolar interactions and magnetic frustration, leading to the stabilization of topological phases in much thicker films. These findings open a new pathway for creating and controlling the topological spin states in perovskites, with broad implications for spintronic device design. [SEP] [HINT] spin -> Materials Science (Syns: twisting, whirl, tailspin) | perovskite -> Materials Science (Syns: ) | different -> Neuroscience (Syns: unlike, dissimilar)",Materials Science
"We present a unified field-theoretic framework for the dynamics of activity and connectivity in interacting neuronal systems. Building upon previous works, where a field approach to activity--connectivity dynamics, formation of collective states and effective fields of collective states were successively introduced, the present paper synthesizes and extends these results toward a general description of multiple hierarchical collective structures. Starting with the dynamical system representing collective states in terms of connections, activity levels, and internal frequencies, we analyze its stability, emphasizing the possibility of transitions between configurations. Then, turning to the field formalism of collective states, we extend this framework to include substructures (subobjects) participating in larger assemblies while retaining intrinsic properties. We define activation classes describing compatible or independent activity patterns between objects and subobjects, and study stability conditions arising from their alignment or mismatch. The global system is described as the collection of landscapes of coexisting and interacting collective states, each characterized both by continuous (activity, frequency) and discrete (class) variables. A corresponding field formalism is developed, with an action functional incorporating both internal dynamics and interaction terms. This nonlinear field model captures cascading transitions between collective states and the formation of composite structures, providing a coherent theoretical basis for emergent neuronal assemblies and their mutual couplings.",Neuroscience
"We present a unified field-theoretic framework for the dynamics of activity and connectivity in interacting neuronal systems. Building upon previous works, where a field approach to activity--connectivity dynamics, formation of collective states and effective fields of collective states were successively introduced, the present paper synthesizes and extends these results toward a general description of multiple hierarchical collective structures. Starting with the dynamical system representing collective states in terms of connections, activity levels, and internal frequencies, we analyze its stability, emphasizing the possibility of transitions between configurations. Then, turning to the field formalism of collective states, we extend this framework to include substructures (subobjects) participating in larger assemblies while retaining intrinsic properties. We define activation classes describing compatible or independent activity patterns between objects and subobjects, and study stability conditions arising from their alignment or mismatch. The global system is described as the collection of landscapes of coexisting and interacting collective states, each characterized both by continuous (activity, frequency) and discrete (class) variables. A corresponding field formalism is developed, with an action functional incorporating both internal dynamics and interaction terms. This nonlinear field model captures cascading transitions between collective states and the formation of composite structures, providing a coherent theoretical basis for emergent neuronal assemblies and their mutual couplings. [SEP] [HINT] field -> Materials Science (Syns: field of honor, line of business, orbit) | connectivity -> Neuroscience (Syns: ) | functional -> Neuroscience (Syns: working, usable, running)",Neuroscience
"Bistability-two distinct stable states under identical parameter-is not only a fundamental physical concept but also of importance in practical applications. While plasmon-polaritonic bistability representing history-dependent stable states within plasmonic systems has been theoretically predicted, it has yet to be demonstrated experimentally due to challenges in realizing suitable nonlinearity at feasible electric-field strengths. Here, we report the experimental observation of electrically driven plasmon-polaritonic bistability in graphene/hexagonal-boron-nitride/graphene tunneling transistors, achieved through momentum-conserving resonant tunneling of Dirac electrons. Using a small twist angle between graphene layers, we engineered devices exhibiting both electronic and plasmon-polaritonic bistability. This bistable plasmonic behavior can be precisely tuned through load resistance and electrostatic gating. Our findings open new pathways for exploring nonlinear optical and electronic phenomena in van der Waals heterostructures and mark a significant advance in nanoplasmonics, with potential applications in optical memory, sensing, and optoelectronic switching.",Materials Science
"Bistability-two distinct stable states under identical parameter-is not only a fundamental physical concept but also of importance in practical applications. While plasmon-polaritonic bistability representing history-dependent stable states within plasmonic systems has been theoretically predicted, it has yet to be demonstrated experimentally due to challenges in realizing suitable nonlinearity at feasible electric-field strengths. Here, we report the experimental observation of electrically driven plasmon-polaritonic bistability in graphene/hexagonal-boron-nitride/graphene tunneling transistors, achieved through momentum-conserving resonant tunneling of Dirac electrons. Using a small twist angle between graphene layers, we engineered devices exhibiting both electronic and plasmon-polaritonic bistability. This bistable plasmonic behavior can be precisely tuned through load resistance and electrostatic gating. Our findings open new pathways for exploring nonlinear optical and electronic phenomena in van der Waals heterostructures and mark a significant advance in nanoplasmonics, with potential applications in optical memory, sensing, and optoelectronic switching. [SEP] [HINT] electronic -> Materials Science (Syns: ) | systems -> Bioinformatics (Syns: organization, organisation, system) | using -> Bioinformatics (Syns: utilize, exploitation, apply)",Materials Science
"This work introduces a novel framework for testing topological variability in weighted networks by combining Hodge decomposition with Wasserstein variance minimization. Traditional approaches that analyze raw edge weights are susceptible to noise driven perturbations, limiting their ability to detect meaningful structural differences between network populations. Network signals are decomposed into various components using combinatorial Hodge theory, then topological disparity is quantified via the 2-Wasserstein distance between persistence diagrams. The test statistic measures variance reduction when comparing within group to between group dispersions in the Wasserstein space. Simulations demonstrate that the proposed method suppresses small random perturbations while maintaining sensitivity to genuine topological differences, particularly when applied to Hodge decomposed flows rather than raw edge weights. The framework is applied to functional brain networks from the Multimodal Treatment of ADHD dataset, comparing cannabis users and non-users",Bioinformatics
"This work introduces a novel framework for testing topological variability in weighted networks by combining Hodge decomposition with Wasserstein variance minimization. Traditional approaches that analyze raw edge weights are susceptible to noise driven perturbations, limiting their ability to detect meaningful structural differences between network populations. Network signals are decomposed into various components using combinatorial Hodge theory, then topological disparity is quantified via the 2-Wasserstein distance between persistence diagrams. The test statistic measures variance reduction when comparing within group to between group dispersions in the Wasserstein space. Simulations demonstrate that the proposed method suppresses small random perturbations while maintaining sensitivity to genuine topological differences, particularly when applied to Hodge decomposed flows rather than raw edge weights. The framework is applied to functional brain networks from the Multimodal Treatment of ADHD dataset, comparing cannabis users and non-users [SEP] [HINT] networks -> Neuroscience (Syns: network, meshwork, electronic network) | functional -> Neuroscience (Syns: working, usable, running) | work -> Bioinformatics (Syns: work out, process, bring)",Bioinformatics
"In neurosciences, the brain processes information via the firing patterns of connected neurons operating across a spectrum of frequencies. To better understand the effects of these frequencies in the neuron dynamics, we have simulated a neuronal network of Izhikevich neurons to examine the interaction between frequency allocation and intermittent phase synchronization dynamics. As the synchronized population of neurons passes through a bifurcation, an additional frequency mode emerges, enabling a match in the mean frequency while retaining distinct most probable frequencies among neurons. Subsequently, the network intermittently transits between two patterns, one partially synchronized and the other unsynchronized. Through our analysis, we demonstrate that the frequency changes on the network lead to characteristic transition times between synchronization states. Moreover, these transitions adhere to beat frequency statistics when the neurons' frequencies differ by multiples of a frequency gap. Finally, our results can improve the performance in predicting transitions on problems where the beat frequency strongly influences the dynamics.",Neuroscience
"In neurosciences, the brain processes information via the firing patterns of connected neurons operating across a spectrum of frequencies. To better understand the effects of these frequencies in the neuron dynamics, we have simulated a neuronal network of Izhikevich neurons to examine the interaction between frequency allocation and intermittent phase synchronization dynamics. As the synchronized population of neurons passes through a bifurcation, an additional frequency mode emerges, enabling a match in the mean frequency while retaining distinct most probable frequencies among neurons. Subsequently, the network intermittently transits between two patterns, one partially synchronized and the other unsynchronized. Through our analysis, we demonstrate that the frequency changes on the network lead to characteristic transition times between synchronization states. Moreover, these transitions adhere to beat frequency statistics when the neurons' frequencies differ by multiples of a frequency gap. Finally, our results can improve the performance in predicting transitions on problems where the beat frequency strongly influences the dynamics. [SEP] [HINT] transition -> Materials Science (Syns: passage, modulation, changeover) | information -> Bioinformatics (Syns: entropy, data, info) | performance -> Bioinformatics (Syns: functioning, operation, carrying out)",Neuroscience
"Collapse Lineage Tree (CLTree) is a software tool that annotates, roots, and evaluates phylogenetic trees by using lineages. A recursive algorithm was designed to annotate the branches by the common taxonomic lineage of its descendants in a rooted tree. For an unrooted tree, it determines the root that best conforms to the taxonomic system based on the aforementioned lineage annotations. Based on the lineage annotations of notes, CLTree infers the monophyly of taxonomic units and quantifies the concordance between the phylogenetic tree and the taxonomic system base on Shannon entropy. The core algorithm of CLTree is highly efficient with linear complexity, capable of processing phylogenetic trees with 17,955 terminal nodes within one second. We believe that CLTree will serve as a powerful tool for study of evolution and taxonomy.",Bioinformatics
"Collapse Lineage Tree (CLTree) is a software tool that annotates, roots, and evaluates phylogenetic trees by using lineages. A recursive algorithm was designed to annotate the branches by the common taxonomic lineage of its descendants in a rooted tree. For an unrooted tree, it determines the root that best conforms to the taxonomic system based on the aforementioned lineage annotations. Based on the lineage annotations of notes, CLTree infers the monophyly of taxonomic units and quantifies the concordance between the phylogenetic tree and the taxonomic system base on Shannon entropy. The core algorithm of CLTree is highly efficient with linear complexity, capable of processing phylogenetic trees with 17,955 terminal nodes within one second. We believe that CLTree will serve as a powerful tool for study of evolution and taxonomy. [SEP] [HINT] based -> Bioinformatics (Syns: ground, free-base, base) | processing -> Neuroscience (Syns: work, process, march) | using -> Bioinformatics (Syns: utilize, exploitation, apply)",Bioinformatics
"Accelerated material discovery increasingly relies on artificial intelligence and machine learning, collectively termed ""AI/ML"". A key challenge in using AI is ensuring that human scientists trust the models are valid and reliable. Accordingly, we define a trustworthy AI framework GIFTERS for materials science and discovery to evaluate whether reported machine learning methods are generalizable, interpretable, fair, transparent, explainable, robust, and stable. Through a critical literature review, we highlight that these are the trustworthiness principles most valued by the materials discovery community. However, we also find that comprehensive approaches to trustworthiness are rarely reported; this is quantified by a median GIFTERS score of 5/7. We observe that Bayesian studies frequently omit fair data practices, while non-Bayesian studies most frequently omit interpretability. Finally, we identify approaches for improving trustworthiness methods in artificial intelligence and machine learning for materials science by considering work accomplished in other scientific disciplines such as healthcare, climate science, and natural language processing with an emphasis on methods that may transfer to materials discovery experiments. By combining these observations, we highlight the necessity of human-in-the-loop, and integrated approaches to bridge the gap between trustworthiness and uncertainty quantification for future directions of materials science research. This ensures that AI/ML methods not only accelerate discovery, but also meet ethical and scientific norms established by the materials discovery community. This work provides a road map for developing trustworthy artificial intelligence systems that will accurately and confidently enable material discovery.",Materials Science
"Accelerated material discovery increasingly relies on artificial intelligence and machine learning, collectively termed ""AI/ML"". A key challenge in using AI is ensuring that human scientists trust the models are valid and reliable. Accordingly, we define a trustworthy AI framework GIFTERS for materials science and discovery to evaluate whether reported machine learning methods are generalizable, interpretable, fair, transparent, explainable, robust, and stable. Through a critical literature review, we highlight that these are the trustworthiness principles most valued by the materials discovery community. However, we also find that comprehensive approaches to trustworthiness are rarely reported; this is quantified by a median GIFTERS score of 5/7. We observe that Bayesian studies frequently omit fair data practices, while non-Bayesian studies most frequently omit interpretability. Finally, we identify approaches for improving trustworthiness methods in artificial intelligence and machine learning for materials science by considering work accomplished in other scientific disciplines such as healthcare, climate science, and natural language processing with an emphasis on methods that may transfer to materials discovery experiments. By combining these observations, we highlight the necessity of human-in-the-loop, and integrated approaches to bridge the gap between trustworthiness and uncertainty quantification for future directions of materials science research. This ensures that AI/ML methods not only accelerate discovery, but also meet ethical and scientific norms established by the materials discovery community. This work provides a road map for developing trustworthy artificial intelligence systems that will accurately and confidently enable material discovery. [SEP] [HINT] language -> Neuroscience (Syns: linguistic process, linguistic communication, spoken communication) | learning -> Bioinformatics (Syns: take, teach, acquire) | processing -> Neuroscience (Syns: work, process, march)",Materials Science
"This review discusses the multifaceted electronic properties of spinel oxides with a particular focus on Lithium Vanadate (LiV2O4), Lithium Titanate (LiTi2O4), and Magnesium Titanate (MgTi2O4). We selected LiTi2O4, LiV2O4, and MgTi2O4 because they serve as quintessential examples of spinel oxides' diverse and intriguing electronic phenomena. LiV2O4 heavy fermion behaviour challenges traditional theories in d-electron systems, LiTi2O4 being the first oxide superconductor provides critical insights into unconventional superconductivity driven by strong electron-phonon interactions, and MgTi2O4 pronounced orbital ordering and metalinsulator transition offers a clear model for exploring electron-lattice coupling. This shows how the inherent structural versatility of the spinel lattice, characterised by its cubic close-packed oxygen network and variable cation distributions, enables a rich interplay of electron-electron correlations, electron-lattice coupling, and orbital degrees of freedom. In LiV2O4, the combination of mixed-valence vanadium ions and a geometrically frustrated pyrochlore lattice gives rise to heavy fermion behaviour, whereas LiTi2O4 exhibits unconventional superconductivity driven by a high density of states at the Fermi level and strong electronphonon interactions. MgTi2O4 undergoes a pronounced metal-insulator transition, where orbital ordering triggers a Peierls-like distortion that stabilises a low-temperature insulating state through Ti-Ti dimerization. How the composition of these compounds affects their properties, based on both theoretical research and experimental findings, is illustrated by this review. It illustrates the promise of Spinels in practical technologies such as energy storage, electrocatalysis, and high-temperature lubrication.",Materials Science
"This review discusses the multifaceted electronic properties of spinel oxides with a particular focus on Lithium Vanadate (LiV2O4), Lithium Titanate (LiTi2O4), and Magnesium Titanate (MgTi2O4). We selected LiTi2O4, LiV2O4, and MgTi2O4 because they serve as quintessential examples of spinel oxides' diverse and intriguing electronic phenomena. LiV2O4 heavy fermion behaviour challenges traditional theories in d-electron systems, LiTi2O4 being the first oxide superconductor provides critical insights into unconventional superconductivity driven by strong electron-phonon interactions, and MgTi2O4 pronounced orbital ordering and metalinsulator transition offers a clear model for exploring electron-lattice coupling. This shows how the inherent structural versatility of the spinel lattice, characterised by its cubic close-packed oxygen network and variable cation distributions, enables a rich interplay of electron-electron correlations, electron-lattice coupling, and orbital degrees of freedom. In LiV2O4, the combination of mixed-valence vanadium ions and a geometrically frustrated pyrochlore lattice gives rise to heavy fermion behaviour, whereas LiTi2O4 exhibits unconventional superconductivity driven by a high density of states at the Fermi level and strong electronphonon interactions. MgTi2O4 undergoes a pronounced metal-insulator transition, where orbital ordering triggers a Peierls-like distortion that stabilises a low-temperature insulating state through Ti-Ti dimerization. How the composition of these compounds affects their properties, based on both theoretical research and experimental findings, is illustrated by this review. It illustrates the promise of Spinels in practical technologies such as energy storage, electrocatalysis, and high-temperature lubrication. [SEP] [HINT] transition -> Materials Science (Syns: passage, modulation, changeover) | based -> Bioinformatics (Syns: ground, free-base, base) | electronic -> Materials Science (Syns: )",Materials Science
"Response of refractory high-entropy alloys MoNbTaVW and HfNbTaTiZr to ultrafast radiation is modelled with the hybrid code XTANT-3, combining tight-binding molecular dynamics with the transport Monte Carlo and Boltzmann equation. A two-temperature state with elevated electronic temperature and a cold atomic lattice is studied. The parameters of the electronic system in such a state are studied: electronic heat capacity, thermal conductivity, and electron-phonon coupling parameter with the electronic temperatures up to ~25,000 K. It is also demonstrated that the two refractory alloys do not show signs of nonthermal melting up to the deposited doses of ~10 eV/atom, making them more radiation resistant than the Cantor alloy or stainless steel. These results suggest that heavy-element high-entropy alloys are more radiation resistant than those containing only lighter elements. Damage in irradiated HfNbTaTiZr starts with the selective diffusion of Ti atoms, forming a transient superionic-like state.",Materials Science
"Response of refractory high-entropy alloys MoNbTaVW and HfNbTaTiZr to ultrafast radiation is modelled with the hybrid code XTANT-3, combining tight-binding molecular dynamics with the transport Monte Carlo and Boltzmann equation. A two-temperature state with elevated electronic temperature and a cold atomic lattice is studied. The parameters of the electronic system in such a state are studied: electronic heat capacity, thermal conductivity, and electron-phonon coupling parameter with the electronic temperatures up to ~25,000 K. It is also demonstrated that the two refractory alloys do not show signs of nonthermal melting up to the deposited doses of ~10 eV/atom, making them more radiation resistant than the Cantor alloy or stainless steel. These results suggest that heavy-element high-entropy alloys are more radiation resistant than those containing only lighter elements. Damage in irradiated HfNbTaTiZr starts with the selective diffusion of Ti atoms, forming a transient superionic-like state. [SEP] [HINT] transport -> Materials Science (Syns: transferral, enthral, shipping) | electronic -> Materials Science (Syns: ) | molecular -> Bioinformatics (Syns: )",Materials Science
"Evidence of non-hermitian behavior has been recently demonstrated in cavity magnonics, including the emergence of mode level attraction and exceptional points in spectroscopic measurements. This work demonstrates experimental evidence of time-domain dynamics of magnon-photon systems that are coupled through a long-range interaction (i.e. remote coupling) exhibiting level attraction mediated by an auxiliary mode. We directly observe the temporal evolution of dissipatively coupled cavity-magnon modes, where heavily damped transmission line modes mediate the interaction. Our frequency-domain measurements confirm the predicted level attraction, while time-domain ring-down measurements reveal the characteristic signatures of dissipative coupling dynamics. Our approach offers in situ tunability over the dissipative coupling strength, including complete suppression, without requiring physical modifications to the experimental setup, providing a versatile platform for exploring tunable, non-Hermitian physics.",Materials Science
"Evidence of non-hermitian behavior has been recently demonstrated in cavity magnonics, including the emergence of mode level attraction and exceptional points in spectroscopic measurements. This work demonstrates experimental evidence of time-domain dynamics of magnon-photon systems that are coupled through a long-range interaction (i.e. remote coupling) exhibiting level attraction mediated by an auxiliary mode. We directly observe the temporal evolution of dissipatively coupled cavity-magnon modes, where heavily damped transmission line modes mediate the interaction. Our frequency-domain measurements confirm the predicted level attraction, while time-domain ring-down measurements reveal the characteristic signatures of dissipative coupling dynamics. Our approach offers in situ tunability over the dissipative coupling strength, including complete suppression, without requiring physical modifications to the experimental setup, providing a versatile platform for exploring tunable, non-Hermitian physics. [SEP] [HINT] work -> Bioinformatics (Syns: work out, process, bring) | systems -> Bioinformatics (Syns: organization, organisation, system) | including -> Bioinformatics (Syns: admit, include, let in)",Materials Science
"Stochastic Reaction Networks (SRNs) are a fundamental modeling framework for systems ranging from chemical kinetics and epidemiology to ecological and synthetic biological processes. A central computational challenge is the estimation of expected outputs across initial conditions and times, a task that is rarely solvable analytically and becomes computationally prohibitive with current methods such as Finite State Projection or the Stochastic Simulation Algorithm. Existing deep learning approaches offer empirical scalability, but provide neither interpretability nor reliability guarantees, limiting their use in scientific analysis and in applications where model outputs inform real-world decisions. Here we introduce DeepSKA, a neural framework that jointly achieves interpretability, guaranteed reliability, and substantial computational gains. DeepSKA yields mathematically transparent representations that generalise across states, times, and output functions, and it integrates this structure with a small number of stochastic simulations to produce unbiased, provably convergent, and dramatically lower-variance estimates than classical Monte Carlo. We demonstrate these capabilities across nine SRNs, including nonlinear and non-mass-action models with up to ten species, where DeepSKA delivers accurate predictions and orders-of-magnitude efficiency improvements. This interpretable and reliable neural framework offers a principled foundation for developing analogous methods for other Markovian systems, including stochastic differential equations.",Bioinformatics
"Stochastic Reaction Networks (SRNs) are a fundamental modeling framework for systems ranging from chemical kinetics and epidemiology to ecological and synthetic biological processes. A central computational challenge is the estimation of expected outputs across initial conditions and times, a task that is rarely solvable analytically and becomes computationally prohibitive with current methods such as Finite State Projection or the Stochastic Simulation Algorithm. Existing deep learning approaches offer empirical scalability, but provide neither interpretability nor reliability guarantees, limiting their use in scientific analysis and in applications where model outputs inform real-world decisions. Here we introduce DeepSKA, a neural framework that jointly achieves interpretability, guaranteed reliability, and substantial computational gains. DeepSKA yields mathematically transparent representations that generalise across states, times, and output functions, and it integrates this structure with a small number of stochastic simulations to produce unbiased, provably convergent, and dramatically lower-variance estimates than classical Monte Carlo. We demonstrate these capabilities across nine SRNs, including nonlinear and non-mass-action models with up to ten species, where DeepSKA delivers accurate predictions and orders-of-magnitude efficiency improvements. This interpretable and reliable neural framework offers a principled foundation for developing analogous methods for other Markovian systems, including stochastic differential equations. [SEP] [HINT] task -> Neuroscience (Syns: tax, project, chore) | computational -> Neuroscience (Syns: ) | learning -> Bioinformatics (Syns: take, teach, acquire)",Bioinformatics
"How does the brain know what is out there and what is not? Living organisms cannot rely solely on sensory signals for perception because they are noisy and ambiguous. To transform sensory signals into stable percepts, the brain uses its prior knowledge or beliefs. Current theories describe perceptual beliefs as probability distributions over the features of the stimuli, summarised by their mean and variance. Beliefs are updated by feature prediction errors: the mismatch between expected and observed feature values. This framework explains how the brain encodes unexpected changes in stimulus features (e.g., higher or lower pitch, stronger or weaker motion). How the brain updates beliefs about a stimulus' presence or absence is, however, unclear.   We propose that the detection of absence relies on a distinct form of prediction error dedicated to reducing the beliefs on stimulus occurrence. We call this signal absence prediction error. Using the human auditory system as a model for sensory processing, we developed a paradigm designed to test this hypothesis. fMRI results showed that absence prediction error is encoded in the auditory thalamus and cortex, indicating that absence is explicitly represented in subcortical sensory pathways. Moreover, while feature prediction error is already encoded in the auditory midbrain, absence prediction error was not, implying that absence-related error signals are supported by a different circuit.   These results identify a neural mechanism for the detection of sensory absence. Such mechanisms may be disrupted in conditions such as psychosis, where predictions about absence and presence are impaired.",Neuroscience
"How does the brain know what is out there and what is not? Living organisms cannot rely solely on sensory signals for perception because they are noisy and ambiguous. To transform sensory signals into stable percepts, the brain uses its prior knowledge or beliefs. Current theories describe perceptual beliefs as probability distributions over the features of the stimuli, summarised by their mean and variance. Beliefs are updated by feature prediction errors: the mismatch between expected and observed feature values. This framework explains how the brain encodes unexpected changes in stimulus features (e.g., higher or lower pitch, stronger or weaker motion). How the brain updates beliefs about a stimulus' presence or absence is, however, unclear.   We propose that the detection of absence relies on a distinct form of prediction error dedicated to reducing the beliefs on stimulus occurrence. We call this signal absence prediction error. Using the human auditory system as a model for sensory processing, we developed a paradigm designed to test this hypothesis. fMRI results showed that absence prediction error is encoded in the auditory thalamus and cortex, indicating that absence is explicitly represented in subcortical sensory pathways. Moreover, while feature prediction error is already encoded in the auditory midbrain, absence prediction error was not, implying that absence-related error signals are supported by a different circuit.   These results identify a neural mechanism for the detection of sensory absence. Such mechanisms may be disrupted in conditions such as psychosis, where predictions about absence and presence are impaired. [SEP] [HINT] features -> Bioinformatics (Syns: characteristic, lineament, feature of speech) | results -> Bioinformatics (Syns: final result, consequence, resultant role) | human -> Neuroscience (Syns: human being, man, homo)",Neuroscience
"Rare-earth tritellurides ($R$Te$_3$) exhibit complex charge-density-wave (CDW) phases intertwined with lattice symmetry, offering a platform to explore unconventional symmetry breaking in correlated materials. Elasto-optical probing, which detects strain-induced changes in birefringence, provides a non-invasive approach to visualize anisotropy and emergent order in these quasi-two-dimensional systems. However, the magnitude and symmetry of the expected optical response remain poorly quantified, hindering experimental interpretation. Here, we perform first-principles calculations of the elastic, dielectric, and piezo-optical tensors of NdTe$_3$ to establish a quantitative framework for strain-induced optical anisotropy. These results establish a quantitative link between lattice strain and optical response in $R$Te$_3$, providing a predictive framework for probing symmetry-breaking states via elasto-birefringence.",Materials Science
"Rare-earth tritellurides ($R$Te$_3$) exhibit complex charge-density-wave (CDW) phases intertwined with lattice symmetry, offering a platform to explore unconventional symmetry breaking in correlated materials. Elasto-optical probing, which detects strain-induced changes in birefringence, provides a non-invasive approach to visualize anisotropy and emergent order in these quasi-two-dimensional systems. However, the magnitude and symmetry of the expected optical response remain poorly quantified, hindering experimental interpretation. Here, we perform first-principles calculations of the elastic, dielectric, and piezo-optical tensors of NdTe$_3$ to establish a quantitative framework for strain-induced optical anisotropy. These results establish a quantitative link between lattice strain and optical response in $R$Te$_3$, providing a predictive framework for probing symmetry-breaking states via elasto-birefringence. [SEP] [HINT] complex -> Bioinformatics (Syns: building complex, coordination compound, composite) | order -> Materials Science (Syns: enjoin, dictate, social club) | results -> Bioinformatics (Syns: final result, consequence, resultant role)",Materials Science
"Medical imaging is a critical initial tool used by clinicians to determine a patient's cancer diagnosis, allowing for faster intervention and more reliable patient prognosis. At subsequent stages of patient diagnosis, genetic information is extracted to help select specific patient treatment options. As the efficacy of cancer treatment often relies on early diagnosis and treatment, we build a deep latent variable model to determine patients' somatic mutation profiles based on their corresponding medical images. We first introduce a point cloud representation of lesions images to allow for invariance to the imaging modality. We then propose, LLOST, a model with dual variational autoencoders coupled together by a separate shared latent space that unifies features from the lesion point clouds and counts of distinct somatic mutations. Therefore our model consists of three latent space, each of which is learned with a conditional normalizing flow prior to account for the diverse distributions of each domain. We conduct qualitative and quantitative experiments on de-identified medical images from The Cancer Imaging Archive and the corresponding somatic mutations from the Pan Cancer dataset of The Cancer Genomic Archive. We show the model's predictive performance on the counts of specific mutations as well as it's ability to accurately predict the occurrence of mutations. In particular, shared patterns between the imaging and somatic mutation domain that reflect cancer type. We conclude with a remark on how to improve the model and possible future avenues of research to include other genetic domains.",Bioinformatics
"Medical imaging is a critical initial tool used by clinicians to determine a patient's cancer diagnosis, allowing for faster intervention and more reliable patient prognosis. At subsequent stages of patient diagnosis, genetic information is extracted to help select specific patient treatment options. As the efficacy of cancer treatment often relies on early diagnosis and treatment, we build a deep latent variable model to determine patients' somatic mutation profiles based on their corresponding medical images. We first introduce a point cloud representation of lesions images to allow for invariance to the imaging modality. We then propose, LLOST, a model with dual variational autoencoders coupled together by a separate shared latent space that unifies features from the lesion point clouds and counts of distinct somatic mutations. Therefore our model consists of three latent space, each of which is learned with a conditional normalizing flow prior to account for the diverse distributions of each domain. We conduct qualitative and quantitative experiments on de-identified medical images from The Cancer Imaging Archive and the corresponding somatic mutations from the Pan Cancer dataset of The Cancer Genomic Archive. We show the model's predictive performance on the counts of specific mutations as well as it's ability to accurately predict the occurrence of mutations. In particular, shared patterns between the imaging and somatic mutation domain that reflect cancer type. We conclude with a remark on how to improve the model and possible future avenues of research to include other genetic domains. [SEP] [HINT] used -> Bioinformatics (Syns: utilize, ill-used, apply) | based -> Bioinformatics (Syns: ground, free-base, base) | features -> Bioinformatics (Syns: characteristic, lineament, feature of speech)",Bioinformatics
"Computer vision methods are increasingly used for the automated analysis of large volumes of video data collected through camera traps, drones, or direct observations of animals in the wild. While recent advances have focused primarily on detecting individual actions, much less work has addressed the detection and annotation of interactions -- a crucial aspect for understanding social and individualized animal behavior. Existing open-source annotation tools support either behavioral labeling without localization of individuals, or localization without the capacity to capture interactions. To bridge this gap, we present SILVI, an open-source labeling software that integrates both functionalities. SILVI enables researchers to annotate behaviors and interactions directly within video data, generating structured outputs suitable for training and validating computer vision models. By linking behavioral ecology with computer vision, SILVI facilitates the development of automated approaches for fine-grained behavioral analyses. Although developed primarily in the context of animal behavior, SILVI could be useful more broadly to annotate human interactions in other videos that require extracting dynamic scene graphs. The software, along with documentation and download instructions, is available at: https://gitlab.gwdg.de/kanbertay/interaction-labelling-app.",Bioinformatics
"Computer vision methods are increasingly used for the automated analysis of large volumes of video data collected through camera traps, drones, or direct observations of animals in the wild. While recent advances have focused primarily on detecting individual actions, much less work has addressed the detection and annotation of interactions -- a crucial aspect for understanding social and individualized animal behavior. Existing open-source annotation tools support either behavioral labeling without localization of individuals, or localization without the capacity to capture interactions. To bridge this gap, we present SILVI, an open-source labeling software that integrates both functionalities. SILVI enables researchers to annotate behaviors and interactions directly within video data, generating structured outputs suitable for training and validating computer vision models. By linking behavioral ecology with computer vision, SILVI facilitates the development of automated approaches for fine-grained behavioral analyses. Although developed primarily in the context of animal behavior, SILVI could be useful more broadly to annotate human interactions in other videos that require extracting dynamic scene graphs. The software, along with documentation and download instructions, is available at: https://gitlab.gwdg.de/kanbertay/interaction-labelling-app. [SEP] [HINT] used -> Bioinformatics (Syns: utilize, ill-used, apply) | understanding -> Neuroscience (Syns: savvy, intellect, sympathy) | work -> Bioinformatics (Syns: work out, process, bring)",Bioinformatics
"Structural connectomes are detailed graphs that map how different brain regions are physically connected, offering critical insight into aging, cognition, and neurodegenerative diseases. However, these connectomes are high-dimensional and densely interconnected, which makes them difficult to interpret and analyze at scale. While low-dimensional spaces like PCA and autoencoders are often used to capture major sources of variation, their latent spaces are generally continuous and cannot fully reflect the mixed nature of variability in connectomes, which include both continuous (e.g., connectivity strength) and discrete factors (e.g., imaging site). Motivated by this, we propose a variational autoencoder (VAE) with a hybrid latent space that jointly models the discrete and continuous components. We analyze a large dataset of 5,761 connectomes from six Alzheimer's disease studies with ten acquisition protocols. Each connectome represents a single scan from a unique subject (3579 females, 2182 males), aged 22 to 102, with 4338 cognitively normal, 809 with mild cognitive impairment (MCI), and 614 with Alzheimer's disease (AD). Each connectome contains 121 brain regions defined by the BrainCOLOR atlas. We train our hybrid VAE in an unsupervised way and characterize what each latent component captures. We find that the discrete space is particularly effective at capturing subtle site-related differences, achieving an Adjusted Rand Index (ARI) of 0.65 with site labels, significantly outperforming PCA and a standard VAE followed by clustering (p < 0.05). These results demonstrate that the hybrid latent space can disentangle distinct sources of variability in connectomes in an unsupervised manner, offering potential for large-scale connectome analysis.",Neuroscience
"Structural connectomes are detailed graphs that map how different brain regions are physically connected, offering critical insight into aging, cognition, and neurodegenerative diseases. However, these connectomes are high-dimensional and densely interconnected, which makes them difficult to interpret and analyze at scale. While low-dimensional spaces like PCA and autoencoders are often used to capture major sources of variation, their latent spaces are generally continuous and cannot fully reflect the mixed nature of variability in connectomes, which include both continuous (e.g., connectivity strength) and discrete factors (e.g., imaging site). Motivated by this, we propose a variational autoencoder (VAE) with a hybrid latent space that jointly models the discrete and continuous components. We analyze a large dataset of 5,761 connectomes from six Alzheimer's disease studies with ten acquisition protocols. Each connectome represents a single scan from a unique subject (3579 females, 2182 males), aged 22 to 102, with 4338 cognitively normal, 809 with mild cognitive impairment (MCI), and 614 with Alzheimer's disease (AD). Each connectome contains 121 brain regions defined by the BrainCOLOR atlas. We train our hybrid VAE in an unsupervised way and characterize what each latent component captures. We find that the discrete space is particularly effective at capturing subtle site-related differences, achieving an Adjusted Rand Index (ARI) of 0.65 with site labels, significantly outperforming PCA and a standard VAE followed by clustering (p < 0.05). These results demonstrate that the hybrid latent space can disentangle distinct sources of variability in connectomes in an unsupervised manner, offering potential for large-scale connectome analysis. [SEP] [HINT] used -> Bioinformatics (Syns: utilize, ill-used, apply) | connectivity -> Neuroscience (Syns: ) | space -> Neuroscience (Syns: distance, place, outer space)",Neuroscience
"BaMg2Bi2 is a Dirac semimetal characterized by a simple Dirac cone crossing the Fermi level at the center of the Brillouin zone, protected by C3 rotational symmetry. Together with its Sr-based analogue SrMg2Bi2, it has been proposed as a promising candidate for a chemically driven topological switch: while SrMg2Bi2 is an insulator, BaMg2Bi2 exhibits non-trivial topological features. A detailed understanding of its electronic structure is essential to elucidate its electronic and transport properties. Previous photoemission studies confirmed the Dirac nature of BaMg2Bi2, but were limited to high photon energies, which hindered direct comparison with density functional theory calculations (DFT), due to reduced resolution and higher-frequency matrix-element modulation in that regime. In this work, we combine high-resolution angle-resolved photoemission spectroscopy (ARPES) and DFT calculations to get full insight on the valence band states, providing a comprehensive picture of the low-energy electronic structure. Our measurements reveal the presence of previously unobserved surface states. We found that they are topologically trivial, but they unlock a more comprehensive understanding of the material's behavior, reconciling previous discrepancies between experiment and theory.",Materials Science
"BaMg2Bi2 is a Dirac semimetal characterized by a simple Dirac cone crossing the Fermi level at the center of the Brillouin zone, protected by C3 rotational symmetry. Together with its Sr-based analogue SrMg2Bi2, it has been proposed as a promising candidate for a chemically driven topological switch: while SrMg2Bi2 is an insulator, BaMg2Bi2 exhibits non-trivial topological features. A detailed understanding of its electronic structure is essential to elucidate its electronic and transport properties. Previous photoemission studies confirmed the Dirac nature of BaMg2Bi2, but were limited to high photon energies, which hindered direct comparison with density functional theory calculations (DFT), due to reduced resolution and higher-frequency matrix-element modulation in that regime. In this work, we combine high-resolution angle-resolved photoemission spectroscopy (ARPES) and DFT calculations to get full insight on the valence band states, providing a comprehensive picture of the low-energy electronic structure. Our measurements reveal the presence of previously unobserved surface states. We found that they are topologically trivial, but they unlock a more comprehensive understanding of the material's behavior, reconciling previous discrepancies between experiment and theory. [SEP] [HINT] dft -> Materials Science (Syns: ) | understanding -> Neuroscience (Syns: savvy, intellect, sympathy) | transport -> Materials Science (Syns: transferral, enthral, shipping)",Materials Science
"Adult language learning varies greatly among individuals. Traditionally associated with frontotemporal language regions, this variability is increasingly seen as stemming from distributed brain networks. However, the role of these networks and their topological organization in explaining these differences remains unclear. We hypothesize that graph-theory-based network analysis of intrinsic multimodal connectivities across multiple networks explains overall and component-specific variations in language learning. We tested this in 101 healthy adults who underwent resting-state fMRI, structural MRI, and diffusion tensor imaging before seven days of six artificial language training tasks. We identified one dominant general learning component shared across tasks and five task-specific ones. Cross-validated predictive models used multimodal multi-network graph-theoretic metrics to predict final learning outcomes (LO) and rates (LR). We significantly predicted the LO and LR of the general component, which were primarily contributed by dorsal attention and frontoparietal networks. Nodal local efficiency was the most consistent predictor, with additional contributions from node clustering coefficient and network centrality for LR, highlighting local robustness, mesoscale network segregation, and global influence in explaining individual differences. Only task-specific word learning LO was predictable, relying on default mode and frontoparietal hubs with high betweenness centrality and efficiency. These findings demonstrate that intrinsic network topologies underlie differences in language learning success, supporting a multiple-systems hypothesis in which attentional-control networks interact with default and subcortical systems to shape learning trajectories. This advances mechanistic understanding and paves the way for personalized language education.",Neuroscience
"Adult language learning varies greatly among individuals. Traditionally associated with frontotemporal language regions, this variability is increasingly seen as stemming from distributed brain networks. However, the role of these networks and their topological organization in explaining these differences remains unclear. We hypothesize that graph-theory-based network analysis of intrinsic multimodal connectivities across multiple networks explains overall and component-specific variations in language learning. We tested this in 101 healthy adults who underwent resting-state fMRI, structural MRI, and diffusion tensor imaging before seven days of six artificial language training tasks. We identified one dominant general learning component shared across tasks and five task-specific ones. Cross-validated predictive models used multimodal multi-network graph-theoretic metrics to predict final learning outcomes (LO) and rates (LR). We significantly predicted the LO and LR of the general component, which were primarily contributed by dorsal attention and frontoparietal networks. Nodal local efficiency was the most consistent predictor, with additional contributions from node clustering coefficient and network centrality for LR, highlighting local robustness, mesoscale network segregation, and global influence in explaining individual differences. Only task-specific word learning LO was predictable, relying on default mode and frontoparietal hubs with high betweenness centrality and efficiency. These findings demonstrate that intrinsic network topologies underlie differences in language learning success, supporting a multiple-systems hypothesis in which attentional-control networks interact with default and subcortical systems to shape learning trajectories. This advances mechanistic understanding and paves the way for personalized language education. [SEP] [HINT] used -> Bioinformatics (Syns: utilize, ill-used, apply) | tasks -> Neuroscience (Syns: tax, task, project) | language -> Neuroscience (Syns: linguistic process, linguistic communication, spoken communication)",Neuroscience
"Excitons and their complexes govern optical-related behaviors in semiconductors. Here, using angle-resolved photoemission spectroscopy (ARPES), we have elucidated the light-matter interaction mediated by quasi-steady excitonic complexes within a monolayer of the prototypical two-dimensional (2D) semiconductor WSe2. Under continuous incident light, we have observed the generation of quasi-steady excitons and their complexes, encompassing ground and excited state excitons, trions, as well as their intricate interplay. We further show spectral evidence of electronic excitation states within the background of quasi-steady excitonic complexes, characterized by valence band (VB) effective mass renormalization, the enhanced spin-orbit coupling (SOC), the formation of an excitonic gap near the Fermi level (EF ) of the conduction band (CB), and intervalley excitonic band folding. Our findings not only unveil a quasi-steady excitonic complex background for the creation of diverse electronic excitations in 2D semiconductors but also offer new insights into the role of excitons in the charge density wave (CDW) formation mechanism and facilitate the advancement of correlated electronic state engineering based on the coupling between electrons and excitonic complexes in a quasi-equilibrium state.",Materials Science
"Excitons and their complexes govern optical-related behaviors in semiconductors. Here, using angle-resolved photoemission spectroscopy (ARPES), we have elucidated the light-matter interaction mediated by quasi-steady excitonic complexes within a monolayer of the prototypical two-dimensional (2D) semiconductor WSe2. Under continuous incident light, we have observed the generation of quasi-steady excitons and their complexes, encompassing ground and excited state excitons, trions, as well as their intricate interplay. We further show spectral evidence of electronic excitation states within the background of quasi-steady excitonic complexes, characterized by valence band (VB) effective mass renormalization, the enhanced spin-orbit coupling (SOC), the formation of an excitonic gap near the Fermi level (EF ) of the conduction band (CB), and intervalley excitonic band folding. Our findings not only unveil a quasi-steady excitonic complex background for the creation of diverse electronic excitations in 2D semiconductors but also offer new insights into the role of excitons in the charge density wave (CDW) formation mechanism and facilitate the advancement of correlated electronic state engineering based on the coupling between electrons and excitonic complexes in a quasi-equilibrium state. [SEP] [HINT] based -> Bioinformatics (Syns: ground, free-base, base) | charge -> Materials Science (Syns: tear, bearing, burster) | electronic -> Materials Science (Syns: )",Materials Science
"We present high-precision ab initio calculations of the four-point vertex function for the three-dimensional uniform electron gas using variational diagrammatic Monte Carlo. From these results, we extract Landau parameters that demonstrate a density-driven crossover from underscreening to overscreening. Guided by our numerical data, we propose a charge-based Kukkonen--Overhauser effective interaction within the local-density approximation, supplemented by a small s-wave correction (sKO$^+$), which accurately captures the electron--electron scattering amplitude. Using our numerically determined scattering amplitude, together with the sKO$^+$ ansatz, we compute the electron-electron contribution to the thermal resistivity, demonstrating excellent agreement with experimental measurements in simple metals.",Materials Science
"We present high-precision ab initio calculations of the four-point vertex function for the three-dimensional uniform electron gas using variational diagrammatic Monte Carlo. From these results, we extract Landau parameters that demonstrate a density-driven crossover from underscreening to overscreening. Guided by our numerical data, we propose a charge-based Kukkonen--Overhauser effective interaction within the local-density approximation, supplemented by a small s-wave correction (sKO$^+$), which accurately captures the electron--electron scattering amplitude. Using our numerically determined scattering amplitude, together with the sKO$^+$ ansatz, we compute the electron-electron contribution to the thermal resistivity, demonstrating excellent agreement with experimental measurements in simple metals. [SEP] [HINT] electron -> Materials Science (Syns: negatron) | using -> Bioinformatics (Syns: utilize, exploitation, apply) | thermal -> Materials Science (Syns: thermic, caloric)",Materials Science
"Compiling shallow and accurate quantum circuits for Hamiltonian simulation remains challenging due to hardware constraints and the combinatorial complexity of minimizing gate count and circuit depth. Existing optimization method pipelines rely on hand-engineered classical heuristics, which cannot learn input-dependent structure and therefore miss substantial opportunities for circuit reduction.   We introduce \textbf{F2}, an offline reinforcement learning framework that exploits free-fermionic structure to efficiently compile Trotter-based Hamiltonian simulation circuits. F2 provides (i) a reinforcement-learning environment over classically simulatable free-fermionic subroutines, (ii) architectural and objective-level inductive biases that stabilize long-horizon value learning, and (iii) a reversible synthetic-trajectory generation mechanism that consistently yields abundant, guaranteed-successful offline data.   Across benchmarks spanning lattice models, protein fragments, and crystalline materials (12-222 qubits), F2 reduces gate count by 47\% and depth by 38\% on average relative to strong baselines (Qiskit, Cirq/OpenFermion) while maintaining average errors of $10^{-7}$. These results show that aligning deep reinforcement learning with the algebraic structure of quantum dynamics enables substantial improvements in circuit synthesis, suggesting a promising direction for scalable, learning-based quantum compilation",Materials Science
"Compiling shallow and accurate quantum circuits for Hamiltonian simulation remains challenging due to hardware constraints and the combinatorial complexity of minimizing gate count and circuit depth. Existing optimization method pipelines rely on hand-engineered classical heuristics, which cannot learn input-dependent structure and therefore miss substantial opportunities for circuit reduction.   We introduce \textbf{F2}, an offline reinforcement learning framework that exploits free-fermionic structure to efficiently compile Trotter-based Hamiltonian simulation circuits. F2 provides (i) a reinforcement-learning environment over classically simulatable free-fermionic subroutines, (ii) architectural and objective-level inductive biases that stabilize long-horizon value learning, and (iii) a reversible synthetic-trajectory generation mechanism that consistently yields abundant, guaranteed-successful offline data.   Across benchmarks spanning lattice models, protein fragments, and crystalline materials (12-222 qubits), F2 reduces gate count by 47\% and depth by 38\% on average relative to strong baselines (Qiskit, Cirq/OpenFermion) while maintaining average errors of $10^{-7}$. These results show that aligning deep reinforcement learning with the algebraic structure of quantum dynamics enables substantial improvements in circuit synthesis, suggesting a promising direction for scalable, learning-based quantum compilation [SEP] [HINT] learning -> Bioinformatics (Syns: take, teach, acquire) | structure -> Bioinformatics (Syns: social system, complex body part, social structure) | results -> Bioinformatics (Syns: final result, consequence, resultant role)",Materials Science
"Recent results show remarkable interfacial--Dzyaloshinskii--Moriya interaction (i-DMI) in magnetic heterostructures composed of relatively thick Fe thin films ($\gg 1$ nm). To investigate its origin, we present a thorough magnetic characterization of the SiO$_2$/${}^{57}\mathrm{Fe}$($t$)/Au and SiO$_2$/Pt/${}^{57}\mathrm{Fe}$($t$)/Au heterostructures ($t = 1.6$ - $2.2$ nm). An i-DMI constant of $D_s^{\mathrm{Pt}} = 0.43\,\mathrm{mJ\,m^{-2}}$ is extracted for the Pt/Fe/Au system, as probed by wavevector-resolved Brillouin light scattering spectroscopy. Ferromagnetic resonance and conversion electron Mössbauer spectroscopy indicate that significant surface anisotropy is present in Pt/Fe/Au, and that an interfacial Fe fraction ($\sim18$) exhibits tilted magnetization ($\sim25^\circ$ out of plane) and an enhanced hyperfine field, correlating with the stronger i-DMI.",Materials Science
"Recent results show remarkable interfacial--Dzyaloshinskii--Moriya interaction (i-DMI) in magnetic heterostructures composed of relatively thick Fe thin films ($\gg 1$ nm). To investigate its origin, we present a thorough magnetic characterization of the SiO$_2$/${}^{57}\mathrm{Fe}$($t$)/Au and SiO$_2$/Pt/${}^{57}\mathrm{Fe}$($t$)/Au heterostructures ($t = 1.6$ - $2.2$ nm). An i-DMI constant of $D_s^{\mathrm{Pt}} = 0.43\,\mathrm{mJ\,m^{-2}}$ is extracted for the Pt/Fe/Au system, as probed by wavevector-resolved Brillouin light scattering spectroscopy. Ferromagnetic resonance and conversion electron Mössbauer spectroscopy indicate that significant surface anisotropy is present in Pt/Fe/Au, and that an interfacial Fe fraction ($\sim18$) exhibits tilted magnetization ($\sim25^\circ$ out of plane) and an enhanced hyperfine field, correlating with the stronger i-DMI. [SEP] [HINT] electron -> Materials Science (Syns: negatron) | results -> Bioinformatics (Syns: final result, consequence, resultant role) | magnetic -> Materials Science (Syns: charismatic, magnetised, magnetized)",Materials Science
"Oral mucosal diseases such as leukoplakia, oral lichen planus, and recurrent   aphthous ulcers exhibit diverse and overlapping visual features,   making diagnosis challenging for non-specialists. While vision-language   models (VLMs) have shown promise in medical image interpretation,   their application in oral healthcare remains underexplored due to   the lack of large-scale, well-annotated datasets. In this work, we present   \textbf{OralGPT}, the first domain-specific two-stage vision-language   framework designed for oral mucosal disease diagnosis and captioning.   In Stage 1, OralGPT learns visual representations and disease-related   concepts from classification labels. In Stage 2, it enhances its language   generation ability using long-form expert-authored captions. To   overcome the annotation bottleneck, we propose a novel similarity-guided   data augmentation strategy that propagates descriptive knowledge from   expert-labeled images to weakly labeled ones. We also construct the   first benchmark dataset for oral mucosal diseases, integrating multi-source   image data with both structured and unstructured textual annotations.   Experimental results on four common oral conditions demonstrate that   OralGPT achieves competitive diagnostic performance while generating   fluent, clinically meaningful image descriptions. This study   provides a foundation for language-assisted diagnostic tools in oral   healthcare.",Bioinformatics
"Oral mucosal diseases such as leukoplakia, oral lichen planus, and recurrent   aphthous ulcers exhibit diverse and overlapping visual features,   making diagnosis challenging for non-specialists. While vision-language   models (VLMs) have shown promise in medical image interpretation,   their application in oral healthcare remains underexplored due to   the lack of large-scale, well-annotated datasets. In this work, we present   \textbf{OralGPT}, the first domain-specific two-stage vision-language   framework designed for oral mucosal disease diagnosis and captioning.   In Stage 1, OralGPT learns visual representations and disease-related   concepts from classification labels. In Stage 2, it enhances its language   generation ability using long-form expert-authored captions. To   overcome the annotation bottleneck, we propose a novel similarity-guided   data augmentation strategy that propagates descriptive knowledge from   expert-labeled images to weakly labeled ones. We also construct the   first benchmark dataset for oral mucosal diseases, integrating multi-source   image data with both structured and unstructured textual annotations.   Experimental results on four common oral conditions demonstrate that   OralGPT achieves competitive diagnostic performance while generating   fluent, clinically meaningful image descriptions. This study   provides a foundation for language-assisted diagnostic tools in oral   healthcare. [SEP] [HINT] language -> Neuroscience (Syns: linguistic process, linguistic communication, spoken communication) | results -> Bioinformatics (Syns: final result, consequence, resultant role) | performance -> Bioinformatics (Syns: functioning, operation, carrying out)",Bioinformatics
"Learning stochastic models of dynamical systems underlying observed data is of interest in many scientific fields. Here we propose a novel method for this task, based on the framework of variational autoencoders for dynamical systems. The method estimates from the data both the system state trajectories and noise time series. This approach allows to perform multi-step system evolution and supports a teacher forcing strategy, alleviating limitations of autoencoder-based approaches for stochastic systems. We demonstrate the performance of the proposed approach on six test problems, covering simulated and experimental data. We further show the effects of the teacher forcing interval on the nature of the internal dynamics, and compare it to the deterministic models with equivalent architecture.",Bioinformatics
"Learning stochastic models of dynamical systems underlying observed data is of interest in many scientific fields. Here we propose a novel method for this task, based on the framework of variational autoencoders for dynamical systems. The method estimates from the data both the system state trajectories and noise time series. This approach allows to perform multi-step system evolution and supports a teacher forcing strategy, alleviating limitations of autoencoder-based approaches for stochastic systems. We demonstrate the performance of the proposed approach on six test problems, covering simulated and experimental data. We further show the effects of the teacher forcing interval on the nature of the internal dynamics, and compare it to the deterministic models with equivalent architecture. [SEP] [HINT] based -> Bioinformatics (Syns: ground, free-base, base) | learning -> Bioinformatics (Syns: take, teach, acquire) | performance -> Bioinformatics (Syns: functioning, operation, carrying out)",Bioinformatics
"Early forecasting of individual cognitive decline in Alzheimer's disease (AD) is central to disease evaluation and management. Despite advances, it is as of yet challenging for existing methodological frameworks to integrate multimodal data for longitudinal personalized forecasting while maintaining interpretability. To address this gap, we present the Neural Koopman Machine (NKM), a new machine learning architecture inspired by dynamical systems and attention mechanisms, designed to forecast multiple cognitive scores simultaneously using multimodal genetic, neuroimaging, proteomic, and demographic data. NKM integrates analytical ($α$) and biological ($β$) knowledge to guide feature grouping and control the hierarchical attention mechanisms to extract relevant patterns. By implementing Fusion Group-Aware Hierarchical Attention within the Koopman operator framework, NKM transforms complex nonlinear trajectories into interpretable linear representations. To demonstrate NKM's efficacy, we applied it to study the Alzheimer's Disease Neuroimaging Initiative (ADNI) dataset. Our results suggest that NKM consistently outperforms both traditional machine learning methods and deep learning models in forecasting trajectories of cognitive decline. Specifically, NKM (1) forecasts changes of multiple cognitive scores simultaneously, (2) quantifies differential biomarker contributions to predicting distinctive cognitive scores, and (3) identifies brain regions most predictive of cognitive deterioration. Together, NKM advances personalized, interpretable forecasting of future cognitive decline in AD using past multimodal data through an explainable, explicit system and reveals potential multimodal biological underpinnings of AD progression.",Bioinformatics
"Early forecasting of individual cognitive decline in Alzheimer's disease (AD) is central to disease evaluation and management. Despite advances, it is as of yet challenging for existing methodological frameworks to integrate multimodal data for longitudinal personalized forecasting while maintaining interpretability. To address this gap, we present the Neural Koopman Machine (NKM), a new machine learning architecture inspired by dynamical systems and attention mechanisms, designed to forecast multiple cognitive scores simultaneously using multimodal genetic, neuroimaging, proteomic, and demographic data. NKM integrates analytical ($α$) and biological ($β$) knowledge to guide feature grouping and control the hierarchical attention mechanisms to extract relevant patterns. By implementing Fusion Group-Aware Hierarchical Attention within the Koopman operator framework, NKM transforms complex nonlinear trajectories into interpretable linear representations. To demonstrate NKM's efficacy, we applied it to study the Alzheimer's Disease Neuroimaging Initiative (ADNI) dataset. Our results suggest that NKM consistently outperforms both traditional machine learning methods and deep learning models in forecasting trajectories of cognitive decline. Specifically, NKM (1) forecasts changes of multiple cognitive scores simultaneously, (2) quantifies differential biomarker contributions to predicting distinctive cognitive scores, and (3) identifies brain regions most predictive of cognitive deterioration. Together, NKM advances personalized, interpretable forecasting of future cognitive decline in AD using past multimodal data through an explainable, explicit system and reveals potential multimodal biological underpinnings of AD progression. [SEP] [HINT] learning -> Bioinformatics (Syns: take, teach, acquire) | complex -> Bioinformatics (Syns: building complex, coordination compound, composite) | results -> Bioinformatics (Syns: final result, consequence, resultant role)",Bioinformatics
"Theories of consciousness depend on data, and it needs to be appropriate data, without overwhelming confounding factors. The reports of Minimal Phenomenal Experience (MPE) in [Metzinger 2024] relate to consciousness in a state purer than everyday consciousness, which may have fewer confounding factors. This essay suggests that the confounding factors, which are absent or diminished in MPE states, are related to language. The self which is absent in mindful states is a product of language. The link between language and MPE states is demonstrated by reference to the phenomenal reports in [Metzinger 2024]. Language, emotion, and mindfulness are analysed in terms of Bayesian pattern matching, or equivalently minimisation of Free Energy, using three types of pattern which are specific to humans. These types are the word patterns of language, self-patterns which drive our emotions and which are also a part of language, and mindful patterns. The practice of mindfulness involves learning mindful patterns, which compete with self-patterns and displace them, allowing mindful states to occur. Consequences of this picture for theories of consciousness, and their relation to MPE states, are explored.",Neuroscience
"Theories of consciousness depend on data, and it needs to be appropriate data, without overwhelming confounding factors. The reports of Minimal Phenomenal Experience (MPE) in [Metzinger 2024] relate to consciousness in a state purer than everyday consciousness, which may have fewer confounding factors. This essay suggests that the confounding factors, which are absent or diminished in MPE states, are related to language. The self which is absent in mindful states is a product of language. The link between language and MPE states is demonstrated by reference to the phenomenal reports in [Metzinger 2024]. Language, emotion, and mindfulness are analysed in terms of Bayesian pattern matching, or equivalently minimisation of Free Energy, using three types of pattern which are specific to humans. These types are the word patterns of language, self-patterns which drive our emotions and which are also a part of language, and mindful patterns. The practice of mindfulness involves learning mindful patterns, which compete with self-patterns and displace them, allowing mindful states to occur. Consequences of this picture for theories of consciousness, and their relation to MPE states, are explored. [SEP] [HINT] language -> Neuroscience (Syns: linguistic process, linguistic communication, spoken communication) | learning -> Bioinformatics (Syns: take, teach, acquire) | using -> Bioinformatics (Syns: utilize, exploitation, apply)",Neuroscience
"Low vision involves a range of visual impairments that significantly impact daily activities, particularly navigation in urban environments. Individuals with low vision often develop adaptive strategies to compensate for visual deficits, relying on head movements to bring objects into their remaining functional field of vision. Research suggests that they focus on road surface markings and building edges to aid in wayfinding and collision avoidance. However, urban navigation presents additional challenges, as obstacles, moving hazards, and tripping dangers may enter their visual loss field, increasing the risk of injury. Traditional eye movement studies are typically conducted in controlled laboratory settings with fixed head positions, limiting the understanding of head-eye coordination in real-world environments. To bridge this gap, we designed a naturalistic, ""free-head"" experiment using eye-tracking technology to examine head and eye movement patterns during urban navigation. Participants with low vision were compared to a control cohort without visual impairment to test the hypothesis that eye and head movements become decoupled in visually impaired individuals. Findings indicate that individuals with peripheral field loss exhibit significant eye-head decoupling, while those with acuity loss demonstrate more synchronized movements. Results for individuals with central field loss were inconclusive but revealed distinct movement patterns. These insights provide valuable direction for rehabilitation strategies, assistive-mobility technologies, and urban design improvements. By expanding research on eye-head coordination, this study contributes to the development of interventions that enhance safety, mobility, and independence for individuals with low vision in complex urban environments.",Bioinformatics
"Low vision involves a range of visual impairments that significantly impact daily activities, particularly navigation in urban environments. Individuals with low vision often develop adaptive strategies to compensate for visual deficits, relying on head movements to bring objects into their remaining functional field of vision. Research suggests that they focus on road surface markings and building edges to aid in wayfinding and collision avoidance. However, urban navigation presents additional challenges, as obstacles, moving hazards, and tripping dangers may enter their visual loss field, increasing the risk of injury. Traditional eye movement studies are typically conducted in controlled laboratory settings with fixed head positions, limiting the understanding of head-eye coordination in real-world environments. To bridge this gap, we designed a naturalistic, ""free-head"" experiment using eye-tracking technology to examine head and eye movement patterns during urban navigation. Participants with low vision were compared to a control cohort without visual impairment to test the hypothesis that eye and head movements become decoupled in visually impaired individuals. Findings indicate that individuals with peripheral field loss exhibit significant eye-head decoupling, while those with acuity loss demonstrate more synchronized movements. Results for individuals with central field loss were inconclusive but revealed distinct movement patterns. These insights provide valuable direction for rehabilitation strategies, assistive-mobility technologies, and urban design improvements. By expanding research on eye-head coordination, this study contributes to the development of interventions that enhance safety, mobility, and independence for individuals with low vision in complex urban environments. [SEP] [HINT] field -> Materials Science (Syns: field of honor, line of business, orbit) | low -> Materials Science (Syns: low-spirited, scurvy, depressed) | understanding -> Neuroscience (Syns: savvy, intellect, sympathy)",Bioinformatics
"Abrikosov vortices in type-II superconductors critically influence current flow and coherence, thereby imposing fundamental limits on superconducting quantum technologies. Quantum circuits employ superconducting elements at micro- and mesoscopic scales, where individual vortices can significantly impact device performance, necessitating investigation of vortex entry, motion, and pinning in these constrained geometries. Cavity-optomechanical platforms combining flux-tunable microwave resonators with superconducting nanomechanical elements offer a promising route to the single-photon strong-coupling regime and enable highly sensitive probing of the mechanical degree of freedom under elevated magnetic fields. Here, we exploit this platform to investigate vortex entry processes at the single-event level. We observe discrete jumps of the mechanical resonance frequency attributable to individual vortex entry, corresponding to attonewton-scale forces and allowing quantitative extraction of single-vortex pinning energies. These signatures are superimposed on a smooth power-law background characteristic of the collective Campbell-regime of vortex elasticity. Our results establish optomechanics-inspired sensing as a powerful method for exploring fundamental superconducting properties and identifying decoherence pathways in quantum circuits. Beyond advancing vortex physics, this work opens new opportunities for integrating mechanical sensing into superconducting device architectures, bridging condensed matter physics and quantum information science.",Materials Science
"Abrikosov vortices in type-II superconductors critically influence current flow and coherence, thereby imposing fundamental limits on superconducting quantum technologies. Quantum circuits employ superconducting elements at micro- and mesoscopic scales, where individual vortices can significantly impact device performance, necessitating investigation of vortex entry, motion, and pinning in these constrained geometries. Cavity-optomechanical platforms combining flux-tunable microwave resonators with superconducting nanomechanical elements offer a promising route to the single-photon strong-coupling regime and enable highly sensitive probing of the mechanical degree of freedom under elevated magnetic fields. Here, we exploit this platform to investigate vortex entry processes at the single-event level. We observe discrete jumps of the mechanical resonance frequency attributable to individual vortex entry, corresponding to attonewton-scale forces and allowing quantitative extraction of single-vortex pinning energies. These signatures are superimposed on a smooth power-law background characteristic of the collective Campbell-regime of vortex elasticity. Our results establish optomechanics-inspired sensing as a powerful method for exploring fundamental superconducting properties and identifying decoherence pathways in quantum circuits. Beyond advancing vortex physics, this work opens new opportunities for integrating mechanical sensing into superconducting device architectures, bridging condensed matter physics and quantum information science. [SEP] [HINT] information -> Bioinformatics (Syns: entropy, data, info) | work -> Bioinformatics (Syns: work out, process, bring) | results -> Bioinformatics (Syns: final result, consequence, resultant role)",Materials Science
"Species distribution models (SDMs), which aim to predict species occurrence based on environmental variables, are widely used to monitor and respond to biodiversity change. Recent deep learning advances for SDMs have been shown to perform well on complex and heterogeneous datasets, but their effectiveness remains limited by spatial biases in the data. In this paper, we revisit deep SDMs from a Bayesian perspective and introduce BATIS, a novel and practical framework wherein prior predictions are updated iteratively using limited observational data. Models must appropriately capture both aleatoric and epistemic uncertainty to effectively combine fine-grained local insights with broader ecological patterns. We benchmark an extensive set of uncertainty quantification approaches on a novel dataset including citizen science observations from the eBird platform. Our empirical study shows how Bayesian deep learning approaches can greatly improve the reliability of SDMs in data-scarce locations, which can contribute to ecological understanding and conservation efforts.",Bioinformatics
"Species distribution models (SDMs), which aim to predict species occurrence based on environmental variables, are widely used to monitor and respond to biodiversity change. Recent deep learning advances for SDMs have been shown to perform well on complex and heterogeneous datasets, but their effectiveness remains limited by spatial biases in the data. In this paper, we revisit deep SDMs from a Bayesian perspective and introduce BATIS, a novel and practical framework wherein prior predictions are updated iteratively using limited observational data. Models must appropriately capture both aleatoric and epistemic uncertainty to effectively combine fine-grained local insights with broader ecological patterns. We benchmark an extensive set of uncertainty quantification approaches on a novel dataset including citizen science observations from the eBird platform. Our empirical study shows how Bayesian deep learning approaches can greatly improve the reliability of SDMs in data-scarce locations, which can contribute to ecological understanding and conservation efforts. [SEP] [HINT] used -> Bioinformatics (Syns: utilize, ill-used, apply) | based -> Bioinformatics (Syns: ground, free-base, base) | understanding -> Neuroscience (Syns: savvy, intellect, sympathy)",Bioinformatics
"Background and objective: Prior probability shift between training and deployment datasets challenges deep learning-based medical image classification. Standard correction methods reweight posterior probabilities to adjust prior bias, yet their benefit is inconsistent. We developed a reliability framework identifying when prior correction helps or harms performance in pathological cell image analysis. Methods: We analyzed 303 colorectal cancer specimens with CD103/CD8 immunostaining, yielding 185,432 annotated cell images across 16 cell types. ResNet models were trained under varying bias ratios (1.1-20$\times$). Feature separability was quantified using cosine similarity-based likelihood quality scores, reflecting intra- versus inter-class distinctions in learned feature spaces. Multiple linear regression, ANOVA, and generalized additive models (GAMs) evaluated associations among feature separability, prior bias, sample adequacy, and F1 performance. Results: Feature separability dominated performance ($β= 1.650$, $p < 0.001$), showing 412-fold stronger impact than prior bias ($β= 0.004$, $p = 0.018$). GAM analysis showed strong predictive power ($R^2 = 0.876$) with mostly linear trends. A quality threshold of 0.294 effectively identified cases requiring correction (AUC = 0.610). Cell types scoring $>0.5$ were robust without correction, whereas those $<0.3$ consistently required adjustment. Conclusion: Feature extraction quality, not bias magnitude, governs correction benefit. The proposed framework provides quantitative guidance for selective correction, enabling efficient deployment and reliable diagnostic AI.",Bioinformatics
"Background and objective: Prior probability shift between training and deployment datasets challenges deep learning-based medical image classification. Standard correction methods reweight posterior probabilities to adjust prior bias, yet their benefit is inconsistent. We developed a reliability framework identifying when prior correction helps or harms performance in pathological cell image analysis. Methods: We analyzed 303 colorectal cancer specimens with CD103/CD8 immunostaining, yielding 185,432 annotated cell images across 16 cell types. ResNet models were trained under varying bias ratios (1.1-20$\times$). Feature separability was quantified using cosine similarity-based likelihood quality scores, reflecting intra- versus inter-class distinctions in learned feature spaces. Multiple linear regression, ANOVA, and generalized additive models (GAMs) evaluated associations among feature separability, prior bias, sample adequacy, and F1 performance. Results: Feature separability dominated performance ($β= 1.650$, $p < 0.001$), showing 412-fold stronger impact than prior bias ($β= 0.004$, $p = 0.018$). GAM analysis showed strong predictive power ($R^2 = 0.876$) with mostly linear trends. A quality threshold of 0.294 effectively identified cases requiring correction (AUC = 0.610). Cell types scoring $>0.5$ were robust without correction, whereas those $<0.3$ consistently required adjustment. Conclusion: Feature extraction quality, not bias magnitude, governs correction benefit. The proposed framework provides quantitative guidance for selective correction, enabling efficient deployment and reliable diagnostic AI. [SEP] [HINT] quality -> Bioinformatics (Syns: lineament, tone, calibre) | datasets -> Bioinformatics (Syns: ) | performance -> Bioinformatics (Syns: functioning, operation, carrying out)",Bioinformatics
"Mathematical models support inference and forecasting in ecology and epidemiology, but results depend on the estimation framework. We compare Bayesian and Frequentist approaches across three biological models using four datasets: Lotka-Volterra predator-prey dynamics (Hudson Bay), a generalized logistic model (lung injury and 2022 U.S. mpox), and an SEIUR epidemic model (COVID-19 in Spain). Both approaches use a normal error structure to ensure a fair comparison.   We first assessed structural identifiability to determine which parameters can theoretically be recovered from the data. We then evaluated practical identifiability and forecasting performance using four metrics: mean absolute error (MAE), mean squared error (MSE), 95 percent prediction interval (PI) coverage, and weighted interval score (WIS). For the Lotka-Volterra model with both prey and predator data, we analyzed three scenarios: prey only, predator only, and both.   The Frequentist workflow used QuantDiffForecast (QDF) in MATLAB, which fits ODE models via nonlinear least squares and quantifies uncertainty through parametric bootstrap. The Bayesian workflow used BayesianFitForecast (BFF), which employs Hamiltonian Monte Carlo sampling via Stan to generate posterior distributions and diagnostics such as the Gelman-Rubin R-hat statistic.   Results show that Frequentist inference performs best when data are rich and fully observed, while Bayesian inference excels when latent-state uncertainty is high and data are sparse, as in the SEIUR COVID-19 model. Structural identifiability clarifies these patterns: full observability benefits both frameworks, while limited observability constrains parameter recovery. This comparison provides guidance for choosing inference frameworks based on data richness, observability, and uncertainty needs.",Bioinformatics
"Mathematical models support inference and forecasting in ecology and epidemiology, but results depend on the estimation framework. We compare Bayesian and Frequentist approaches across three biological models using four datasets: Lotka-Volterra predator-prey dynamics (Hudson Bay), a generalized logistic model (lung injury and 2022 U.S. mpox), and an SEIUR epidemic model (COVID-19 in Spain). Both approaches use a normal error structure to ensure a fair comparison.   We first assessed structural identifiability to determine which parameters can theoretically be recovered from the data. We then evaluated practical identifiability and forecasting performance using four metrics: mean absolute error (MAE), mean squared error (MSE), 95 percent prediction interval (PI) coverage, and weighted interval score (WIS). For the Lotka-Volterra model with both prey and predator data, we analyzed three scenarios: prey only, predator only, and both.   The Frequentist workflow used QuantDiffForecast (QDF) in MATLAB, which fits ODE models via nonlinear least squares and quantifies uncertainty through parametric bootstrap. The Bayesian workflow used BayesianFitForecast (BFF), which employs Hamiltonian Monte Carlo sampling via Stan to generate posterior distributions and diagnostics such as the Gelman-Rubin R-hat statistic.   Results show that Frequentist inference performs best when data are rich and fully observed, while Bayesian inference excels when latent-state uncertainty is high and data are sparse, as in the SEIUR COVID-19 model. Structural identifiability clarifies these patterns: full observability benefits both frameworks, while limited observability constrains parameter recovery. This comparison provides guidance for choosing inference frameworks based on data richness, observability, and uncertainty needs. [SEP] [HINT] used -> Bioinformatics (Syns: utilize, ill-used, apply) | based -> Bioinformatics (Syns: ground, free-base, base) | structure -> Bioinformatics (Syns: social system, complex body part, social structure)",Bioinformatics
"A fine-grained account of functional selectivity in the cortex is essential for understanding how visual information is processed and represented in the brain. Classical studies using designed experiments have identified multiple category-selective regions; however, these approaches rely on preconceived hypotheses about categories. Subsequent data-driven discovery methods have sought to address this limitation but are often limited by simple, typically linear encoding models. We propose an in silico approach for data-driven discovery of novel category-selectivity hypotheses based on an encoder-decoder transformer model. The architecture incorporates a brain-region to image-feature cross-attention mechanism, enabling nonlinear mappings between high-dimensional deep network features and semantic patterns encoded in the brain activity. We further introduce a method to characterize the selectivity of individual parcels by leveraging diffusion-based image generative models and large-scale datasets to synthesize and select images that maximally activate each parcel. Our approach reveals regions with complex, compositional selectivity involving diverse semantic concepts, which we validate in silico both within and across subjects. Using a brain encoder as a ""digital twin"" offers a powerful, data-driven framework for generating and testing hypotheses about visual selectivity in the human brain - hypotheses that can guide future fMRI experiments. Our code is available at: https://kriegeskorte-lab.github.io/in-silico-mapping/ .",Neuroscience
"A fine-grained account of functional selectivity in the cortex is essential for understanding how visual information is processed and represented in the brain. Classical studies using designed experiments have identified multiple category-selective regions; however, these approaches rely on preconceived hypotheses about categories. Subsequent data-driven discovery methods have sought to address this limitation but are often limited by simple, typically linear encoding models. We propose an in silico approach for data-driven discovery of novel category-selectivity hypotheses based on an encoder-decoder transformer model. The architecture incorporates a brain-region to image-feature cross-attention mechanism, enabling nonlinear mappings between high-dimensional deep network features and semantic patterns encoded in the brain activity. We further introduce a method to characterize the selectivity of individual parcels by leveraging diffusion-based image generative models and large-scale datasets to synthesize and select images that maximally activate each parcel. Our approach reveals regions with complex, compositional selectivity involving diverse semantic concepts, which we validate in silico both within and across subjects. Using a brain encoder as a ""digital twin"" offers a powerful, data-driven framework for generating and testing hypotheses about visual selectivity in the human brain - hypotheses that can guide future fMRI experiments. Our code is available at: https://kriegeskorte-lab.github.io/in-silico-mapping/ . [SEP] [HINT] based -> Bioinformatics (Syns: ground, free-base, base) | features -> Bioinformatics (Syns: characteristic, lineament, feature of speech) | understanding -> Neuroscience (Syns: savvy, intellect, sympathy)",Neuroscience
"Healthcare AI systems have historically faced challenges in merging contextual reasoning, long-term state management, and human-verifiable workflows into a cohesive framework. This paper introduces a completely innovative architecture and concept: combining the Model Context Protocol (MCP) with a specific clinical application, known as MCP-AI. This integration allows intelligent agents to reason over extended periods, collaborate securely, and adhere to authentic clinical logic, representing a significant shift away from traditional Clinical Decision Support Systems (CDSS) and prompt-based Large Language Models (LLMs). As healthcare systems become more complex, the need for autonomous, context-aware clinical reasoning frameworks has become urgent. We present MCP-AI, a novel architecture for explainable medical decision-making built upon the Model Context Protocol (MCP) a modular, executable specification for orchestrating generative and descriptive AI agents in real-time workflows. Each MCP file captures clinical objectives, patient context, reasoning state, and task logic, forming a reusable and auditable memory object. Unlike conventional CDSS or stateless prompt-based AI systems, MCP-AI supports adaptive, longitudinal, and collaborative reasoning across care settings. MCP-AI is validated through two use cases: (1) diagnostic modeling of Fragile X Syndrome with comorbid depression, and (2) remote coordination for Type 2 Diabetes and hypertension. In either scenario, the protocol facilitates physician-in-the-loop validation, streamlines clinical processes, and guarantees secure transitions of AI responsibilities between healthcare providers. The system connects with HL7/FHIR interfaces and adheres to regulatory standards, such as HIPAA and FDA SaMD guidelines. MCP-AI provides a scalable basis for interpretable, composable, and safety-oriented AI within upcoming clinical environments.",Bioinformatics
"Healthcare AI systems have historically faced challenges in merging contextual reasoning, long-term state management, and human-verifiable workflows into a cohesive framework. This paper introduces a completely innovative architecture and concept: combining the Model Context Protocol (MCP) with a specific clinical application, known as MCP-AI. This integration allows intelligent agents to reason over extended periods, collaborate securely, and adhere to authentic clinical logic, representing a significant shift away from traditional Clinical Decision Support Systems (CDSS) and prompt-based Large Language Models (LLMs). As healthcare systems become more complex, the need for autonomous, context-aware clinical reasoning frameworks has become urgent. We present MCP-AI, a novel architecture for explainable medical decision-making built upon the Model Context Protocol (MCP) a modular, executable specification for orchestrating generative and descriptive AI agents in real-time workflows. Each MCP file captures clinical objectives, patient context, reasoning state, and task logic, forming a reusable and auditable memory object. Unlike conventional CDSS or stateless prompt-based AI systems, MCP-AI supports adaptive, longitudinal, and collaborative reasoning across care settings. MCP-AI is validated through two use cases: (1) diagnostic modeling of Fragile X Syndrome with comorbid depression, and (2) remote coordination for Type 2 Diabetes and hypertension. In either scenario, the protocol facilitates physician-in-the-loop validation, streamlines clinical processes, and guarantees secure transitions of AI responsibilities between healthcare providers. The system connects with HL7/FHIR interfaces and adheres to regulatory standards, such as HIPAA and FDA SaMD guidelines. MCP-AI provides a scalable basis for interpretable, composable, and safety-oriented AI within upcoming clinical environments. [SEP] [HINT] task -> Neuroscience (Syns: tax, project, chore) | clinical -> Bioinformatics (Syns: ) | language -> Neuroscience (Syns: linguistic process, linguistic communication, spoken communication)",Bioinformatics
"Energy-based models have become a central paradigm for understanding computation and stability in both theoretical neuroscience and machine learning. However, the energetic framework typically relies on symmetry in synaptic or weight matrices - a constraint that excludes biologically realistic systems such as excitatory-inhibitory (E-I) networks. When symmetry is relaxed, the classical notion of a global energy landscape fails, leaving the dynamics of asymmetric neural systems conceptually unanchored. In this work, we extend the energetic framework to asymmetric firing rate networks, revealing an underlying game-theoretic structure for the neural dynamics in which each neuron is an agent that seeks to minimize its own energy. In addition, we exploit rigorous stability principles from network theory to study regulation and balancing of neural activity in E-I networks. We combine the novel game-energetic interpretation and the stability results to revisit standard frameworks in theoretical neuroscience, such as the Wilson-Cowan and lateral inhibition models. These insights allow us to study cortical columns of lateral inhibition microcircuits as contrast enhancer - with the ability to selectively sharpen subtle differences in the environment through hierarchical excitation-inhibition interplay. Our results bridge energetic and game-theoretic views of neural computation, offering a pathway toward the systematic engineering of biologically grounded, dynamically stable neural architectures.",Neuroscience
"Energy-based models have become a central paradigm for understanding computation and stability in both theoretical neuroscience and machine learning. However, the energetic framework typically relies on symmetry in synaptic or weight matrices - a constraint that excludes biologically realistic systems such as excitatory-inhibitory (E-I) networks. When symmetry is relaxed, the classical notion of a global energy landscape fails, leaving the dynamics of asymmetric neural systems conceptually unanchored. In this work, we extend the energetic framework to asymmetric firing rate networks, revealing an underlying game-theoretic structure for the neural dynamics in which each neuron is an agent that seeks to minimize its own energy. In addition, we exploit rigorous stability principles from network theory to study regulation and balancing of neural activity in E-I networks. We combine the novel game-energetic interpretation and the stability results to revisit standard frameworks in theoretical neuroscience, such as the Wilson-Cowan and lateral inhibition models. These insights allow us to study cortical columns of lateral inhibition microcircuits as contrast enhancer - with the ability to selectively sharpen subtle differences in the environment through hierarchical excitation-inhibition interplay. Our results bridge energetic and game-theoretic views of neural computation, offering a pathway toward the systematic engineering of biologically grounded, dynamically stable neural architectures. [SEP] [HINT] understanding -> Neuroscience (Syns: savvy, intellect, sympathy) | cortical -> Neuroscience (Syns: ) | structure -> Bioinformatics (Syns: social system, complex body part, social structure)",Neuroscience
"Silicene growth on graphene has emerged as a novel method for fabricating silicon-based van der Waals heterostructures. However, the silicene flakes produced in this manner are the result of an exotic growth mode characterized by metastable nanostructures with varying degrees of deviation from equilibrium, with large two-dimensional flakes surrounded by a rim that coexist with small 3D islands, and, at large deposits, thick dendritic pyramids separated by a denuded zone. In order to rationalize and control this growth, a model is derived that revisits the dewetting thermodynamics and considers generally ignored adsorption and step-edge energies. The model is investigated using kinetic Monte-Carlo simulations and mean-field rate equations, and implemented by close inspection of microscopy images. This model perfectly reproduces the experimental outcomes, unveiling an anomalous growth mode, and provides guidelines on experimental conditions for high-quality silicene growth.",Materials Science
"Silicene growth on graphene has emerged as a novel method for fabricating silicon-based van der Waals heterostructures. However, the silicene flakes produced in this manner are the result of an exotic growth mode characterized by metastable nanostructures with varying degrees of deviation from equilibrium, with large two-dimensional flakes surrounded by a rim that coexist with small 3D islands, and, at large deposits, thick dendritic pyramids separated by a denuded zone. In order to rationalize and control this growth, a model is derived that revisits the dewetting thermodynamics and considers generally ignored adsorption and step-edge energies. The model is investigated using kinetic Monte-Carlo simulations and mean-field rate equations, and implemented by close inspection of microscopy images. This model perfectly reproduces the experimental outcomes, unveiling an anomalous growth mode, and provides guidelines on experimental conditions for high-quality silicene growth. [SEP] [HINT] order -> Materials Science (Syns: enjoin, dictate, social club) | using -> Bioinformatics (Syns: utilize, exploitation, apply) | method -> Bioinformatics (Syns: method acting)",Materials Science
"Spin field-effect transistors (SFETs) are promising candidates for low-power spin-based electronics, yet existing realizations that rely on spin-orbit coupling are constrained by limited material choices and short spin-coherence lengths. Here we propose a different operating principle based on multiferroic altermagnets, in which spin splitting is tuned by an electric field through symmetry control rather than conventional spin-orbit physics. Using an effective model combined with quantum transport simulations, we show that the conductance is determined by the degree of matching between the electrically controlled spin texture of the channel and the fixed spin polarization of ferromagnetic contacts, enabling clear ON and OFF states. Remarkably, we also address a long-standing challenge in multiferroic device design: spintronic channels require metallic carriers, whereas ferroelectricity is usually suppressed in metals. We resolve this conflict by imprinting multiferroic altermagnetism into highly conductive materials via the proximity effect. First-principles calculations for graphene on multiferroic vanadium sulfide halides confirm that graphene acquires a ferroelectrically switchable spin splitting while retaining its metallic character. These results establish a practical route to SFET implementation and identify multiferroic altermagnets as a versatile platform for next-generation spintronic devices.",Materials Science
"Spin field-effect transistors (SFETs) are promising candidates for low-power spin-based electronics, yet existing realizations that rely on spin-orbit coupling are constrained by limited material choices and short spin-coherence lengths. Here we propose a different operating principle based on multiferroic altermagnets, in which spin splitting is tuned by an electric field through symmetry control rather than conventional spin-orbit physics. Using an effective model combined with quantum transport simulations, we show that the conductance is determined by the degree of matching between the electrically controlled spin texture of the channel and the fixed spin polarization of ferromagnetic contacts, enabling clear ON and OFF states. Remarkably, we also address a long-standing challenge in multiferroic device design: spintronic channels require metallic carriers, whereas ferroelectricity is usually suppressed in metals. We resolve this conflict by imprinting multiferroic altermagnetism into highly conductive materials via the proximity effect. First-principles calculations for graphene on multiferroic vanadium sulfide halides confirm that graphene acquires a ferroelectrically switchable spin splitting while retaining its metallic character. These results establish a practical route to SFET implementation and identify multiferroic altermagnets as a versatile platform for next-generation spintronic devices. [SEP] [HINT] field -> Materials Science (Syns: field of honor, line of business, orbit) | based -> Bioinformatics (Syns: ground, free-base, base) | spin -> Materials Science (Syns: twisting, whirl, tailspin)",Materials Science
"Silicon carbide (SiC) divacancies are attractive candidates for spin defect qubits possessing long coherence times and optical addressability. The high activation barriers associated with SiC defect formation and motion pose challenges for their study by first-principles molecular dynamics. In this work, we develop and deploy machine learning interatomic potentials (MLIPs) to accelerate defect dynamics simulations while retaining ab initio accuracy. We employ an active learning strategy comprising symmetry-adapted collective variable discovery and enhanced sampling to compile configurationally diverse training data, calculation of energies and forces using density functional theory (DFT), and training of an E(3)-equivariant MLIP based on the Allegro model. The trained MLIP reproduces DFT-level accuracy in defect transition activation free energy barriers, enables the efficient and stable simulation of multi-defect 216-atom supercells, and permits an analysis of the temperature dependence of defect thermodynamic stability and formation/annihilation kinetics to propose an optimal annealing temperature to maximally stabilize VV divacancies.",Materials Science
"Silicon carbide (SiC) divacancies are attractive candidates for spin defect qubits possessing long coherence times and optical addressability. The high activation barriers associated with SiC defect formation and motion pose challenges for their study by first-principles molecular dynamics. In this work, we develop and deploy machine learning interatomic potentials (MLIPs) to accelerate defect dynamics simulations while retaining ab initio accuracy. We employ an active learning strategy comprising symmetry-adapted collective variable discovery and enhanced sampling to compile configurationally diverse training data, calculation of energies and forces using density functional theory (DFT), and training of an E(3)-equivariant MLIP based on the Allegro model. The trained MLIP reproduces DFT-level accuracy in defect transition activation free energy barriers, enables the efficient and stable simulation of multi-defect 216-atom supercells, and permits an analysis of the temperature dependence of defect thermodynamic stability and formation/annihilation kinetics to propose an optimal annealing temperature to maximally stabilize VV divacancies. [SEP] [HINT] transition -> Materials Science (Syns: passage, modulation, changeover) | based -> Bioinformatics (Syns: ground, free-base, base) | spin -> Materials Science (Syns: twisting, whirl, tailspin)",Materials Science
"Genetic nurture effects and assortative mating (AM) occur across many human behaviors and can bias estimates from traditional genetic models. These influences are typically studied univariately, within the same trait. However, estimation of cross-trait genetic nurture effects and cross-trait AM remains underexplored due to the absence of suitable approaches. To address this, we developed a multivariate extension of the SEM-PGS model for datasets with genotyped and phenotyped parents and offspring, enabling joint estimation of within-trait and cross-trait genetic and environmental influences. By integrating haplotypic polygenic scores (PGS) into a structural equation modeling framework, the model simultaneously estimates same-trait and cross-trait direct effects, genetic nurture, vertical transmission, and assortative mating. We also provide the first formal description of how copaths can be used to model multivariate assortative mating and derive the corresponding parameter expectations in matrix form. Forward-time Monte Carlo simulations under varying conditions of r^2_PGS and N_trio demonstrate that the model yields unbiased estimates of both within-trait and cross-trait effects when assumptions are met. The precision of estimates was adequate with large sample sizes (N_trio > 16k) and improved as PGS predictive power increased. In addition, our simulation results show that failing to model cross-trait effects biases within-trait estimates, underscoring the importance of incorporating cross-trait effects. The multivariate SEM-PGS model offers a powerful and flexible tool for disentangling gene-environment interplay and advancing the understanding of familial influences on human traits.",Bioinformatics
"Genetic nurture effects and assortative mating (AM) occur across many human behaviors and can bias estimates from traditional genetic models. These influences are typically studied univariately, within the same trait. However, estimation of cross-trait genetic nurture effects and cross-trait AM remains underexplored due to the absence of suitable approaches. To address this, we developed a multivariate extension of the SEM-PGS model for datasets with genotyped and phenotyped parents and offspring, enabling joint estimation of within-trait and cross-trait genetic and environmental influences. By integrating haplotypic polygenic scores (PGS) into a structural equation modeling framework, the model simultaneously estimates same-trait and cross-trait direct effects, genetic nurture, vertical transmission, and assortative mating. We also provide the first formal description of how copaths can be used to model multivariate assortative mating and derive the corresponding parameter expectations in matrix form. Forward-time Monte Carlo simulations under varying conditions of r^2_PGS and N_trio demonstrate that the model yields unbiased estimates of both within-trait and cross-trait effects when assumptions are met. The precision of estimates was adequate with large sample sizes (N_trio > 16k) and improved as PGS predictive power increased. In addition, our simulation results show that failing to model cross-trait effects biases within-trait estimates, underscoring the importance of incorporating cross-trait effects. The multivariate SEM-PGS model offers a powerful and flexible tool for disentangling gene-environment interplay and advancing the understanding of familial influences on human traits. [SEP] [HINT] used -> Bioinformatics (Syns: utilize, ill-used, apply) | understanding -> Neuroscience (Syns: savvy, intellect, sympathy) | datasets -> Bioinformatics (Syns: )",Bioinformatics
"Interoception and exteroception provide continuous feedback about the body and the environment, yet how they are dynamically integrated within a unified predictive coding framework has remained under-specified. This paper develops and empirically validates an integrative predictive coding model that treats interoceptive and exteroceptive inference as parallel hierarchical systems exchanging precision-weighted prediction errors. Within this framework, arbitration between the two streams is governed by relative precision weights (w) and integrated within the anterior insula (AIC) and anterior cingulate cortex (ACC). Computational simulations of the model reproduced biologically plausible dynamics: prediction errors decayed exponentially while arbitration weights self-normalized toward equilibrium (w = 0.5), demonstrating stable convergence and coherent integration. Simulated anxiety and PTSD profiles, characterized respectively by interoceptive and exteroceptive overweighting, yielded rigid, self-sustaining imbalances (w to 1 or w to 0) and slowed recalibration. Empirical application of the arbitration equation to published EEG-fMRI datasets further validated the model. The framework contributes a unifying account of how dysregulated precision weighting may underlie anxiety (overweighted interoception) and PTSD (underweighted interoception). Building on this validation, a proposed experimental paradigm is outlined to test the model's predictions in humans. It examines recalibration across anxiety, neutral, and PTSD groups following targeted interoceptive or exteroceptive therapies. Key predictions include identifiable neural markers of coherence, modulation of heartbeat-evoked potentials by vagal stimulation, and precision-sensitive behavioral signatures in interoceptive-exteroceptive congruency tasks.",Neuroscience
"Interoception and exteroception provide continuous feedback about the body and the environment, yet how they are dynamically integrated within a unified predictive coding framework has remained under-specified. This paper develops and empirically validates an integrative predictive coding model that treats interoceptive and exteroceptive inference as parallel hierarchical systems exchanging precision-weighted prediction errors. Within this framework, arbitration between the two streams is governed by relative precision weights (w) and integrated within the anterior insula (AIC) and anterior cingulate cortex (ACC). Computational simulations of the model reproduced biologically plausible dynamics: prediction errors decayed exponentially while arbitration weights self-normalized toward equilibrium (w = 0.5), demonstrating stable convergence and coherent integration. Simulated anxiety and PTSD profiles, characterized respectively by interoceptive and exteroceptive overweighting, yielded rigid, self-sustaining imbalances (w to 1 or w to 0) and slowed recalibration. Empirical application of the arbitration equation to published EEG-fMRI datasets further validated the model. The framework contributes a unifying account of how dysregulated precision weighting may underlie anxiety (overweighted interoception) and PTSD (underweighted interoception). Building on this validation, a proposed experimental paradigm is outlined to test the model's predictions in humans. It examines recalibration across anxiety, neutral, and PTSD groups following targeted interoceptive or exteroceptive therapies. Key predictions include identifiable neural markers of coherence, modulation of heartbeat-evoked potentials by vagal stimulation, and precision-sensitive behavioral signatures in interoceptive-exteroceptive congruency tasks. [SEP] [HINT] computational -> Neuroscience (Syns: ) | datasets -> Bioinformatics (Syns: ) | systems -> Bioinformatics (Syns: organization, organisation, system)",Neuroscience
"The Language of Thought (LOT) hypothesis posits that at least some important cognitive processes involve language-like representations. These representations must be processed by appropriate hardware. Since the organ of biological cognition is the nervous system, whether biological cognition relies on a LOT depends on how neural hardware works. I distinguish between different versions of LOT, articulate their hardware requirements, and consider which versions of LOT are supported by empirical evidence. I argue that the Classical LOT hypothesis (Fodor 1975) is ruled out; the version of LOT that is best supported by empirical evidence is the Nonclassical LOT thesis that some neural representations mirror some of the structure of natural language and represent in a language-like way, yet they encode information nondigitally and are processed by ordinary (nondigital, and hence Nonclassical) neural computations that rely not only on syntactic structure but many other features.",Neuroscience
"The Language of Thought (LOT) hypothesis posits that at least some important cognitive processes involve language-like representations. These representations must be processed by appropriate hardware. Since the organ of biological cognition is the nervous system, whether biological cognition relies on a LOT depends on how neural hardware works. I distinguish between different versions of LOT, articulate their hardware requirements, and consider which versions of LOT are supported by empirical evidence. I argue that the Classical LOT hypothesis (Fodor 1975) is ruled out; the version of LOT that is best supported by empirical evidence is the Nonclassical LOT thesis that some neural representations mirror some of the structure of natural language and represent in a language-like way, yet they encode information nondigitally and are processed by ordinary (nondigital, and hence Nonclassical) neural computations that rely not only on syntactic structure but many other features. [SEP] [HINT] language -> Neuroscience (Syns: linguistic process, linguistic communication, spoken communication) | structure -> Bioinformatics (Syns: social system, complex body part, social structure) | information -> Bioinformatics (Syns: entropy, data, info)",Neuroscience
"While liquid crystals (LCs) have been extensively studied, obtaining a comprehensive nanoscale picture of their molecular organization remains challenging, as conventional techniques face an intrinsic trade-off between spatial and chemical resolution. Here, cryogenic atom probe tomography (cryo-APT) is introduced as a new analytical approach for LC materials, using 4'-Pentyl-4-cyanobiphenyl (5CB) and 4'-Octyl-4-cyanobiphenyl (8CB) as representative model compounds. This was enabled by a tailored cryogenic focused ion beam (cryo-FIB) protocol optimized for small organic molecules. The method enables controlled field evaporation of both intact molecules and diagnostic fragments, achieving over 90% molecular retention while preserving four characteristic dissociation patterns. By spatially correlating these fragmentation profiles with the local electric field derived from the tip geometry, we reveal field-directed dissociation pathways of CB molecules. In parallel, the distribution of intact molecular ions enables nanoscale visualization of material structure: we resolve homogeneous mixing of 5CB and 8CB in the nematic phase and directly observe the sub-nanometer crystalline layering in a supercooled 8CB sample, with contrast to the surrounding amorphous matrix suggesting the presence of a solid-liquid interface. This work establishes cryo-APT as a new powerful analytical platform for LC research and reveals its broad potential for application in soft matter systems.",Materials Science
"While liquid crystals (LCs) have been extensively studied, obtaining a comprehensive nanoscale picture of their molecular organization remains challenging, as conventional techniques face an intrinsic trade-off between spatial and chemical resolution. Here, cryogenic atom probe tomography (cryo-APT) is introduced as a new analytical approach for LC materials, using 4'-Pentyl-4-cyanobiphenyl (5CB) and 4'-Octyl-4-cyanobiphenyl (8CB) as representative model compounds. This was enabled by a tailored cryogenic focused ion beam (cryo-FIB) protocol optimized for small organic molecules. The method enables controlled field evaporation of both intact molecules and diagnostic fragments, achieving over 90% molecular retention while preserving four characteristic dissociation patterns. By spatially correlating these fragmentation profiles with the local electric field derived from the tip geometry, we reveal field-directed dissociation pathways of CB molecules. In parallel, the distribution of intact molecular ions enables nanoscale visualization of material structure: we resolve homogeneous mixing of 5CB and 8CB in the nematic phase and directly observe the sub-nanometer crystalline layering in a supercooled 8CB sample, with contrast to the surrounding amorphous matrix suggesting the presence of a solid-liquid interface. This work establishes cryo-APT as a new powerful analytical platform for LC research and reveals its broad potential for application in soft matter systems. [SEP] [HINT] field -> Materials Science (Syns: field of honor, line of business, orbit) | molecular -> Bioinformatics (Syns: ) | work -> Bioinformatics (Syns: work out, process, bring)",Materials Science
"Understanding the relationship between antibody sequence, structure and function is essential for the design of antibody-based therapeutics and research tools. Recently, machine learning (ML) models mostly based on the application of large language models to sequence information have been developed to predict antibody properties. Yet there are open directions to incorporate structural information, not only to enhance prediction but also to offer insights into the underlying molecular mechanisms. This chapter provides an overview of these approaches and describes two ML frameworks that integrate structural data (via graph representations) with neural networks to predict properties of antibodies: ANTIPASTI predicts binding affinity (a global property) whereas INFUSSE predicts residue flexibility (a local property). We survey the principles underpinning these models; the ways in which they encode structural knowledge; and the strategies that can be used to extract biologically relevant statistical signals that can help discover and disentangle molecular determinants of the properties of interest.",Bioinformatics
"Understanding the relationship between antibody sequence, structure and function is essential for the design of antibody-based therapeutics and research tools. Recently, machine learning (ML) models mostly based on the application of large language models to sequence information have been developed to predict antibody properties. Yet there are open directions to incorporate structural information, not only to enhance prediction but also to offer insights into the underlying molecular mechanisms. This chapter provides an overview of these approaches and describes two ML frameworks that integrate structural data (via graph representations) with neural networks to predict properties of antibodies: ANTIPASTI predicts binding affinity (a global property) whereas INFUSSE predicts residue flexibility (a local property). We survey the principles underpinning these models; the ways in which they encode structural knowledge; and the strategies that can be used to extract biologically relevant statistical signals that can help discover and disentangle molecular determinants of the properties of interest. [SEP] [HINT] used -> Bioinformatics (Syns: utilize, ill-used, apply) | based -> Bioinformatics (Syns: ground, free-base, base) | language -> Neuroscience (Syns: linguistic process, linguistic communication, spoken communication)",Bioinformatics
"A central question in psycholinguistics is the timing of syntax in sentence processing. Much of the existing evidence comes from violation paradigms, which conflate two separable processes - syntactic category detection and phrase structure construction - and implicitly assume that phrase structure follows category detection. In this study, we use co-registered EEG and eye-tracking data from the ZuCo corpus to disentangle these processes and test their temporal order under naturalistic reading conditions. Analyses of gaze transitions showed that readers preferentially moved between syntactic heads, suggesting that phrase structures, rather than serial word order, organize scanpaths. Bayesian network modeling further revealed that structural depth was the strongest driver of deviations from linear reading, outweighing lexical familiarity and surprisal. Finally, fixation-related potentials demonstrated that syntactic surprisal influences neural activity before word onset (-184 to -10 ms) and during early integration (48 to 300 ms). These findings extend current models of syntactic timing by showing that phrase structure construction can precede category detection and dominate lexical influences, supporting a predictive ""tree-scaffolding"" account of comprehension.",Neuroscience
"A central question in psycholinguistics is the timing of syntax in sentence processing. Much of the existing evidence comes from violation paradigms, which conflate two separable processes - syntactic category detection and phrase structure construction - and implicitly assume that phrase structure follows category detection. In this study, we use co-registered EEG and eye-tracking data from the ZuCo corpus to disentangle these processes and test their temporal order under naturalistic reading conditions. Analyses of gaze transitions showed that readers preferentially moved between syntactic heads, suggesting that phrase structures, rather than serial word order, organize scanpaths. Bayesian network modeling further revealed that structural depth was the strongest driver of deviations from linear reading, outweighing lexical familiarity and surprisal. Finally, fixation-related potentials demonstrated that syntactic surprisal influences neural activity before word onset (-184 to -10 ms) and during early integration (48 to 300 ms). These findings extend current models of syntactic timing by showing that phrase structure construction can precede category detection and dominate lexical influences, supporting a predictive ""tree-scaffolding"" account of comprehension. [SEP] [HINT] structure -> Bioinformatics (Syns: social system, complex body part, social structure) | order -> Materials Science (Syns: enjoin, dictate, social club) | existing -> Bioinformatics (Syns: subsist, existent, survive)",Neuroscience
"12-lead ECGs with high sampling frequency are the clinical gold standard for arrhythmia detection, but their short-term, spot-check nature often misses intermittent events. Wearable ECGs enable long-term monitoring but suffer from irregular, lower sampling frequencies due to battery constraints, making morphology analysis challenging. We present an end-to-end classification pipeline to address these issues. We train a latent ODE to model continuous ECG waveforms and create robust feature vectors from high-frequency single-channel signals. We construct three latent vectors per waveform via downsampling the initial 360 Hz ECG to 90 Hz and 45 Hz. We then use a gradient boosted tree to classify these vectors and test robustness across frequencies. Performance shows minimal degradation, with macro-averaged AUC-ROC values of 0.984, 0.978, and 0.976 at 360 Hz, 90 Hz, and 45 Hz, respectively, suggesting a way to sidestep the trade-off between signal fidelity and battery life. This enables smaller wearables, promoting long-term monitoring of cardiac health.",Bioinformatics
"12-lead ECGs with high sampling frequency are the clinical gold standard for arrhythmia detection, but their short-term, spot-check nature often misses intermittent events. Wearable ECGs enable long-term monitoring but suffer from irregular, lower sampling frequencies due to battery constraints, making morphology analysis challenging. We present an end-to-end classification pipeline to address these issues. We train a latent ODE to model continuous ECG waveforms and create robust feature vectors from high-frequency single-channel signals. We construct three latent vectors per waveform via downsampling the initial 360 Hz ECG to 90 Hz and 45 Hz. We then use a gradient boosted tree to classify these vectors and test robustness across frequencies. Performance shows minimal degradation, with macro-averaged AUC-ROC values of 0.984, 0.978, and 0.976 at 360 Hz, 90 Hz, and 45 Hz, respectively, suggesting a way to sidestep the trade-off between signal fidelity and battery life. This enables smaller wearables, promoting long-term monitoring of cardiac health. [SEP] [HINT] clinical -> Bioinformatics (Syns: ) | performance -> Bioinformatics (Syns: functioning, operation, carrying out) | high -> Bioinformatics (Syns: heights, senior high school, eminent)",Bioinformatics
"Artificial intelligence has advanced significantly through deep learning, reinforcement learning, and large language and vision models. However, these systems often remain task specific, struggle to adapt to changing conditions, and cannot generalize in ways similar to human cognition. Additionally, they mainly focus on mimicking brain structures, which often leads to black-box models with limited transparency and adaptability. Inspired by the structure and function of biological cognition, this paper introduces the concept of ""Neurocognitive-Inspired Intelligence (NII),"" a hybrid approach that combines neuroscience, cognitive science, computer vision, and AI to develop more general, adaptive, and robust intelligent systems capable of rapid learning, learning from less data, and leveraging prior experience. These systems aim to emulate the human brain's ability to flexibly learn, reason, remember, perceive, and act in real-world settings with minimal supervision. We review the limitations of current AI methods, define core principles of neurocognitive-inspired intelligence, and propose a modular, biologically inspired architecture that emphasizes integration, embodiment, and adaptability. We also discuss potential implementation strategies and outline various real-world applications, from robotics to education and healthcare. Importantly, this paper offers a hybrid roadmap for future research, laying the groundwork for building AI systems that more closely resemble human cognition.",Neuroscience
"Artificial intelligence has advanced significantly through deep learning, reinforcement learning, and large language and vision models. However, these systems often remain task specific, struggle to adapt to changing conditions, and cannot generalize in ways similar to human cognition. Additionally, they mainly focus on mimicking brain structures, which often leads to black-box models with limited transparency and adaptability. Inspired by the structure and function of biological cognition, this paper introduces the concept of ""Neurocognitive-Inspired Intelligence (NII),"" a hybrid approach that combines neuroscience, cognitive science, computer vision, and AI to develop more general, adaptive, and robust intelligent systems capable of rapid learning, learning from less data, and leveraging prior experience. These systems aim to emulate the human brain's ability to flexibly learn, reason, remember, perceive, and act in real-world settings with minimal supervision. We review the limitations of current AI methods, define core principles of neurocognitive-inspired intelligence, and propose a modular, biologically inspired architecture that emphasizes integration, embodiment, and adaptability. We also discuss potential implementation strategies and outline various real-world applications, from robotics to education and healthcare. Importantly, this paper offers a hybrid roadmap for future research, laying the groundwork for building AI systems that more closely resemble human cognition. [SEP] [HINT] task -> Neuroscience (Syns: tax, project, chore) | language -> Neuroscience (Syns: linguistic process, linguistic communication, spoken communication) | learning -> Bioinformatics (Syns: take, teach, acquire)",Neuroscience
"Snarls and superbubbles are fundamental pangenome decompositions capturing variant sites. These bubble-like structures underpin key tasks in computational pangenomics, including structural-variant genotyping, distance indexing, haplotype sampling, and variant annotation. Snarls can be quadratically-many in the size of the graph, and since their introduction in 2018 with the vg toolkit, there has been no work on identifying all snarls in linear time. Moreover, while it is known how to find superbubbles in linear time, this result is a highly specialized solution only achieved after a long series of papers.   We present the first algorithm identifying all snarls in linear time. This is based on a new representation of all snarls, of size linear in the input graph size, and which can be computed in linear time. Our algorithm is based on a unified framework that also provides a new linear-time algorithm for finding superbubbles. An observation behind our results is that all such structures are separated from the rest of the graph by two vertices (except for cases which are trivially computable), i.e. their endpoints are a 2-separator of the underlying undirected graph. Based on this, we employ the well-known SPQR tree decomposition, which encodes all 2-separators, to guide a traversal that finds the bubble-like structures efficiently.   We implemented our algorithms in C++ (available at https://github.com/algbio/BubbleFinder) and evaluated them on various pangenomic datasets. Our algorithms outcompete or they are on the same level of existing methods. For snarls, we are up to two times faster than vg, while identifying all snarls. When computing superbubbles, we are up to 50 times faster than BubbleGun. Our SPQR tree framework provides a unifying perspective on bubble-like structures in pangenomics, together with a template for finding other bubble-like structures efficiently.",Bioinformatics
"Snarls and superbubbles are fundamental pangenome decompositions capturing variant sites. These bubble-like structures underpin key tasks in computational pangenomics, including structural-variant genotyping, distance indexing, haplotype sampling, and variant annotation. Snarls can be quadratically-many in the size of the graph, and since their introduction in 2018 with the vg toolkit, there has been no work on identifying all snarls in linear time. Moreover, while it is known how to find superbubbles in linear time, this result is a highly specialized solution only achieved after a long series of papers.   We present the first algorithm identifying all snarls in linear time. This is based on a new representation of all snarls, of size linear in the input graph size, and which can be computed in linear time. Our algorithm is based on a unified framework that also provides a new linear-time algorithm for finding superbubbles. An observation behind our results is that all such structures are separated from the rest of the graph by two vertices (except for cases which are trivially computable), i.e. their endpoints are a 2-separator of the underlying undirected graph. Based on this, we employ the well-known SPQR tree decomposition, which encodes all 2-separators, to guide a traversal that finds the bubble-like structures efficiently.   We implemented our algorithms in C++ (available at https://github.com/algbio/BubbleFinder) and evaluated them on various pangenomic datasets. Our algorithms outcompete or they are on the same level of existing methods. For snarls, we are up to two times faster than vg, while identifying all snarls. When computing superbubbles, we are up to 50 times faster than BubbleGun. Our SPQR tree framework provides a unifying perspective on bubble-like structures in pangenomics, together with a template for finding other bubble-like structures efficiently. [SEP] [HINT] tasks -> Neuroscience (Syns: tax, task, project) | based -> Bioinformatics (Syns: ground, free-base, base) | computational -> Neuroscience (Syns: )",Bioinformatics
"Artificial neural networks (ANNs) have become the de facto standard for modeling the human visual system, primarily due to their success in predicting neural responses. However, with many models now achieving similar predictive accuracy, we need a stronger criterion. Here, we use small-scale adversarial probes to characterize the local representational geometry of many highly predictive ANN-based brain models. We report four key findings. First, we show that most contemporary ANN-based brain models are unexpectedly fragile. Despite high prediction scores, their response predictions are highly sensitive to small, imperceptible perturbations, revealing unreliable local coding directions. Second, we demonstrate that a model's sensitivity to adversarial probes can better discriminate between candidate neural encoding models than prediction accuracy alone. Third, we find that standard models rely on distinct local coding directions that do not transfer across model architectures. Finally, we show that adversarial probes from robustified models produce generalizable and semantically meaningful changes, suggesting that they capture the local coding dimensions of the visual system. Together, our work shows that local representational geometry provides a stronger criterion for brain model evaluation. We also provide empirical grounds for favoring robust models, whose more stable coding axes not only align better with neural selectivity but also generate concrete, testable predictions for future experiments.",Neuroscience
"Artificial neural networks (ANNs) have become the de facto standard for modeling the human visual system, primarily due to their success in predicting neural responses. However, with many models now achieving similar predictive accuracy, we need a stronger criterion. Here, we use small-scale adversarial probes to characterize the local representational geometry of many highly predictive ANN-based brain models. We report four key findings. First, we show that most contemporary ANN-based brain models are unexpectedly fragile. Despite high prediction scores, their response predictions are highly sensitive to small, imperceptible perturbations, revealing unreliable local coding directions. Second, we demonstrate that a model's sensitivity to adversarial probes can better discriminate between candidate neural encoding models than prediction accuracy alone. Third, we find that standard models rely on distinct local coding directions that do not transfer across model architectures. Finally, we show that adversarial probes from robustified models produce generalizable and semantically meaningful changes, suggesting that they capture the local coding dimensions of the visual system. Together, our work shows that local representational geometry provides a stronger criterion for brain model evaluation. We also provide empirical grounds for favoring robust models, whose more stable coding axes not only align better with neural selectivity but also generate concrete, testable predictions for future experiments. [SEP] [HINT] networks -> Neuroscience (Syns: network, meshwork, electronic network) | work -> Bioinformatics (Syns: work out, process, bring) | human -> Neuroscience (Syns: human being, man, homo)",Neuroscience
"The role of Artificial Intelligence (AI) is growing in every stage of drug development. Nevertheless, a major challenge in drug discovery AI remains: Drug pharmacokinetic (PK) and Drug-Target Interaction (DTI) datasets collected in different studies often exhibit limited overlap, creating data overlap sparsity. Thus, data curation becomes difficult, negatively impacting downstream research investigations in high-throughput screening, polypharmacy, and drug combination. We propose xImagand-DKI, a novel SMILES/Protein-to-Pharmacokinetic/DTI (SP2PKDTI) diffusion model capable of generating an array of PK and DTI target properties conditioned on SMILES and protein inputs that exhibit data overlap sparsity. We infuse additional molecular and genomic domain knowledge from the Gene Ontology (GO) and molecular fingerprints to further improve our model performance. We show that xImagand-DKI-generated synthetic PK data closely resemble real data univariate and bivariate distributions, and can adequately fill in gaps among PK and DTI datasets. As such, xImagand-DKI is a promising solution for data overlap sparsity and may improve performance for downstream drug discovery research tasks. Code available at: https://github.com/GenerativeDrugDiscovery/xImagand-DKI",Bioinformatics
"The role of Artificial Intelligence (AI) is growing in every stage of drug development. Nevertheless, a major challenge in drug discovery AI remains: Drug pharmacokinetic (PK) and Drug-Target Interaction (DTI) datasets collected in different studies often exhibit limited overlap, creating data overlap sparsity. Thus, data curation becomes difficult, negatively impacting downstream research investigations in high-throughput screening, polypharmacy, and drug combination. We propose xImagand-DKI, a novel SMILES/Protein-to-Pharmacokinetic/DTI (SP2PKDTI) diffusion model capable of generating an array of PK and DTI target properties conditioned on SMILES and protein inputs that exhibit data overlap sparsity. We infuse additional molecular and genomic domain knowledge from the Gene Ontology (GO) and molecular fingerprints to further improve our model performance. We show that xImagand-DKI-generated synthetic PK data closely resemble real data univariate and bivariate distributions, and can adequately fill in gaps among PK and DTI datasets. As such, xImagand-DKI is a promising solution for data overlap sparsity and may improve performance for downstream drug discovery research tasks. Code available at: https://github.com/GenerativeDrugDiscovery/xImagand-DKI [SEP] [HINT] molecular -> Bioinformatics (Syns: ) | datasets -> Bioinformatics (Syns: ) | performance -> Bioinformatics (Syns: functioning, operation, carrying out)",Bioinformatics
"We present a first-principles study of the nonlinear optical properties of sliding ferroelectric bilayers based on MoSe$_2$ and Janus MoSSe. Two Janus configurations are considered: i) one bilayer where the two intralayer polarizations caused by Janus chemical asymmetry cancel each other out, yielding photocurrent spectra comparable to pristine MoSe$_2$ bilayers; ii) another bilayer where the intralayer polarizations add up, for which the photoresponses are strongly enhanced. Our results show that photocurrent generation in the polar Janus structures is predominantly governed by vertical chemical asymmetry, with limited dependence on the sliding direction. These findings highlight complementary design strategies: interlayer sliding enables sensitivity to external tuning, while the Janus intralayer polarization enhances photoresponses in the visible range. The interplay between composition and stacking therefore provides a versatile platform for tailoring light-matter interactions in 2D ferroelectric materials.",Materials Science
"We present a first-principles study of the nonlinear optical properties of sliding ferroelectric bilayers based on MoSe$_2$ and Janus MoSSe. Two Janus configurations are considered: i) one bilayer where the two intralayer polarizations caused by Janus chemical asymmetry cancel each other out, yielding photocurrent spectra comparable to pristine MoSe$_2$ bilayers; ii) another bilayer where the intralayer polarizations add up, for which the photoresponses are strongly enhanced. Our results show that photocurrent generation in the polar Janus structures is predominantly governed by vertical chemical asymmetry, with limited dependence on the sliding direction. These findings highlight complementary design strategies: interlayer sliding enables sensitivity to external tuning, while the Janus intralayer polarization enhances photoresponses in the visible range. The interplay between composition and stacking therefore provides a versatile platform for tailoring light-matter interactions in 2D ferroelectric materials. [SEP] [HINT] based -> Bioinformatics (Syns: ground, free-base, base) | results -> Bioinformatics (Syns: final result, consequence, resultant role) | optical -> Materials Science (Syns: ocular, opthalmic, optic)",Materials Science
"A universal theorem of sensory information, analogous to the second law of thermodynamics, is derived. Beginning from a minimal description of a sensory neuron, a state-space representation of firing rate emerges naturally from Shannon's measure of information. A special case of this formulation predicts a previously unknown inequality governing sensory adaptation, which was confirmed across different modalities, species, and experimental conditions. Further analysis shows that the firing rate behaves like a state function in thermodynamics, leading to an entropy production equation from which a general law follows: any closed cycle of stimulation yields a non-negative net gain of sensory information.",Neuroscience
"A universal theorem of sensory information, analogous to the second law of thermodynamics, is derived. Beginning from a minimal description of a sensory neuron, a state-space representation of firing rate emerges naturally from Shannon's measure of information. A special case of this formulation predicts a previously unknown inequality governing sensory adaptation, which was confirmed across different modalities, species, and experimental conditions. Further analysis shows that the firing rate behaves like a state function in thermodynamics, leading to an entropy production equation from which a general law follows: any closed cycle of stimulation yields a non-negative net gain of sensory information. [SEP] [HINT] experimental -> Materials Science (Syns: data-based, observational) | different -> Neuroscience (Syns: unlike, dissimilar) | state -> Bioinformatics (Syns: posit, put forward, express)",Neuroscience
"Drug-drug interactions (DDIs) remain a major source of preventable harm, and many clinically important mechanisms are still unknown. Existing models either rely on pharmacologic knowledge graphs (KGs), which fail on unseen drugs, or on electronic health records (EHRs), which are noisy, temporal, and site-dependent. We introduce, to our knowledge, the first system that conditions KG relation scoring on patient-level EHR context and distills that reasoning into an EHR-only model for zero-shot inference. A fusion ""Teacher"" learns mechanism-specific relations for drug pairs represented in both sources, while a distilled ""Student"" generalizes to new or rarely used drugs without KG access at inference. Both operate under a shared ontology (set) of pharmacologic mechanisms (drug relations) to produce interpretable, auditable alerts rather than opaque risk scores. Trained on a multi-institution EHR corpus paired with a curated DrugBank DDI graph, and evaluated using a clinically aligned, decision-focused protocol with leakage-safe negatives that avoid artificially easy pairs, the system maintains precision across multi-institutuion test data, produces mechanism-specific, clinically consistent predictions, reduces false alerts (higher precision) at comparable overall detection performance (F1), and misses fewer true interactions compared to prior methods. Case studies further show zero-shot identification of clinically recognized CYP-mediated and pharmacodynamic mechanisms for drugs absent from the KG, supporting real-world use in clinical decision support and pharmacovigilance.",Bioinformatics
"Drug-drug interactions (DDIs) remain a major source of preventable harm, and many clinically important mechanisms are still unknown. Existing models either rely on pharmacologic knowledge graphs (KGs), which fail on unseen drugs, or on electronic health records (EHRs), which are noisy, temporal, and site-dependent. We introduce, to our knowledge, the first system that conditions KG relation scoring on patient-level EHR context and distills that reasoning into an EHR-only model for zero-shot inference. A fusion ""Teacher"" learns mechanism-specific relations for drug pairs represented in both sources, while a distilled ""Student"" generalizes to new or rarely used drugs without KG access at inference. Both operate under a shared ontology (set) of pharmacologic mechanisms (drug relations) to produce interpretable, auditable alerts rather than opaque risk scores. Trained on a multi-institution EHR corpus paired with a curated DrugBank DDI graph, and evaluated using a clinically aligned, decision-focused protocol with leakage-safe negatives that avoid artificially easy pairs, the system maintains precision across multi-institutuion test data, produces mechanism-specific, clinically consistent predictions, reduces false alerts (higher precision) at comparable overall detection performance (F1), and misses fewer true interactions compared to prior methods. Case studies further show zero-shot identification of clinically recognized CYP-mediated and pharmacodynamic mechanisms for drugs absent from the KG, supporting real-world use in clinical decision support and pharmacovigilance. [SEP] [HINT] used -> Bioinformatics (Syns: utilize, ill-used, apply) | clinical -> Bioinformatics (Syns: ) | electronic -> Materials Science (Syns: )",Bioinformatics
"Hirschsprung Disease is characterized by the absence of ganglion cells in the myenteric plexus. Therefore, their correct identification is crucial for diagnosing Hirschsprung disease. We introduce a three-stage segmentation framework based on a Vision Transformer (ViT-B/16) that mimics the pathologist's diagnostic approach. The framework sequentially segments the muscularis propria, delineates the myenteric plexus, and identifies ganglion cells within anatomically valid regions. 30 whole-slide images of colon tissue were used, each containing expert manual annotations of muscularis, plexus, and ganglion cells at varying levels of certainty. A 5-fold cross-validation scheme was applied to each stage, along with resolution-specific tiling strategies and tailored postprocessing to ensure anatomical consistency. The proposed method achieved a Dice coefficient of 89.9% and a Plexus Inclusion Rate of 100% for muscularis segmentation. Plexus segmentation reached a recall of 94.8%, a precision of 84.2% and a Ganglia Inclusion Rate of 99.7%. For high-certainty ganglion cells, the model achieved 62.1% precision and 89.1% recall, while joint certainty scores yielded 67.0% precision. These results indicate that ViT-based models are effective at leveraging global tissue context and capturing cellular morphology at small scales, even within complex histological tissue structures. This multi-stage methodology has great potential to support digital pathology workflows by reducing inter-observer variability and assisting in the evaluation of Hirschsprung disease. The clinical impact will be evaluated in future work with larger multi-center datasets and additional expert annotations.",Bioinformatics
"Hirschsprung Disease is characterized by the absence of ganglion cells in the myenteric plexus. Therefore, their correct identification is crucial for diagnosing Hirschsprung disease. We introduce a three-stage segmentation framework based on a Vision Transformer (ViT-B/16) that mimics the pathologist's diagnostic approach. The framework sequentially segments the muscularis propria, delineates the myenteric plexus, and identifies ganglion cells within anatomically valid regions. 30 whole-slide images of colon tissue were used, each containing expert manual annotations of muscularis, plexus, and ganglion cells at varying levels of certainty. A 5-fold cross-validation scheme was applied to each stage, along with resolution-specific tiling strategies and tailored postprocessing to ensure anatomical consistency. The proposed method achieved a Dice coefficient of 89.9% and a Plexus Inclusion Rate of 100% for muscularis segmentation. Plexus segmentation reached a recall of 94.8%, a precision of 84.2% and a Ganglia Inclusion Rate of 99.7%. For high-certainty ganglion cells, the model achieved 62.1% precision and 89.1% recall, while joint certainty scores yielded 67.0% precision. These results indicate that ViT-based models are effective at leveraging global tissue context and capturing cellular morphology at small scales, even within complex histological tissue structures. This multi-stage methodology has great potential to support digital pathology workflows by reducing inter-observer variability and assisting in the evaluation of Hirschsprung disease. The clinical impact will be evaluated in future work with larger multi-center datasets and additional expert annotations. [SEP] [HINT] tissue -> Bioinformatics (Syns: tissue paper, weave) | based -> Bioinformatics (Syns: ground, free-base, base) | clinical -> Bioinformatics (Syns: )",Bioinformatics
"Surface elasticity is central to understanding the mechanics and stability of surfaces and interfaces. It is characterized by quantities such as surface tension, residual surface stress, and surface stiffness, however their analytical expressions are typically difficult to derive from atomistic data, and depend strongly on modeling choices. This work presents a neural network-based equation learner which combines customized activation functions and connection-based pruning to discover parsimonious, closed-form equations for surface elasticity from atomistic simulations. Applying the method to seven face centered cubic (FCC) metals, our equation learner uncovers interpretable equations that describe both low-Miller index and high-Miller index surface properties, capturing long-tail property distributions accurately. The discovered expressions are decoupled into two components: a universal, geometry-driven orientation function, and material-specific baseline coefficients. We find that lower-order properties such as surface tension are fundamentally geometry dependent, while higher-order properties such as surface stress and elasticity show more complex geometry and material dependence. We also relate material dependent coefficients to bulk properties, forming a clear map from bulk material properties to surface elasticity. Overall, this approach demonstrates that interpretable neurosymbolic machine learning can bridge the gap between atomistic simulations and physical laws, enabling the discovery of generalizable structure-property relationships for materials science phenomena such as surface elasticity.",Materials Science
"Surface elasticity is central to understanding the mechanics and stability of surfaces and interfaces. It is characterized by quantities such as surface tension, residual surface stress, and surface stiffness, however their analytical expressions are typically difficult to derive from atomistic data, and depend strongly on modeling choices. This work presents a neural network-based equation learner which combines customized activation functions and connection-based pruning to discover parsimonious, closed-form equations for surface elasticity from atomistic simulations. Applying the method to seven face centered cubic (FCC) metals, our equation learner uncovers interpretable equations that describe both low-Miller index and high-Miller index surface properties, capturing long-tail property distributions accurately. The discovered expressions are decoupled into two components: a universal, geometry-driven orientation function, and material-specific baseline coefficients. We find that lower-order properties such as surface tension are fundamentally geometry dependent, while higher-order properties such as surface stress and elasticity show more complex geometry and material dependence. We also relate material dependent coefficients to bulk properties, forming a clear map from bulk material properties to surface elasticity. Overall, this approach demonstrates that interpretable neurosymbolic machine learning can bridge the gap between atomistic simulations and physical laws, enabling the discovery of generalizable structure-property relationships for materials science phenomena such as surface elasticity. [SEP] [HINT] understanding -> Neuroscience (Syns: savvy, intellect, sympathy) | learning -> Bioinformatics (Syns: take, teach, acquire) | complex -> Bioinformatics (Syns: building complex, coordination compound, composite)",Materials Science
"Alzheimer's disease (AD) is characterized by the progressive spread of pathology across brain networks, yet forecasting this cascade at the individual level remains challenging. We present a personalized graph-based dynamical model that captures the spatiotemporal evolution of cortical atrophy from longitudinal MRI and PET data. The approach constructs individualized brain graphs and learns the dynamics driving regional neurodegeneration. Applied to 1,891 participants from the Alzheimer's Disease Neuroimaging Initiative, the model accurately predicts key AD biomarkers -- including amyloid-beta, tau, neurodegeneration, and cognition -- outperforming clinical and neuroimaging benchmarks. Patient-specific parameters reveal distinct progression subtypes and anticipate future cognitive decline more effectively than standard biomarkers. Sensitivity analysis highlights regional drivers of disease spread, reproducing known temporolimbic and frontal vulnerability patterns. This network-based digital twin framework offers a quantitative, personalized paradigm for AD trajectory prediction, with implications for patient stratification, clinical trial design, and targeted therapeutic development.",Neuroscience
"Alzheimer's disease (AD) is characterized by the progressive spread of pathology across brain networks, yet forecasting this cascade at the individual level remains challenging. We present a personalized graph-based dynamical model that captures the spatiotemporal evolution of cortical atrophy from longitudinal MRI and PET data. The approach constructs individualized brain graphs and learns the dynamics driving regional neurodegeneration. Applied to 1,891 participants from the Alzheimer's Disease Neuroimaging Initiative, the model accurately predicts key AD biomarkers -- including amyloid-beta, tau, neurodegeneration, and cognition -- outperforming clinical and neuroimaging benchmarks. Patient-specific parameters reveal distinct progression subtypes and anticipate future cognitive decline more effectively than standard biomarkers. Sensitivity analysis highlights regional drivers of disease spread, reproducing known temporolimbic and frontal vulnerability patterns. This network-based digital twin framework offers a quantitative, personalized paradigm for AD trajectory prediction, with implications for patient stratification, clinical trial design, and targeted therapeutic development. [SEP] [HINT] clinical -> Bioinformatics (Syns: ) | cortical -> Neuroscience (Syns: ) | including -> Bioinformatics (Syns: admit, include, let in)",Neuroscience
"Spatial transcriptomics (ST) technologies can be used to align transcriptomes with histopathological morphology, presenting exciting new opportunities for biomolecular discovery. Using ST data, we construct a novel framework, GeneFlow, to map transcriptomics onto paired cellular images. By combining an attention-based RNA encoder with a conditional UNet guided by rectified flow, we generate high-resolution images with different staining methods (e.g. H&E, DAPI) to highlight various cellular/tissue structures. Rectified flow with high-order ODE solvers creates a continuous, bijective mapping between transcriptomics and image manifolds, addressing the many-to-one relationship inherent in this problem. Our method enables the generation of realistic cellular morphology features and spatially resolved intercellular interactions from observational gene expression profiles, provides potential to incorporate genetic/chemical perturbations, and enables disease diagnosis by revealing dysregulated patterns in imaging phenotypes. Our rectified flow-based method outperforms diffusion-based baseline method in all experiments. Code can be found at https://github.com/wangmengbo/GeneFlow.",Bioinformatics
"Spatial transcriptomics (ST) technologies can be used to align transcriptomes with histopathological morphology, presenting exciting new opportunities for biomolecular discovery. Using ST data, we construct a novel framework, GeneFlow, to map transcriptomics onto paired cellular images. By combining an attention-based RNA encoder with a conditional UNet guided by rectified flow, we generate high-resolution images with different staining methods (e.g. H&E, DAPI) to highlight various cellular/tissue structures. Rectified flow with high-order ODE solvers creates a continuous, bijective mapping between transcriptomics and image manifolds, addressing the many-to-one relationship inherent in this problem. Our method enables the generation of realistic cellular morphology features and spatially resolved intercellular interactions from observational gene expression profiles, provides potential to incorporate genetic/chemical perturbations, and enables disease diagnosis by revealing dysregulated patterns in imaging phenotypes. Our rectified flow-based method outperforms diffusion-based baseline method in all experiments. Code can be found at https://github.com/wangmengbo/GeneFlow. [SEP] [HINT] used -> Bioinformatics (Syns: utilize, ill-used, apply) | features -> Bioinformatics (Syns: characteristic, lineament, feature of speech) | different -> Neuroscience (Syns: unlike, dissimilar)",Bioinformatics
"Prostate cancer (PCa) remains a significant global health concern among men, particularly due to the lethality of its more aggressive variants. Despite therapeutic advancements that have enhanced survival for many patients, high grade PCa continues to contribute substantially to cancer related mortality. Emerging evidence points to the MYB proto-oncogene as a critical factor in promoting tumor progression, therapeutic resistance, and disease relapse. Notably, differential expression patterns have been observed, with markedly elevated MYB levels in tumor tissues from Black men relative to their White counterparts potentially offering insight into documented racial disparities in clinical outcomes. This study investigates the association between MYB expression and key oncogenic features, including androgen receptor (AR) signaling, disease progression, and the risk of biochemical recurrence. Employing a multimodal approach that integrates histopathological examination, quantitative digital imaging, and analyses of public transcriptomic datasets, our findings suggest that MYB overexpression is strongly linked to adverse prognosis. These results underscore MYB's potential as a prognostic biomarker and as a candidate for the development of individualized therapeutic strategies.",Bioinformatics
"Prostate cancer (PCa) remains a significant global health concern among men, particularly due to the lethality of its more aggressive variants. Despite therapeutic advancements that have enhanced survival for many patients, high grade PCa continues to contribute substantially to cancer related mortality. Emerging evidence points to the MYB proto-oncogene as a critical factor in promoting tumor progression, therapeutic resistance, and disease relapse. Notably, differential expression patterns have been observed, with markedly elevated MYB levels in tumor tissues from Black men relative to their White counterparts potentially offering insight into documented racial disparities in clinical outcomes. This study investigates the association between MYB expression and key oncogenic features, including androgen receptor (AR) signaling, disease progression, and the risk of biochemical recurrence. Employing a multimodal approach that integrates histopathological examination, quantitative digital imaging, and analyses of public transcriptomic datasets, our findings suggest that MYB overexpression is strongly linked to adverse prognosis. These results underscore MYB's potential as a prognostic biomarker and as a candidate for the development of individualized therapeutic strategies. [SEP] [HINT] clinical -> Bioinformatics (Syns: ) | results -> Bioinformatics (Syns: final result, consequence, resultant role) | including -> Bioinformatics (Syns: admit, include, let in)",Bioinformatics
"Accurate early prediction of in-hospital mortality in intensive care units (ICUs) is essential for timely clinical intervention and efficient resource allocation. This study develops and evaluates machine learning models that integrate both structured clinical data and unstructured textual information, specifically discharge summaries and radiology reports, from the MIMIC-IV database. We used LASSO and XGBoost for feature selection, followed by a multivariate logistic regression trained on the top features identified by both models. Incorporating textual features using TF-IDF and BERT embeddings significantly improved predictive performance. The final logistic regression model, which combined structured and textual input, achieved an AUC of 0.918, compared to 0.753 when using structured data alone, a relative improvement 22%. The analysis of the decision curve demonstrated a superior standardized net benefit in a wide range of threshold probabilities (0.2-0.8), confirming the clinical utility of the model. These results underscore the added prognostic value of unstructured clinical notes and support their integration into interpretable feature-driven risk prediction models for ICU patients.",Bioinformatics
"Accurate early prediction of in-hospital mortality in intensive care units (ICUs) is essential for timely clinical intervention and efficient resource allocation. This study develops and evaluates machine learning models that integrate both structured clinical data and unstructured textual information, specifically discharge summaries and radiology reports, from the MIMIC-IV database. We used LASSO and XGBoost for feature selection, followed by a multivariate logistic regression trained on the top features identified by both models. Incorporating textual features using TF-IDF and BERT embeddings significantly improved predictive performance. The final logistic regression model, which combined structured and textual input, achieved an AUC of 0.918, compared to 0.753 when using structured data alone, a relative improvement 22%. The analysis of the decision curve demonstrated a superior standardized net benefit in a wide range of threshold probabilities (0.2-0.8), confirming the clinical utility of the model. These results underscore the added prognostic value of unstructured clinical notes and support their integration into interpretable feature-driven risk prediction models for ICU patients. [SEP] [HINT] used -> Bioinformatics (Syns: utilize, ill-used, apply) | clinical -> Bioinformatics (Syns: ) | features -> Bioinformatics (Syns: characteristic, lineament, feature of speech)",Bioinformatics
"Current neuroimaging studies on neurodegenerative diseases and psychological risk factors have been developed predominantly in non Hispanic White cohorts, with other populations markedly underrepresented. In this work, we construct directed hyper connectomes among large scale functional brain systems based on causal influences between brain regions, and examine their links to Alzheimer Disease progression and worry levels across racial groups. By using Health and Aging Brain Study Health Disparities (HABS HD) dataset, our experimental results suggest that neglecting racial variation in brain network architecture may reduce predictive performance in both cognitive and affective phenotypes. Important shared and population-specific hyper-connectome patterns related to both AD progression and worry levels were identified. We further observed distinct closed loop directed circuits across groups, suggesting that different populations may rely on distinct feedback based network regulation strategies when supporting cognition or managing emotional states. Together, these results indicate a common backbone of network vulnerability with population-dependent variations in regulatory coordination, underscoring the importance of population-aware neuroimaging models.",Neuroscience
"Current neuroimaging studies on neurodegenerative diseases and psychological risk factors have been developed predominantly in non Hispanic White cohorts, with other populations markedly underrepresented. In this work, we construct directed hyper connectomes among large scale functional brain systems based on causal influences between brain regions, and examine their links to Alzheimer Disease progression and worry levels across racial groups. By using Health and Aging Brain Study Health Disparities (HABS HD) dataset, our experimental results suggest that neglecting racial variation in brain network architecture may reduce predictive performance in both cognitive and affective phenotypes. Important shared and population-specific hyper-connectome patterns related to both AD progression and worry levels were identified. We further observed distinct closed loop directed circuits across groups, suggesting that different populations may rely on distinct feedback based network regulation strategies when supporting cognition or managing emotional states. Together, these results indicate a common backbone of network vulnerability with population-dependent variations in regulatory coordination, underscoring the importance of population-aware neuroimaging models. [SEP] [HINT] based -> Bioinformatics (Syns: ground, free-base, base) | non -> Materials Science (Syns: not) | functional -> Neuroscience (Syns: working, usable, running)",Neuroscience
"In recent years, the alignment between artificial neural network (ANN) embeddings and blood oxygenation level dependent (BOLD) responses in functional magnetic resonance imaging (fMRI) via neural encoding models has significantly advanced research on neural representation mechanisms and interpretability in the brain. However, these approaches remain limited in characterizing the brain's inherently nonlinear response properties. To address this, we propose the Jacobian-based Nonlinearity Evaluation (JNE), an interpretability metric for nonlinear neural encoding models. JNE quantifies nonlinearity by statistically measuring the dispersion of local linear mappings (Jacobians) from model representations to predicted BOLD responses, thereby approximating the nonlinearity of BOLD signals. Centered on proposing JNE as a novel interpretability metric, we validated its effectiveness through controlled simulation experiments on various activation functions and network architectures, and further verified it on real fMRI data, demonstrating a hierarchical progression of nonlinear characteristics from primary to higher-order visual cortices, consistent with established cortical organization. We further extended JNE with Sample-Specificity (JNE-SS), revealing stimulus-selective nonlinear response patterns in functionally specialized brain regions. As the first interpretability metric for quantifying nonlinear responses, JNE provides new insights into brain information processing. Code available at https://github.com/Gaitxh/JNE.",Neuroscience
"In recent years, the alignment between artificial neural network (ANN) embeddings and blood oxygenation level dependent (BOLD) responses in functional magnetic resonance imaging (fMRI) via neural encoding models has significantly advanced research on neural representation mechanisms and interpretability in the brain. However, these approaches remain limited in characterizing the brain's inherently nonlinear response properties. To address this, we propose the Jacobian-based Nonlinearity Evaluation (JNE), an interpretability metric for nonlinear neural encoding models. JNE quantifies nonlinearity by statistically measuring the dispersion of local linear mappings (Jacobians) from model representations to predicted BOLD responses, thereby approximating the nonlinearity of BOLD signals. Centered on proposing JNE as a novel interpretability metric, we validated its effectiveness through controlled simulation experiments on various activation functions and network architectures, and further verified it on real fMRI data, demonstrating a hierarchical progression of nonlinear characteristics from primary to higher-order visual cortices, consistent with established cortical organization. We further extended JNE with Sample-Specificity (JNE-SS), revealing stimulus-selective nonlinear response patterns in functionally specialized brain regions. As the first interpretability metric for quantifying nonlinear responses, JNE provides new insights into brain information processing. Code available at https://github.com/Gaitxh/JNE. [SEP] [HINT] cortical -> Neuroscience (Syns: ) | functional -> Neuroscience (Syns: working, usable, running) | information -> Bioinformatics (Syns: entropy, data, info)",Neuroscience
"We developed an explainable deep learning framework integrating protein-protein interaction (PPI) network centrality metrics with node embeddings for cancer therapeutic target prioritization. A high-confidence PPI network was constructed from STRING database interactions, computing six centrality metrics: degree, strength, betweenness, closeness, eigenvector centrality, and clustering coefficient. Node2Vec embeddings captured latent network topology. Combined features trained XGBoost and neural network classifiers using DepMap CRISPR essentiality scores as ground truth. Model interpretability was assessed through GradientSHAP analysis quantifying feature contributions. We developed a novel blended scoring approach combining model probability predictions with SHAP attribution magnitudes for enhanced gene prioritization. Our framework achieved state-of-the-art performance with AUROC of 0.930 and AUPRC of 0.656 for identifying the top 10\% most essential genes. GradientSHAP analysis revealed centrality measures contributed significantly to predictions, with degree centrality showing strongest correlation ($ρ$ = -0.357) with gene essentiality. The blended scoring approach created robust gene prioritization rankings, successfully identifying known essential genes including ribosomal proteins (RPS27A, RPS17, RPS6) and oncogenes (MYC). This study presents a human-based, combinatorial in silico framework successfully integrating network biology with explainable AI for therapeutic target discovery. The framework provides mechanistic transparency through feature attribution analysis while maintaining state-of-the-art predictive performance. Its reproducible design and reliance on human molecular datasets demonstrate a reduction-to-practice example of next-generation, animal-free modeling for cancer therapeutic target discovery and prioritization.",Bioinformatics
"We developed an explainable deep learning framework integrating protein-protein interaction (PPI) network centrality metrics with node embeddings for cancer therapeutic target prioritization. A high-confidence PPI network was constructed from STRING database interactions, computing six centrality metrics: degree, strength, betweenness, closeness, eigenvector centrality, and clustering coefficient. Node2Vec embeddings captured latent network topology. Combined features trained XGBoost and neural network classifiers using DepMap CRISPR essentiality scores as ground truth. Model interpretability was assessed through GradientSHAP analysis quantifying feature contributions. We developed a novel blended scoring approach combining model probability predictions with SHAP attribution magnitudes for enhanced gene prioritization. Our framework achieved state-of-the-art performance with AUROC of 0.930 and AUPRC of 0.656 for identifying the top 10\% most essential genes. GradientSHAP analysis revealed centrality measures contributed significantly to predictions, with degree centrality showing strongest correlation ($ρ$ = -0.357) with gene essentiality. The blended scoring approach created robust gene prioritization rankings, successfully identifying known essential genes including ribosomal proteins (RPS27A, RPS17, RPS6) and oncogenes (MYC). This study presents a human-based, combinatorial in silico framework successfully integrating network biology with explainable AI for therapeutic target discovery. The framework provides mechanistic transparency through feature attribution analysis while maintaining state-of-the-art predictive performance. Its reproducible design and reliance on human molecular datasets demonstrate a reduction-to-practice example of next-generation, animal-free modeling for cancer therapeutic target discovery and prioritization. [SEP] [HINT] features -> Bioinformatics (Syns: characteristic, lineament, feature of speech) | learning -> Bioinformatics (Syns: take, teach, acquire) | molecular -> Bioinformatics (Syns: )",Bioinformatics
"The interpretation of high-harmonic generation (HHG) in solids typically relies on phenomenological dephasing times far shorter than what is expected from microscopic scattering processes. Here we show that zero-point fluctuations associated with optical phonons naturally suppress long-range electronic coherences and generate clean harmonic spectra without introducing ad-hoc decoherence parameters. Using a 1D semiconductor composed of two distinct sites per unit cell and realistic phonon amplitudes, we demonstrate that random per-site optical-phonon jitter reproduces the spectral sharpening typically attributed to ultrafast $T_2$ dephasing. In contrast, acoustic phonons and local strain, whose distortions are correlated over nanometer scales, produce negligible spectral cleaning. We further show that such long-range site coherence leads to carrier-envelope-phase-dependent effects in the HHG spectrum driven by long pulses, but these effects collapse once optical-phonon-induced decoherence is included. Our results (i) identify optical zero-point motion as a key mechanism governing coherence in solid-state HHG, (ii) demonstrate that it can be qualitatively modeled in periodic solids through site-distance-dependent dephasing, and (iii) suggest that CEP-resolved measurements can probe electronic coherence lengths and atomic fluctuations in crystalline materials.",Materials Science
"The interpretation of high-harmonic generation (HHG) in solids typically relies on phenomenological dephasing times far shorter than what is expected from microscopic scattering processes. Here we show that zero-point fluctuations associated with optical phonons naturally suppress long-range electronic coherences and generate clean harmonic spectra without introducing ad-hoc decoherence parameters. Using a 1D semiconductor composed of two distinct sites per unit cell and realistic phonon amplitudes, we demonstrate that random per-site optical-phonon jitter reproduces the spectral sharpening typically attributed to ultrafast $T_2$ dephasing. In contrast, acoustic phonons and local strain, whose distortions are correlated over nanometer scales, produce negligible spectral cleaning. We further show that such long-range site coherence leads to carrier-envelope-phase-dependent effects in the HHG spectrum driven by long pulses, but these effects collapse once optical-phonon-induced decoherence is included. Our results (i) identify optical zero-point motion as a key mechanism governing coherence in solid-state HHG, (ii) demonstrate that it can be qualitatively modeled in periodic solids through site-distance-dependent dephasing, and (iii) suggest that CEP-resolved measurements can probe electronic coherence lengths and atomic fluctuations in crystalline materials. [SEP] [HINT] phonon -> Materials Science (Syns: ) | electronic -> Materials Science (Syns: ) | results -> Bioinformatics (Syns: final result, consequence, resultant role)",Materials Science
"Effective communication is central to achieving positive healthcare outcomes in mental health contexts, yet international students often face linguistic and cultural barriers that hinder their communication of mental distress. In this study, we evaluate the effectiveness of AI-generated images in supporting self-expression of mental distress. To achieve this, twenty Chinese international students studying at UK universities were invited to describe their personal experiences of mental distress. These descriptions were elaborated using GPT-4o with four persona-based prompt templates rooted in contemporary counselling practice to generate corresponding images. Participants then evaluated the helpfulness of generated images in facilitating the expression of their feelings based on their original descriptions. The resulting dataset comprises 100 textual descriptions of mental distress, 400 generated images, and corresponding human evaluation scores. Findings indicate that prompt design substantially affects perceived helpfulness, with the illustrator persona achieving the highest ratings. This work introduces the first publicly available text-to-image evaluation dataset with human judgment scores in the mental health domain, offering valuable resources for image evaluation, reinforcement learning with human feedback, and multi-modal research on mental health communication.",Neuroscience
"Effective communication is central to achieving positive healthcare outcomes in mental health contexts, yet international students often face linguistic and cultural barriers that hinder their communication of mental distress. In this study, we evaluate the effectiveness of AI-generated images in supporting self-expression of mental distress. To achieve this, twenty Chinese international students studying at UK universities were invited to describe their personal experiences of mental distress. These descriptions were elaborated using GPT-4o with four persona-based prompt templates rooted in contemporary counselling practice to generate corresponding images. Participants then evaluated the helpfulness of generated images in facilitating the expression of their feelings based on their original descriptions. The resulting dataset comprises 100 textual descriptions of mental distress, 400 generated images, and corresponding human evaluation scores. Findings indicate that prompt design substantially affects perceived helpfulness, with the illustrator persona achieving the highest ratings. This work introduces the first publicly available text-to-image evaluation dataset with human judgment scores in the mental health domain, offering valuable resources for image evaluation, reinforcement learning with human feedback, and multi-modal research on mental health communication. [SEP] [HINT] based -> Bioinformatics (Syns: ground, free-base, base) | learning -> Bioinformatics (Syns: take, teach, acquire) | work -> Bioinformatics (Syns: work out, process, bring)",Neuroscience
"Sequential activation of place-tuned neurons in an animal during navigation is typically interpreted as reflecting the sequence of input from adjacent positions along the trajectory. More recent theories about such place cells suggest sequences arise from abstract cognitive objectives like planning. Here, we propose a mechanistic and parsimonious interpretation to complement these ideas: hippocampal sequences arise from intrinsic recurrent circuitry that propagates activity without readily available input, acting as a temporal memory buffer for extremely sparse inputs. We implement a minimal sequence generator inspired by neurobiology and pair it with an actor-critic learner for egocentric visual navigation. Our agent reliably solves a continuous maze without explicit geometric cues, with performance depending on the length of the recurrent sequence. Crucially, the model outperforms LSTM cores under sparse input conditions (16 channels, ~2.5% activity), but not under dense input, revealing a strong interaction between representational sparsity and memory architecture. In contrast to LSTM agents, hidden sequence units develop localized place fields, distance-dependent spatial kernels, and task-dependent remapping, while inputs orthogonalize and spatial information increases across layers. These phenomena align with neurobiological data and are causal to performance. Together, our results show that sparse input synergizes with sequence-generating dynamics, providing both a mechanistic account of place cell sequences in the mammalian hippocampus and a simple inductive bias for reinforcement learning based on sparse egocentric inputs in navigation tasks.",Neuroscience
"Sequential activation of place-tuned neurons in an animal during navigation is typically interpreted as reflecting the sequence of input from adjacent positions along the trajectory. More recent theories about such place cells suggest sequences arise from abstract cognitive objectives like planning. Here, we propose a mechanistic and parsimonious interpretation to complement these ideas: hippocampal sequences arise from intrinsic recurrent circuitry that propagates activity without readily available input, acting as a temporal memory buffer for extremely sparse inputs. We implement a minimal sequence generator inspired by neurobiology and pair it with an actor-critic learner for egocentric visual navigation. Our agent reliably solves a continuous maze without explicit geometric cues, with performance depending on the length of the recurrent sequence. Crucially, the model outperforms LSTM cores under sparse input conditions (16 channels, ~2.5% activity), but not under dense input, revealing a strong interaction between representational sparsity and memory architecture. In contrast to LSTM agents, hidden sequence units develop localized place fields, distance-dependent spatial kernels, and task-dependent remapping, while inputs orthogonalize and spatial information increases across layers. These phenomena align with neurobiological data and are causal to performance. Together, our results show that sparse input synergizes with sequence-generating dynamics, providing both a mechanistic account of place cell sequences in the mammalian hippocampus and a simple inductive bias for reinforcement learning based on sparse egocentric inputs in navigation tasks. [SEP] [HINT] based -> Bioinformatics (Syns: ground, free-base, base) | learning -> Bioinformatics (Syns: take, teach, acquire) | information -> Bioinformatics (Syns: entropy, data, info)",Neuroscience
"Background: The locus of the gene PTK2B encoding the tyrosine kinase Pyk2 has been associated with the risk of late-onset Alzheimer's disease, the predominant form of dementia. Pyk2 is primarily expressed in neurons where it is involved in excitatory neurotransmission and synaptic functions. Although previous studies have implicated Pyk2 in amyloid-$β$ and Tau pathologies of Alzheimer's disease, its exact role remains unresolved, with evidence showing both detrimental and protective effects in mouse models. Here, we investigate the role of Pyk2 in hippocampal hyperactivity, Tau phosphorylation and synaptic loss associated with Alzheimer's disease-related alterations occurring in the early stages of the disease. Methods: Pyk2's involvement in amyloid-$β$ oligomer-induced hippocampal neuronal hyperactivity was investigated using whole cell patch-clamp in hippocampal slices from WT and Pyk2 KO mice. Various Pyk2 mutants were overexpressed in cultured cortical neurons to study Pyk2's role in synaptic loss. Pyk2 and Tau interaction was assessed with bimolecular fluorescence complementation assays in cultured neurons and co-immunoprecipitation in mouse cortex. Pyk2's ability to directly phosphorylate Tau was determined using in vitro kinase assays. To evaluate the impact of Pyk2 on Tau expression and phosphorylation in synapses, cellular fractionation was performed on hippocampi from WT and Pyk2 KO mice. Results: Genetic deletion of Pyk2 prevented amyloid-$β$ oligomer-induced hippocampal neuronal hyperactivity and synaptic loss. Overexpression of Pyk2 in neurons decreased dendritic spine density independently of its autophosphorylation or kinase activity, but through its proline-rich motif 1. Furthermore, Pyk2 interacted with Tau in synapses and directly phosphorylated it at Tyr18 in vitro, while Pyk2 deletion decreased Tau phosphorylation at Thr181 and its synaptic localization in the hippocampus. Conclusions: Pyk2 contributes to hippocampal neuronal hyperactivity and synaptic loss, two early events in Alzheimer's disease pathogenesis. It is also involved in Tau synaptic localization and phosphorylation, processes known to be detrimental in Alzheimer's disease. These findings highlight Pyk2 as a critical player in Alzheimer's disease pathophysiology and suggest its potential as a promising therapeutic target for early intervention.",Neuroscience
"Background: The locus of the gene PTK2B encoding the tyrosine kinase Pyk2 has been associated with the risk of late-onset Alzheimer's disease, the predominant form of dementia. Pyk2 is primarily expressed in neurons where it is involved in excitatory neurotransmission and synaptic functions. Although previous studies have implicated Pyk2 in amyloid-$β$ and Tau pathologies of Alzheimer's disease, its exact role remains unresolved, with evidence showing both detrimental and protective effects in mouse models. Here, we investigate the role of Pyk2 in hippocampal hyperactivity, Tau phosphorylation and synaptic loss associated with Alzheimer's disease-related alterations occurring in the early stages of the disease. Methods: Pyk2's involvement in amyloid-$β$ oligomer-induced hippocampal neuronal hyperactivity was investigated using whole cell patch-clamp in hippocampal slices from WT and Pyk2 KO mice. Various Pyk2 mutants were overexpressed in cultured cortical neurons to study Pyk2's role in synaptic loss. Pyk2 and Tau interaction was assessed with bimolecular fluorescence complementation assays in cultured neurons and co-immunoprecipitation in mouse cortex. Pyk2's ability to directly phosphorylate Tau was determined using in vitro kinase assays. To evaluate the impact of Pyk2 on Tau expression and phosphorylation in synapses, cellular fractionation was performed on hippocampi from WT and Pyk2 KO mice. Results: Genetic deletion of Pyk2 prevented amyloid-$β$ oligomer-induced hippocampal neuronal hyperactivity and synaptic loss. Overexpression of Pyk2 in neurons decreased dendritic spine density independently of its autophosphorylation or kinase activity, but through its proline-rich motif 1. Furthermore, Pyk2 interacted with Tau in synapses and directly phosphorylated it at Tyr18 in vitro, while Pyk2 deletion decreased Tau phosphorylation at Thr181 and its synaptic localization in the hippocampus. Conclusions: Pyk2 contributes to hippocampal neuronal hyperactivity and synaptic loss, two early events in Alzheimer's disease pathogenesis. It is also involved in Tau synaptic localization and phosphorylation, processes known to be detrimental in Alzheimer's disease. These findings highlight Pyk2 as a critical player in Alzheimer's disease pathophysiology and suggest its potential as a promising therapeutic target for early intervention. [SEP] [HINT] cortical -> Neuroscience (Syns: ) | using -> Bioinformatics (Syns: utilize, exploitation, apply) | potential -> Bioinformatics (Syns: voltage, potential difference, electric potential)",Neuroscience
"Protein structure is central to biological function, and enabling multimodal protein models requires joint reasoning over sequence, structure, and function. A key barrier is the lack of principled protein structure tokenizers (PSTs): existing approaches fix token size or rely on continuous vector codebooks, limiting interpretability, multi-scale control, and transfer across architectures. We introduce GeoBPE, a geometry-grounded PST that transforms continuous, noisy, multi-scale backbone conformations into discrete ``sentences'' of geometry while enforcing global constraints. Analogous to byte-pair encoding, GeoBPE generates a hierarchical vocabulary of geometric primitives by iteratively (i) clustering Geo-Pair occurrences with k-medoids to yield a resolution-controllable vocabulary; (ii) quantizing each Geo-Pair to its closest medoid prototype; and (iii) reducing drift through differentiable inverse kinematics that optimizes boundary glue angles under an $\mathrm{SE}(3)$ end-frame loss. GeoBPE offers compression ($>$10x reduction in bits-per-residue at similar distortion rate), data efficiency ($>$10x less training data), and generalization (maintains test/train distortion ratio of $1.0-1.1$). It is architecture-agnostic: (a) its hierarchical vocabulary provides a strong inductive bias for coarsening residue-level embeddings from large PLMs into motif- and protein-level representations, consistently outperforming leading PSTs across $12$ tasks and $24$ test splits; (b) paired with a transformer, GeoBPE supports unconditional backbone generation via language modeling; and (c) tokens align with CATH functional families and support expert-interpretable case studies, offering functional meaning absent in prior PSTs. Code is available at https://github.com/shiningsunnyday/PT-BPE/.",Bioinformatics
"Protein structure is central to biological function, and enabling multimodal protein models requires joint reasoning over sequence, structure, and function. A key barrier is the lack of principled protein structure tokenizers (PSTs): existing approaches fix token size or rely on continuous vector codebooks, limiting interpretability, multi-scale control, and transfer across architectures. We introduce GeoBPE, a geometry-grounded PST that transforms continuous, noisy, multi-scale backbone conformations into discrete ``sentences'' of geometry while enforcing global constraints. Analogous to byte-pair encoding, GeoBPE generates a hierarchical vocabulary of geometric primitives by iteratively (i) clustering Geo-Pair occurrences with k-medoids to yield a resolution-controllable vocabulary; (ii) quantizing each Geo-Pair to its closest medoid prototype; and (iii) reducing drift through differentiable inverse kinematics that optimizes boundary glue angles under an $\mathrm{SE}(3)$ end-frame loss. GeoBPE offers compression ($>$10x reduction in bits-per-residue at similar distortion rate), data efficiency ($>$10x less training data), and generalization (maintains test/train distortion ratio of $1.0-1.1$). It is architecture-agnostic: (a) its hierarchical vocabulary provides a strong inductive bias for coarsening residue-level embeddings from large PLMs into motif- and protein-level representations, consistently outperforming leading PSTs across $12$ tasks and $24$ test splits; (b) paired with a transformer, GeoBPE supports unconditional backbone generation via language modeling; and (c) tokens align with CATH functional families and support expert-interpretable case studies, offering functional meaning absent in prior PSTs. Code is available at https://github.com/shiningsunnyday/PT-BPE/. [SEP] [HINT] tasks -> Neuroscience (Syns: tax, task, project) | language -> Neuroscience (Syns: linguistic process, linguistic communication, spoken communication) | functional -> Neuroscience (Syns: working, usable, running)",Bioinformatics
"This paper describes GeoPl@ntNet, an interactive web application designed to make Essential Biodiversity Variables accessible and understandable to everyone through dynamic maps and fact sheets. Its core purpose is to allow users to explore high-resolution AI-generated maps of species distributions, habitat types, and biodiversity indicators across Europe. These maps, developed through a cascading pipeline involving convolutional neural networks and large language models, provide an intuitive yet information-rich interface to better understand biodiversity, with resolutions as precise as 50x50 meters. The website also enables exploration of specific regions, allowing users to select areas of interest on the map (e.g., urban green spaces, protected areas, or riverbanks) to view local species and their coverage. Additionally, GeoPl@ntNet generates comprehensive reports for selected regions, including insights into the number of protected species, invasive species, and endemic species.",Bioinformatics
"This paper describes GeoPl@ntNet, an interactive web application designed to make Essential Biodiversity Variables accessible and understandable to everyone through dynamic maps and fact sheets. Its core purpose is to allow users to explore high-resolution AI-generated maps of species distributions, habitat types, and biodiversity indicators across Europe. These maps, developed through a cascading pipeline involving convolutional neural networks and large language models, provide an intuitive yet information-rich interface to better understand biodiversity, with resolutions as precise as 50x50 meters. The website also enables exploration of specific regions, allowing users to select areas of interest on the map (e.g., urban green spaces, protected areas, or riverbanks) to view local species and their coverage. Additionally, GeoPl@ntNet generates comprehensive reports for selected regions, including insights into the number of protected species, invasive species, and endemic species. [SEP] [HINT] language -> Neuroscience (Syns: linguistic process, linguistic communication, spoken communication) | networks -> Neuroscience (Syns: network, meshwork, electronic network) | including -> Bioinformatics (Syns: admit, include, let in)",Bioinformatics
"We investigate and quantify the basin geometry and extreme final state uncertainty of two identical electrically asymmetrically coupled Chialvo neurons. The system's diverse behaviors are presented, along with the mathematical reasoning behind its chaotic and nonchaotic dynamics as determined by the structure of the coupled equations. The system is found to be multistable with two qualitatively different attractors. Although each neuron is individually nonchaotic, the chaotic basin takes up the vast majority of the coupled system's state space, but the nonchaotic basin stretches to infinity due to chance synchronization. The boundary between the basins is found to be fractal, leading to extreme final state sensitivity. This uncertainty and its potential effect on the synchronization of biological neurons may have significant implications for understanding human behavior and neurological disease.",Neuroscience
"We investigate and quantify the basin geometry and extreme final state uncertainty of two identical electrically asymmetrically coupled Chialvo neurons. The system's diverse behaviors are presented, along with the mathematical reasoning behind its chaotic and nonchaotic dynamics as determined by the structure of the coupled equations. The system is found to be multistable with two qualitatively different attractors. Although each neuron is individually nonchaotic, the chaotic basin takes up the vast majority of the coupled system's state space, but the nonchaotic basin stretches to infinity due to chance synchronization. The boundary between the basins is found to be fractal, leading to extreme final state sensitivity. This uncertainty and its potential effect on the synchronization of biological neurons may have significant implications for understanding human behavior and neurological disease. [SEP] [HINT] understanding -> Neuroscience (Syns: savvy, intellect, sympathy) | structure -> Bioinformatics (Syns: social system, complex body part, social structure) | human -> Neuroscience (Syns: human being, man, homo)",Neuroscience
"The performance of modern light-emitting technologies, from lasers to LEDs, is limited by nonradiative losses, with Auger recombination being the dominant channel at device-relevant carrier densities. Reliable modeling of this process is essential, yet conventional treatments neglect dynamic dielectric effects, limiting the predictive reliability at operating conditions. We develop a general framework that incorporates the frequency-dependent screened Coulomb interaction $W_{00}(\mathbf{q},ω)$, computed from low-scaling \textit{GW}, into both direct and phonon-assisted Auger amplitudes. Demonstrated on orthorhombic $γ$-CsPbI$_3$ (band gap $E_g\approx1.73$ eV) and $γ$-CsSnI$_3$ ($E_g\approx1.30$ eV), the approach shows that dynamic screening enhances the dielectric response, lowering the room-temperature Auger coefficient by $\sim$50-60 %. This renormalization shifts the crossover between radiative and nonradiative recombination by nearly a factor of two in carrier density. Dynamic dielectric screening thus emerges as a quantitative determinant of Auger recombination, offering a transferable framework for predictive modeling across polar semiconductors where frequency-independent screening models are inadequate.",Materials Science
"The performance of modern light-emitting technologies, from lasers to LEDs, is limited by nonradiative losses, with Auger recombination being the dominant channel at device-relevant carrier densities. Reliable modeling of this process is essential, yet conventional treatments neglect dynamic dielectric effects, limiting the predictive reliability at operating conditions. We develop a general framework that incorporates the frequency-dependent screened Coulomb interaction $W_{00}(\mathbf{q},ω)$, computed from low-scaling \textit{GW}, into both direct and phonon-assisted Auger amplitudes. Demonstrated on orthorhombic $γ$-CsPbI$_3$ (band gap $E_g\approx1.73$ eV) and $γ$-CsSnI$_3$ ($E_g\approx1.30$ eV), the approach shows that dynamic screening enhances the dielectric response, lowering the room-temperature Auger coefficient by $\sim$50-60 %. This renormalization shifts the crossover between radiative and nonradiative recombination by nearly a factor of two in carrier density. Dynamic dielectric screening thus emerges as a quantitative determinant of Auger recombination, offering a transferable framework for predictive modeling across polar semiconductors where frequency-independent screening models are inadequate. [SEP] [HINT] performance -> Bioinformatics (Syns: functioning, operation, carrying out) | framework -> Bioinformatics (Syns: theoretical account, model, fabric) | models -> Bioinformatics (Syns: framework, modelling, good example)",Materials Science
"In early stage drug discovery, bioactivity prediction of molecules against target proteins plays a crucial role. Trdaitional QSAR models that utilizes molecular descriptor based data often struggles to predict bioactivity of molecules effectively due to its limitation in capturing structural and contextual information embedded within each compound. To address this challenge, we propose Rep3Net, a unified deep learning architecture that not only incorporates descriptor data but also includes spatial and relational information through graph-based represenation of compounds and contextual information through ChemBERTa generated embeddings from SMILES strings. Our model employing multimodal concatenated features produce reliable bioactivity prediction on Poly [ADP-ribose] polymerase 1 (PARP-1) dataset. PARP-1 is a crucial agent in DNA damage repair and has become a significant theraputic target in malignancies that depend on it for survival and growth. A comprehensive analysis and comparison with conventional standalone models including GCN, GAT, XGBoost, etc. demonstrates that our architecture achieves the highest predictive performance. In computational screening of compounds in drug discovery, our architecture provides a scalable framework for bioactivity prediction.",Bioinformatics
"In early stage drug discovery, bioactivity prediction of molecules against target proteins plays a crucial role. Trdaitional QSAR models that utilizes molecular descriptor based data often struggles to predict bioactivity of molecules effectively due to its limitation in capturing structural and contextual information embedded within each compound. To address this challenge, we propose Rep3Net, a unified deep learning architecture that not only incorporates descriptor data but also includes spatial and relational information through graph-based represenation of compounds and contextual information through ChemBERTa generated embeddings from SMILES strings. Our model employing multimodal concatenated features produce reliable bioactivity prediction on Poly [ADP-ribose] polymerase 1 (PARP-1) dataset. PARP-1 is a crucial agent in DNA damage repair and has become a significant theraputic target in malignancies that depend on it for survival and growth. A comprehensive analysis and comparison with conventional standalone models including GCN, GAT, XGBoost, etc. demonstrates that our architecture achieves the highest predictive performance. In computational screening of compounds in drug discovery, our architecture provides a scalable framework for bioactivity prediction. [SEP] [HINT] based -> Bioinformatics (Syns: ground, free-base, base) | computational -> Neuroscience (Syns: ) | features -> Bioinformatics (Syns: characteristic, lineament, feature of speech)",Bioinformatics
"Topology is being widely adopted to understand and to categorize quantum matter in modern physics. The nexus of topology orders, which engenders distinct quantum phases with benefits to both fundamental research and practical applications for future quantum devices, can be driven by topological phase transition through modulating intrinsic or extrinsic ordering parameters. The conjoined topology, however, is still elusive in experiments due to the lack of suitable material platforms. Here we use scanning tunneling microscopy, angle-resolved photoemission spectroscopy, and theoretical calculations to investigate the doping-driven band structure evolution of a quasi-one-dimensional material system, bismuth halide, which contains rare multiple band inversions in two time-reversal-invariant momenta. According to the unique bulk-boundary correspondence in topological matter, we unveil a composite topological phase, the coexistence of a strong topological phase and a high-order topological phase, evoked by the band inversion associated with topological phase transition in this system. Moreover, we reveal multiple-stage topological phase transitions by varying the halide element ratio: from high-order topology to weak topology, the unusual dual topology, and trivial/weak topology subsequently. Our results not only realize an ideal material platform with composite topology, but also provide an insightful pathway to establish abundant topological phases in the framework of band inversion theory.",Materials Science
"Topology is being widely adopted to understand and to categorize quantum matter in modern physics. The nexus of topology orders, which engenders distinct quantum phases with benefits to both fundamental research and practical applications for future quantum devices, can be driven by topological phase transition through modulating intrinsic or extrinsic ordering parameters. The conjoined topology, however, is still elusive in experiments due to the lack of suitable material platforms. Here we use scanning tunneling microscopy, angle-resolved photoemission spectroscopy, and theoretical calculations to investigate the doping-driven band structure evolution of a quasi-one-dimensional material system, bismuth halide, which contains rare multiple band inversions in two time-reversal-invariant momenta. According to the unique bulk-boundary correspondence in topological matter, we unveil a composite topological phase, the coexistence of a strong topological phase and a high-order topological phase, evoked by the band inversion associated with topological phase transition in this system. Moreover, we reveal multiple-stage topological phase transitions by varying the halide element ratio: from high-order topology to weak topology, the unusual dual topology, and trivial/weak topology subsequently. Our results not only realize an ideal material platform with composite topology, but also provide an insightful pathway to establish abundant topological phases in the framework of band inversion theory. [SEP] [HINT] transition -> Materials Science (Syns: passage, modulation, changeover) | structure -> Bioinformatics (Syns: social system, complex body part, social structure) | results -> Bioinformatics (Syns: final result, consequence, resultant role)",Materials Science
"In-situ measurement is a key feature to better understand and precisely control the growth of complex structures, such as vertical-cavity surface-emitting lasers. In this work, we are showing the precise measurement of optical indices of AlGaAs at 600 {\textdegree}C over a wide spectral range (450--1400 nm). To do so, in-situ spectral reflectance measurement is used, combined with ex-situ layer thickness and composition measurement by x-ray diffraction enabling for precise determination of the optical indices with an accuracy better than 1%. To validate our measurements, we realized the complete automation of the growth of a GaAs/AlAs 940 nm-DBR by molecular beam epitaxy, without the need to pre-calibrate cells fluxes. The fabricated DBR shows a deviation of 0.2 nm of the stop-band central-wavelength compared to the targeted one. This approach holds significant interest for the III--V semiconductor community and epitaxial growth techniques.",Materials Science
"In-situ measurement is a key feature to better understand and precisely control the growth of complex structures, such as vertical-cavity surface-emitting lasers. In this work, we are showing the precise measurement of optical indices of AlGaAs at 600 {\textdegree}C over a wide spectral range (450--1400 nm). To do so, in-situ spectral reflectance measurement is used, combined with ex-situ layer thickness and composition measurement by x-ray diffraction enabling for precise determination of the optical indices with an accuracy better than 1%. To validate our measurements, we realized the complete automation of the growth of a GaAs/AlAs 940 nm-DBR by molecular beam epitaxy, without the need to pre-calibrate cells fluxes. The fabricated DBR shows a deviation of 0.2 nm of the stop-band central-wavelength compared to the targeted one. This approach holds significant interest for the III--V semiconductor community and epitaxial growth techniques. [SEP] [HINT] complex -> Bioinformatics (Syns: building complex, coordination compound, composite) | molecular -> Bioinformatics (Syns: ) | optical -> Materials Science (Syns: ocular, opthalmic, optic)",Materials Science
"Large language models (LLMs) excel at explicit reasoning, but their implicit computational strategies remain underexplored. Decades of psychophysics research show that humans intuitively process and integrate noisy signals using near-optimal Bayesian strategies in perceptual tasks. We ask whether LLMs exhibit similar behaviour and perform optimal multimodal integration without explicit training or instruction. Adopting the psychophysics paradigm, we infer computational principles of LLMs from systematic behavioural studies. We introduce a behavioural benchmark - BayesBench: four magnitude estimation tasks (length, location, distance, and duration) over text and image, inspired by classic psychophysics, and evaluate a diverse set of nine LLMs alongside human judgments for calibration. Through controlled ablations of noise, context, and instruction prompts, we measure performance, behaviour and efficiency in multimodal cue-combination. Beyond accuracy and efficiency metrics, we introduce a Bayesian Consistency Score that detects Bayes-consistent behavioural shifts even when accuracy saturates. Our results show that while capable models often adapt in Bayes-consistent ways, accuracy does not guarantee robustness. Notably, GPT-5 Mini achieves perfect text accuracy but fails to integrate visual cues efficiently. This reveals a critical dissociation between capability and strategy, suggesting accuracy-centric benchmarks may over-index on performance while missing brittle uncertainty handling. These findings reveal emergent principled handling of uncertainty and highlight the correlation between accuracy and Bayesian tendencies. We release our psychophysics benchmark and consistency metric (https://bayes-bench.github.io) as evaluation tools and to inform future multimodal architecture designs.",Neuroscience
"Large language models (LLMs) excel at explicit reasoning, but their implicit computational strategies remain underexplored. Decades of psychophysics research show that humans intuitively process and integrate noisy signals using near-optimal Bayesian strategies in perceptual tasks. We ask whether LLMs exhibit similar behaviour and perform optimal multimodal integration without explicit training or instruction. Adopting the psychophysics paradigm, we infer computational principles of LLMs from systematic behavioural studies. We introduce a behavioural benchmark - BayesBench: four magnitude estimation tasks (length, location, distance, and duration) over text and image, inspired by classic psychophysics, and evaluate a diverse set of nine LLMs alongside human judgments for calibration. Through controlled ablations of noise, context, and instruction prompts, we measure performance, behaviour and efficiency in multimodal cue-combination. Beyond accuracy and efficiency metrics, we introduce a Bayesian Consistency Score that detects Bayes-consistent behavioural shifts even when accuracy saturates. Our results show that while capable models often adapt in Bayes-consistent ways, accuracy does not guarantee robustness. Notably, GPT-5 Mini achieves perfect text accuracy but fails to integrate visual cues efficiently. This reveals a critical dissociation between capability and strategy, suggesting accuracy-centric benchmarks may over-index on performance while missing brittle uncertainty handling. These findings reveal emergent principled handling of uncertainty and highlight the correlation between accuracy and Bayesian tendencies. We release our psychophysics benchmark and consistency metric (https://bayes-bench.github.io) as evaluation tools and to inform future multimodal architecture designs. [SEP] [HINT] tasks -> Neuroscience (Syns: tax, task, project) | language -> Neuroscience (Syns: linguistic process, linguistic communication, spoken communication) | computational -> Neuroscience (Syns: )",Neuroscience
"Extracellular matrix (ECM) remodeling is central to a wide variety of healthy and diseased tissue processes. Unfortunately, predicting ECM remodeling under various chemical and mechanical conditions has proven to be excessively challenging, due in part to its complex regulation by intracellular and extracellular molecular reaction networks that are spatially and temporally dynamic. We introduce ECMSim, which is a highly interactive, real-time, and web application designed to simulate heterogeneous matrix remodeling. The current model simulates cardiac scar tissue with configurable input conditions using a large-scale model of the cardiac fibroblast signaling network. Cardiac fibrosis is a major component of many forms of heart failure. ECMSim simulates over 1.3 million equations simultaneously in real time that include more than 125 species and more than 200 edges in each cell in a 100*100 spatial array (10,000 cells), which accounts for inputs, receptors, intracellular signaling cascades, ECM production, and feedback loops, as well as molecular diffusion. The algorithm is represented by a set of ordinary differential equations (ODEs) that are coupled with ECM molecular diffusion. The equations are solved on demand using compiled C++ and the WebAssembly standard. The platform includes brush-style cell selection to target a subset of cells with adjustable input molecule concentrations, parameter sliders to adjust parameters on demand, and multiple coupled real-time visualizations of network dynamics at multiple scales. Implementing ECMSim in standard web technologies enables a fully functional application that combines real-time simulation, visual interaction, and model editing. The software enables the investigation of pathological or experimental conditions, hypothetical scenarios, matrix remodeling, or the testing of the effects of an experimental drug(s) with a target receptor.",Bioinformatics
"Extracellular matrix (ECM) remodeling is central to a wide variety of healthy and diseased tissue processes. Unfortunately, predicting ECM remodeling under various chemical and mechanical conditions has proven to be excessively challenging, due in part to its complex regulation by intracellular and extracellular molecular reaction networks that are spatially and temporally dynamic. We introduce ECMSim, which is a highly interactive, real-time, and web application designed to simulate heterogeneous matrix remodeling. The current model simulates cardiac scar tissue with configurable input conditions using a large-scale model of the cardiac fibroblast signaling network. Cardiac fibrosis is a major component of many forms of heart failure. ECMSim simulates over 1.3 million equations simultaneously in real time that include more than 125 species and more than 200 edges in each cell in a 100*100 spatial array (10,000 cells), which accounts for inputs, receptors, intracellular signaling cascades, ECM production, and feedback loops, as well as molecular diffusion. The algorithm is represented by a set of ordinary differential equations (ODEs) that are coupled with ECM molecular diffusion. The equations are solved on demand using compiled C++ and the WebAssembly standard. The platform includes brush-style cell selection to target a subset of cells with adjustable input molecule concentrations, parameter sliders to adjust parameters on demand, and multiple coupled real-time visualizations of network dynamics at multiple scales. Implementing ECMSim in standard web technologies enables a fully functional application that combines real-time simulation, visual interaction, and model editing. The software enables the investigation of pathological or experimental conditions, hypothetical scenarios, matrix remodeling, or the testing of the effects of an experimental drug(s) with a target receptor. [SEP] [HINT] tissue -> Bioinformatics (Syns: tissue paper, weave) | networks -> Neuroscience (Syns: network, meshwork, electronic network) | functional -> Neuroscience (Syns: working, usable, running)",Bioinformatics
"The rapid growth of Artificial Intelligence (AI) in healthcare has sparked interest in Trustworthy AI and AI Implementation Science, both of which are essential for accelerating clinical adoption. However, strict regulations, gaps between research and clinical settings, and challenges in evaluating AI systems continue to hinder real-world implementation. This study presents an AI implementation case study within Shriners Childrens (SC), a large multisite pediatric system, showcasing the modernization of SCs Research Data Warehouse (RDW) to OMOP CDM v5.4 within a secure Microsoft Fabric environment. We introduce a Python-based data quality assessment tool compatible with SCs infrastructure, extending OHDsi's R/Java-based Data Quality Dashboard (DQD) and integrating Trustworthy AI principles using the METRIC framework. This extension enhances data quality evaluation by addressing informative missingness, redundancy, timeliness, and distributional consistency. We also compare systematic and case-specific AI implementation strategies for Craniofacial Microsomia (CFM) using the FHIR standard. Our contributions include a real-world evaluation of AI implementations, integration of Trustworthy AI principles into data quality assessment, and insights into hybrid implementation strategies that blend systematic infrastructure with use-case-driven approaches to advance AI in healthcare.",Bioinformatics
"The rapid growth of Artificial Intelligence (AI) in healthcare has sparked interest in Trustworthy AI and AI Implementation Science, both of which are essential for accelerating clinical adoption. However, strict regulations, gaps between research and clinical settings, and challenges in evaluating AI systems continue to hinder real-world implementation. This study presents an AI implementation case study within Shriners Childrens (SC), a large multisite pediatric system, showcasing the modernization of SCs Research Data Warehouse (RDW) to OMOP CDM v5.4 within a secure Microsoft Fabric environment. We introduce a Python-based data quality assessment tool compatible with SCs infrastructure, extending OHDsi's R/Java-based Data Quality Dashboard (DQD) and integrating Trustworthy AI principles using the METRIC framework. This extension enhances data quality evaluation by addressing informative missingness, redundancy, timeliness, and distributional consistency. We also compare systematic and case-specific AI implementation strategies for Craniofacial Microsomia (CFM) using the FHIR standard. Our contributions include a real-world evaluation of AI implementations, integration of Trustworthy AI principles into data quality assessment, and insights into hybrid implementation strategies that blend systematic infrastructure with use-case-driven approaches to advance AI in healthcare. [SEP] [HINT] clinical -> Bioinformatics (Syns: ) | quality -> Bioinformatics (Syns: lineament, tone, calibre) | systems -> Bioinformatics (Syns: organization, organisation, system)",Bioinformatics
"Machine learning has markedly advanced de novo peptide sequencing (DNS) for mass spectrometry-based proteomics. DNS tools offer a reliable way to identify peptides without relying on reference databases, extending proteomic analysis and unlocking applications into less-charted regions of the proteome. However, they still face a key limitation. DNS tools lack principled methods for estimating false discovery rates (FDR) and instead rely on model-specific confidence scores that are often miscalibrated. This limits trust in results, hinders cross-model comparisons and reduces validation success. Here we present Winnow, a model-agnostic framework for estimating FDR from calibrated DNS outputs. Winnow maps raw model scores to calibrated confidences using a neural network trained on peptide-spectrum match (PSM)-derived features. From these calibrated scores, Winnow computes PSM-specific error metrics and an experiment-wide FDR estimate using a novel decoy-free FDR estimator. It supports both zero-shot and dataset-specific calibration, enabling flexible application via direct inference, fine-tuning, or training a custom model. We demonstrate that, when applied to InstaNovo predictions, Winnow's calibrator improves recall at fixed FDR thresholds, and its FDR estimator tracks true error rates when benchmarked against reference proteomes and database search. Winnow ensures accurate FDR control across datasets, helping unlock the full potential of DNS.",Bioinformatics
"Machine learning has markedly advanced de novo peptide sequencing (DNS) for mass spectrometry-based proteomics. DNS tools offer a reliable way to identify peptides without relying on reference databases, extending proteomic analysis and unlocking applications into less-charted regions of the proteome. However, they still face a key limitation. DNS tools lack principled methods for estimating false discovery rates (FDR) and instead rely on model-specific confidence scores that are often miscalibrated. This limits trust in results, hinders cross-model comparisons and reduces validation success. Here we present Winnow, a model-agnostic framework for estimating FDR from calibrated DNS outputs. Winnow maps raw model scores to calibrated confidences using a neural network trained on peptide-spectrum match (PSM)-derived features. From these calibrated scores, Winnow computes PSM-specific error metrics and an experiment-wide FDR estimate using a novel decoy-free FDR estimator. It supports both zero-shot and dataset-specific calibration, enabling flexible application via direct inference, fine-tuning, or training a custom model. We demonstrate that, when applied to InstaNovo predictions, Winnow's calibrator improves recall at fixed FDR thresholds, and its FDR estimator tracks true error rates when benchmarked against reference proteomes and database search. Winnow ensures accurate FDR control across datasets, helping unlock the full potential of DNS. [SEP] [HINT] learning -> Bioinformatics (Syns: take, teach, acquire) | framework -> Bioinformatics (Syns: theoretical account, model, fabric) | using -> Bioinformatics (Syns: utilize, exploitation, apply)",Bioinformatics
"Advances in single-cell sequencing have enabled high-resolution profiling of diverse molecular modalities, while integrating unpaired multi-omics single-cell data remains challenging. Existing approaches either rely on pair information or prior correspondences, or require computing a global pairwise coupling matrix, limiting their scalability and flexibility. In this paper, we introduce a scalable and flexible generative framework called single-cell Multi-omics Regularized Disentangled Representations (scMRDR) for unpaired multi-omics integration. Specifically, we disentangle each cell's latent representations into modality-shared and modality-specific components using a well-designed $β$-VAE architecture, which are augmented with isometric regularization to preserve intra-omics biological heterogeneity, adversarial objective to encourage cross-modal alignment, and masked reconstruction loss strategy to address the issue of missing features across modalities. Our method achieves excellent performance on benchmark datasets in terms of batch correction, modality alignment, and biological signal preservation. Crucially, it scales effectively to large-level datasets and supports integration of more than two omics, offering a powerful and flexible solution for large-scale multi-omics data integration and downstream biological discovery.",Bioinformatics
"Advances in single-cell sequencing have enabled high-resolution profiling of diverse molecular modalities, while integrating unpaired multi-omics single-cell data remains challenging. Existing approaches either rely on pair information or prior correspondences, or require computing a global pairwise coupling matrix, limiting their scalability and flexibility. In this paper, we introduce a scalable and flexible generative framework called single-cell Multi-omics Regularized Disentangled Representations (scMRDR) for unpaired multi-omics integration. Specifically, we disentangle each cell's latent representations into modality-shared and modality-specific components using a well-designed $β$-VAE architecture, which are augmented with isometric regularization to preserve intra-omics biological heterogeneity, adversarial objective to encourage cross-modal alignment, and masked reconstruction loss strategy to address the issue of missing features across modalities. Our method achieves excellent performance on benchmark datasets in terms of batch correction, modality alignment, and biological signal preservation. Crucially, it scales effectively to large-level datasets and supports integration of more than two omics, offering a powerful and flexible solution for large-scale multi-omics data integration and downstream biological discovery. [SEP] [HINT] features -> Bioinformatics (Syns: characteristic, lineament, feature of speech) | information -> Bioinformatics (Syns: entropy, data, info) | molecular -> Bioinformatics (Syns: )",Bioinformatics
"Simulated microbial communities are used in benchmarking microbial abundance estimators and other bioinformatic utilities. To match current data scales, large simulated samples are needed, and many. The speed of current implementations might create bottlenecks for scientists testing new innovations. Here, a new implementation is introduced, based on existing error models. The new implementation, Izzy, provides up to a 60x speedup while maintaining a simple and easy-to-use interface.",Bioinformatics
"Simulated microbial communities are used in benchmarking microbial abundance estimators and other bioinformatic utilities. To match current data scales, large simulated samples are needed, and many. The speed of current implementations might create bottlenecks for scientists testing new innovations. Here, a new implementation is introduced, based on existing error models. The new implementation, Izzy, provides up to a 60x speedup while maintaining a simple and easy-to-use interface. [SEP] [HINT] used -> Bioinformatics (Syns: utilize, ill-used, apply) | data -> Bioinformatics (Syns: data point, information, datum) | large -> Bioinformatics (Syns: prominent, great, tumid)",Bioinformatics
"This work presents a detailed investigation of the discharge behavior of spherical granular materials through a conical--cylindrical hopper using \emph{Discrete Element Method (DEM)} simulations. The aim is to assess the applicability limits of the empirical \emph{Beverloo law}. The system was modeled with a monodisperse particles whose mechanical properties correspond to the $Al_{95}Fe_2Cr_2Ti_1$ alloy, and interparticle contacts were described using the Hertz--Mindlin (no slip) model. The simulations systematically explored the influence of particle diameter ($d$) and bed height ($h$) on the resulting mass flow rate ($Q$).   The results reveal the coexistence of transient and steady-state discharge regimes. Good agreement with the Beverloo scaling was observed for relatively small diameter ratios ($D/d = 10$) and sufficiently large bed heights, where the flow stabilizes rapidly. For larger $D/d$ ratios, the discharge rate decays exponentially, indicating a breakdown of the constant-hydrostatic-pressure assumption underlying the Beverloo model. A dimensionless criterion for the validity of the Beverloo law is proposed as $Π_h = h/D > 2$, or equivalently $N = h/d > 20$. The quantitative agreement between DEM simulations and experimental measurements for polydisperse particle size distributions further validates the computational model and demonstrates its predictive capability for granular discharge in confined geometries.",Materials Science
"This work presents a detailed investigation of the discharge behavior of spherical granular materials through a conical--cylindrical hopper using \emph{Discrete Element Method (DEM)} simulations. The aim is to assess the applicability limits of the empirical \emph{Beverloo law}. The system was modeled with a monodisperse particles whose mechanical properties correspond to the $Al_{95}Fe_2Cr_2Ti_1$ alloy, and interparticle contacts were described using the Hertz--Mindlin (no slip) model. The simulations systematically explored the influence of particle diameter ($d$) and bed height ($h$) on the resulting mass flow rate ($Q$).   The results reveal the coexistence of transient and steady-state discharge regimes. Good agreement with the Beverloo scaling was observed for relatively small diameter ratios ($D/d = 10$) and sufficiently large bed heights, where the flow stabilizes rapidly. For larger $D/d$ ratios, the discharge rate decays exponentially, indicating a breakdown of the constant-hydrostatic-pressure assumption underlying the Beverloo model. A dimensionless criterion for the validity of the Beverloo law is proposed as $Π_h = h/D > 2$, or equivalently $N = h/d > 20$. The quantitative agreement between DEM simulations and experimental measurements for polydisperse particle size distributions further validates the computational model and demonstrates its predictive capability for granular discharge in confined geometries. [SEP] [HINT] computational -> Neuroscience (Syns: ) | work -> Bioinformatics (Syns: work out, process, bring) | results -> Bioinformatics (Syns: final result, consequence, resultant role)",Materials Science
"Hexagonal Boron Nitride (h-BN) is a highly intriguing candidate for heterostructure optoelectronic applications, such as Deep Ultraviolet photodetectors, UV sensing and communication systems and solar cells. This is primarily due to its unique properties, including a layer dependent wide energy bandgap, superior mechanical strength, high thermal conductivity, high band-edge absorption coefficient, and exceptional transparency in the UV region. The widely adopted synthesis method for h-BN thin films is Chemical Vapor Deposition (CVD) Method, which often utilizes catalytic substrates like copper (Cu) and Nickel (Ni). However, integrating the synthesized h-BN into device applications requires a subsequent transfer process to the target substrate. This transfer step introduces significant material damage, such as folding, cracking and polymer residues, which ultimately degrade the optoelectronic properties of the material and compromise device performance. To overcome this major challenge, there is a strong need to synthesize high-quality h-BN films directly onto dielectric substrates such as silicon (Si), SiO2, quartz, sapphire or AlN without the need for transfer. The primary difficulty in direct synthesis lies in achieving homogenous, high crystallinity films with controllable thickness due to the absence of a catalytic effect. In this work, we investigated the optimization of growth parameters for the direct synthesis of ultrathin h-BN films on non-catalytic quartz substrates, which are highly transparent in the UV region, using the Low-pressure Chemical Vapor Deposition (LPCVD) method. The optimal synthesis conditions were determined to be 1050oC for 60 min, achieved by the decomposition of 150 mg Ammonia Borane (AB) precursor at 80oC. This optimization is crucial for advancing large-scale, high-performance h-BN based DUV photodetector fabrication.",Materials Science
"Hexagonal Boron Nitride (h-BN) is a highly intriguing candidate for heterostructure optoelectronic applications, such as Deep Ultraviolet photodetectors, UV sensing and communication systems and solar cells. This is primarily due to its unique properties, including a layer dependent wide energy bandgap, superior mechanical strength, high thermal conductivity, high band-edge absorption coefficient, and exceptional transparency in the UV region. The widely adopted synthesis method for h-BN thin films is Chemical Vapor Deposition (CVD) Method, which often utilizes catalytic substrates like copper (Cu) and Nickel (Ni). However, integrating the synthesized h-BN into device applications requires a subsequent transfer process to the target substrate. This transfer step introduces significant material damage, such as folding, cracking and polymer residues, which ultimately degrade the optoelectronic properties of the material and compromise device performance. To overcome this major challenge, there is a strong need to synthesize high-quality h-BN films directly onto dielectric substrates such as silicon (Si), SiO2, quartz, sapphire or AlN without the need for transfer. The primary difficulty in direct synthesis lies in achieving homogenous, high crystallinity films with controllable thickness due to the absence of a catalytic effect. In this work, we investigated the optimization of growth parameters for the direct synthesis of ultrathin h-BN films on non-catalytic quartz substrates, which are highly transparent in the UV region, using the Low-pressure Chemical Vapor Deposition (LPCVD) method. The optimal synthesis conditions were determined to be 1050oC for 60 min, achieved by the decomposition of 150 mg Ammonia Borane (AB) precursor at 80oC. This optimization is crucial for advancing large-scale, high-performance h-BN based DUV photodetector fabrication. [SEP] [HINT] based -> Bioinformatics (Syns: ground, free-base, base) | systems -> Bioinformatics (Syns: organization, organisation, system) | including -> Bioinformatics (Syns: admit, include, let in)",Materials Science
"Transition Metal Nitrides are a versatile class of materials, combining chemical robustness, high hardness, and superconducting behaviour with critical temperatures between 2 to 10 K. While several binary TMNs have been explored, superconductivity in stoichiometric W2N has remained largely unexplored. Here, we report on superconducting thin films of stoichiometric W2N, demonstrating a distinctly high upper critical field of 8.5 T, uncommon among binary TMNs. This robust superconducting response under high magnetic fields highlights the technological relevance of W2N for integrated quantum and cryogenic electronic platforms. Overall, these results position stoichiometric W2N as a promising addition to the TMN superconducting landscape, opening new avenues for functional materials design based on chemically stable and mechanically resilient nitrides.",Materials Science
"Transition Metal Nitrides are a versatile class of materials, combining chemical robustness, high hardness, and superconducting behaviour with critical temperatures between 2 to 10 K. While several binary TMNs have been explored, superconductivity in stoichiometric W2N has remained largely unexplored. Here, we report on superconducting thin films of stoichiometric W2N, demonstrating a distinctly high upper critical field of 8.5 T, uncommon among binary TMNs. This robust superconducting response under high magnetic fields highlights the technological relevance of W2N for integrated quantum and cryogenic electronic platforms. Overall, these results position stoichiometric W2N as a promising addition to the TMN superconducting landscape, opening new avenues for functional materials design based on chemically stable and mechanically resilient nitrides. [SEP] [HINT] field -> Materials Science (Syns: field of honor, line of business, orbit) | transition -> Materials Science (Syns: passage, modulation, changeover) | based -> Bioinformatics (Syns: ground, free-base, base)",Materials Science
"Mammalian tissue architecture is central to biological function, and its disruption is a hallmark of disease. Medical imaging techniques can generate large point cloud datasets that capture changes in the cellular composition of such tissues with disease progression. However, regions of interest (ROIs) are usually defined by quadrat-based methods that ignore intrinsic structure and risk fragmenting meaningful features. Here, we introduce TopROI, a topology-informed, network-based method for partitioning point clouds into ROIs that preserves both local geometry and higher-order architecture. TopROI integrates geometry-informed networks with persistent homology, combining cell neighbourhoods and multiscale cycles to guide community detection. Applied to synthetic point clouds that mimic glandular structure, TopROI outperforms quadrat-based and purely geometric partitions by maintaining biologically plausible ROI geometry and better preserving ground-truth structures. Applied to cellular point clouds obtained from human colorectal cancer biopsies, TopROI generates ROIs that preserve crypt-like structures and enable persistent homology analysis of individual regions. This study reveals a continuum of architectural changes from healthy mucosa to carcinoma, reflecting progressive disorganisation in tissue structure. TopROI thus provides a principled and flexible framework for defining biologically meaningful ROIs in large point clouds, enabling more accurate quantification of tissue organization and new insights into structural changes associated with disease progression.",Bioinformatics
"Mammalian tissue architecture is central to biological function, and its disruption is a hallmark of disease. Medical imaging techniques can generate large point cloud datasets that capture changes in the cellular composition of such tissues with disease progression. However, regions of interest (ROIs) are usually defined by quadrat-based methods that ignore intrinsic structure and risk fragmenting meaningful features. Here, we introduce TopROI, a topology-informed, network-based method for partitioning point clouds into ROIs that preserves both local geometry and higher-order architecture. TopROI integrates geometry-informed networks with persistent homology, combining cell neighbourhoods and multiscale cycles to guide community detection. Applied to synthetic point clouds that mimic glandular structure, TopROI outperforms quadrat-based and purely geometric partitions by maintaining biologically plausible ROI geometry and better preserving ground-truth structures. Applied to cellular point clouds obtained from human colorectal cancer biopsies, TopROI generates ROIs that preserve crypt-like structures and enable persistent homology analysis of individual regions. This study reveals a continuum of architectural changes from healthy mucosa to carcinoma, reflecting progressive disorganisation in tissue structure. TopROI thus provides a principled and flexible framework for defining biologically meaningful ROIs in large point clouds, enabling more accurate quantification of tissue organization and new insights into structural changes associated with disease progression. [SEP] [HINT] tissue -> Bioinformatics (Syns: tissue paper, weave) | networks -> Neuroscience (Syns: network, meshwork, electronic network) | structure -> Bioinformatics (Syns: social system, complex body part, social structure)",Bioinformatics
"Complex systems produce high-dimensional signals that lack macroscopic variables analogous to entropy, temperature, or free energy. This work introduces a thermoinformational formulation that derives entropy, internal energy, temperature, and Helmholtz free energy directly from empirical microstate distributions of arbitrary datasets. The approach provides a data-driven description of how a system reorganizes, exchanges information, and moves between stable and unstable states. Applied to dual-EEG recordings from mother-infant dyads performing the A-not-B task, the formulation captures increases in informational heat during switches and errors, and reveals that correct choices arise from more stable, low-temperature states. In an independent optogenetic dam-pup experiment, the same variables separate stimulation conditions and trace coherent trajectories in thermodynamic state space. Across both human and rodent systems, this thermoinformational formulation yields compact and physically interpretable macroscopic variables that generalize across species, modalities, and experimental paradigms.",Neuroscience
"Complex systems produce high-dimensional signals that lack macroscopic variables analogous to entropy, temperature, or free energy. This work introduces a thermoinformational formulation that derives entropy, internal energy, temperature, and Helmholtz free energy directly from empirical microstate distributions of arbitrary datasets. The approach provides a data-driven description of how a system reorganizes, exchanges information, and moves between stable and unstable states. Applied to dual-EEG recordings from mother-infant dyads performing the A-not-B task, the formulation captures increases in informational heat during switches and errors, and reveals that correct choices arise from more stable, low-temperature states. In an independent optogenetic dam-pup experiment, the same variables separate stimulation conditions and trace coherent trajectories in thermodynamic state space. Across both human and rodent systems, this thermoinformational formulation yields compact and physically interpretable macroscopic variables that generalize across species, modalities, and experimental paradigms. [SEP] [HINT] complex -> Bioinformatics (Syns: building complex, coordination compound, composite) | work -> Bioinformatics (Syns: work out, process, bring) | systems -> Bioinformatics (Syns: organization, organisation, system)",Neuroscience
"The emergent Weyl modes with the broken time-reversal symmetry or inversion symmetry provide large Berry curvature and chirality to carriers, offering the realistic platforms to explore topology of electrons in three-dimensional systems. However, the reversal transition between different types of Weyl modes in a single material, which is of particular interest in the fundamental research in Weyl physics and potential application in spintronics, is scarcely achieved due to restriction of inborn symmetry in crystals. Here, by tuning the direction and strength of magnetic field in an ideal Dirac semimetal, Bi4(Br0.27I0.73)4, we report the realization of multiple Weyl modes, including gapped Weyl mode, Weyl nodal ring, and coupled Weyl mode by the magnetoresistivity measurements and electronic structure calculations. Specifically, under a magnetic field with broken mirror symmetry, anomalous Hall effect with step feature results from the large Berry curvature for the gapped Weyl mode. A prominent negative magnetoresistivity is observed at low magnetic field with preserved mirror symmetry and disappears at high magnetic field, which is correlated to the chiral anomaly and its annihilation of Weyl nodal ring, respectively. Our findings reveal distinct Weyl modes under the intertwined crystal symmetry and time-reversal breaking, laying the foundation of manipulating multiple Weyl modes in chiral spintronic network.",Materials Science
"The emergent Weyl modes with the broken time-reversal symmetry or inversion symmetry provide large Berry curvature and chirality to carriers, offering the realistic platforms to explore topology of electrons in three-dimensional systems. However, the reversal transition between different types of Weyl modes in a single material, which is of particular interest in the fundamental research in Weyl physics and potential application in spintronics, is scarcely achieved due to restriction of inborn symmetry in crystals. Here, by tuning the direction and strength of magnetic field in an ideal Dirac semimetal, Bi4(Br0.27I0.73)4, we report the realization of multiple Weyl modes, including gapped Weyl mode, Weyl nodal ring, and coupled Weyl mode by the magnetoresistivity measurements and electronic structure calculations. Specifically, under a magnetic field with broken mirror symmetry, anomalous Hall effect with step feature results from the large Berry curvature for the gapped Weyl mode. A prominent negative magnetoresistivity is observed at low magnetic field with preserved mirror symmetry and disappears at high magnetic field, which is correlated to the chiral anomaly and its annihilation of Weyl nodal ring, respectively. Our findings reveal distinct Weyl modes under the intertwined crystal symmetry and time-reversal breaking, laying the foundation of manipulating multiple Weyl modes in chiral spintronic network. [SEP] [HINT] field -> Materials Science (Syns: field of honor, line of business, orbit) | transition -> Materials Science (Syns: passage, modulation, changeover) | low -> Materials Science (Syns: low-spirited, scurvy, depressed)",Materials Science
"We study a stochastic model of a copolymerization process that has been extensively investigated in the physics literature. The main questions of interest include: (i) what are the criteria for transience, null recurrence, and positive recurrence in terms of the system parameters; (ii) in the transient regime, what are the limiting fractions of the different monomer types; and (iii) in the transient regime, what is the speed of growth of the polymer? Previous studies in the physics literature have addressed these questions using heuristic methods. Here, we utilize rigorous mathematical arguments to derive the results from the physics literature. Moreover, the techniques developed allow us to generalize to the copolymerization process with finitely many monomer types. We expect that the mathematical methods used and developed in this work will also enable the study of even more complex models in the future.",Bioinformatics
"We study a stochastic model of a copolymerization process that has been extensively investigated in the physics literature. The main questions of interest include: (i) what are the criteria for transience, null recurrence, and positive recurrence in terms of the system parameters; (ii) in the transient regime, what are the limiting fractions of the different monomer types; and (iii) in the transient regime, what is the speed of growth of the polymer? Previous studies in the physics literature have addressed these questions using heuristic methods. Here, we utilize rigorous mathematical arguments to derive the results from the physics literature. Moreover, the techniques developed allow us to generalize to the copolymerization process with finitely many monomer types. We expect that the mathematical methods used and developed in this work will also enable the study of even more complex models in the future. [SEP] [HINT] used -> Bioinformatics (Syns: utilize, ill-used, apply) | complex -> Bioinformatics (Syns: building complex, coordination compound, composite) | work -> Bioinformatics (Syns: work out, process, bring)",Bioinformatics
"Remote photoplethysmography (rPPG) aims to extract non-contact physiological signals from facial videos and has shown great potential. However, existing rPPG approaches struggle to bridge the gap between source and target domains. Recent test-time adaptation (TTA) solutions typically optimize rPPG model for the incoming test videos using self-training loss under an unrealistic assumption that the target domain remains stationary. However, time-varying factors like weather and lighting in dynamic environments often cause continual domain shifts. The erroneous gradients accumulation from these shifts may corrupt the model's key parameters for physiological information, leading to catastrophic forgetting. Therefore, We propose a physiology-related parameters freezing strategy to retain such knowledge. It isolates physiology-related and domain-related parameters by assessing the model's uncertainty to current domain and freezes the physiology-related parameters during adaptation to prevent catastrophic forgetting. Moreover, the dynamic domain shifts with various non-physiological characteristics may lead to conflicting optimization objectives during TTA, which is manifested as the over-adapted model losing its adaptability to future domains. To fix over-adaptation, we propose a preemptive gradient modification strategy. It preemptively adapts to future domains and uses the acquired gradients to modify current adaptation, thereby preserving the model's adaptability. In summary, we propose a stable continual test-time adaptation (CTTA) framework for rPPG measurement, called \textbf{PhysRAP}, which \textbf{R}emembers the past, \textbf{A}dapts to the present, and \textbf{P}reempts the future. Extensive experiments show its state-of-the-art performance, especially in domain shifts. The code is available at https://github.com/xjtucsy/PhysRAP.",Bioinformatics
"Remote photoplethysmography (rPPG) aims to extract non-contact physiological signals from facial videos and has shown great potential. However, existing rPPG approaches struggle to bridge the gap between source and target domains. Recent test-time adaptation (TTA) solutions typically optimize rPPG model for the incoming test videos using self-training loss under an unrealistic assumption that the target domain remains stationary. However, time-varying factors like weather and lighting in dynamic environments often cause continual domain shifts. The erroneous gradients accumulation from these shifts may corrupt the model's key parameters for physiological information, leading to catastrophic forgetting. Therefore, We propose a physiology-related parameters freezing strategy to retain such knowledge. It isolates physiology-related and domain-related parameters by assessing the model's uncertainty to current domain and freezes the physiology-related parameters during adaptation to prevent catastrophic forgetting. Moreover, the dynamic domain shifts with various non-physiological characteristics may lead to conflicting optimization objectives during TTA, which is manifested as the over-adapted model losing its adaptability to future domains. To fix over-adaptation, we propose a preemptive gradient modification strategy. It preemptively adapts to future domains and uses the acquired gradients to modify current adaptation, thereby preserving the model's adaptability. In summary, we propose a stable continual test-time adaptation (CTTA) framework for rPPG measurement, called \textbf{PhysRAP}, which \textbf{R}emembers the past, \textbf{A}dapts to the present, and \textbf{P}reempts the future. Extensive experiments show its state-of-the-art performance, especially in domain shifts. The code is available at https://github.com/xjtucsy/PhysRAP. [SEP] [HINT] framework -> Bioinformatics (Syns: theoretical account, model, fabric) | using -> Bioinformatics (Syns: utilize, exploitation, apply) | existing -> Bioinformatics (Syns: subsist, existent, survive)",Bioinformatics
"This paper considers the problem of error correction in multi-class classification of face images on unbalanced samples. The study is based on the analysis of a data frame containing images labeled by seven different emotional states of people of different ages. Particular attention is paid to the problem of class imbalance, in which some emotions significantly prevail over others. To solve the classification problem, a neural network model based on LSTM with an attention mechanism focusing on key areas of the face that are informative for emotion recognition is used. As part of the experiments, the model is trained on all possible configurations of subsets of six classes with subsequent error correction for the seventh class, excluded at the training stage. The results show that correction is possible for all classes, although the degree of success varies: some classes are better restored, others are worse. In addition, on the test sample, when correcting some classes, an increase in key quality metrics for small classes was recorded, which indicates the promise of the proposed approach in solving applied problems related to the search for rare events, for example, in anti-fraud systems. Thus, the proposed method can be effectively applied in facial expression analysis systems and in tasks requiring stable classification under skewed class distribution.",Neuroscience
"This paper considers the problem of error correction in multi-class classification of face images on unbalanced samples. The study is based on the analysis of a data frame containing images labeled by seven different emotional states of people of different ages. Particular attention is paid to the problem of class imbalance, in which some emotions significantly prevail over others. To solve the classification problem, a neural network model based on LSTM with an attention mechanism focusing on key areas of the face that are informative for emotion recognition is used. As part of the experiments, the model is trained on all possible configurations of subsets of six classes with subsequent error correction for the seventh class, excluded at the training stage. The results show that correction is possible for all classes, although the degree of success varies: some classes are better restored, others are worse. In addition, on the test sample, when correcting some classes, an increase in key quality metrics for small classes was recorded, which indicates the promise of the proposed approach in solving applied problems related to the search for rare events, for example, in anti-fraud systems. Thus, the proposed method can be effectively applied in facial expression analysis systems and in tasks requiring stable classification under skewed class distribution. [SEP] [HINT] tasks -> Neuroscience (Syns: tax, task, project) | based -> Bioinformatics (Syns: ground, free-base, base) | quality -> Bioinformatics (Syns: lineament, tone, calibre)",Neuroscience
"Pb-based perovskites with multiple cations are fascinating materials showing various phenomena such as high piezoelectric, electromechanical, and relaxor properties. While chemical disordering accompanied by polar nanoregions and nanosized domains is commonly believed to cause the relaxor nature, little is known about ferroelectric microstructures of chemically ordered Pb-based perovskites. In this study, we discovered intriguing meandering ferroelectric domains in chemically ordered ferroelectric Pb(Sc$_{1/2}$Nb$_{1/2}$)O$_{3}$ using in-situ transmission electron microscopy with dark-field imaging. Observation results demonstrate that electric polarization can fluctuate around the [111] direction despite the formation of long-range ordered rhombohedral domains, which results in unique weak relaxor properties. In-situ imaging upon heating successfully reveals the dynamic behavior of domain-wall movements with lattice distortion and paraelectric-ferroelectric phase coexistence in the vicinity of the Curie temperature, indicating a discontinuous phase transition. Our research provides new insights into the effect of chemical ordering on ferroelectric nanodomains.",Materials Science
"Pb-based perovskites with multiple cations are fascinating materials showing various phenomena such as high piezoelectric, electromechanical, and relaxor properties. While chemical disordering accompanied by polar nanoregions and nanosized domains is commonly believed to cause the relaxor nature, little is known about ferroelectric microstructures of chemically ordered Pb-based perovskites. In this study, we discovered intriguing meandering ferroelectric domains in chemically ordered ferroelectric Pb(Sc$_{1/2}$Nb$_{1/2}$)O$_{3}$ using in-situ transmission electron microscopy with dark-field imaging. Observation results demonstrate that electric polarization can fluctuate around the [111] direction despite the formation of long-range ordered rhombohedral domains, which results in unique weak relaxor properties. In-situ imaging upon heating successfully reveals the dynamic behavior of domain-wall movements with lattice distortion and paraelectric-ferroelectric phase coexistence in the vicinity of the Curie temperature, indicating a discontinuous phase transition. Our research provides new insights into the effect of chemical ordering on ferroelectric nanodomains. [SEP] [HINT] electron -> Materials Science (Syns: negatron) | results -> Bioinformatics (Syns: final result, consequence, resultant role) | using -> Bioinformatics (Syns: utilize, exploitation, apply)",Materials Science
"The human brain is a complex system defined by multi-way, higher-order interactions invisible to traditional pairwise network models. Although a diverse array of analytical methods has been developed to address this shortcoming, the field remains fragmented, lacking a unifying conceptual framework that integrates and organizes the rapidly expanding methodological landscape of higher-order brain connectivity. This review provides a synthesis of the methodologies for studying higher-order brain connectivity. We propose a fundamental distinction between implicit paradigms, which quantify the statistical strength of group interactions, and explicit paradigms, which construct higher-order structural representations like hypergraphs and topological data analysis. We trace the evolution of each approach, from early Correlation-of-Correlations and information-theoretic concepts of synergy/redundancy, to the edge-centric paradigm and advanced topological methods. Through a critical analysis of conceptual, statistical, and computational challenges, we argue that the future of the field lies not in a single best method, but in a principled integration of these complementary approaches. This manuscript aims to provide a unified map and a critical perspective to guide researchers toward a robust and insightful understanding of the brain's complex, multi-level architecture.",Bioinformatics
"The human brain is a complex system defined by multi-way, higher-order interactions invisible to traditional pairwise network models. Although a diverse array of analytical methods has been developed to address this shortcoming, the field remains fragmented, lacking a unifying conceptual framework that integrates and organizes the rapidly expanding methodological landscape of higher-order brain connectivity. This review provides a synthesis of the methodologies for studying higher-order brain connectivity. We propose a fundamental distinction between implicit paradigms, which quantify the statistical strength of group interactions, and explicit paradigms, which construct higher-order structural representations like hypergraphs and topological data analysis. We trace the evolution of each approach, from early Correlation-of-Correlations and information-theoretic concepts of synergy/redundancy, to the edge-centric paradigm and advanced topological methods. Through a critical analysis of conceptual, statistical, and computational challenges, we argue that the future of the field lies not in a single best method, but in a principled integration of these complementary approaches. This manuscript aims to provide a unified map and a critical perspective to guide researchers toward a robust and insightful understanding of the brain's complex, multi-level architecture. [SEP] [HINT] field -> Materials Science (Syns: field of honor, line of business, orbit) | computational -> Neuroscience (Syns: ) | understanding -> Neuroscience (Syns: savvy, intellect, sympathy)",Bioinformatics
"Ultra-weak photon emission (UPE) from living systems is widely hypothesized to reflect un-derlying self-organization and long-range coordination in biological dynamics. However, distin-guishing biologically driven correlations from trivial stochastic or instrumental effects requires a robust, multi-method framework. In this work, we establish and benchmark a comprehensive anal-ysis pipeline for photon-count time series, combining Distribution Entropy Analysis, Rényi entro-py, Detrended Fluctuation Analysis, its generalization Multifractal Detrended Fluctuation Analysis, and tail-statistics characterization. Surrogate signals constructed from Poisson processes, Fractional Gaussian Noise, and Renewal Processes with power-law waiting times are used to validate sensitivity to memory, intermittency, and multifractality. Across all methods, a coherent hierarchy of dynamical regimes is recovered, demonstrating internal methodological consistency. Application to experimental dark-count data and attenuated coherent-laser emission confirm Poisson-like behavior, establishing an essential statistical baseline for UPE studies. The combined results show that this multi-resolution approach reliably separates trivial photon-counting statistics from struc-tured long-range organization, providing a validated methodological foundation for future biological UPE measurements and their interpretation in the context of non-equilibrium statistical physics, information dynamics, and prospective markers of biological coherence.",Bioinformatics
"Ultra-weak photon emission (UPE) from living systems is widely hypothesized to reflect un-derlying self-organization and long-range coordination in biological dynamics. However, distin-guishing biologically driven correlations from trivial stochastic or instrumental effects requires a robust, multi-method framework. In this work, we establish and benchmark a comprehensive anal-ysis pipeline for photon-count time series, combining Distribution Entropy Analysis, Rényi entro-py, Detrended Fluctuation Analysis, its generalization Multifractal Detrended Fluctuation Analysis, and tail-statistics characterization. Surrogate signals constructed from Poisson processes, Fractional Gaussian Noise, and Renewal Processes with power-law waiting times are used to validate sensitivity to memory, intermittency, and multifractality. Across all methods, a coherent hierarchy of dynamical regimes is recovered, demonstrating internal methodological consistency. Application to experimental dark-count data and attenuated coherent-laser emission confirm Poisson-like behavior, establishing an essential statistical baseline for UPE studies. The combined results show that this multi-resolution approach reliably separates trivial photon-counting statistics from struc-tured long-range organization, providing a validated methodological foundation for future biological UPE measurements and their interpretation in the context of non-equilibrium statistical physics, information dynamics, and prospective markers of biological coherence. [SEP] [HINT] used -> Bioinformatics (Syns: utilize, ill-used, apply) | information -> Bioinformatics (Syns: entropy, data, info) | results -> Bioinformatics (Syns: final result, consequence, resultant role)",Bioinformatics
"Foundation machine learning interatomic potentials (MLIPs) are trained on overlapping chemical spaces, yet their latent representations remain model-specific. Here, we show that independently developed MLIPs exhibit statistically consistent geometric organisation of atomic environments, which we term the Platonic representation. By projecting embeddings relative to a set of atomic anchors, we unify the latent spaces of seven MLIPs (spanning equivariant, non-equivariant, conservative, and non-conservative architectures) into a common metric space that preserves chemical periodicity and structural invariants. This unified framework enables direct cross-model optimal transport, interpretable embedding arithmetic, and the detection of representational biases. Furthermore, we demonstrate that geometric distortions in this space can indicate physical prediction failures, including symmetry breaking and incorrect phonon dispersions. Our results show that the latent spaces of diverse MLIPs present consistent statistical geometry shaped by shared physical and chemical constraints, suggesting that the Platonic representation offers a practical route toward interoperable, comparable, and interpretable foundation models for materials science.",Materials Science
"Foundation machine learning interatomic potentials (MLIPs) are trained on overlapping chemical spaces, yet their latent representations remain model-specific. Here, we show that independently developed MLIPs exhibit statistically consistent geometric organisation of atomic environments, which we term the Platonic representation. By projecting embeddings relative to a set of atomic anchors, we unify the latent spaces of seven MLIPs (spanning equivariant, non-equivariant, conservative, and non-conservative architectures) into a common metric space that preserves chemical periodicity and structural invariants. This unified framework enables direct cross-model optimal transport, interpretable embedding arithmetic, and the detection of representational biases. Furthermore, we demonstrate that geometric distortions in this space can indicate physical prediction failures, including symmetry breaking and incorrect phonon dispersions. Our results show that the latent spaces of diverse MLIPs present consistent statistical geometry shaped by shared physical and chemical constraints, suggesting that the Platonic representation offers a practical route toward interoperable, comparable, and interpretable foundation models for materials science. [SEP] [HINT] phonon -> Materials Science (Syns: ) | learning -> Bioinformatics (Syns: take, teach, acquire) | space -> Neuroscience (Syns: distance, place, outer space)",Materials Science
"The recent capability to use THz pulses to control the nuclear quantum degrees of freedom in crystals has opened promising avenues for the advanced manipulation of material properties. While numerical approaches exist for studying the time evolution of the quantum nuclear density matrix, an interpretable analytical framework to explicitly analyze the influence of quantum fluctuations on nuclear dynamics remains lacking. In this work, we present an analytical quantum theory of nonlinear phononics. This framework is a basis for deriving models of realistic materials, allowing for exact solutions of the nuclear time evolution with full consideration of quantum fluctuations. This is accomplished by treating for all possible third- and fourth-order phonon couplings and expressing forces as analytic functions of such fluctuations. We provide an analytic proof that, in general, a strong pulse displacing a phonon mode from equilibrium induces the quenching, or squeezing, of its quantum lattice fluctuations. This finding, which establishes a systematization of the mechanism observed in Ref. 1, introduces a new paradigm in nonlinear phononics, harnessing this cooling effect to drive symmetry breaking in quantum paraelectric materials.",Materials Science
"The recent capability to use THz pulses to control the nuclear quantum degrees of freedom in crystals has opened promising avenues for the advanced manipulation of material properties. While numerical approaches exist for studying the time evolution of the quantum nuclear density matrix, an interpretable analytical framework to explicitly analyze the influence of quantum fluctuations on nuclear dynamics remains lacking. In this work, we present an analytical quantum theory of nonlinear phononics. This framework is a basis for deriving models of realistic materials, allowing for exact solutions of the nuclear time evolution with full consideration of quantum fluctuations. This is accomplished by treating for all possible third- and fourth-order phonon couplings and expressing forces as analytic functions of such fluctuations. We provide an analytic proof that, in general, a strong pulse displacing a phonon mode from equilibrium induces the quenching, or squeezing, of its quantum lattice fluctuations. This finding, which establishes a systematization of the mechanism observed in Ref. 1, introduces a new paradigm in nonlinear phononics, harnessing this cooling effect to drive symmetry breaking in quantum paraelectric materials. [SEP] [HINT] phonon -> Materials Science (Syns: ) | framework -> Bioinformatics (Syns: theoretical account, model, fabric) | theory -> Materials Science (Syns: possibility, hypothesis)",Materials Science
"Accurate and reliable forecasting models are critical for guiding public health responses and policy decisions during pandemics such as COVID-19. Retrospective evaluation of model performance is essential for improving epidemic forecasting capabilities. In this study, we used COVID-19 wastewater data from CDC's National Wastewater Surveillance System to generate sequential weekly retrospective forecasts for the United States from March 2022 through September 2024, both at the national level and for four major regions (Northeast, Midwest, South, and West). We produced 133 weekly forecasts using 11 models, including ARIMA, generalized additive models (GAM), simple linear regression (SLR), Prophet, and the n-sub-epidemic framework (top-ranked, weighted-ensemble, and unweighted-ensemble variants). Forecast performance was assessed using mean absolute error (MAE), mean squared error (MSE), weighted interval score (WIS), and 95% prediction interval coverage. The n-sub-epidemic unweighted ensembles outperformed all other models at 3-4-week horizons, particularly at the national level and in the Midwest and West. ARIMA and GAM performed best at 1-2-week horizons in most regions, whereas Prophet and SLR consistently underperformed across regions and horizons. These findings highlight the value of region-specific modeling strategies and demonstrate the utility of the n-sub-epidemic framework for real-time outbreak forecasting using wastewater surveillance data.",Bioinformatics
"Accurate and reliable forecasting models are critical for guiding public health responses and policy decisions during pandemics such as COVID-19. Retrospective evaluation of model performance is essential for improving epidemic forecasting capabilities. In this study, we used COVID-19 wastewater data from CDC's National Wastewater Surveillance System to generate sequential weekly retrospective forecasts for the United States from March 2022 through September 2024, both at the national level and for four major regions (Northeast, Midwest, South, and West). We produced 133 weekly forecasts using 11 models, including ARIMA, generalized additive models (GAM), simple linear regression (SLR), Prophet, and the n-sub-epidemic framework (top-ranked, weighted-ensemble, and unweighted-ensemble variants). Forecast performance was assessed using mean absolute error (MAE), mean squared error (MSE), weighted interval score (WIS), and 95% prediction interval coverage. The n-sub-epidemic unweighted ensembles outperformed all other models at 3-4-week horizons, particularly at the national level and in the Midwest and West. ARIMA and GAM performed best at 1-2-week horizons in most regions, whereas Prophet and SLR consistently underperformed across regions and horizons. These findings highlight the value of region-specific modeling strategies and demonstrate the utility of the n-sub-epidemic framework for real-time outbreak forecasting using wastewater surveillance data. [SEP] [HINT] used -> Bioinformatics (Syns: utilize, ill-used, apply) | performance -> Bioinformatics (Syns: functioning, operation, carrying out) | including -> Bioinformatics (Syns: admit, include, let in)",Bioinformatics
"A few million words suffice for children to acquire language. Yet, the brain mechanisms underlying this unique ability remain poorly understood. To address this issue, we investigate neural activity recorded from over 7,400 electrodes implanted in the brains of 46 children, teenagers, and adults for epilepsy monitoring, as they listened to an audiobook version of ""The Little Prince"". We then train neural encoding and decoding models using representations, derived either from linguistic theory or from large language models, to map the location, dynamics and development of the language hierarchy in the brain. We find that a broad range of linguistic features is robustly represented across the cortex, even in 2-5-year-olds. Crucially, these representations evolve with age: while fast phonetic features are already present in the superior temporal gyrus of the youngest individuals, slower word-level representations only emerge in the associative cortices of older individuals. Remarkably, this neuro-developmental trajectory is spontaneously captured by large language models: with training, these AI models learned representations that can only be identified in the adult human brain. Together, these findings reveal the maturation of language representations in the developing brain and show that modern AI systems provide a promising tool to model the neural bases of language acquisition.",Neuroscience
"A few million words suffice for children to acquire language. Yet, the brain mechanisms underlying this unique ability remain poorly understood. To address this issue, we investigate neural activity recorded from over 7,400 electrodes implanted in the brains of 46 children, teenagers, and adults for epilepsy monitoring, as they listened to an audiobook version of ""The Little Prince"". We then train neural encoding and decoding models using representations, derived either from linguistic theory or from large language models, to map the location, dynamics and development of the language hierarchy in the brain. We find that a broad range of linguistic features is robustly represented across the cortex, even in 2-5-year-olds. Crucially, these representations evolve with age: while fast phonetic features are already present in the superior temporal gyrus of the youngest individuals, slower word-level representations only emerge in the associative cortices of older individuals. Remarkably, this neuro-developmental trajectory is spontaneously captured by large language models: with training, these AI models learned representations that can only be identified in the adult human brain. Together, these findings reveal the maturation of language representations in the developing brain and show that modern AI systems provide a promising tool to model the neural bases of language acquisition. [SEP] [HINT] decoding -> Neuroscience (Syns: decrypt, decipherment, decryption) | language -> Neuroscience (Syns: linguistic process, linguistic communication, spoken communication) | features -> Bioinformatics (Syns: characteristic, lineament, feature of speech)",Neuroscience
"The quantum metric -- which quantifies the distance between quantum states -- is a fundamental component of the quantum geometric tensor, playing a crucial role in a wide range of physical phenomena. Its direct detection and control remains a challenge, requiring suitable material candidates. In this work, we present the emergence of a tunable quantum metric in a versatile two-dimensional material platform, namely, few-layer phosphorene. Using ab-initio-derived models, we show how electric fields can be used to substantially enhance the quantum metric as well as the associated quantum weight. Furthermore, we present a layer-dependent evolution of the quantum metric and its interplay with the electric field in this material. Our results establish few-layer phosphorene as a promising platform for exploring control over the quantum metric and the resulting metric responses in real materials.",Materials Science
"The quantum metric -- which quantifies the distance between quantum states -- is a fundamental component of the quantum geometric tensor, playing a crucial role in a wide range of physical phenomena. Its direct detection and control remains a challenge, requiring suitable material candidates. In this work, we present the emergence of a tunable quantum metric in a versatile two-dimensional material platform, namely, few-layer phosphorene. Using ab-initio-derived models, we show how electric fields can be used to substantially enhance the quantum metric as well as the associated quantum weight. Furthermore, we present a layer-dependent evolution of the quantum metric and its interplay with the electric field in this material. Our results establish few-layer phosphorene as a promising platform for exploring control over the quantum metric and the resulting metric responses in real materials. [SEP] [HINT] used -> Bioinformatics (Syns: utilize, ill-used, apply) | field -> Materials Science (Syns: field of honor, line of business, orbit) | results -> Bioinformatics (Syns: final result, consequence, resultant role)",Materials Science
"Microbial consortia offer significant biotechnological advantages over monocultures for bioproduction. However, industrial deployment is hampered by the lack of scalable architectures to ensure stable coexistence between populations. Existing strategies rely on genetic modifications, which impose metabolic load, or environmental changes, which can reduce production. We present a versatile control architecture to regulate density and composition of a two-strain consortium without genetic engineering or drastic environmental changes. Our bioreactor-based control architecture comprises a mixing chamber where both strains are co-cultured and a reservoir sustaining the slower-growing strain. For both chambers we develop model-based and sim-to-real learning controllers. The control architecture is then validated in vivo on a two-strain Escherichia coli consortium, achieving precise and robust regulation of consortium density and composition, including tracking of time-varying references and recovery from perturbations.",Bioinformatics
"Microbial consortia offer significant biotechnological advantages over monocultures for bioproduction. However, industrial deployment is hampered by the lack of scalable architectures to ensure stable coexistence between populations. Existing strategies rely on genetic modifications, which impose metabolic load, or environmental changes, which can reduce production. We present a versatile control architecture to regulate density and composition of a two-strain consortium without genetic engineering or drastic environmental changes. Our bioreactor-based control architecture comprises a mixing chamber where both strains are co-cultured and a reservoir sustaining the slower-growing strain. For both chambers we develop model-based and sim-to-real learning controllers. The control architecture is then validated in vivo on a two-strain Escherichia coli consortium, achieving precise and robust regulation of consortium density and composition, including tracking of time-varying references and recovery from perturbations. [SEP] [HINT] learning -> Bioinformatics (Syns: take, teach, acquire) | including -> Bioinformatics (Syns: admit, include, let in) | existing -> Bioinformatics (Syns: subsist, existent, survive)",Bioinformatics
"The presence of an expanded polyglutamine produces a toxic gain of function in huntingtin. Protein aggregation resulting from this gain of function is likely to be the cause of neuronal death. Two main mechanisms of aggregation have been proposed: hydrogen bonding by polar-zipper formation and covalent bonding by transglutaminase-catalyzed cross-linking. In cell culture models of Huntington's disease, aggregates are mostly stabilized by hydrogen bonds, but covalent bonds are also likely to occur. Nothing is known about the nature of the bonds that stabilize the aggregates in the brain of patients with Huntington's disease. It seems that the nature of the bond stabilizing the aggregates is one of the most important questions, as the answer would condition the therapeutic approach to Huntington's disease.",Neuroscience
"The presence of an expanded polyglutamine produces a toxic gain of function in huntingtin. Protein aggregation resulting from this gain of function is likely to be the cause of neuronal death. Two main mechanisms of aggregation have been proposed: hydrogen bonding by polar-zipper formation and covalent bonding by transglutaminase-catalyzed cross-linking. In cell culture models of Huntington's disease, aggregates are mostly stabilized by hydrogen bonds, but covalent bonds are also likely to occur. Nothing is known about the nature of the bonds that stabilize the aggregates in the brain of patients with Huntington's disease. It seems that the nature of the bond stabilizing the aggregates is one of the most important questions, as the answer would condition the therapeutic approach to Huntington's disease. [SEP] [HINT] protein -> Bioinformatics (Syns: ) | models -> Bioinformatics (Syns: framework, modelling, good example) | brain -> Neuroscience (Syns: learning ability, mentality, brainiac)",Neuroscience
"Brain-computer interfaces (BCIs) are evolving from research prototypes into clinical, assistive, and performance enhancement technologies. Despite the rapid rise and promise of implantable technologies, there is a need for better and more capable wearable and non-invasive approaches whilst also minimising hardware requirements. We present a non-invasive BCI for mind-drawing that iteratively infers a subject's internal visual intent by adaptively presenting visual stimuli (probes) on a screen encoded at different flicker-frequencies and analyses the steady-state visual evoked potentials (SSVEPs). A Gabor-inspired or machine-learned policies dynamically update the spatial placement of the visual probes on the screen to explore the image space and reconstruct simple imagined shapes within approximately two minutes or less using just single-channel EEG data. Additionally, by leveraging stable diffusion models, reconstructed mental images can be transformed into realistic and detailed visual representations. Whilst we expect that similar results might be achievable with e.g. eye-tracking techniques, our work shows that symbiotic human-AI interaction can significantly increase BCI bit-rates by more than a factor 5x, providing a platform for future development of AI-augmented BCI.",Neuroscience
"Brain-computer interfaces (BCIs) are evolving from research prototypes into clinical, assistive, and performance enhancement technologies. Despite the rapid rise and promise of implantable technologies, there is a need for better and more capable wearable and non-invasive approaches whilst also minimising hardware requirements. We present a non-invasive BCI for mind-drawing that iteratively infers a subject's internal visual intent by adaptively presenting visual stimuli (probes) on a screen encoded at different flicker-frequencies and analyses the steady-state visual evoked potentials (SSVEPs). A Gabor-inspired or machine-learned policies dynamically update the spatial placement of the visual probes on the screen to explore the image space and reconstruct simple imagined shapes within approximately two minutes or less using just single-channel EEG data. Additionally, by leveraging stable diffusion models, reconstructed mental images can be transformed into realistic and detailed visual representations. Whilst we expect that similar results might be achievable with e.g. eye-tracking techniques, our work shows that symbiotic human-AI interaction can significantly increase BCI bit-rates by more than a factor 5x, providing a platform for future development of AI-augmented BCI. [SEP] [HINT] space -> Neuroscience (Syns: distance, place, outer space) | work -> Bioinformatics (Syns: work out, process, bring) | performance -> Bioinformatics (Syns: functioning, operation, carrying out)",Neuroscience
"Large language models (LLMs) have revolutionized human-machine interaction, and have been extended by embedding diverse modalities such as images into a shared language space. Yet, neural decoding has remained constrained by static, non-interactive methods. We introduce CorText, a framework that integrates neural activity directly into the latent space of an LLM, enabling open-ended, natural language interaction with brain data. Trained on fMRI data recorded during viewing of natural scenes, CorText generates accurate image captions and can answer more detailed questions better than controls, while having access to neural data only. We showcase that CorText achieves zero-shot generalization beyond semantic categories seen during training. Furthermore, we present a counterfactual analysis that emulates in-silico cortical microstimulation. These advances mark a shift from passive decoding toward generative, flexible interfaces between brain activity and language.",Neuroscience
"Large language models (LLMs) have revolutionized human-machine interaction, and have been extended by embedding diverse modalities such as images into a shared language space. Yet, neural decoding has remained constrained by static, non-interactive methods. We introduce CorText, a framework that integrates neural activity directly into the latent space of an LLM, enabling open-ended, natural language interaction with brain data. Trained on fMRI data recorded during viewing of natural scenes, CorText generates accurate image captions and can answer more detailed questions better than controls, while having access to neural data only. We showcase that CorText achieves zero-shot generalization beyond semantic categories seen during training. Furthermore, we present a counterfactual analysis that emulates in-silico cortical microstimulation. These advances mark a shift from passive decoding toward generative, flexible interfaces between brain activity and language. [SEP] [HINT] decoding -> Neuroscience (Syns: decrypt, decipherment, decryption) | language -> Neuroscience (Syns: linguistic process, linguistic communication, spoken communication) | cortical -> Neuroscience (Syns: )",Neuroscience
"Viral infections trigger complex immune responses with heterogeneous outcomes shaped by nonlinear feedbacks. An ordinary differential equation model is developed to investigate immune response dynamics during viral infection, incorporating six modules: viral load, innate immunity, cellular immunity, humoral immunity, immune suppression, and IL-6 levels. Bifurcation analysis reveals that under continuous viral exposure, when viral clearance rate and intrinsic viral death rate satisfy specific conditions, the system exhibits up to five stable equilibria. This indicates that different health and disease states may coexist depending on initial conditions, while severe inflammation mainly arises from strong activation of cellular immunity, highlighting the complexity of immune responses. Simulations of finite-time viral exposure demonstrate multi-timescale recovery characteristics: viral load and IL-6 levels decline rapidly, whereas humoral immune activation and immunosuppression show delayed and sustained patterns. Furthermore, analysis of infectious period and disease duration also indicates that during transition from early acute response to chronic disease, viral replication rate plays a critical role, while immune response intensity is sensitive to both viral clearance and immune self-activation. Subsystem analysis identifies the three-component subsystem of viral load, innate immunity, and cellular immunity as core drivers of bistability and oscillations, while humoral immunity, immune suppression, and IL-6 primarily modulate response amplitude and timing. This work establishes a theoretical framework for analyzing immune response and chronic risks through feedback dynamical modelling, providing insights for intervention strategies.",Bioinformatics
"Viral infections trigger complex immune responses with heterogeneous outcomes shaped by nonlinear feedbacks. An ordinary differential equation model is developed to investigate immune response dynamics during viral infection, incorporating six modules: viral load, innate immunity, cellular immunity, humoral immunity, immune suppression, and IL-6 levels. Bifurcation analysis reveals that under continuous viral exposure, when viral clearance rate and intrinsic viral death rate satisfy specific conditions, the system exhibits up to five stable equilibria. This indicates that different health and disease states may coexist depending on initial conditions, while severe inflammation mainly arises from strong activation of cellular immunity, highlighting the complexity of immune responses. Simulations of finite-time viral exposure demonstrate multi-timescale recovery characteristics: viral load and IL-6 levels decline rapidly, whereas humoral immune activation and immunosuppression show delayed and sustained patterns. Furthermore, analysis of infectious period and disease duration also indicates that during transition from early acute response to chronic disease, viral replication rate plays a critical role, while immune response intensity is sensitive to both viral clearance and immune self-activation. Subsystem analysis identifies the three-component subsystem of viral load, innate immunity, and cellular immunity as core drivers of bistability and oscillations, while humoral immunity, immune suppression, and IL-6 primarily modulate response amplitude and timing. This work establishes a theoretical framework for analyzing immune response and chronic risks through feedback dynamical modelling, providing insights for intervention strategies. [SEP] [HINT] transition -> Materials Science (Syns: passage, modulation, changeover) | complex -> Bioinformatics (Syns: building complex, coordination compound, composite) | work -> Bioinformatics (Syns: work out, process, bring)",Bioinformatics
"Sorting cells based on their mechanical properties is essential for applications in disease diagnostics, cell therapy, and biomedical research. Deterministic Lateral Displacement (DLD) devices provide a label-free method for achieving such sorting, but their performance is highly sensitive to cell size and deformability. Designing effective DLD geometries often demands extensive trial-and-error experimentation, as even small variations in cellular mechanical traits can cause significant changes in migration behavior. To address this challenge, we propose a simulation-driven machine learning (ML) framework that predicts suitable DLD design candidates for a given cell type. Our approach integrates high-fidelity particle-based simulations to model cell deformation and migration through microfluidic pillar arrays with supervised ML models trained to estimate optimal geometries. By mapping mechanical parameters such as bending rigidity and shear modulus to deformation index and migration angle, the framework enables rapid, data-informed design of DLD systems. We also demonstrate a deployable web interface to make this tool accessible for real-world device prototyping.",Bioinformatics
"Sorting cells based on their mechanical properties is essential for applications in disease diagnostics, cell therapy, and biomedical research. Deterministic Lateral Displacement (DLD) devices provide a label-free method for achieving such sorting, but their performance is highly sensitive to cell size and deformability. Designing effective DLD geometries often demands extensive trial-and-error experimentation, as even small variations in cellular mechanical traits can cause significant changes in migration behavior. To address this challenge, we propose a simulation-driven machine learning (ML) framework that predicts suitable DLD design candidates for a given cell type. Our approach integrates high-fidelity particle-based simulations to model cell deformation and migration through microfluidic pillar arrays with supervised ML models trained to estimate optimal geometries. By mapping mechanical parameters such as bending rigidity and shear modulus to deformation index and migration angle, the framework enables rapid, data-informed design of DLD systems. We also demonstrate a deployable web interface to make this tool accessible for real-world device prototyping. [SEP] [HINT] based -> Bioinformatics (Syns: ground, free-base, base) | learning -> Bioinformatics (Syns: take, teach, acquire) | performance -> Bioinformatics (Syns: functioning, operation, carrying out)",Bioinformatics
"Motivated by the notion that a preponderance of Coulomb interactions might lead to hydrodynamics, we carry out an ab initio calculation of the charge carrier transport properties of the electron-hole plasma of doped graphene. We include both the phonon and Coulomb interactions within a momentum and band resolved Boltzmann transport formalism. We find that, under suitable conditions, the strong Coulomb drag effect induces effects like negative conductivity and joint electron-hole hydrodynamics (bifluidity) in the plasma. We also identify the exclusive electron or hole hydrodynamics. We find that there is a strong violation of the Wiedemann-Franz law in the low doped regimes. Our work elucidates the roles of the microscopic scattering mechanisms that drive these hydrodynamic phenomena.",Materials Science
"Motivated by the notion that a preponderance of Coulomb interactions might lead to hydrodynamics, we carry out an ab initio calculation of the charge carrier transport properties of the electron-hole plasma of doped graphene. We include both the phonon and Coulomb interactions within a momentum and band resolved Boltzmann transport formalism. We find that, under suitable conditions, the strong Coulomb drag effect induces effects like negative conductivity and joint electron-hole hydrodynamics (bifluidity) in the plasma. We also identify the exclusive electron or hole hydrodynamics. We find that there is a strong violation of the Wiedemann-Franz law in the low doped regimes. Our work elucidates the roles of the microscopic scattering mechanisms that drive these hydrodynamic phenomena. [SEP] [HINT] phonon -> Materials Science (Syns: ) | low -> Materials Science (Syns: low-spirited, scurvy, depressed) | transport -> Materials Science (Syns: transferral, enthral, shipping)",Materials Science
"Metamaterials with tunable optical properties provide a versatile platform for controlling electromagnetic interactions at the nanoscale. This study explores the anisotropic thermal behavior of metamaterials composed of planar plates perforated with periodic arrays of cylinders possessing elliptical cross sections. In contrast to conventional circular perforations, elliptical geometries inherently break rotational symmetry, introducing anisotropy in the effective electromagnetic and thermal response of the structure. Using a fluctuation electrodynamics framework combined with full-wave numerical simulations, we quantify the near-field radiative heat transfer between such elliptically perforated plates as a function of ellipse orientation, aspect ratio, and separation distance. The results reveal that elliptical perforations enable enhanced spectral and directional control of evanescent mode coupling and surface polariton excitation, leading to significant modulation of the near-field heat flux. These findings highlight the potential of geometrically engineered anisotropy for advanced thermal management and energy conversion applications, and offer new design strategies for the development of thermally functional metamaterials operating in the near-field regime.",Materials Science
"Metamaterials with tunable optical properties provide a versatile platform for controlling electromagnetic interactions at the nanoscale. This study explores the anisotropic thermal behavior of metamaterials composed of planar plates perforated with periodic arrays of cylinders possessing elliptical cross sections. In contrast to conventional circular perforations, elliptical geometries inherently break rotational symmetry, introducing anisotropy in the effective electromagnetic and thermal response of the structure. Using a fluctuation electrodynamics framework combined with full-wave numerical simulations, we quantify the near-field radiative heat transfer between such elliptically perforated plates as a function of ellipse orientation, aspect ratio, and separation distance. The results reveal that elliptical perforations enable enhanced spectral and directional control of evanescent mode coupling and surface polariton excitation, leading to significant modulation of the near-field heat flux. These findings highlight the potential of geometrically engineered anisotropy for advanced thermal management and energy conversion applications, and offer new design strategies for the development of thermally functional metamaterials operating in the near-field regime. [SEP] [HINT] functional -> Neuroscience (Syns: working, usable, running) | results -> Bioinformatics (Syns: final result, consequence, resultant role) | framework -> Bioinformatics (Syns: theoretical account, model, fabric)",Materials Science
"Magneto-optical effects in non-magnetic noble metals can be greatly enhanced by leveraging the in-plane Lorentz force at engineered plasmonic resonances. We demonstrate a 2D array of gold nanodiscs designed to host a hybrid resonance of localized plasmon and surface lattice modes. The structure exhibits a Verdet constant of 1.98e6 deg/T.m, corresponding to a Faraday rotation of -0.15 deg at a 1 T magnetic field. This Verdet constant represents a 15-fold enhancement over unpatterned gold and is highly competitive with many plasmon-enhanced diamagnetic nanostructures. These findings offer new opportunities for harnessing strong magneto-plasmonic effects in optoelectronic devices by patterning common non-magnetic metals.",Materials Science
"Magneto-optical effects in non-magnetic noble metals can be greatly enhanced by leveraging the in-plane Lorentz force at engineered plasmonic resonances. We demonstrate a 2D array of gold nanodiscs designed to host a hybrid resonance of localized plasmon and surface lattice modes. The structure exhibits a Verdet constant of 1.98e6 deg/T.m, corresponding to a Faraday rotation of -0.15 deg at a 1 T magnetic field. This Verdet constant represents a 15-fold enhancement over unpatterned gold and is highly competitive with many plasmon-enhanced diamagnetic nanostructures. These findings offer new opportunities for harnessing strong magneto-plasmonic effects in optoelectronic devices by patterning common non-magnetic metals. [SEP] [HINT] structure -> Bioinformatics (Syns: social system, complex body part, social structure) | demonstrate -> Bioinformatics (Syns: evidence, march, prove) | lattice -> Materials Science (Syns: grille, fretwork, latticework)",Materials Science
"Understanding how glioblastoma (GBM) emerges from initially healthy glial tissue requires models that integrate bioelectrical, metabolic, and multicellular dynamics. This work introduces an ASAL-inspired agent-based framework that simulates bioelectric state transitions in glial cells as a function of mitochondrial efficiency (Meff), ion-channel conductances, gap-junction coupling, and ROS dynamics. Using a 64x64 multicellular grid over 60,000 simulation steps, we show that reducing Meff below a critical threshold (~0.6) drives sustained depolarization, ATP collapse, and elevated ROS, reproducing key electrophysiological signatures associated with GBM. We further apply evolutionary optimization (genetic algorithms and MAP-Elites) to explore resilience, parameter sensitivity, and the emergence of tumor-like attractors. Early evolutionary runs converge toward depolarized, ROS-dominated regimes characterized by weakened electrical coupling and altered ionic transport. These results highlight mitochondrial dysfunction and disrupted bioelectric signaling as sufficient drivers of malignant-like transitions and provide a computational basis for probing the bioelectrical origins of oncogenesis.",Neuroscience
"Understanding how glioblastoma (GBM) emerges from initially healthy glial tissue requires models that integrate bioelectrical, metabolic, and multicellular dynamics. This work introduces an ASAL-inspired agent-based framework that simulates bioelectric state transitions in glial cells as a function of mitochondrial efficiency (Meff), ion-channel conductances, gap-junction coupling, and ROS dynamics. Using a 64x64 multicellular grid over 60,000 simulation steps, we show that reducing Meff below a critical threshold (~0.6) drives sustained depolarization, ATP collapse, and elevated ROS, reproducing key electrophysiological signatures associated with GBM. We further apply evolutionary optimization (genetic algorithms and MAP-Elites) to explore resilience, parameter sensitivity, and the emergence of tumor-like attractors. Early evolutionary runs converge toward depolarized, ROS-dominated regimes characterized by weakened electrical coupling and altered ionic transport. These results highlight mitochondrial dysfunction and disrupted bioelectric signaling as sufficient drivers of malignant-like transitions and provide a computational basis for probing the bioelectrical origins of oncogenesis. [SEP] [HINT] tissue -> Bioinformatics (Syns: tissue paper, weave) | computational -> Neuroscience (Syns: ) | understanding -> Neuroscience (Syns: savvy, intellect, sympathy)",Neuroscience
"The presence of interictal epileptiform discharges (IEDs) in electroencephalogram (EEG) recordings is a critical biomarker of epilepsy. Even trained neurologists find detecting IEDs difficult, leading many practitioners to turn to machine learning for help. While existing machine learning algorithms can achieve strong accuracy on this task, most models are uninterpretable and cannot justify their conclusions. Absent the ability to understand model reasoning, doctors cannot leverage their expertise to identify incorrect model predictions and intervene accordingly. To improve the human-model interaction, we introduce ProtoEEG-kNN, an inherently interpretable model that follows a simple case-based reasoning process. ProtoEEG-kNN reasons by comparing an EEG to similar EEGs from the training set and visually demonstrates its reasoning both in terms of IED morphology (shape) and spatial distribution (location). We show that ProtoEEG-kNN can achieve state-of-the-art accuracy in IED detection while providing explanations that experts prefer over existing approaches.",Neuroscience
"The presence of interictal epileptiform discharges (IEDs) in electroencephalogram (EEG) recordings is a critical biomarker of epilepsy. Even trained neurologists find detecting IEDs difficult, leading many practitioners to turn to machine learning for help. While existing machine learning algorithms can achieve strong accuracy on this task, most models are uninterpretable and cannot justify their conclusions. Absent the ability to understand model reasoning, doctors cannot leverage their expertise to identify incorrect model predictions and intervene accordingly. To improve the human-model interaction, we introduce ProtoEEG-kNN, an inherently interpretable model that follows a simple case-based reasoning process. ProtoEEG-kNN reasons by comparing an EEG to similar EEGs from the training set and visually demonstrates its reasoning both in terms of IED morphology (shape) and spatial distribution (location). We show that ProtoEEG-kNN can achieve state-of-the-art accuracy in IED detection while providing explanations that experts prefer over existing approaches. [SEP] [HINT] learning -> Bioinformatics (Syns: take, teach, acquire) | existing -> Bioinformatics (Syns: subsist, existent, survive) | eeg -> Neuroscience (Syns: encephalogram, electroencephalogram)",Neuroscience
"Recordings of brain activity, such as functional MRI (fMRI), provide low-dimensional, indirect observations of neural dynamics evolving in high-dimensional, unobservable spaces. Embedding observed brain dynamics into a higher-dimensional representation may help reveal functional organization, but precisely how remains unclear. Hamiltonian mechanics suggests that, by introducing an additional dimension of conjugate momenta, the dynamical behaviour of a conservative system can be formulated in a more compact and mathematically elegant manner. Here we develop a physics-informed, data-driven framework that lifts whole-brain activity to the complex-valued field. Specifically, we augment observed signals (generalized coordinates) with latent ``dark signals'' that play the role of conjugate momenta in a whole-brain Hamiltonian system. We show that the Hilbert transform provides an augmentation approach with optimal fitting accuracy within this framework, yielding a Schrödinger-like equation governing complex-valued, augmented brain dynamics. Empirically, this complex-valued model consistently outperforms its real-valued counterpart, improving short-horizon prediction in the linear regime (correlation 0.12$\to$0.82) and achieving superior fits under nonlinear, nonequilibrium dynamics (0.47$\to$0.88). The framework strengthens structure-function coupling, recovers hierarchical intrinsic timescales, and yields biologically plausible directed effective connectivity that varies systematically with age and reconfigures from rest to task via global rescaling plus targeted rewiring. Together, these results establish a principled, testable paradigm for network neuroscience and offer transformative insight into the spatiotemporal organization and functional roles of large-scale brain dynamics.",Neuroscience
"Recordings of brain activity, such as functional MRI (fMRI), provide low-dimensional, indirect observations of neural dynamics evolving in high-dimensional, unobservable spaces. Embedding observed brain dynamics into a higher-dimensional representation may help reveal functional organization, but precisely how remains unclear. Hamiltonian mechanics suggests that, by introducing an additional dimension of conjugate momenta, the dynamical behaviour of a conservative system can be formulated in a more compact and mathematically elegant manner. Here we develop a physics-informed, data-driven framework that lifts whole-brain activity to the complex-valued field. Specifically, we augment observed signals (generalized coordinates) with latent ``dark signals'' that play the role of conjugate momenta in a whole-brain Hamiltonian system. We show that the Hilbert transform provides an augmentation approach with optimal fitting accuracy within this framework, yielding a Schrödinger-like equation governing complex-valued, augmented brain dynamics. Empirically, this complex-valued model consistently outperforms its real-valued counterpart, improving short-horizon prediction in the linear regime (correlation 0.12$\to$0.82) and achieving superior fits under nonlinear, nonequilibrium dynamics (0.47$\to$0.88). The framework strengthens structure-function coupling, recovers hierarchical intrinsic timescales, and yields biologically plausible directed effective connectivity that varies systematically with age and reconfigures from rest to task via global rescaling plus targeted rewiring. Together, these results establish a principled, testable paradigm for network neuroscience and offer transformative insight into the spatiotemporal organization and functional roles of large-scale brain dynamics. [SEP] [HINT] task -> Neuroscience (Syns: tax, project, chore) | connectivity -> Neuroscience (Syns: ) | functional -> Neuroscience (Syns: working, usable, running)",Neuroscience
"Loss of lung function in cystic fibrosis (CF) occurs progressively, punctuated by acute pulmonary exacerbations (PEx) in which abrupt declines in lung function are not fully recovered. A key component of CF management over the past half century has been the treatment of PEx to slow lung function decline. This has been credited with improvements in survival for people with CF (PwCF), but there is no consensus on the optimal approach to PEx management. BEAT-CF (Bayesian evidence-adaptive treatment of CF) was established to build an evidence-informed knowledge base for CF management. The BEAT-CF causal model is a directed acyclic graph (DAG) and Bayesian network (BN) for PEx that aims to inform the design and analysis of clinical trials comparing the effectiveness of alternative approaches to PEx management. The causal model describes relationships between background risk factors, treatments, and pathogen colonisation of the airways that affect the outcome of an individual PEx episode. The key factors, outcomes, and causal relationships were elicited from CF clinical experts and together represent current expert understanding of the pathophysiology of a PEx episode, guiding the design of data collection and studies and enabling causal inference. Here, we present the DAG that documents this understanding, along with the processes used in its development, providing transparency around our trial design and study processes, as well as a reusable framework for others.",Bioinformatics
"Loss of lung function in cystic fibrosis (CF) occurs progressively, punctuated by acute pulmonary exacerbations (PEx) in which abrupt declines in lung function are not fully recovered. A key component of CF management over the past half century has been the treatment of PEx to slow lung function decline. This has been credited with improvements in survival for people with CF (PwCF), but there is no consensus on the optimal approach to PEx management. BEAT-CF (Bayesian evidence-adaptive treatment of CF) was established to build an evidence-informed knowledge base for CF management. The BEAT-CF causal model is a directed acyclic graph (DAG) and Bayesian network (BN) for PEx that aims to inform the design and analysis of clinical trials comparing the effectiveness of alternative approaches to PEx management. The causal model describes relationships between background risk factors, treatments, and pathogen colonisation of the airways that affect the outcome of an individual PEx episode. The key factors, outcomes, and causal relationships were elicited from CF clinical experts and together represent current expert understanding of the pathophysiology of a PEx episode, guiding the design of data collection and studies and enabling causal inference. Here, we present the DAG that documents this understanding, along with the processes used in its development, providing transparency around our trial design and study processes, as well as a reusable framework for others. [SEP] [HINT] used -> Bioinformatics (Syns: utilize, ill-used, apply) | clinical -> Bioinformatics (Syns: ) | understanding -> Neuroscience (Syns: savvy, intellect, sympathy)",Bioinformatics
"In clinical proteomics, available input is often limited. In addition, phospho-proteomics is of particular interest since the dysregulation of these post-translational modifications (PTMs) has been implicated in various diseases such as cancer. We therefore assessed the feasibility of low input phospho-proteomics via phospho-bulk titration and low-input starting material. We found that there was identification of more phospho-peptides through phospho-bulk titration because of sample loss during preparation of low input starting material. Additionally, we explored various lysis buffers and boiling times for efficiency of decrosslinking formalin-fixed cells since cells and tissues are often fixed for preservation and sorting via FACS. We found that boiling in 0.05M Tris pH 7.6 with 5% SDS for 60 min yielded the highest number of phospho-peptides. Lastly, we applied Evotips Pure and phospho-bulk titration to treated Jurkat cells and identified 7 phospho-sites involved in T-cell stimulation.",Bioinformatics
"In clinical proteomics, available input is often limited. In addition, phospho-proteomics is of particular interest since the dysregulation of these post-translational modifications (PTMs) has been implicated in various diseases such as cancer. We therefore assessed the feasibility of low input phospho-proteomics via phospho-bulk titration and low-input starting material. We found that there was identification of more phospho-peptides through phospho-bulk titration because of sample loss during preparation of low input starting material. Additionally, we explored various lysis buffers and boiling times for efficiency of decrosslinking formalin-fixed cells since cells and tissues are often fixed for preservation and sorting via FACS. We found that boiling in 0.05M Tris pH 7.6 with 5% SDS for 60 min yielded the highest number of phospho-peptides. Lastly, we applied Evotips Pure and phospho-bulk titration to treated Jurkat cells and identified 7 phospho-sites involved in T-cell stimulation. [SEP] [HINT] low -> Materials Science (Syns: low-spirited, scurvy, depressed) | clinical -> Bioinformatics (Syns: )",Bioinformatics
"Spatial transcriptomics allows researchers to visualize and analyze gene expression within the precise location of tissues or cells. It provides spatially resolved gene expression data but often lacks cellular resolution, necessitating cell type deconvolution to infer cellular composition at each spatial location. In this paper we propose BASIN for cell type deconvolution, which models deconvolution as a nonnegative matrix factorization (NMF) problem incorporating graph Laplacian prior. Rather than find a deterministic optima like other recent methods, we propose a matrix variate Bayesian NMF method with nonnegativity and sparsity priors, in which the variables are maintained in their matrix form to derive a more efficient matrix normal posterior. BASIN employs a Gibbs sampler to approximate the posterior distribution of cell type proportions and other parameters, offering a distribution of possible solutions, enhancing robustness and providing inherent uncertainty quantification. The performance of BASIN is evaluated on different spatial transcriptomics datasets and outperforms other deconvolution methods in terms of accuracy and efficiency. The results also show the effect of the incorporated priors and reflect a truncated matrix normal distribution as we expect.",Bioinformatics
"Spatial transcriptomics allows researchers to visualize and analyze gene expression within the precise location of tissues or cells. It provides spatially resolved gene expression data but often lacks cellular resolution, necessitating cell type deconvolution to infer cellular composition at each spatial location. In this paper we propose BASIN for cell type deconvolution, which models deconvolution as a nonnegative matrix factorization (NMF) problem incorporating graph Laplacian prior. Rather than find a deterministic optima like other recent methods, we propose a matrix variate Bayesian NMF method with nonnegativity and sparsity priors, in which the variables are maintained in their matrix form to derive a more efficient matrix normal posterior. BASIN employs a Gibbs sampler to approximate the posterior distribution of cell type proportions and other parameters, offering a distribution of possible solutions, enhancing robustness and providing inherent uncertainty quantification. The performance of BASIN is evaluated on different spatial transcriptomics datasets and outperforms other deconvolution methods in terms of accuracy and efficiency. The results also show the effect of the incorporated priors and reflect a truncated matrix normal distribution as we expect. [SEP] [HINT] datasets -> Bioinformatics (Syns: ) | performance -> Bioinformatics (Syns: functioning, operation, carrying out) | results -> Bioinformatics (Syns: final result, consequence, resultant role)",Bioinformatics
"The binary metal borides provide a promising platform for searching unique materials with superconductivity and super-hardness under high pressure, owing to the distinctive bonding characters of boron. In this work, combined the first-principles calculations and crystal structure predictions, we predicted 4 exotic stoichiometries and 8 unique U-B compounds under high pressure. The predicted compounds have layered or caged structure units and 4 of them host high hardness under ambient pressure. By removal of the U atoms, we predicted three meta-stable boron clathrates at ambient pressure. Remarkably, the Vickers hardness of the predicted C2/m-B6 is estimated to be 49-53 GPa, and the C2/m-B12 is superconducting with the Tc value of 16.12 K. Our calculations enrich the phase diagram of binary metal borides and boron allotropes, providing insights for the future theoretical and experimental studies on unique materials.",Materials Science
"The binary metal borides provide a promising platform for searching unique materials with superconductivity and super-hardness under high pressure, owing to the distinctive bonding characters of boron. In this work, combined the first-principles calculations and crystal structure predictions, we predicted 4 exotic stoichiometries and 8 unique U-B compounds under high pressure. The predicted compounds have layered or caged structure units and 4 of them host high hardness under ambient pressure. By removal of the U atoms, we predicted three meta-stable boron clathrates at ambient pressure. Remarkably, the Vickers hardness of the predicted C2/m-B6 is estimated to be 49-53 GPa, and the C2/m-B12 is superconducting with the Tc value of 16.12 K. Our calculations enrich the phase diagram of binary metal borides and boron allotropes, providing insights for the future theoretical and experimental studies on unique materials. [SEP] [HINT] structure -> Bioinformatics (Syns: social system, complex body part, social structure) | metal -> Materials Science (Syns: metallic element, metallic, alloy) | crystal -> Materials Science (Syns: crystallization, quartz, lechatelierite)",Materials Science
"Orbital angular momentum offers a new channel for information transport in a vast set of materials. Its coherent generation and detection remain, however, largely unexplored. Here, we demonstrate that chiral surface acoustic waves (SAWs) generate sizable orbital currents in light-metal/ferromagnet bilayers through both the acoustic orbital Hall effect and acoustic orbital pumping. Using symmetry analysis of SAW-driven voltages, we disentangle vorticity-sensitive orbital currents arising from lattice rotation in the non-magnetic layer from angular-momentum pumping from the ferromagnet. Strong signals are observed only in nickel/chromium and nickel/titanium, while nickel/aluminum and all cobalt-based bilayers show negligible responses, revealing the critical roles of orbital Hall conductivity, phonon-orbital coupling, and interfacial orbital transparency. Comparison with spin-torque ferromagnetic resonance and second-harmonic measurements -- where electrically driven orbital angular momentum are weaker -- demonstrates that phonon excitation generates orbital currents more efficiently. These results establish chiral SAWs as an effective route for orbitronic functionality and open pathways toward phonon-controlled orbital magnetism.",Materials Science
"Orbital angular momentum offers a new channel for information transport in a vast set of materials. Its coherent generation and detection remain, however, largely unexplored. Here, we demonstrate that chiral surface acoustic waves (SAWs) generate sizable orbital currents in light-metal/ferromagnet bilayers through both the acoustic orbital Hall effect and acoustic orbital pumping. Using symmetry analysis of SAW-driven voltages, we disentangle vorticity-sensitive orbital currents arising from lattice rotation in the non-magnetic layer from angular-momentum pumping from the ferromagnet. Strong signals are observed only in nickel/chromium and nickel/titanium, while nickel/aluminum and all cobalt-based bilayers show negligible responses, revealing the critical roles of orbital Hall conductivity, phonon-orbital coupling, and interfacial orbital transparency. Comparison with spin-torque ferromagnetic resonance and second-harmonic measurements -- where electrically driven orbital angular momentum are weaker -- demonstrates that phonon excitation generates orbital currents more efficiently. These results establish chiral SAWs as an effective route for orbitronic functionality and open pathways toward phonon-controlled orbital magnetism. [SEP] [HINT] phonon -> Materials Science (Syns: ) | transport -> Materials Science (Syns: transferral, enthral, shipping) | information -> Bioinformatics (Syns: entropy, data, info)",Materials Science
"Integrating magnetic order to moiré superlattices is of significant scientific and technological interest. Based on first-principles calculations, we study the interplay of magnetic proximity and moiré proximity in WSe2/WSe2/CrI3 trilayers with different stackings and twist angles. Large valley splitting is observed due to redistribution of the exciton charge density across layers via a super-exchange-like mechanism, and its electric-field dependence bears similarity to electrically tunable and valley-selective Feshbach resonances. The valley splitting can be magnified in moiré superlattices owing to the superposition of Umklapp excitons folded from moiré minibands, yielding spatially modulated and enhanced magnetic proximity. The moiré proximity effect is demonstrated via an imprinted moiré potential on CrI3 layer and its feedback to the direct moiré potential on WSe2 bilayers is observed. The cooperation between the direct and imprinted moiré potentials is shown to yield novel topological and correlated states.",Materials Science
"Integrating magnetic order to moiré superlattices is of significant scientific and technological interest. Based on first-principles calculations, we study the interplay of magnetic proximity and moiré proximity in WSe2/WSe2/CrI3 trilayers with different stackings and twist angles. Large valley splitting is observed due to redistribution of the exciton charge density across layers via a super-exchange-like mechanism, and its electric-field dependence bears similarity to electrically tunable and valley-selective Feshbach resonances. The valley splitting can be magnified in moiré superlattices owing to the superposition of Umklapp excitons folded from moiré minibands, yielding spatially modulated and enhanced magnetic proximity. The moiré proximity effect is demonstrated via an imprinted moiré potential on CrI3 layer and its feedback to the direct moiré potential on WSe2 bilayers is observed. The cooperation between the direct and imprinted moiré potentials is shown to yield novel topological and correlated states. [SEP] [HINT] based -> Bioinformatics (Syns: ground, free-base, base) | charge -> Materials Science (Syns: tear, bearing, burster) | order -> Materials Science (Syns: enjoin, dictate, social club)",Materials Science
"Materials utilized by novel energy systems are often studied using weakly correlated mean-field theories. However, if these systems incorporate heavy elements or strongly correlated topological materials, relativistic effects must be included. Therefore, we present an unrestricted coupled-cluster with single and double excitation formalism (CCSD) within a molecular mean-field exact-two component framework (X2Cmmf) using a restricted Dirac-Hartree-Fock (DHF) reference state. Our mean-field transformation utilizes the one-electron, Dirac-Coulomb, Dirac-Coulomb-Gaunt and Dirac-Coulomb-Breit Hamiltonian. The code was bench-marked against DIRAC which also uses DHF-X2Cmmf accounting for the Dirac-Coulomb and Dirac-Coulomb-Gaunt Hamiltonian. The dipole moments of Li-H, and Cl-F were calculated using an approximate molecular to atomic basis transformation and compared to experiment. The CCSD energy showed agreement with DIRAC to around ten to the power of minus four Hartree and exhibited a small variation of the dipole moment with the introduction of higher order electron-electron interactions. This paper allows for study of relativistic processes within this mean-field approach and lays the foundation for future theoretical development of relativistic Coupled-Cluster Theory using a DHF reference state within this framework.",Materials Science
"Materials utilized by novel energy systems are often studied using weakly correlated mean-field theories. However, if these systems incorporate heavy elements or strongly correlated topological materials, relativistic effects must be included. Therefore, we present an unrestricted coupled-cluster with single and double excitation formalism (CCSD) within a molecular mean-field exact-two component framework (X2Cmmf) using a restricted Dirac-Hartree-Fock (DHF) reference state. Our mean-field transformation utilizes the one-electron, Dirac-Coulomb, Dirac-Coulomb-Gaunt and Dirac-Coulomb-Breit Hamiltonian. The code was bench-marked against DIRAC which also uses DHF-X2Cmmf accounting for the Dirac-Coulomb and Dirac-Coulomb-Gaunt Hamiltonian. The dipole moments of Li-H, and Cl-F were calculated using an approximate molecular to atomic basis transformation and compared to experiment. The CCSD energy showed agreement with DIRAC to around ten to the power of minus four Hartree and exhibited a small variation of the dipole moment with the introduction of higher order electron-electron interactions. This paper allows for study of relativistic processes within this mean-field approach and lays the foundation for future theoretical development of relativistic Coupled-Cluster Theory using a DHF reference state within this framework. [SEP] [HINT] molecular -> Bioinformatics (Syns: ) | order -> Materials Science (Syns: enjoin, dictate, social club) | systems -> Bioinformatics (Syns: organization, organisation, system)",Materials Science
"Understanding the growth and form of shapes is one of the most fundamental problems in biology. While many prior works have analyzed the beak shapes of Darwin's finches, other cranial features are relatively less explored. In this work, we develop geometric and statistical methods for analyzing the skull morphology of Darwin's finches and their relatives, focusing on the relationship between their skull dimensions, orbit curvature, and neurocranial geometries. Specifically, by utilizing tools in computational geometry, differential geometry, and numerical optimization, we develop efficient algorithms for quantifying various key geometric features of the skull. We then perform a statistical analysis and discover a strong correlation between skull size and orbit curvature. Based on our findings, we further establish a predictive model that can estimate the orbit curvature using easily obtainable linear skull measurements. Our results show that the predictive model is highly effective and is capable of explaining 85.48\% of the variance (R-squared) in curvature with an average prediction error of only 6.35\%. Altogether, our work provides a quantitative foundation for understanding the functional and evolutionary pressures that shape avian skulls, thereby offering a validated framework for future studies in comparative anatomy and evolutionary biology.",Bioinformatics
"Understanding the growth and form of shapes is one of the most fundamental problems in biology. While many prior works have analyzed the beak shapes of Darwin's finches, other cranial features are relatively less explored. In this work, we develop geometric and statistical methods for analyzing the skull morphology of Darwin's finches and their relatives, focusing on the relationship between their skull dimensions, orbit curvature, and neurocranial geometries. Specifically, by utilizing tools in computational geometry, differential geometry, and numerical optimization, we develop efficient algorithms for quantifying various key geometric features of the skull. We then perform a statistical analysis and discover a strong correlation between skull size and orbit curvature. Based on our findings, we further establish a predictive model that can estimate the orbit curvature using easily obtainable linear skull measurements. Our results show that the predictive model is highly effective and is capable of explaining 85.48\% of the variance (R-squared) in curvature with an average prediction error of only 6.35\%. Altogether, our work provides a quantitative foundation for understanding the functional and evolutionary pressures that shape avian skulls, thereby offering a validated framework for future studies in comparative anatomy and evolutionary biology. [SEP] [HINT] based -> Bioinformatics (Syns: ground, free-base, base) | computational -> Neuroscience (Syns: ) | features -> Bioinformatics (Syns: characteristic, lineament, feature of speech)",Bioinformatics
"In experiments probing human vision at the few-photon level, precise alignment of the eye is necessary such that stimuli reach the highest-density rod region of the retina. However, in literature there seems to be no consensus on the optimal eye alignment for such experiments. Typically, experiments are performed by presenting stimuli nasally or temporally, but the angle under which the few-photon pulses are presented varies between 7 deg and 23 deg. Here we combine a $3$-dimensional eye model with retinal rod density measurements from literature in a ray tracing simulation to study the optimal eye alignment conditions and necessary alignment precision. We find that stimuli, directed at the eye's nodal point, may be best presented under an inferior angle of 13.1 deg with respect to the visual axis. Defining a target area on the retina with a radius of 0.5 mm around the optimum location, we find the horizontal and vertical angular precision should be better than 0.85 deg given a horizontal and vertical translational precision of 1 mm and a depth translational precision of 5 mm.",Bioinformatics
"In experiments probing human vision at the few-photon level, precise alignment of the eye is necessary such that stimuli reach the highest-density rod region of the retina. However, in literature there seems to be no consensus on the optimal eye alignment for such experiments. Typically, experiments are performed by presenting stimuli nasally or temporally, but the angle under which the few-photon pulses are presented varies between 7 deg and 23 deg. Here we combine a $3$-dimensional eye model with retinal rod density measurements from literature in a ray tracing simulation to study the optimal eye alignment conditions and necessary alignment precision. We find that stimuli, directed at the eye's nodal point, may be best presented under an inferior angle of 13.1 deg with respect to the visual axis. Defining a target area on the retina with a radius of 0.5 mm around the optimum location, we find the horizontal and vertical angular precision should be better than 0.85 deg given a horizontal and vertical translational precision of 1 mm and a depth translational precision of 5 mm. [SEP] [HINT] human -> Neuroscience (Syns: human being, man, homo) | visual -> Neuroscience (Syns: optical, ocular, optic) | density -> Materials Science (Syns: tightness, concentration, compactness)",Bioinformatics
"Identifying the principles that determine neural population activity is paramount in the field of neuroscience. We propose the Principle of Isomorphism (PIso): population activity preserves the essential mathematical structures of the tasks it supports. Using grid cells as a model system, we show that the neural metric task is characterized by a flat Riemannian manifold, while path integration is characterized by an Abelian Lie group. We prove that each task independently constrains population activity to a toroidal topology. We further show that these perspectives are unified naturally in Euclidean space, where commutativity and flatness are intrinsically compatible and can be extended to related systems including head-direction cells and 3D grid cells. To examine how toroidal topology maps onto single-cell firing patterns, we develop a minimal network architecture that explicitly constrains population activity to toroidal manifolds. Our model robustly generates hexagonal firing fields and reveals systematic relationships between network parameters and grid spacings. Crucially, we demonstrate that conformal isometry, a commonly proposed hypothesis, alone is insufficient for hexagonal field formation. Our findings establish a direct link between computational tasks and the hexagonal-toroidal organization of grid cells, thereby providing a general framework for understanding population activity in neural systems and designing task-informed architectures in machine learning.",Neuroscience
"Identifying the principles that determine neural population activity is paramount in the field of neuroscience. We propose the Principle of Isomorphism (PIso): population activity preserves the essential mathematical structures of the tasks it supports. Using grid cells as a model system, we show that the neural metric task is characterized by a flat Riemannian manifold, while path integration is characterized by an Abelian Lie group. We prove that each task independently constrains population activity to a toroidal topology. We further show that these perspectives are unified naturally in Euclidean space, where commutativity and flatness are intrinsically compatible and can be extended to related systems including head-direction cells and 3D grid cells. To examine how toroidal topology maps onto single-cell firing patterns, we develop a minimal network architecture that explicitly constrains population activity to toroidal manifolds. Our model robustly generates hexagonal firing fields and reveals systematic relationships between network parameters and grid spacings. Crucially, we demonstrate that conformal isometry, a commonly proposed hypothesis, alone is insufficient for hexagonal field formation. Our findings establish a direct link between computational tasks and the hexagonal-toroidal organization of grid cells, thereby providing a general framework for understanding population activity in neural systems and designing task-informed architectures in machine learning. [SEP] [HINT] field -> Materials Science (Syns: field of honor, line of business, orbit) | task -> Neuroscience (Syns: tax, project, chore) | tasks -> Neuroscience (Syns: tax, task, project)",Neuroscience
"The neural coding is yet to be discovered. The neuronal operational modes that arise with fixed inputs but with varying degrees of stimulation help to elucidate their coding properties. In neurons receiving {\it in vivo} stimulation, we show that two operation modes can be described with simplified models: the coincidence detection mode and the integration mode. Our derivations include a simplified polynomial model with non-linear coefficients ($β_i$) that capture the subthreshold dynamics of these modes of operation. The resulting model can explain these transitions with the sign and size of the smallest nonlinear coefficient of the polynomial alone. Defining neuronal operational modes provides insight into the processing and transmission of information through electrical currents. Requisite operational modes for proper neuronal functioning may explain disorders involving dysfunction of electrophysiological behavior, such as channelopathies.",Neuroscience
"The neural coding is yet to be discovered. The neuronal operational modes that arise with fixed inputs but with varying degrees of stimulation help to elucidate their coding properties. In neurons receiving {\it in vivo} stimulation, we show that two operation modes can be described with simplified models: the coincidence detection mode and the integration mode. Our derivations include a simplified polynomial model with non-linear coefficients ($β_i$) that capture the subthreshold dynamics of these modes of operation. The resulting model can explain these transitions with the sign and size of the smallest nonlinear coefficient of the polynomial alone. Defining neuronal operational modes provides insight into the processing and transmission of information through electrical currents. Requisite operational modes for proper neuronal functioning may explain disorders involving dysfunction of electrophysiological behavior, such as channelopathies. [SEP] [HINT] information -> Bioinformatics (Syns: entropy, data, info) | processing -> Neuroscience (Syns: work, process, march) | dynamics -> Bioinformatics (Syns: kinetics, dynamic, moral force)",Neuroscience
"Characterizing interactions between brain areas is a fundamental goal of systems neuroscience. While such analyses are possible when areas are recorded simultaneously, it is rare to observe all combinations of areas of interest within a single animal or recording session. How can we leverage multi-animal datasets to better understand multi-area interactions? Building on recent progress in large-scale, multi-animal models, we introduce NeuroPaint, a masked autoencoding approach for inferring the dynamics of unrecorded brain areas. By training across animals with overlapping subsets of recorded areas, NeuroPaint learns to reconstruct activity in missing areas based on shared structure across individuals. We train and evaluate our approach on synthetic data and two multi-animal, multi-area Neuropixels datasets. Our results demonstrate that models trained across animals with partial observations can successfully in-paint the dynamics of unrecorded areas, enabling multi-area analyses that transcend the limitations of any single experiment.",Neuroscience
"Characterizing interactions between brain areas is a fundamental goal of systems neuroscience. While such analyses are possible when areas are recorded simultaneously, it is rare to observe all combinations of areas of interest within a single animal or recording session. How can we leverage multi-animal datasets to better understand multi-area interactions? Building on recent progress in large-scale, multi-animal models, we introduce NeuroPaint, a masked autoencoding approach for inferring the dynamics of unrecorded brain areas. By training across animals with overlapping subsets of recorded areas, NeuroPaint learns to reconstruct activity in missing areas based on shared structure across individuals. We train and evaluate our approach on synthetic data and two multi-animal, multi-area Neuropixels datasets. Our results demonstrate that models trained across animals with partial observations can successfully in-paint the dynamics of unrecorded areas, enabling multi-area analyses that transcend the limitations of any single experiment. [SEP] [HINT] based -> Bioinformatics (Syns: ground, free-base, base) | structure -> Bioinformatics (Syns: social system, complex body part, social structure) | datasets -> Bioinformatics (Syns: )",Neuroscience
"We theoretically study the effect of spin-orbit coupling (SOC) on anomalous quantum oscillations in InAs/GaSb quantum wells. By comparing different cases, we show that SOC induces two opposing effects on anomalous quantum oscillations: it suppresses the oscillations in the clean case, while enhancing them in the disordered case. Using an effective model, we analyze in detail the origins of anomalous oscillations in both clean and disordered cases. Based on these origins, we explain why SOC suppresses or enhances the anomalous oscillations in different cases, thereby extending the understanding of the conventional theory. Moreover, in the disordered case, SOC can induce a phase shift of the anomalous oscillations. We further identify a parameter window where the anomalous oscillations are significantly enhanced in the presence of both disorder and SOC. These results provide a theoretical basis for understanding the role of SOC in anomalous quantum oscillations.",Materials Science
"We theoretically study the effect of spin-orbit coupling (SOC) on anomalous quantum oscillations in InAs/GaSb quantum wells. By comparing different cases, we show that SOC induces two opposing effects on anomalous quantum oscillations: it suppresses the oscillations in the clean case, while enhancing them in the disordered case. Using an effective model, we analyze in detail the origins of anomalous oscillations in both clean and disordered cases. Based on these origins, we explain why SOC suppresses or enhances the anomalous oscillations in different cases, thereby extending the understanding of the conventional theory. Moreover, in the disordered case, SOC can induce a phase shift of the anomalous oscillations. We further identify a parameter window where the anomalous oscillations are significantly enhanced in the presence of both disorder and SOC. These results provide a theoretical basis for understanding the role of SOC in anomalous quantum oscillations. [SEP] [HINT] based -> Bioinformatics (Syns: ground, free-base, base) | understanding -> Neuroscience (Syns: savvy, intellect, sympathy) | results -> Bioinformatics (Syns: final result, consequence, resultant role)",Materials Science
"We present a computational framework that integrates functional-structural plant modeling (FSPM) with an evolutionary algorithm to optimize three-dimensional maize canopy architecture for enhanced light interception under high-density planting. The optimization revealed an emergent ideotype characterized by two distinct strategies: a vertically stratified leaf profile (steep, narrow upper leaves for penetration; broad, horizontal lower leaves for capture) and a radially tiled azimuthal arrangement that breaks the conventional distichous symmetry of maize to minimize self and mutual shading. Reverse ray-tracing simulations show that this architecture intercepts significantly more photosynthetically active radiation (PAR) than virtual canopies parameterized from high-performing field hybrids, with gains that generalize across multiple U.S. latitudes and planting densities. The optimized trait combinations align with characteristics of modern density-tolerant cultivars, supporting biological plausibility. Because recent gene editing advances enable more independent control of architectural traits, the designs identified here are increasingly feasible. By uncovering effective, non-intuitive trait configurations, our approach provides a scalable, predictive tool to guide breeding targets, improve light-use efficiency, and ultimately support sustainable yield gains.",Bioinformatics
"We present a computational framework that integrates functional-structural plant modeling (FSPM) with an evolutionary algorithm to optimize three-dimensional maize canopy architecture for enhanced light interception under high-density planting. The optimization revealed an emergent ideotype characterized by two distinct strategies: a vertically stratified leaf profile (steep, narrow upper leaves for penetration; broad, horizontal lower leaves for capture) and a radially tiled azimuthal arrangement that breaks the conventional distichous symmetry of maize to minimize self and mutual shading. Reverse ray-tracing simulations show that this architecture intercepts significantly more photosynthetically active radiation (PAR) than virtual canopies parameterized from high-performing field hybrids, with gains that generalize across multiple U.S. latitudes and planting densities. The optimized trait combinations align with characteristics of modern density-tolerant cultivars, supporting biological plausibility. Because recent gene editing advances enable more independent control of architectural traits, the designs identified here are increasingly feasible. By uncovering effective, non-intuitive trait configurations, our approach provides a scalable, predictive tool to guide breeding targets, improve light-use efficiency, and ultimately support sustainable yield gains. [SEP] [HINT] field -> Materials Science (Syns: field of honor, line of business, orbit) | computational -> Neuroscience (Syns: ) | framework -> Bioinformatics (Syns: theoretical account, model, fabric)",Bioinformatics
"Histopathologists establish cancer grade by assessing histological structures, such as glands in prostate cancer. Yet, digital pathology pipelines often rely on grid-based tiling that ignores tissue architecture. This introduces irrelevant information and limits interpretability. We introduce histology-informed tiling (HIT), which uses semantic segmentation to extract glands from whole slide images (WSIs) as biologically meaningful input patches for multiple-instance learning (MIL) and phenotyping. Trained on 137 samples from the ProMPT cohort, HIT achieved a gland-level Dice score of 0.83 +/- 0.17. By extracting 380,000 glands from 760 WSIs across ICGC-C and TCGA-PRAD cohorts, HIT improved MIL models AUCs by 10% for detecting copy number variation (CNVs) in genes related to epithelial-mesenchymal transitions (EMT) and MYC, and revealed 15 gland clusters, several of which were associated with cancer relapse, oncogenic mutations, and high Gleason. Therefore, HIT improved the accuracy and interpretability of MIL predictions, while streamlining computations by focussing on biologically meaningful structures during feature extraction.",Bioinformatics
"Histopathologists establish cancer grade by assessing histological structures, such as glands in prostate cancer. Yet, digital pathology pipelines often rely on grid-based tiling that ignores tissue architecture. This introduces irrelevant information and limits interpretability. We introduce histology-informed tiling (HIT), which uses semantic segmentation to extract glands from whole slide images (WSIs) as biologically meaningful input patches for multiple-instance learning (MIL) and phenotyping. Trained on 137 samples from the ProMPT cohort, HIT achieved a gland-level Dice score of 0.83 +/- 0.17. By extracting 380,000 glands from 760 WSIs across ICGC-C and TCGA-PRAD cohorts, HIT improved MIL models AUCs by 10% for detecting copy number variation (CNVs) in genes related to epithelial-mesenchymal transitions (EMT) and MYC, and revealed 15 gland clusters, several of which were associated with cancer relapse, oncogenic mutations, and high Gleason. Therefore, HIT improved the accuracy and interpretability of MIL predictions, while streamlining computations by focussing on biologically meaningful structures during feature extraction. [SEP] [HINT] tissue -> Bioinformatics (Syns: tissue paper, weave) | learning -> Bioinformatics (Syns: take, teach, acquire) | information -> Bioinformatics (Syns: entropy, data, info)",Bioinformatics
"Understanding the relationship between nerve anatomy and the functional outcomes of electrical stimulation is critical for optimizing neural interface design. In this study, we conducted acute experiments on four pigs in which epineural cuff electrodes with multiple contacts were placed around upper limb nerves. A subset of electrical stimulation configurations -- previously identified via computational study -- was applied, and the resulting evoked electromyographic (EMG) responses were recorded from target muscles. Muscle recruitment curves were extracted and analysed offline to quantify activation patterns. Following the electrophysiological experiments, the stimulated nerves were harvested and processed for histological analysis to visualize fascicular organization and distribution. This work presents preliminary results from the combined analysis of muscle activation profiles and fascicle anatomy in one animal. Our findings aim to inform the design of stimulation strategies by linking electrode configuration to selective muscle recruitment, ultimately contributing to more effective neuromodulation and neuroprosthetic applications.",Bioinformatics
"Understanding the relationship between nerve anatomy and the functional outcomes of electrical stimulation is critical for optimizing neural interface design. In this study, we conducted acute experiments on four pigs in which epineural cuff electrodes with multiple contacts were placed around upper limb nerves. A subset of electrical stimulation configurations -- previously identified via computational study -- was applied, and the resulting evoked electromyographic (EMG) responses were recorded from target muscles. Muscle recruitment curves were extracted and analysed offline to quantify activation patterns. Following the electrophysiological experiments, the stimulated nerves were harvested and processed for histological analysis to visualize fascicular organization and distribution. This work presents preliminary results from the combined analysis of muscle activation profiles and fascicle anatomy in one animal. Our findings aim to inform the design of stimulation strategies by linking electrode configuration to selective muscle recruitment, ultimately contributing to more effective neuromodulation and neuroprosthetic applications. [SEP] [HINT] computational -> Neuroscience (Syns: ) | understanding -> Neuroscience (Syns: savvy, intellect, sympathy) | functional -> Neuroscience (Syns: working, usable, running)",Bioinformatics
"Objective: Quantitative real-time PCR is widely used for gene expression analysis, yet inconsistencies in data storage and reporting limit reproducibility. While MIQE guidelines define the minimal information required for publication, they do not specify structured digital storage formats compatible with long-term reanalysis. This work presents qLOOK (qPCR-LOg-boOK), a tool for standardized digital storage and reproducible analysis of qPCR experiments. Results: qLOOK is a modular R-based system that extracts data from Thermo Fisher/ABI .EDS files, formats it into a structured table (qLOOK_Data.xlsx), performs normalization and statistical analysis, and generates a log file (qLOOK_Summary.txt) recording reference genes, calibrators, and analytical parameters. All required R libraries are automatically installed and loaded, allowing researchers without coding experience to use the scripts. By preserving the qLOOK_Data table and the qLOOK_Summary log, users can reproduce or extend analyses without reprocessing raw files. While currently limited to .EDS files, the modular design allows adaptation to additional qPCR formats in the future. Besides providing an easy and transparent approach to analyze qPCR experiments, qLOOK also provides a minimal, standardized, and transparent solution for digital documentation, enhancing reproducibility, supporting long-term data stewardship, and facilitating integration into electronic laboratory notebooks or publication supplementary material.",Bioinformatics
"Objective: Quantitative real-time PCR is widely used for gene expression analysis, yet inconsistencies in data storage and reporting limit reproducibility. While MIQE guidelines define the minimal information required for publication, they do not specify structured digital storage formats compatible with long-term reanalysis. This work presents qLOOK (qPCR-LOg-boOK), a tool for standardized digital storage and reproducible analysis of qPCR experiments. Results: qLOOK is a modular R-based system that extracts data from Thermo Fisher/ABI .EDS files, formats it into a structured table (qLOOK_Data.xlsx), performs normalization and statistical analysis, and generates a log file (qLOOK_Summary.txt) recording reference genes, calibrators, and analytical parameters. All required R libraries are automatically installed and loaded, allowing researchers without coding experience to use the scripts. By preserving the qLOOK_Data table and the qLOOK_Summary log, users can reproduce or extend analyses without reprocessing raw files. While currently limited to .EDS files, the modular design allows adaptation to additional qPCR formats in the future. Besides providing an easy and transparent approach to analyze qPCR experiments, qLOOK also provides a minimal, standardized, and transparent solution for digital documentation, enhancing reproducibility, supporting long-term data stewardship, and facilitating integration into electronic laboratory notebooks or publication supplementary material. [SEP] [HINT] used -> Bioinformatics (Syns: utilize, ill-used, apply) | electronic -> Materials Science (Syns: ) | information -> Bioinformatics (Syns: entropy, data, info)",Bioinformatics
"Two-dimensional (2D) van der Waals (vdW) ferromagnet Fe$_5$GeTe$_2$ has garnered significant interest due to its high Curie temperature (T$_C$), large saturation magnetization, and complex magnetic behavior arising, in part, from multiple inequivalent iron sites and vacancies. While several aspects of its complex magnetic and structural characteristics have been examined through careful experiments and first principles studies, much of it remains debatable. In this study, we present one of the first comprehensive temperature-dependent Raman spectrum for bulk Fe$_5$GeTe$_2$ and in the process reveal an interesting peak shift anomaly at 150 K. We discuss the possible relationship of this Raman anomaly with the anomalous lattice expansion reported earlier for this material at around 110 K. The impact of the anomalous lattice expansion on the magnetic anisotropy in this van der Waals material is also revealed by an isothermal magnetization analysis. These findings will prove crucial for the use of Fe$_5$GeTe$_2$ in high-performance spintronic devices.",Materials Science
"Two-dimensional (2D) van der Waals (vdW) ferromagnet Fe$_5$GeTe$_2$ has garnered significant interest due to its high Curie temperature (T$_C$), large saturation magnetization, and complex magnetic behavior arising, in part, from multiple inequivalent iron sites and vacancies. While several aspects of its complex magnetic and structural characteristics have been examined through careful experiments and first principles studies, much of it remains debatable. In this study, we present one of the first comprehensive temperature-dependent Raman spectrum for bulk Fe$_5$GeTe$_2$ and in the process reveal an interesting peak shift anomaly at 150 K. We discuss the possible relationship of this Raman anomaly with the anomalous lattice expansion reported earlier for this material at around 110 K. The impact of the anomalous lattice expansion on the magnetic anisotropy in this van der Waals material is also revealed by an isothermal magnetization analysis. These findings will prove crucial for the use of Fe$_5$GeTe$_2$ in high-performance spintronic devices. [SEP] [HINT] complex -> Bioinformatics (Syns: building complex, coordination compound, composite) | structural -> Materials Science (Syns: geomorphologic, morphologic, morphological) | material -> Materials Science (Syns: stuff, cloth, real)",Materials Science
"Although polymerization and curing reactions govern the performance of advanced materials, their simulation remains challenging owing to the need for accurate, transferable potentials and rarity of chemical events. Conventional reactive force fields such as ReaxFF require system-specific parametrization, while universal machine learning interatomic potentials (uMLIPs) exhibit limited sampling efficiency. This paper introduces a novel simulation framework integrating a uMLIP with a time-dependent bond-boost scheme. The bias potential increases monotonically with time, and the use of a unified parameter set across reaction classes enables consistent acceleration without system-specific tuning. For radical polymerization of vinyl monomers, the proposed framework reproduces characteristic trends, such as linear molecular-weight growth with conversion, initiator-concentration scaling, and relative monomer reactivity trends. For step-growth polycondensation of nylon-6,6, it captures the characteristic sharp increase in molecular weight at high conversion rates, consistent with experimental behavior. For epoxy curing at a copper substrate, it reveals interfacial ring-opening and cross-linking events, consistent with spectroscopic evidence of Cu-O-C bond formation. Overall, coupling uMLIPs with time-dependent bond boost enables practical and transferable simulations of polymerization and curing processes. The proposed framework reliably resolves mechanistic pathways and relative reactivity, offering molecular-level insights into polymer growth and interfacial adhesion.",Materials Science
"Although polymerization and curing reactions govern the performance of advanced materials, their simulation remains challenging owing to the need for accurate, transferable potentials and rarity of chemical events. Conventional reactive force fields such as ReaxFF require system-specific parametrization, while universal machine learning interatomic potentials (uMLIPs) exhibit limited sampling efficiency. This paper introduces a novel simulation framework integrating a uMLIP with a time-dependent bond-boost scheme. The bias potential increases monotonically with time, and the use of a unified parameter set across reaction classes enables consistent acceleration without system-specific tuning. For radical polymerization of vinyl monomers, the proposed framework reproduces characteristic trends, such as linear molecular-weight growth with conversion, initiator-concentration scaling, and relative monomer reactivity trends. For step-growth polycondensation of nylon-6,6, it captures the characteristic sharp increase in molecular weight at high conversion rates, consistent with experimental behavior. For epoxy curing at a copper substrate, it reveals interfacial ring-opening and cross-linking events, consistent with spectroscopic evidence of Cu-O-C bond formation. Overall, coupling uMLIPs with time-dependent bond boost enables practical and transferable simulations of polymerization and curing processes. The proposed framework reliably resolves mechanistic pathways and relative reactivity, offering molecular-level insights into polymer growth and interfacial adhesion. [SEP] [HINT] learning -> Bioinformatics (Syns: take, teach, acquire) | molecular -> Bioinformatics (Syns: ) | performance -> Bioinformatics (Syns: functioning, operation, carrying out)",Materials Science
"Background: Despite high in-silico performance (AUC >0.80), 85% of AI cancer biomarkers fail clinical translation, exposing a critical algorithm-to-outcome gap. Methods: We introduce the Algorithm-to-Outcome Concordance (AOC) framework, integrating model accuracy (AUC), clinical correlation (Corr), and trial heterogeneity. We validated AOC across 6 neoantigen vaccine trials (2017-2025) and 3 independent melanoma immunotherapy cohorts (n=188 patients). Results: AOC ranged 0.18-0.79 across trials, with failed trials (ORR <15%) showing AOC <0.40. External validation revealed unstable algorithm-outcome correlation (C-index: 0.49-0.61, p>0.05), demonstrating the necessity of explicit concordance assessment. Conclusions: AOC provides a quantitative framework for pre-trial risk assessment and adaptive trial design. Prospective validation is underway in KEYNOTE-942 extension studies.",Bioinformatics
"Background: Despite high in-silico performance (AUC >0.80), 85% of AI cancer biomarkers fail clinical translation, exposing a critical algorithm-to-outcome gap. Methods: We introduce the Algorithm-to-Outcome Concordance (AOC) framework, integrating model accuracy (AUC), clinical correlation (Corr), and trial heterogeneity. We validated AOC across 6 neoantigen vaccine trials (2017-2025) and 3 independent melanoma immunotherapy cohorts (n=188 patients). Results: AOC ranged 0.18-0.79 across trials, with failed trials (ORR <15%) showing AOC <0.40. External validation revealed unstable algorithm-outcome correlation (C-index: 0.49-0.61, p>0.05), demonstrating the necessity of explicit concordance assessment. Conclusions: AOC provides a quantitative framework for pre-trial risk assessment and adaptive trial design. Prospective validation is underway in KEYNOTE-942 extension studies. [SEP] [HINT] clinical -> Bioinformatics (Syns: ) | performance -> Bioinformatics (Syns: functioning, operation, carrying out) | framework -> Bioinformatics (Syns: theoretical account, model, fabric)",Bioinformatics
"Proteins perform essential biological functions, and accurate classification of their sequences is critical for understanding structure-function relationships, enzyme mechanisms, and molecular interactions. This study presents a deep learning-based framework for functional group classification of protein sequences derived from the Protein Data Bank (PDB). Four architectures were implemented: Convolutional Neural Network (CNN), Bidirectional Long Short-Term Memory (BiLSTM), CNN-BiLSTM hybrid, and CNN with Attention. Each model was trained using k-mer integer encoding to capture both local and long-range dependencies. Among these, the CNN achieved the highest validation accuracy of 91.8%, demonstrating the effectiveness of localized motif detection. Explainable AI techniques, including Grad-CAM and Integrated Gradients, were applied to interpret model predictions and identify biologically meaningful sequence motifs. The discovered motifs, enriched in histidine, aspartate, glutamate, and lysine, represent amino acid residues commonly found in catalytic and metal-binding regions of transferase enzymes. These findings highlight that deep learning models can uncover functionally relevant biochemical signatures, bridging the gap between predictive accuracy and biological interpretability in protein sequence analysis.",Bioinformatics
"Proteins perform essential biological functions, and accurate classification of their sequences is critical for understanding structure-function relationships, enzyme mechanisms, and molecular interactions. This study presents a deep learning-based framework for functional group classification of protein sequences derived from the Protein Data Bank (PDB). Four architectures were implemented: Convolutional Neural Network (CNN), Bidirectional Long Short-Term Memory (BiLSTM), CNN-BiLSTM hybrid, and CNN with Attention. Each model was trained using k-mer integer encoding to capture both local and long-range dependencies. Among these, the CNN achieved the highest validation accuracy of 91.8%, demonstrating the effectiveness of localized motif detection. Explainable AI techniques, including Grad-CAM and Integrated Gradients, were applied to interpret model predictions and identify biologically meaningful sequence motifs. The discovered motifs, enriched in histidine, aspartate, glutamate, and lysine, represent amino acid residues commonly found in catalytic and metal-binding regions of transferase enzymes. These findings highlight that deep learning models can uncover functionally relevant biochemical signatures, bridging the gap between predictive accuracy and biological interpretability in protein sequence analysis. [SEP] [HINT] understanding -> Neuroscience (Syns: savvy, intellect, sympathy) | learning -> Bioinformatics (Syns: take, teach, acquire) | functional -> Neuroscience (Syns: working, usable, running)",Bioinformatics
"The brain-body-environment framework studies adaptive behavior through embodied and situated agents, emphasizing interactions between brains, biomechanics, and environmental dynamics. However, many models often treat the brain as a network of coupled ordinary differential equations (ODEs), neglecting finer spatial properties which can not only increase model complexity but also constrain observable neural dynamics. To address this limitation, we propose a spatially extended approach using partial differential equations (PDEs) for both the brain and body. As a case study, we revisit a previously developed model of a child swinging, now incorporating spatial dynamics. By considering the spatio-temporal properties of the brain and body, we analyze how input location and propagation along a PDE influence behavior. This approach offers new insights into the role of spatial organization in adaptive behavior, bridging the gap between abstract neural models and the physical constraints of embodied systems. Our results highlight the importance of spatial dynamics in understanding brain-body-environment interactions.",Neuroscience
"The brain-body-environment framework studies adaptive behavior through embodied and situated agents, emphasizing interactions between brains, biomechanics, and environmental dynamics. However, many models often treat the brain as a network of coupled ordinary differential equations (ODEs), neglecting finer spatial properties which can not only increase model complexity but also constrain observable neural dynamics. To address this limitation, we propose a spatially extended approach using partial differential equations (PDEs) for both the brain and body. As a case study, we revisit a previously developed model of a child swinging, now incorporating spatial dynamics. By considering the spatio-temporal properties of the brain and body, we analyze how input location and propagation along a PDE influence behavior. This approach offers new insights into the role of spatial organization in adaptive behavior, bridging the gap between abstract neural models and the physical constraints of embodied systems. Our results highlight the importance of spatial dynamics in understanding brain-body-environment interactions. [SEP] [HINT] understanding -> Neuroscience (Syns: savvy, intellect, sympathy) | results -> Bioinformatics (Syns: final result, consequence, resultant role) | framework -> Bioinformatics (Syns: theoretical account, model, fabric)",Neuroscience
"A model of consciousness is proposed which, having a logical basis, lends itself to simulation using a simple mathematical model called Consciousness as Entropy Reduction (CER). The approach has been inspired by previous models such as GWT, IIT and an earlier less mainstream model called ""Feature Map"" in Psychology. CER considers the contents of consciousness and subconsciousness as \textit{scenarios}: a vector of patterns (or features) on various ""channels"" (or feature locations). In CER, a feature map itself is not consciousness but only the input \textit{scenario} into a world of possible subconscious \textit{scenarios} from which the conscious \textit{scenario} (i.e., conscious experience) is chosen. Essentially, it creates an internal simulation of the outside world. Solving problems in simulation internally as a ""thought experiment"" is obviously more economical than doing experiments in a real environment and lends itself to adaptability and hence is a major evolutionary advantage. CER also has connections with the Hopfield model in artificial neural networks.",Neuroscience
"A model of consciousness is proposed which, having a logical basis, lends itself to simulation using a simple mathematical model called Consciousness as Entropy Reduction (CER). The approach has been inspired by previous models such as GWT, IIT and an earlier less mainstream model called ""Feature Map"" in Psychology. CER considers the contents of consciousness and subconsciousness as \textit{scenarios}: a vector of patterns (or features) on various ""channels"" (or feature locations). In CER, a feature map itself is not consciousness but only the input \textit{scenario} into a world of possible subconscious \textit{scenarios} from which the conscious \textit{scenario} (i.e., conscious experience) is chosen. Essentially, it creates an internal simulation of the outside world. Solving problems in simulation internally as a ""thought experiment"" is obviously more economical than doing experiments in a real environment and lends itself to adaptability and hence is a major evolutionary advantage. CER also has connections with the Hopfield model in artificial neural networks. [SEP] [HINT] using -> Bioinformatics (Syns: utilize, exploitation, apply) | neural -> Bioinformatics (Syns: neuronic, nervous, neuronal) | models -> Bioinformatics (Syns: framework, modelling, good example)",Neuroscience
"Nanopore protein sequencing produces long, noisy ionic current traces in which key molecular phases, such as protein capture and translocation, are embedded. Capture phases mark the successful entry of a protein into the pore and serve as both a checkpoint and a signal that a channel merits further analysis. However, manual identification of capture phases is time-intensive, often requiring several days for expert reviewers to annotate the data due to the need for domain-specific interpretation of complex signal patterns. To address this, a lightweight one-dimensional convolutional neural network (1D CNN) was developed and trained to detect capture phases in down-sampled signal windows. Evaluated against CNN-LSTM (Long Short-Term Memory) hybrids, histogram-based classifiers, and other CNN variants using run-level data splits, our best model, CaptureNet-Deep, achieved an F1 score of 0.94 and precision of 93.39% on held-out test data. The model supports low-latency inference and is integrated into a dashboard for Oxford Nanopore experiments, reducing the total analysis time from several days to under thirty minutes. These results show that efficient, real-time capture detection is possible using simple, interpretable architectures and suggest a broader role for lightweight ML models in sequencing workflows.",Bioinformatics
"Nanopore protein sequencing produces long, noisy ionic current traces in which key molecular phases, such as protein capture and translocation, are embedded. Capture phases mark the successful entry of a protein into the pore and serve as both a checkpoint and a signal that a channel merits further analysis. However, manual identification of capture phases is time-intensive, often requiring several days for expert reviewers to annotate the data due to the need for domain-specific interpretation of complex signal patterns. To address this, a lightweight one-dimensional convolutional neural network (1D CNN) was developed and trained to detect capture phases in down-sampled signal windows. Evaluated against CNN-LSTM (Long Short-Term Memory) hybrids, histogram-based classifiers, and other CNN variants using run-level data splits, our best model, CaptureNet-Deep, achieved an F1 score of 0.94 and precision of 93.39% on held-out test data. The model supports low-latency inference and is integrated into a dashboard for Oxford Nanopore experiments, reducing the total analysis time from several days to under thirty minutes. These results show that efficient, real-time capture detection is possible using simple, interpretable architectures and suggest a broader role for lightweight ML models in sequencing workflows. [SEP] [HINT] complex -> Bioinformatics (Syns: building complex, coordination compound, composite) | molecular -> Bioinformatics (Syns: ) | results -> Bioinformatics (Syns: final result, consequence, resultant role)",Bioinformatics
"Live-cell imaging (LCI) technology enables the detailed spatio-temporal characterization of living cells at the single-cell level, which is critical for advancing research in the life sciences, from biomedical applications to bioprocessing. High-throughput setups with tens to hundreds of parallel cell cultivations offer the potential for robust and reproducible insights. However, these insights are obscured by the large amount of LCI data recorded per experiment. Recent advances in state-of-the-art deep learning methods for cell segmentation and tracking now enable the automated analysis of such large data volumes, offering unprecedented opportunities to systematically study single-cell dynamics. The next key challenge lies in integrating these powerful tools into accessible, flexible, and user-friendly workflows that support routine application in biological research. In this work, we present acia-workflows, a platform that combines three key components: (1) the Automated live-Cell Imaging Analysis (acia) Python library, which supports the modular design of image analysis pipelines offering eight deep learning segmentation and tracking approaches; (2) workflows that assemble the image analysis pipeline, its software dependencies, documentation, and visualizations into a single Jupyter Notebook, leading to accessible, reproducible and scalable analysis workflows; and (3) a collection of application workflows showcasing the analysis and customization capabilities in real-world applications. Specifically, we present three workflows to investigate various types of microfluidic LCI experiments ranging from growth rate comparisons to precise, minute-resolution quantitative analyses of individual dynamic cells responses to changing oxygen conditions. Our collection of more than ten application workflows is open source and publicly available at https://github.com/JuBiotech/acia-workflows.",Bioinformatics
"Live-cell imaging (LCI) technology enables the detailed spatio-temporal characterization of living cells at the single-cell level, which is critical for advancing research in the life sciences, from biomedical applications to bioprocessing. High-throughput setups with tens to hundreds of parallel cell cultivations offer the potential for robust and reproducible insights. However, these insights are obscured by the large amount of LCI data recorded per experiment. Recent advances in state-of-the-art deep learning methods for cell segmentation and tracking now enable the automated analysis of such large data volumes, offering unprecedented opportunities to systematically study single-cell dynamics. The next key challenge lies in integrating these powerful tools into accessible, flexible, and user-friendly workflows that support routine application in biological research. In this work, we present acia-workflows, a platform that combines three key components: (1) the Automated live-Cell Imaging Analysis (acia) Python library, which supports the modular design of image analysis pipelines offering eight deep learning segmentation and tracking approaches; (2) workflows that assemble the image analysis pipeline, its software dependencies, documentation, and visualizations into a single Jupyter Notebook, leading to accessible, reproducible and scalable analysis workflows; and (3) a collection of application workflows showcasing the analysis and customization capabilities in real-world applications. Specifically, we present three workflows to investigate various types of microfluidic LCI experiments ranging from growth rate comparisons to precise, minute-resolution quantitative analyses of individual dynamic cells responses to changing oxygen conditions. Our collection of more than ten application workflows is open source and publicly available at https://github.com/JuBiotech/acia-workflows. [SEP] [HINT] learning -> Bioinformatics (Syns: take, teach, acquire) | imaging -> Bioinformatics (Syns: imagery, imagination, visualise) | potential -> Bioinformatics (Syns: voltage, potential difference, electric potential)",Bioinformatics
"$α$-Li$_3$PS$_4$ is a promising solid-state electrolyte with the highest ionic conductivity among its polymorphs. However, its formation presents a thermodynamic paradox: the $α$-phase is the equilibrium phase at high temperature and transforms to the stable $γ$-Li$_3$PS$_4$ polymorph when cooled to room temperature; however, $α$-Li$_3$PS$_4$ can be synthesized and quenched in a metastable state via rapid heating at relatively low temperatures. The origin of this synthesizability and anomalous stability has remained elusive. Here, we resolve this paradox by establishing a comprehensive time-temperature-transformation (TTT) diagram, constructed from a computational temperature-size phase diagram and experimental high-time-resolution isothermal measurements. Our density functional theory calculations reveal that at the nanoscale, the $α$-phase is stabilized by its low surface energy, which drastically lowers the nucleation barrier across a wide temperature range. This size-dependent stabilization is directly visualized using in-situ synchrotron X-ray diffraction and electron microscopy, capturing the rapid nucleation of nano-sized $α$-phase and its subsequent slow transformation. This work presents a generalizable framework that integrates thermodynamic and kinetic factors for understanding nucleation and phase transformation mechanisms, providing a rational strategy for the targeted synthesis of functional metastable materials.",Materials Science
"$α$-Li$_3$PS$_4$ is a promising solid-state electrolyte with the highest ionic conductivity among its polymorphs. However, its formation presents a thermodynamic paradox: the $α$-phase is the equilibrium phase at high temperature and transforms to the stable $γ$-Li$_3$PS$_4$ polymorph when cooled to room temperature; however, $α$-Li$_3$PS$_4$ can be synthesized and quenched in a metastable state via rapid heating at relatively low temperatures. The origin of this synthesizability and anomalous stability has remained elusive. Here, we resolve this paradox by establishing a comprehensive time-temperature-transformation (TTT) diagram, constructed from a computational temperature-size phase diagram and experimental high-time-resolution isothermal measurements. Our density functional theory calculations reveal that at the nanoscale, the $α$-phase is stabilized by its low surface energy, which drastically lowers the nucleation barrier across a wide temperature range. This size-dependent stabilization is directly visualized using in-situ synchrotron X-ray diffraction and electron microscopy, capturing the rapid nucleation of nano-sized $α$-phase and its subsequent slow transformation. This work presents a generalizable framework that integrates thermodynamic and kinetic factors for understanding nucleation and phase transformation mechanisms, providing a rational strategy for the targeted synthesis of functional metastable materials. [SEP] [HINT] low -> Materials Science (Syns: low-spirited, scurvy, depressed) | computational -> Neuroscience (Syns: ) | understanding -> Neuroscience (Syns: savvy, intellect, sympathy)",Materials Science
"Quantum emitters in hexagonal boron nitride (hBN) that exhibit optically detected magnetic resonance (ODMR) signatures have recently garnered significant attention as an emerging solid-state platform for quantum technologies. However, the underlying spin dynamics, and the mechanisms determining the spin-dependent fluorescence in these defects are still poorly understood. In this work we perform detailed photodynamical studies of the spin complexes in hBN. In particular, we show that spin transitions are located within the metastable manifold which can be explained by the rate model, populating in a cascading manner. In addition, we perform temperature dependent measurements on these defects and show that the spin-lattice relaxation and coherence times increase as the temperature reduces. Furthermore, we find that the ODMR frequencies of the S=1 transition show only a marginal frequency shift as a function of temperature, which makes them a robust sensor at cryogenic temperatures. These insights are crucial for further understanding of the spin dynamics of quantum emitters in hBN and their practical implementation in quantum sensing.",Materials Science
"Quantum emitters in hexagonal boron nitride (hBN) that exhibit optically detected magnetic resonance (ODMR) signatures have recently garnered significant attention as an emerging solid-state platform for quantum technologies. However, the underlying spin dynamics, and the mechanisms determining the spin-dependent fluorescence in these defects are still poorly understood. In this work we perform detailed photodynamical studies of the spin complexes in hBN. In particular, we show that spin transitions are located within the metastable manifold which can be explained by the rate model, populating in a cascading manner. In addition, we perform temperature dependent measurements on these defects and show that the spin-lattice relaxation and coherence times increase as the temperature reduces. Furthermore, we find that the ODMR frequencies of the S=1 transition show only a marginal frequency shift as a function of temperature, which makes them a robust sensor at cryogenic temperatures. These insights are crucial for further understanding of the spin dynamics of quantum emitters in hBN and their practical implementation in quantum sensing. [SEP] [HINT] transition -> Materials Science (Syns: passage, modulation, changeover) | spin -> Materials Science (Syns: twisting, whirl, tailspin) | understanding -> Neuroscience (Syns: savvy, intellect, sympathy)",Materials Science
"Near-Infrared (NIR) light emitting metal halides are emerging as a new generation of optical materials owing to their appealing features, which include low-cost synthesis, solution processability and adjustable optical properties. NIR emitting perovskite-based light-emitting diodes (LEDs) have reached an external quantum efficiency (EQE) over 20% and a device stability of over 10,000 h. Such results have sparked an interest in exploring new NIR metal halide emitters. In this review, we summarize several different types of NIR-emitting metal halides, including lead/tin bromide/iodide perovskites, lanthanide ions doped/based metal halides, double perovskites, low dimensional hybrid and Bi3+/Sb3+/Cr3+ doped metal halides, and assess their recent advancements. The characteristics and mechanisms of narrow-band or broadband NIR luminescence in all these materials are discussed in detail. We also highlight the various applications of NIR-emitting metal halides and provide an outlook for the field.",Materials Science
"Near-Infrared (NIR) light emitting metal halides are emerging as a new generation of optical materials owing to their appealing features, which include low-cost synthesis, solution processability and adjustable optical properties. NIR emitting perovskite-based light-emitting diodes (LEDs) have reached an external quantum efficiency (EQE) over 20% and a device stability of over 10,000 h. Such results have sparked an interest in exploring new NIR metal halide emitters. In this review, we summarize several different types of NIR-emitting metal halides, including lead/tin bromide/iodide perovskites, lanthanide ions doped/based metal halides, double perovskites, low dimensional hybrid and Bi3+/Sb3+/Cr3+ doped metal halides, and assess their recent advancements. The characteristics and mechanisms of narrow-band or broadband NIR luminescence in all these materials are discussed in detail. We also highlight the various applications of NIR-emitting metal halides and provide an outlook for the field. [SEP] [HINT] low -> Materials Science (Syns: low-spirited, scurvy, depressed) | results -> Bioinformatics (Syns: final result, consequence, resultant role) | dimensional -> Materials Science (Syns: )",Materials Science
"Vanadium dioxide (VO$_2$) exhibits hysteresis in resistance while undergoing a thermally driven insulator-metal transition (IMT). Understanding the nonequilibrium effects in resistance is of great interest, as VO$_2$ is a strong candidate for brain-inspired computing, which is more energy efficient for AI tasks compared to traditional computing. Accurate models of the connection between microscopic and macroscopic transport properties and microscopic imaging of VO$_2$ will allow us to better utilize VO$_2$ in future applications. However, predictions of macroscopic resistance of VO$_2$ that quantitatively match observations using spatially resolved data have not yet been achieved. Here, we demonstrate an accurate prediction of the macroscopic resistance of VO$_2$ throughout the entire temperature range of interest, by developing a multiscale resistor network model incorporating the assumption of fractal sub-pixel structure of the optical data, where the configuration of insulating and metallic domains within each pixel are drawn from the random field Ising model near criticality. This strongly indicates that the observed fractal, power law structure of metallic and insulating domains extends down to much smaller length scales than the current record for experimental resolution of this system, and that the two-dimensional random field Ising model near criticality is a suitable model for describing the metal and insulator patches of VO$_2$ down to scales that approach the unit cell.",Materials Science
"Vanadium dioxide (VO$_2$) exhibits hysteresis in resistance while undergoing a thermally driven insulator-metal transition (IMT). Understanding the nonequilibrium effects in resistance is of great interest, as VO$_2$ is a strong candidate for brain-inspired computing, which is more energy efficient for AI tasks compared to traditional computing. Accurate models of the connection between microscopic and macroscopic transport properties and microscopic imaging of VO$_2$ will allow us to better utilize VO$_2$ in future applications. However, predictions of macroscopic resistance of VO$_2$ that quantitatively match observations using spatially resolved data have not yet been achieved. Here, we demonstrate an accurate prediction of the macroscopic resistance of VO$_2$ throughout the entire temperature range of interest, by developing a multiscale resistor network model incorporating the assumption of fractal sub-pixel structure of the optical data, where the configuration of insulating and metallic domains within each pixel are drawn from the random field Ising model near criticality. This strongly indicates that the observed fractal, power law structure of metallic and insulating domains extends down to much smaller length scales than the current record for experimental resolution of this system, and that the two-dimensional random field Ising model near criticality is a suitable model for describing the metal and insulator patches of VO$_2$ down to scales that approach the unit cell. [SEP] [HINT] field -> Materials Science (Syns: field of honor, line of business, orbit) | transition -> Materials Science (Syns: passage, modulation, changeover) | tasks -> Neuroscience (Syns: tax, task, project)",Materials Science
"Current syntheses of CsPbBr3 halide perovskite nanocrystals (NCs) rely on over-stoichiometric amounts of Pb2+ precursors, resulting in unreacted lead ions at the end of the process. In our synthesis scheme of CsPbBr3 NCs we replaced excess Pb2+ with different exogenous metal cations (M) and investigated their effect on the synthesis products. These cations can be divided into two groups: group 1 delivers monodisperse CsPbBr3 cubes capped with oleate species (as for the case when Pb2+ is used in excess) and with photoluminescence quantum yield (PLQY) as high as 90% with some cations (for example with M= In3+); group 2 yields irregularly shaped CsPbBr3 NCs with broad size distributions. In both cases, the addition of a tertiary ammonium cation (didodecylmethyl ammonium, DDMA+) during the synthesis, after the nucleation of the NCs, reshapes the NCs to monodisperse truncated cubes. Such NCs feature a mixed oleate/DDMA+ surface termination with PLQY values up to 90%. For group 1 cations, this happens only if the ammonium cation is directly added as a salt (DDMA-Br) while for group 2 cations this happens even if the corresponding tertiary amine (DDMA) is added, instead of DDMA-Br. This is attributed to the fact that only group 2 cations can facilitate the protonation of DDMA by the excess oleic acid present in the reaction environment. In all cases studied, the incorporation of M cations is marginal and the reshaping of the NCs is only transient: if the reactions are run for a long time the truncated cubes evolve to cubes.",Materials Science
"Current syntheses of CsPbBr3 halide perovskite nanocrystals (NCs) rely on over-stoichiometric amounts of Pb2+ precursors, resulting in unreacted lead ions at the end of the process. In our synthesis scheme of CsPbBr3 NCs we replaced excess Pb2+ with different exogenous metal cations (M) and investigated their effect on the synthesis products. These cations can be divided into two groups: group 1 delivers monodisperse CsPbBr3 cubes capped with oleate species (as for the case when Pb2+ is used in excess) and with photoluminescence quantum yield (PLQY) as high as 90% with some cations (for example with M= In3+); group 2 yields irregularly shaped CsPbBr3 NCs with broad size distributions. In both cases, the addition of a tertiary ammonium cation (didodecylmethyl ammonium, DDMA+) during the synthesis, after the nucleation of the NCs, reshapes the NCs to monodisperse truncated cubes. Such NCs feature a mixed oleate/DDMA+ surface termination with PLQY values up to 90%. For group 1 cations, this happens only if the ammonium cation is directly added as a salt (DDMA-Br) while for group 2 cations this happens even if the corresponding tertiary amine (DDMA) is added, instead of DDMA-Br. This is attributed to the fact that only group 2 cations can facilitate the protonation of DDMA by the excess oleic acid present in the reaction environment. In all cases studied, the incorporation of M cations is marginal and the reshaping of the NCs is only transient: if the reactions are run for a long time the truncated cubes evolve to cubes. [SEP] [HINT] used -> Bioinformatics (Syns: utilize, ill-used, apply) | perovskite -> Materials Science (Syns: ) | different -> Neuroscience (Syns: unlike, dissimilar)",Materials Science
"Recalling previously experienced movements is essential for a range of activities, including sports, music, and rehabilitation, yet little is known about the accuracy and decay of proprioceptive working memory. We examined how introducing a short-term memory component affected movement reproduction accuracy by comparing movement reproduction under two conditions: simultaneous reproduction (SimRep) and memorized reproduction (MemRep). In Experiment 1 (N = 191), participants felt a 5-s haptic trajectory with one hand and reproduced it with the other hand simultaneously or immediately after the template ended. Errors were greater in MemRep than SimRep (31.1 deg vs. 21.5 deg, p < 0.001). MemRep trajectories showed systematic temporal distortions: participants lagged fast movements and led slow ones (R = -0.32, p = 0.01), unlike the ~279 ms lag in SimRep. In Experiment 2 (N = 33), we varied template durations (2-8 s). Longer durations increased error for MemRep but not SimRep (p < 0.001). During MemRep, accuracy declined steadily, with replay-template correlations dropping from ~0.4 to ~0.1 over ~3 s, while SimRep correlations rose from ~0.25 to ~0.6. In ~10% of MemRep templates, participants moved in the wrong direction initially, especially for low-amplitude movements (p < 0.001). Templates with more than four movements showed element omission; after four movements had been reproduced participants ceased movement prematurely, affecting up to 40% of 8-s templates. These findings show that transferring proprioceptive experiences into working memory introduces systematic temporal and structural distortions. Accuracy decays within seconds, and memory span for movement trajectories was limited to four movements.",Neuroscience
"Recalling previously experienced movements is essential for a range of activities, including sports, music, and rehabilitation, yet little is known about the accuracy and decay of proprioceptive working memory. We examined how introducing a short-term memory component affected movement reproduction accuracy by comparing movement reproduction under two conditions: simultaneous reproduction (SimRep) and memorized reproduction (MemRep). In Experiment 1 (N = 191), participants felt a 5-s haptic trajectory with one hand and reproduced it with the other hand simultaneously or immediately after the template ended. Errors were greater in MemRep than SimRep (31.1 deg vs. 21.5 deg, p < 0.001). MemRep trajectories showed systematic temporal distortions: participants lagged fast movements and led slow ones (R = -0.32, p = 0.01), unlike the ~279 ms lag in SimRep. In Experiment 2 (N = 33), we varied template durations (2-8 s). Longer durations increased error for MemRep but not SimRep (p < 0.001). During MemRep, accuracy declined steadily, with replay-template correlations dropping from ~0.4 to ~0.1 over ~3 s, while SimRep correlations rose from ~0.25 to ~0.6. In ~10% of MemRep templates, participants moved in the wrong direction initially, especially for low-amplitude movements (p < 0.001). Templates with more than four movements showed element omission; after four movements had been reproduced participants ceased movement prematurely, affecting up to 40% of 8-s templates. These findings show that transferring proprioceptive experiences into working memory introduces systematic temporal and structural distortions. Accuracy decays within seconds, and memory span for movement trajectories was limited to four movements. [SEP] [HINT] including -> Bioinformatics (Syns: admit, include, let in) | structural -> Materials Science (Syns: geomorphologic, morphologic, morphological) | findings -> Neuroscience (Syns: determination, finding)",Neuroscience
"Recent advances in general-purpose AI systems with attention-based transformers offer a potential window into how the neocortex and cerebellum, despite their relatively uniform circuit architectures, give rise to diverse functions and, ultimately, to human intelligence. This Perspective provides a cross-domain comparison between the brain and AI that goes beyond the traditional focus on visual processing, adopting the emerging perspecive of world-model-based computation. Here, we identify shared computational mechanisms in the attention-based neocortex and the non-attentional cerebellum: both predict future world events from past inputs and construct internal world models through prediction-error learning. These predictive world models are repurposed for seemingly distinct functions -- understanding in sensory processing and generation in motor processing -- enabling the brain to achieve multi-domain capabilities and human-like adaptive intelligence. Notably, attention-based AI has independently converged on a similar learning paradigm and world-model-based computation. We conclude that these shared mechanisms in both biological and artificial systems constitute a core computational foundation for realizing diverse functions including high-level intelligence, despite their relatively uniform circuit structures. Our theoretical insights bridge neuroscience and AI, advancing our understanding of the computational essence of intelligence.",Neuroscience
"Recent advances in general-purpose AI systems with attention-based transformers offer a potential window into how the neocortex and cerebellum, despite their relatively uniform circuit architectures, give rise to diverse functions and, ultimately, to human intelligence. This Perspective provides a cross-domain comparison between the brain and AI that goes beyond the traditional focus on visual processing, adopting the emerging perspecive of world-model-based computation. Here, we identify shared computational mechanisms in the attention-based neocortex and the non-attentional cerebellum: both predict future world events from past inputs and construct internal world models through prediction-error learning. These predictive world models are repurposed for seemingly distinct functions -- understanding in sensory processing and generation in motor processing -- enabling the brain to achieve multi-domain capabilities and human-like adaptive intelligence. Notably, attention-based AI has independently converged on a similar learning paradigm and world-model-based computation. We conclude that these shared mechanisms in both biological and artificial systems constitute a core computational foundation for realizing diverse functions including high-level intelligence, despite their relatively uniform circuit structures. Our theoretical insights bridge neuroscience and AI, advancing our understanding of the computational essence of intelligence. [SEP] [HINT] computational -> Neuroscience (Syns: ) | understanding -> Neuroscience (Syns: savvy, intellect, sympathy) | learning -> Bioinformatics (Syns: take, teach, acquire)",Neuroscience
"Respiratory ailments are increasing globally at an alarming rate and are currently one of the leading factors of death and infirmity worldwide. Among respiratory diseases, those linked to poor air quality and pollutants are increasing at a proportionally higher rate than those linked to viral or other factors. Diagnosing disorders of the respiratory system is often performed initially by routine physical examinations and questionnaires. Once most patients have symptoms that are severe enough to warrant clinical testing, the ailment could have already caused pulmonary damage. Clinical diagnosis involves the use of cumbersome, expensive equipment that measures different parameters separately, e.g., Capnography (CO2) and spirometry (bidirectional tidal mass flow). These disparate sets of data must then be interpreted collectively by a qualified medical practitioner. This paper details the design of a portable, inexpensive, mixed-signal data-logging system that measures a chosen set of parameters in exhaled breath from humans or animals. The data is a comprehensive set of pertinent gases and mass flow that when looked at simultaneously, gives a synergistic view of these interrelated breathing biomarkers and thus the state of the respiratory system as a whole. A mask-mounted, tabletop, and handheld version was developed for different applications. The system, when fully developed, would enable a new set of clinical vitals that only require a patient to breathe through a single, small device for a few moments. This new set of clinical vitals could enable the early diagnosis of many respiratory ailments, something that could have a large positive impact on disease prognosis and quality of life.",Bioinformatics
"Respiratory ailments are increasing globally at an alarming rate and are currently one of the leading factors of death and infirmity worldwide. Among respiratory diseases, those linked to poor air quality and pollutants are increasing at a proportionally higher rate than those linked to viral or other factors. Diagnosing disorders of the respiratory system is often performed initially by routine physical examinations and questionnaires. Once most patients have symptoms that are severe enough to warrant clinical testing, the ailment could have already caused pulmonary damage. Clinical diagnosis involves the use of cumbersome, expensive equipment that measures different parameters separately, e.g., Capnography (CO2) and spirometry (bidirectional tidal mass flow). These disparate sets of data must then be interpreted collectively by a qualified medical practitioner. This paper details the design of a portable, inexpensive, mixed-signal data-logging system that measures a chosen set of parameters in exhaled breath from humans or animals. The data is a comprehensive set of pertinent gases and mass flow that when looked at simultaneously, gives a synergistic view of these interrelated breathing biomarkers and thus the state of the respiratory system as a whole. A mask-mounted, tabletop, and handheld version was developed for different applications. The system, when fully developed, would enable a new set of clinical vitals that only require a patient to breathe through a single, small device for a few moments. This new set of clinical vitals could enable the early diagnosis of many respiratory ailments, something that could have a large positive impact on disease prognosis and quality of life. [SEP] [HINT] clinical -> Bioinformatics (Syns: ) | quality -> Bioinformatics (Syns: lineament, tone, calibre) | different -> Neuroscience (Syns: unlike, dissimilar)",Bioinformatics
"Doping cadmium oxide with rare earth (RE) elements is a way to control the band gap and enhance carrier concentration and mobility. This work presents how one of REs, europium, impacts performance of CdO/Si diode. The samples were grown using plasma-assisted molecular beam epitaxy. Doping level was modified by changing the temperature of the effusion cell with Eu and therefore flux of Eu particles. Different dopant concentrations were confirmed by secondary ion mass spectrometry. Atomic force microscopy images revealed a grain-like surface structure of the samples with grain size increasing after rapid thermal processing (RTP). Raman spectroscopy showed that introducing Eu changes vibrational properties of CdO through intraionic anharmonicity reduction. Kelvin probe method revealed upward band bending caused by oxygen adsorption during RTP. Electrical measurements confirmed that rectifying junctions were manufactured and that they are able to produce photocurrent in the spectral range of 450-1150 nm without external voltage bias. Introducing Eu into CdO was found to increase e.g. rectifying factor and responsivity. The results show that doping CdO with Eu is a way to enhance performance of the presented zero-power-consumption photodetectors, making it a promising material for future applications in optoelectronics.",Materials Science
"Doping cadmium oxide with rare earth (RE) elements is a way to control the band gap and enhance carrier concentration and mobility. This work presents how one of REs, europium, impacts performance of CdO/Si diode. The samples were grown using plasma-assisted molecular beam epitaxy. Doping level was modified by changing the temperature of the effusion cell with Eu and therefore flux of Eu particles. Different dopant concentrations were confirmed by secondary ion mass spectrometry. Atomic force microscopy images revealed a grain-like surface structure of the samples with grain size increasing after rapid thermal processing (RTP). Raman spectroscopy showed that introducing Eu changes vibrational properties of CdO through intraionic anharmonicity reduction. Kelvin probe method revealed upward band bending caused by oxygen adsorption during RTP. Electrical measurements confirmed that rectifying junctions were manufactured and that they are able to produce photocurrent in the spectral range of 450-1150 nm without external voltage bias. Introducing Eu into CdO was found to increase e.g. rectifying factor and responsivity. The results show that doping CdO with Eu is a way to enhance performance of the presented zero-power-consumption photodetectors, making it a promising material for future applications in optoelectronics. [SEP] [HINT] structure -> Bioinformatics (Syns: social system, complex body part, social structure) | molecular -> Bioinformatics (Syns: ) | processing -> Neuroscience (Syns: work, process, march)",Materials Science
"Menopause reshapes female physiology, yet its full temporal footprint is obscured by uncertainty in the age of the final menstrual period (FMP). Here we analyse cross-sectional data on 300 million laboratory tests from more than a million women in two population-scale cohorts (Israel-Clalit and US-NHANES). We apply a deconvolution algorithm inspired by astronomical image ""de-blurring"" to align each test to time-from-FMP rather than chronological age. Nearly every assay - spanning endocrine, bone, hepatic, lipid, osmolality, inflammatory and muscular systems - exhibits a jump at FMP that is absent in males and highly concordant between cohorts. Jumps were largest in the sex hormones, followed by bone, toxins, red blood cells, liver, iron, lipids, kidney, and muscle. Changes are mostly detrimental except iron indices and anemia that improve post-menopause, and depression scores that spike only transiently. Hormone-replacement therapy attenuates many of the step-like changes. Sex hormone dysregulation occurs more than 10 years prior to FMP. These findings reveal the step-like dysregulation across physiology caused by loss of sex hormones and establish deconvolution as a general strategy for disentangling age-related transitions in large, noisy datasets.",Bioinformatics
"Menopause reshapes female physiology, yet its full temporal footprint is obscured by uncertainty in the age of the final menstrual period (FMP). Here we analyse cross-sectional data on 300 million laboratory tests from more than a million women in two population-scale cohorts (Israel-Clalit and US-NHANES). We apply a deconvolution algorithm inspired by astronomical image ""de-blurring"" to align each test to time-from-FMP rather than chronological age. Nearly every assay - spanning endocrine, bone, hepatic, lipid, osmolality, inflammatory and muscular systems - exhibits a jump at FMP that is absent in males and highly concordant between cohorts. Jumps were largest in the sex hormones, followed by bone, toxins, red blood cells, liver, iron, lipids, kidney, and muscle. Changes are mostly detrimental except iron indices and anemia that improve post-menopause, and depression scores that spike only transiently. Hormone-replacement therapy attenuates many of the step-like changes. Sex hormone dysregulation occurs more than 10 years prior to FMP. These findings reveal the step-like dysregulation across physiology caused by loss of sex hormones and establish deconvolution as a general strategy for disentangling age-related transitions in large, noisy datasets. [SEP] [HINT] systems -> Bioinformatics (Syns: organization, organisation, system) | findings -> Neuroscience (Syns: determination, finding) | data -> Bioinformatics (Syns: data point, information, datum)",Bioinformatics
"The ability to reversibly and site-selectively tune ambipolar doping in a single semiconductor is crucial for reconfigurable electronics beyond silicon, but remains highly challenging. Here, we present a rewritable architecture based on electron-beam programmable field-effect transistors (FETs). Using WSe$_2$ as a model system, we demonstrate electron-beam-induced doping that enables reversible, precisely controlled carrier modulation exceeding $10^{13}$ cm$^{-2}$. The in-situ writing, erasing, and rewriting of ambipolar doping of nanoscale patterns was directly visualized by scanning microwave impedance microscopy. This mask-free, lithography-compatible approach can achieve precise band engineering within individual channels, yielding near-ideal subthreshold swings (~ 60 mV/dec) and finely tunable threshold voltages for both carrier types without specialized contact engineering. These capabilities allow on-demand realization of high performance logic, including CMOS inverters with high voltage gains and low power consumption, as well as NAND-to-NOR transitions on the same device via direct polarity rewriting. Our platform offers a scalable and versatile route for rapid prototyping of complementary electronics.",Materials Science
"The ability to reversibly and site-selectively tune ambipolar doping in a single semiconductor is crucial for reconfigurable electronics beyond silicon, but remains highly challenging. Here, we present a rewritable architecture based on electron-beam programmable field-effect transistors (FETs). Using WSe$_2$ as a model system, we demonstrate electron-beam-induced doping that enables reversible, precisely controlled carrier modulation exceeding $10^{13}$ cm$^{-2}$. The in-situ writing, erasing, and rewriting of ambipolar doping of nanoscale patterns was directly visualized by scanning microwave impedance microscopy. This mask-free, lithography-compatible approach can achieve precise band engineering within individual channels, yielding near-ideal subthreshold swings (~ 60 mV/dec) and finely tunable threshold voltages for both carrier types without specialized contact engineering. These capabilities allow on-demand realization of high performance logic, including CMOS inverters with high voltage gains and low power consumption, as well as NAND-to-NOR transitions on the same device via direct polarity rewriting. Our platform offers a scalable and versatile route for rapid prototyping of complementary electronics. [SEP] [HINT] based -> Bioinformatics (Syns: ground, free-base, base) | low -> Materials Science (Syns: low-spirited, scurvy, depressed) | performance -> Bioinformatics (Syns: functioning, operation, carrying out)",Materials Science
"Ovarian cancer remains one of the most lethal gynecological malignancies, largely due to late diagnosis and extensive heterogeneity across subtypes. Current diagnostic methods are limited in their ability to reveal underlying genomic variations essential for precision oncology. This study introduces a novel hybrid deep learning pipeline that integrates quantitative nuclear morphometry with deep convolutional image features to perform ovarian cancer subtype classification and gene mutation inference directly from Hematoxylin and Eosin (H&E) histopathological images. Using $\sim45,000$ image patches sourced from The Cancer Genome Atlas (TCGA) and public datasets, a fusion model combining a ResNet-50 Convolutional Neural Network (CNN) encoder and a Vision Transformer (ViT) was developed. This model successfully captured both local morphological texture and global tissue context. The pipeline achieved a robust overall subtype classification accuracy of $84.2\%$ (Macro AUC of $0.87 \pm 0.03$). Crucially, the model demonstrated the capacity for gene mutation inference with moderate-to-high accuracy: $AUC_{TP53} = 0.82 \pm 0.02$, $AUC_{BRCA1} = 0.76 \pm 0.04$, and $AUC_{ARID1A} = 0.73 \pm 0.05$. Feature importance analysis established direct quantitative links, revealing that nuclear solidity and eccentricity were the dominant predictors for TP53 mutation. These findings validate that quantifiable histological phenotypes encode measurable genomic signals, paving the way for cost-effective, precision histopathology in ovarian cancer triage and diagnosis.",Bioinformatics
"Ovarian cancer remains one of the most lethal gynecological malignancies, largely due to late diagnosis and extensive heterogeneity across subtypes. Current diagnostic methods are limited in their ability to reveal underlying genomic variations essential for precision oncology. This study introduces a novel hybrid deep learning pipeline that integrates quantitative nuclear morphometry with deep convolutional image features to perform ovarian cancer subtype classification and gene mutation inference directly from Hematoxylin and Eosin (H&E) histopathological images. Using $\sim45,000$ image patches sourced from The Cancer Genome Atlas (TCGA) and public datasets, a fusion model combining a ResNet-50 Convolutional Neural Network (CNN) encoder and a Vision Transformer (ViT) was developed. This model successfully captured both local morphological texture and global tissue context. The pipeline achieved a robust overall subtype classification accuracy of $84.2\%$ (Macro AUC of $0.87 \pm 0.03$). Crucially, the model demonstrated the capacity for gene mutation inference with moderate-to-high accuracy: $AUC_{TP53} = 0.82 \pm 0.02$, $AUC_{BRCA1} = 0.76 \pm 0.04$, and $AUC_{ARID1A} = 0.73 \pm 0.05$. Feature importance analysis established direct quantitative links, revealing that nuclear solidity and eccentricity were the dominant predictors for TP53 mutation. These findings validate that quantifiable histological phenotypes encode measurable genomic signals, paving the way for cost-effective, precision histopathology in ovarian cancer triage and diagnosis. [SEP] [HINT] tissue -> Bioinformatics (Syns: tissue paper, weave) | features -> Bioinformatics (Syns: characteristic, lineament, feature of speech) | learning -> Bioinformatics (Syns: take, teach, acquire)",Bioinformatics
"Quantitatively characterizing the spatial organization of cells and their interaction is essential for understanding cancer progression and immune response. Recent advances in machine intelligence have enabled large-scale segmentation and classification of cell nuclei from digitized histopathology slides, generating massive point pattern and marked point pattern datasets. However, accessible tools for quantitative analysis of such complex cellular spatial organization remain limited. In this paper, we first review 27 traditional spatial summary statistics, areal indices, and topological features applicable to point pattern data. Then, we introduce SASHIMI (Spatial Analysis for Segmented Histopathology Images using Machine Intelligence), a browser-based tool for real-time spatial analysis of artificial intelligence (AI)-segmented histopathology images. SASHIMI computes a comprehensive suite of mathematically grounded descriptors, including spatial statistics, proximity-based measures, grid-level similarity indices, spatial autocorrelation measures, and topological descriptors, to quantify cellular abundance and cell-cell interaction. Applied to two cancer datasets, oral potentially malignant disorders (OPMD) and non-small-cell lung cancer (NSCLC), SASHIMI identified multiple spatial features significantly associated with patient survival outcomes. SASHIMI provides an accessible and reproducible platform for single-cell-level spatial profiling of tumor morphological architecture, offering a robust framework for quantitative exploration of tissue organization across cancer types.",Bioinformatics
"Quantitatively characterizing the spatial organization of cells and their interaction is essential for understanding cancer progression and immune response. Recent advances in machine intelligence have enabled large-scale segmentation and classification of cell nuclei from digitized histopathology slides, generating massive point pattern and marked point pattern datasets. However, accessible tools for quantitative analysis of such complex cellular spatial organization remain limited. In this paper, we first review 27 traditional spatial summary statistics, areal indices, and topological features applicable to point pattern data. Then, we introduce SASHIMI (Spatial Analysis for Segmented Histopathology Images using Machine Intelligence), a browser-based tool for real-time spatial analysis of artificial intelligence (AI)-segmented histopathology images. SASHIMI computes a comprehensive suite of mathematically grounded descriptors, including spatial statistics, proximity-based measures, grid-level similarity indices, spatial autocorrelation measures, and topological descriptors, to quantify cellular abundance and cell-cell interaction. Applied to two cancer datasets, oral potentially malignant disorders (OPMD) and non-small-cell lung cancer (NSCLC), SASHIMI identified multiple spatial features significantly associated with patient survival outcomes. SASHIMI provides an accessible and reproducible platform for single-cell-level spatial profiling of tumor morphological architecture, offering a robust framework for quantitative exploration of tissue organization across cancer types. [SEP] [HINT] tissue -> Bioinformatics (Syns: tissue paper, weave) | features -> Bioinformatics (Syns: characteristic, lineament, feature of speech) | understanding -> Neuroscience (Syns: savvy, intellect, sympathy)",Bioinformatics
"In threshold-linear networks (TLNs), a fixed point is called minimal if no proper subset of its support is also a fixed point. Curto et al (Advances in Applied Mathematics, 2024) conjectured that every stable fixed point of any TLN must be a minimal fixed point. We provide a counterexample to this conjecture: an explicit competitive TLN on 3 neurons that exhibits a stable fixed point whose support is not minimal (it contains the support of another stable fixed point). We prove that there is no competitive TLN on 2 neurons which contains a stable non-minimal fixed point, so our 3-neuron construction is the smallest such example. By expanding our base example, we show for any positive integers $i, j$ with $i < j-1$ that there exists a competitive TLN with stable fixed point supports $τ\subsetneq σ$ for which $|τ| = i$ and $|σ| = j$. Using a different expansion of our base example, we also show that chains of nested stable fixed points in competitive TLNs can be made arbitrarily long.",Neuroscience
"In threshold-linear networks (TLNs), a fixed point is called minimal if no proper subset of its support is also a fixed point. Curto et al (Advances in Applied Mathematics, 2024) conjectured that every stable fixed point of any TLN must be a minimal fixed point. We provide a counterexample to this conjecture: an explicit competitive TLN on 3 neurons that exhibits a stable fixed point whose support is not minimal (it contains the support of another stable fixed point). We prove that there is no competitive TLN on 2 neurons which contains a stable non-minimal fixed point, so our 3-neuron construction is the smallest such example. By expanding our base example, we show for any positive integers $i, j$ with $i < j-1$ that there exists a competitive TLN with stable fixed point supports $τ\subsetneq σ$ for which $|τ| = i$ and $|σ| = j$. Using a different expansion of our base example, we also show that chains of nested stable fixed points in competitive TLNs can be made arbitrarily long. [SEP] [HINT] networks -> Neuroscience (Syns: network, meshwork, electronic network) | different -> Neuroscience (Syns: unlike, dissimilar) | using -> Bioinformatics (Syns: utilize, exploitation, apply)",Neuroscience
"Natural systems are remarkably robust and resilient, maintaining essential functions despite variability, uncertainty, and hostile conditions. Understanding these nonlinear, dynamic behaviours is challenging because such systems involve many interacting parameters, yet it is crucial for explaining processes from cellular regulation to disease onset and epidemic spreading. Robustness and resilience describe a system's ability to preserve and recover desired behaviours in the presence of intrinsic and extrinsic fluctuations. This survey reviews how different disciplines define these concepts, examines methods for assessing whether key properties of uncertain, networked dynamical systems are structural (parameter-free) or robust (preserved for parameter variations within an uncertainty bounding set), and discusses integrated structural and probabilistic techniques for biological and epidemiological models. The text introduces formal definitions of resilience for families of systems obtained by adding stochastic perturbations to a nominal deterministic model, enabling a probabilistic characterisation of the ability to remain within or return to a prescribed attractor. These definitions generalise probabilistic robustness and shed new light on classical biological examples. In addition, the survey summarises resilience indicators and data-driven tools for detecting resilience loss and regime shifts, drawing on bifurcation analysis to anticipate qualitative changes in system behaviour. Together, these methodologies support the study and control of complex natural systems, guiding the design of biomolecular feedback architectures, the identification of therapeutic targets, the forecasting and management of epidemics, and the detection of tipping points in ecological and biological networks.",Bioinformatics
"Natural systems are remarkably robust and resilient, maintaining essential functions despite variability, uncertainty, and hostile conditions. Understanding these nonlinear, dynamic behaviours is challenging because such systems involve many interacting parameters, yet it is crucial for explaining processes from cellular regulation to disease onset and epidemic spreading. Robustness and resilience describe a system's ability to preserve and recover desired behaviours in the presence of intrinsic and extrinsic fluctuations. This survey reviews how different disciplines define these concepts, examines methods for assessing whether key properties of uncertain, networked dynamical systems are structural (parameter-free) or robust (preserved for parameter variations within an uncertainty bounding set), and discusses integrated structural and probabilistic techniques for biological and epidemiological models. The text introduces formal definitions of resilience for families of systems obtained by adding stochastic perturbations to a nominal deterministic model, enabling a probabilistic characterisation of the ability to remain within or return to a prescribed attractor. These definitions generalise probabilistic robustness and shed new light on classical biological examples. In addition, the survey summarises resilience indicators and data-driven tools for detecting resilience loss and regime shifts, drawing on bifurcation analysis to anticipate qualitative changes in system behaviour. Together, these methodologies support the study and control of complex natural systems, guiding the design of biomolecular feedback architectures, the identification of therapeutic targets, the forecasting and management of epidemics, and the detection of tipping points in ecological and biological networks. [SEP] [HINT] understanding -> Neuroscience (Syns: savvy, intellect, sympathy) | complex -> Bioinformatics (Syns: building complex, coordination compound, composite) | systems -> Bioinformatics (Syns: organization, organisation, system)",Bioinformatics
"In control problems and basic scientific modeling, it is important to compare observations with dynamical simulations. For example, comparing two neural systems can shed light on the nature of emergent computations in the brain and deep neural networks. Recently, Ostrow et al. (2023) introduced Dynamical Similarity Analysis (DSA), a method to measure the similarity of two systems based on their recurrent dynamics rather than geometry or topology. However, DSA does not consider how inputs affect the dynamics, meaning that two similar systems, if driven differently, may be classified as different. Because real-world dynamical systems are rarely autonomous, it is important to account for the effects of input drive. To this end, we introduce a novel metric for comparing both intrinsic (recurrent) and input-driven dynamics, called InputDSA (iDSA). InputDSA extends the DSA framework by estimating and comparing both input and intrinsic dynamic operators using a variant of Dynamic Mode Decomposition with control (DMDc) based on subspace identification. We demonstrate that InputDSA can successfully compare partially observed, input-driven systems from noisy data. We show that when the true inputs are unknown, surrogate inputs can be substituted without a major deterioration in similarity estimates. We apply InputDSA on Recurrent Neural Networks (RNNs) trained with Deep Reinforcement Learning, identifying that high-performing networks are dynamically similar to one another, while low-performing networks are more diverse. Lastly, we apply InputDSA to neural data recorded from rats performing a cognitive task, demonstrating that it identifies a transition from input-driven evidence accumulation to intrinsically-driven decision-making. Our work demonstrates that InputDSA is a robust and efficient method for comparing intrinsic dynamics and the effect of external input on dynamical systems.",Bioinformatics
"In control problems and basic scientific modeling, it is important to compare observations with dynamical simulations. For example, comparing two neural systems can shed light on the nature of emergent computations in the brain and deep neural networks. Recently, Ostrow et al. (2023) introduced Dynamical Similarity Analysis (DSA), a method to measure the similarity of two systems based on their recurrent dynamics rather than geometry or topology. However, DSA does not consider how inputs affect the dynamics, meaning that two similar systems, if driven differently, may be classified as different. Because real-world dynamical systems are rarely autonomous, it is important to account for the effects of input drive. To this end, we introduce a novel metric for comparing both intrinsic (recurrent) and input-driven dynamics, called InputDSA (iDSA). InputDSA extends the DSA framework by estimating and comparing both input and intrinsic dynamic operators using a variant of Dynamic Mode Decomposition with control (DMDc) based on subspace identification. We demonstrate that InputDSA can successfully compare partially observed, input-driven systems from noisy data. We show that when the true inputs are unknown, surrogate inputs can be substituted without a major deterioration in similarity estimates. We apply InputDSA on Recurrent Neural Networks (RNNs) trained with Deep Reinforcement Learning, identifying that high-performing networks are dynamically similar to one another, while low-performing networks are more diverse. Lastly, we apply InputDSA to neural data recorded from rats performing a cognitive task, demonstrating that it identifies a transition from input-driven evidence accumulation to intrinsically-driven decision-making. Our work demonstrates that InputDSA is a robust and efficient method for comparing intrinsic dynamics and the effect of external input on dynamical systems. [SEP] [HINT] transition -> Materials Science (Syns: passage, modulation, changeover) | based -> Bioinformatics (Syns: ground, free-base, base) | networks -> Neuroscience (Syns: network, meshwork, electronic network)",Bioinformatics
"Cyclic thermal loads imposed on a W divertor by strikepoint sweeping may induce low-cycle thermal fatigue cracking of its plasma-facing surfaces. This cracking may be accelerated by plasma-material interactions such as H implantation, blistering, fuzz and void formation. Fatigue cracking may also synergise with ELM cracking. To explore these novel forms of environmentally assisted fatigue, FEA modelling was used to design a uniaxial fatigue experiment for Magnum-PSI that represents strikepoint sweeping at 1 Hz across a 100 mm span of a divertor target. Magnum-PSI was used to combine cyclic thermal loading of W with H implantation and two forms of ELM like pre-cracking. Quantitative SEM analysis of fatigue-cracked W revealed that H implantation significantly delayed crack initiation, with preimplanted targets requiring 450-600 cycles before failure compared to 150 cycles for non-implanted samples. This was attributed to hydrogen-induced dislocation pinning, which produces a case-hardening effect that inhibits persistent slip band formation. ELM-like pre-cracking combined with strikepoint sweeping was found to give rise to localised melting and the formation of 30 micromete diameter droplets, caused by thermal isolation of W regions by fatigue cracks. The implications for the fatigue lifetime of tokamak divertors are also discussed.",Materials Science
"Cyclic thermal loads imposed on a W divertor by strikepoint sweeping may induce low-cycle thermal fatigue cracking of its plasma-facing surfaces. This cracking may be accelerated by plasma-material interactions such as H implantation, blistering, fuzz and void formation. Fatigue cracking may also synergise with ELM cracking. To explore these novel forms of environmentally assisted fatigue, FEA modelling was used to design a uniaxial fatigue experiment for Magnum-PSI that represents strikepoint sweeping at 1 Hz across a 100 mm span of a divertor target. Magnum-PSI was used to combine cyclic thermal loading of W with H implantation and two forms of ELM like pre-cracking. Quantitative SEM analysis of fatigue-cracked W revealed that H implantation significantly delayed crack initiation, with preimplanted targets requiring 450-600 cycles before failure compared to 150 cycles for non-implanted samples. This was attributed to hydrogen-induced dislocation pinning, which produces a case-hardening effect that inhibits persistent slip band formation. ELM-like pre-cracking combined with strikepoint sweeping was found to give rise to localised melting and the formation of 30 micromete diameter droplets, caused by thermal isolation of W regions by fatigue cracks. The implications for the fatigue lifetime of tokamak divertors are also discussed. [SEP] [HINT] used -> Bioinformatics (Syns: utilize, ill-used, apply) | band -> Materials Science (Syns: set, stria, dance orchestra) | thermal -> Materials Science (Syns: thermic, caloric)",Materials Science
"Learning a compact representation of history is critical for planning and generalization in partially observable environments. While meta-reinforcement learning (RL) agents can attain near Bayes-optimal policies, they often fail to learn the compact, interpretable Bayes-optimal belief states. This representational inefficiency potentially limits the agent's adaptability and generalization capacity. Inspired by predictive coding in neuroscience--which suggests that the brain predicts sensory inputs as a neural implementation of Bayesian inference--and by auxiliary predictive objectives in deep RL, we investigate whether integrating self-supervised predictive coding modules into meta-RL can facilitate learning of Bayes-optimal representations. Through state machine simulation, we show that meta-RL with predictive modules consistently generates more interpretable representations that better approximate Bayes-optimal belief states compared to conventional meta-RL across a wide variety of tasks, even when both achieve optimal policies. In challenging tasks requiring active information seeking, only meta-RL with predictive modules successfully learns optimal representations and policies, whereas conventional meta-RL struggles with inadequate representation learning. Finally, we demonstrate that better representation learning leads to improved generalization. Our results strongly suggest the role of predictive learning as a guiding principle for effective representation learning in agents navigating partial observability.",Neuroscience
"Learning a compact representation of history is critical for planning and generalization in partially observable environments. While meta-reinforcement learning (RL) agents can attain near Bayes-optimal policies, they often fail to learn the compact, interpretable Bayes-optimal belief states. This representational inefficiency potentially limits the agent's adaptability and generalization capacity. Inspired by predictive coding in neuroscience--which suggests that the brain predicts sensory inputs as a neural implementation of Bayesian inference--and by auxiliary predictive objectives in deep RL, we investigate whether integrating self-supervised predictive coding modules into meta-RL can facilitate learning of Bayes-optimal representations. Through state machine simulation, we show that meta-RL with predictive modules consistently generates more interpretable representations that better approximate Bayes-optimal belief states compared to conventional meta-RL across a wide variety of tasks, even when both achieve optimal policies. In challenging tasks requiring active information seeking, only meta-RL with predictive modules successfully learns optimal representations and policies, whereas conventional meta-RL struggles with inadequate representation learning. Finally, we demonstrate that better representation learning leads to improved generalization. Our results strongly suggest the role of predictive learning as a guiding principle for effective representation learning in agents navigating partial observability. [SEP] [HINT] tasks -> Neuroscience (Syns: tax, task, project) | learning -> Bioinformatics (Syns: take, teach, acquire) | information -> Bioinformatics (Syns: entropy, data, info)",Neuroscience
"Vapor-pressure-mismatched materials, such as transition metal chalcogenides, have emerged as key electronic, photonic, and quantum materials. Hybrid pulsed laser deposition (hPLD) has become a preferred method for epitaxial or textured growth of these materials; however, unintentional carbon (C) incorporation remains a persistent concern, particularly when using organic chalcogen precursors as safer alternatives to toxic hydrides. The mechanisms governing C incorporation and its impact on film growth and properties in hPLD remain poorly understood. Here, we investigate the influence of C-containing side products generated from organosulfur precursor pyrolysis on ZnS, BaTiS$_3$, and TiS$_2$ thin films grown by hPLD using tert-butyl disulfide (TBDS). Structural characterization via X-ray diffraction and atomic force microscopy, combined with secondary ion mass spectrometry, is used to systematically examine the effects of growth temperature and TBDS partial pressure on film morphology, crystallinity, and C incorporation. Optimal growth temperatures of 400°C, 500°C, and 700°C are identified for ZnS, TiS$_2$, and BaTiS$_3$, respectively. Growth above or below these temperatures leads to increased C incorporation at both the interface and within the film, correlating with degraded texture. In contrast, highly textured films exhibit minimal C content, comparable to films grown without TBDS. For TiS$_2$, C incorporation depends strongly on TBDS pressure, with 10$^{-1}$ Pa identified as the optimal pressure for minimizing contamination. At higher pressures, loss of preferential texture is observed, likely due to C graphitization poisoning the interface and bulk. These results provide new insight into process-induced C impurities in hPLD-grown chalcogenide thin films and have important implications for sulfide-based thin film technologies.",Materials Science
"Vapor-pressure-mismatched materials, such as transition metal chalcogenides, have emerged as key electronic, photonic, and quantum materials. Hybrid pulsed laser deposition (hPLD) has become a preferred method for epitaxial or textured growth of these materials; however, unintentional carbon (C) incorporation remains a persistent concern, particularly when using organic chalcogen precursors as safer alternatives to toxic hydrides. The mechanisms governing C incorporation and its impact on film growth and properties in hPLD remain poorly understood. Here, we investigate the influence of C-containing side products generated from organosulfur precursor pyrolysis on ZnS, BaTiS$_3$, and TiS$_2$ thin films grown by hPLD using tert-butyl disulfide (TBDS). Structural characterization via X-ray diffraction and atomic force microscopy, combined with secondary ion mass spectrometry, is used to systematically examine the effects of growth temperature and TBDS partial pressure on film morphology, crystallinity, and C incorporation. Optimal growth temperatures of 400°C, 500°C, and 700°C are identified for ZnS, TiS$_2$, and BaTiS$_3$, respectively. Growth above or below these temperatures leads to increased C incorporation at both the interface and within the film, correlating with degraded texture. In contrast, highly textured films exhibit minimal C content, comparable to films grown without TBDS. For TiS$_2$, C incorporation depends strongly on TBDS pressure, with 10$^{-1}$ Pa identified as the optimal pressure for minimizing contamination. At higher pressures, loss of preferential texture is observed, likely due to C graphitization poisoning the interface and bulk. These results provide new insight into process-induced C impurities in hPLD-grown chalcogenide thin films and have important implications for sulfide-based thin film technologies. [SEP] [HINT] used -> Bioinformatics (Syns: utilize, ill-used, apply) | transition -> Materials Science (Syns: passage, modulation, changeover) | results -> Bioinformatics (Syns: final result, consequence, resultant role)",Materials Science
"The structural and magnetic properties of the two-dimensional spin-$1/2$ depleted-kagome compound Cu$_7$(TeO$_3$)$_2$(SO$_4$)$_2$(OH)$_6$ are investigated using x-ray diffraction, magnetization, heat capacity, and $^1$H Nuclear Magnetic Resonance (NMR) measurements. From the analysis of magnetic susceptibility, we found a large Curie-Weiss temperature [$θ_{\rm CW} = -50(2)$ K] and the co-existence of antiferromagnetic and ferromagnetic interactions. The value of $θ_{\rm CW}$ gives an estimate of the average nearest-neighbour antiferromagnetic interaction of $J/k_{\rm B} \simeq 66$ K. The NMR relaxation rates ($1/T_1$ and $1/T_2$) exhibit a peak, providing evidence for a magnetic long-range order at $T^*\simeq 4$ K which appears to be canted antiferromagnetic type. Heat capacity also features a broad maximum at $T^*$ that moves towards higher temperatures with increasing magnetic field, reflecting defect induced Schottky anomaly. The frustration parameter $f_r = \lvert θ_{\rm CW} \lvert/{T^{*}}\simeq 12.5$ renders the compound a highly frustrated low-dimensional magnet.",Materials Science
"The structural and magnetic properties of the two-dimensional spin-$1/2$ depleted-kagome compound Cu$_7$(TeO$_3$)$_2$(SO$_4$)$_2$(OH)$_6$ are investigated using x-ray diffraction, magnetization, heat capacity, and $^1$H Nuclear Magnetic Resonance (NMR) measurements. From the analysis of magnetic susceptibility, we found a large Curie-Weiss temperature [$θ_{\rm CW} = -50(2)$ K] and the co-existence of antiferromagnetic and ferromagnetic interactions. The value of $θ_{\rm CW}$ gives an estimate of the average nearest-neighbour antiferromagnetic interaction of $J/k_{\rm B} \simeq 66$ K. The NMR relaxation rates ($1/T_1$ and $1/T_2$) exhibit a peak, providing evidence for a magnetic long-range order at $T^*\simeq 4$ K which appears to be canted antiferromagnetic type. Heat capacity also features a broad maximum at $T^*$ that moves towards higher temperatures with increasing magnetic field, reflecting defect induced Schottky anomaly. The frustration parameter $f_r = \lvert θ_{\rm CW} \lvert/{T^{*}}\simeq 12.5$ renders the compound a highly frustrated low-dimensional magnet. [SEP] [HINT] features -> Bioinformatics (Syns: characteristic, lineament, feature of speech) | defect -> Materials Science (Syns: mar, shortcoming, fault) | order -> Materials Science (Syns: enjoin, dictate, social club)",Materials Science
"The gut microbiota has emerged as a fundamental regulator of sleep physiology, influencing neural, endocrine, and immune pathways through the gut-microbiota-brain axis (GMBA). This bidirectional communication system modulates neurotransmitter production, circadian rhythms, and metabolic homeostasis, while disruptions in microbial composition have been linked to sleep disorders, neuroinflammation, and systemic immune dysfunction. Recent findings suggest that gut dysbiosis contributes to sleep disturbances by altering serotonin, GABA, and short-chain fatty acid (SCFA) metabolism, with implications for neurodegenerative diseases, metabolic syndromes, and mood disorders. Additionally, the gut microbiota interacts with the endocrine and immune systems, shaping inflammatory responses and stress adaptation mechanisms. This review explores the intricate connections between sleep and the gut microbiota, integrating emerging research on microbiota-targeted therapies, such as probiotics, fecal microbiota transplantation (FMT), and chrononutrition, as potential interventions to restore sleep homeostasis and improve health outcomes",Neuroscience
"The gut microbiota has emerged as a fundamental regulator of sleep physiology, influencing neural, endocrine, and immune pathways through the gut-microbiota-brain axis (GMBA). This bidirectional communication system modulates neurotransmitter production, circadian rhythms, and metabolic homeostasis, while disruptions in microbial composition have been linked to sleep disorders, neuroinflammation, and systemic immune dysfunction. Recent findings suggest that gut dysbiosis contributes to sleep disturbances by altering serotonin, GABA, and short-chain fatty acid (SCFA) metabolism, with implications for neurodegenerative diseases, metabolic syndromes, and mood disorders. Additionally, the gut microbiota interacts with the endocrine and immune systems, shaping inflammatory responses and stress adaptation mechanisms. This review explores the intricate connections between sleep and the gut microbiota, integrating emerging research on microbiota-targeted therapies, such as probiotics, fecal microbiota transplantation (FMT), and chrononutrition, as potential interventions to restore sleep homeostasis and improve health outcomes [SEP] [HINT] potential -> Bioinformatics (Syns: voltage, potential difference, electric potential) | findings -> Neuroscience (Syns: determination, finding)",Neuroscience
"Multi-view pose estimation is essential for quantifying animal behavior in scientific research, yet current methods struggle to achieve accurate tracking with limited labeled data and suffer from poor uncertainty estimates. We address these challenges with a comprehensive framework combining novel training and post-processing techniques, and a model distillation procedure that leverages the strengths of these techniques to produce a more efficient and effective pose estimator. Our multi-view transformer (MVT) utilizes pretrained backbones and enables simultaneous processing of information across all views, while a novel patch masking scheme learns robust cross-view correspondences without camera calibration. For calibrated setups, we incorporate geometric consistency through 3D augmentation and a triangulation loss. We extend the existing Ensemble Kalman Smoother (EKS) post-processor to the nonlinear case and enhance uncertainty quantification via a variance inflation technique. Finally, to leverage the scaling properties of the MVT, we design a distillation procedure that exploits improved EKS predictions and uncertainty estimates to generate high-quality pseudo-labels, thereby reducing dependence on manual labels. Our framework components consistently outperform existing methods across three diverse animal species (flies, mice, chickadees), with each component contributing complementary benefits. The result is a practical, uncertainty-aware system for reliable pose estimation that enables downstream behavioral analyses under real-world data constraints.",Bioinformatics
"Multi-view pose estimation is essential for quantifying animal behavior in scientific research, yet current methods struggle to achieve accurate tracking with limited labeled data and suffer from poor uncertainty estimates. We address these challenges with a comprehensive framework combining novel training and post-processing techniques, and a model distillation procedure that leverages the strengths of these techniques to produce a more efficient and effective pose estimator. Our multi-view transformer (MVT) utilizes pretrained backbones and enables simultaneous processing of information across all views, while a novel patch masking scheme learns robust cross-view correspondences without camera calibration. For calibrated setups, we incorporate geometric consistency through 3D augmentation and a triangulation loss. We extend the existing Ensemble Kalman Smoother (EKS) post-processor to the nonlinear case and enhance uncertainty quantification via a variance inflation technique. Finally, to leverage the scaling properties of the MVT, we design a distillation procedure that exploits improved EKS predictions and uncertainty estimates to generate high-quality pseudo-labels, thereby reducing dependence on manual labels. Our framework components consistently outperform existing methods across three diverse animal species (flies, mice, chickadees), with each component contributing complementary benefits. The result is a practical, uncertainty-aware system for reliable pose estimation that enables downstream behavioral analyses under real-world data constraints. [SEP] [HINT] information -> Bioinformatics (Syns: entropy, data, info) | processing -> Neuroscience (Syns: work, process, march) | framework -> Bioinformatics (Syns: theoretical account, model, fabric)",Bioinformatics
"Understanding how dielectric anisotropy governs excitonic behavior in two-dimensional (2D) halide perovskites is critical for predicting and engineering their optoelectronic properties. In this work, we investigate Cs(n+1)PbnBr3n+1 nanoplatelets (n = 2-5) experimentally and theoretically and show that the interplay between dielectric confinement and anisotropic screening critically determines both their electronic structure and excitonic landscape. To incorporate the dielectric screening effects, the Coulomb kernel in the Fock exchange term is refined using a model dielectric function together with a model Bethe-Salpeter Equation approach. The exciton binding energies show a monotonic decrease from 0.26 eV to 0.21 eV from n = 2 to 5, with 20 meV decrease per layer up to n = 4, and thereafter less change. The relatively small change per layer is a consequence of the strong spatial localization of excitons. By analyzing directionally resolved dielectric tensors, we demonstrate that the in-plane dielectric constant predominantly dictates optical transitions and is close to converging to the bulk value already at n = 5, while the out-of-plane dielectric response reflects the confined nature of excitonic wave functions as expected. Our calculated absorption spectra capture experimental results within 0.02 eV throughout the confinement regime (n = 2-5). The effects of lattice dynamics on the dimensionally dependent dielectric response and subsequent exciton screening occurring on longer time-scales than the optical response are also analyzed, important for analysis and interpretation of exciton lifetime, diffusion, and band alignments. The results establish a clear correlation between dielectric anisotropy, electronic structure, and exciton binding energy at different timescales in layered perovskites, providing essential insight for the design of 2D optoelectronic materials and devices.",Materials Science
"Understanding how dielectric anisotropy governs excitonic behavior in two-dimensional (2D) halide perovskites is critical for predicting and engineering their optoelectronic properties. In this work, we investigate Cs(n+1)PbnBr3n+1 nanoplatelets (n = 2-5) experimentally and theoretically and show that the interplay between dielectric confinement and anisotropic screening critically determines both their electronic structure and excitonic landscape. To incorporate the dielectric screening effects, the Coulomb kernel in the Fock exchange term is refined using a model dielectric function together with a model Bethe-Salpeter Equation approach. The exciton binding energies show a monotonic decrease from 0.26 eV to 0.21 eV from n = 2 to 5, with 20 meV decrease per layer up to n = 4, and thereafter less change. The relatively small change per layer is a consequence of the strong spatial localization of excitons. By analyzing directionally resolved dielectric tensors, we demonstrate that the in-plane dielectric constant predominantly dictates optical transitions and is close to converging to the bulk value already at n = 5, while the out-of-plane dielectric response reflects the confined nature of excitonic wave functions as expected. Our calculated absorption spectra capture experimental results within 0.02 eV throughout the confinement regime (n = 2-5). The effects of lattice dynamics on the dimensionally dependent dielectric response and subsequent exciton screening occurring on longer time-scales than the optical response are also analyzed, important for analysis and interpretation of exciton lifetime, diffusion, and band alignments. The results establish a clear correlation between dielectric anisotropy, electronic structure, and exciton binding energy at different timescales in layered perovskites, providing essential insight for the design of 2D optoelectronic materials and devices. [SEP] [HINT] understanding -> Neuroscience (Syns: savvy, intellect, sympathy) | electronic -> Materials Science (Syns: ) | structure -> Bioinformatics (Syns: social system, complex body part, social structure)",Materials Science
"Dislocations and polishing-induced defect networks in synthetic diamond generate local strain fields that broaden Raman features and limit optical, thermal, and electronic performance. Sub-melt laser annealing has emerged as a route to repair near-surface defects without graphitization, yet quantitative evidence of densification, defect depletion, and property recovery remains limited. Here, we show that nanosecond pulsed-laser annealing (PLA) can relax dislocation-associated strain in single-crystal CVD diamond by compacting and reorganizing the damaged near-surface region. Single- and two-pulse PLA were applied, and structural evolution was quantified using co-registered ISO 25178 white-light interferometry, depth-resolved Raman spectroscopy, and cross-sectional STEM with geometric phase analysis (GPA). Across a 5x6 grid(n = 30), responsive regions show large reductions in local slope (Sdq 45-65%), developed area (Sdr 60-90%), height spread (Sp, Sz 30-65%), void volume (Vv 57-60%), and roughness amplitude (Sa, Sq 48-57%), consistent with densification of ~4-6.5 nm. Raman profiling reveals narrowing of the diamond line and improved spectral uniformity to depths of ~2-3 μm, indicating relaxation of dislocation-mediated strain beyond the compaction layer. STEM-GPA strain maps confirm smoother strain fields, reduced hotspots, and redistribution of localized strain concentrations after PLA. These results show that sub-melt PLA reduces dislocation-driven strain by compacting surface-connected free volume and reorganizing defect networks. The approach provides a scalable path to upgrade industrial-grade diamond including homoepitaxial, heteroepitaxial, and polycrystalline CVD to low-defect, device-ready surfaces relevant to high-power electronics, photonics, and quantum substrates.",Materials Science
"Dislocations and polishing-induced defect networks in synthetic diamond generate local strain fields that broaden Raman features and limit optical, thermal, and electronic performance. Sub-melt laser annealing has emerged as a route to repair near-surface defects without graphitization, yet quantitative evidence of densification, defect depletion, and property recovery remains limited. Here, we show that nanosecond pulsed-laser annealing (PLA) can relax dislocation-associated strain in single-crystal CVD diamond by compacting and reorganizing the damaged near-surface region. Single- and two-pulse PLA were applied, and structural evolution was quantified using co-registered ISO 25178 white-light interferometry, depth-resolved Raman spectroscopy, and cross-sectional STEM with geometric phase analysis (GPA). Across a 5x6 grid(n = 30), responsive regions show large reductions in local slope (Sdq 45-65%), developed area (Sdr 60-90%), height spread (Sp, Sz 30-65%), void volume (Vv 57-60%), and roughness amplitude (Sa, Sq 48-57%), consistent with densification of ~4-6.5 nm. Raman profiling reveals narrowing of the diamond line and improved spectral uniformity to depths of ~2-3 μm, indicating relaxation of dislocation-mediated strain beyond the compaction layer. STEM-GPA strain maps confirm smoother strain fields, reduced hotspots, and redistribution of localized strain concentrations after PLA. These results show that sub-melt PLA reduces dislocation-driven strain by compacting surface-connected free volume and reorganizing defect networks. The approach provides a scalable path to upgrade industrial-grade diamond including homoepitaxial, heteroepitaxial, and polycrystalline CVD to low-defect, device-ready surfaces relevant to high-power electronics, photonics, and quantum substrates. [SEP] [HINT] features -> Bioinformatics (Syns: characteristic, lineament, feature of speech) | networks -> Neuroscience (Syns: network, meshwork, electronic network) | defect -> Materials Science (Syns: mar, shortcoming, fault)",Materials Science
"Application of machine learning techniques enables segmentation of functional tissue units in histology whole-slide images (WSIs). We built a pipeline to apply previously validated segmentation models of kidney structures and extract quantitative features from these structures. Such quantitative analysis also requires qualitative inspection of results for quality control, exploration, and communication. We extend the Vitessce web-based visualization tool to enable visualization of segmentations of multiple types of functional tissue units, such as, glomeruli, tubules, arteries/arterioles in the kidney. Moreover, we propose a standard representation for files containing multiple segmentation bitmasks, which we define polymorphically, such that existing formats including OME-TIFF, OME-NGFF, AnnData, MuData, and SpatialData can be used. We demonstrate that these methods enable researchers and the broader public to interactively explore datasets containing multiple segmented entities and associated features, including for exploration of renal morphometry of biopsies from the Kidney Precision Medicine Project (KPMP) and the Human Biomolecular Atlas Program (HuBMAP).",Bioinformatics
"Application of machine learning techniques enables segmentation of functional tissue units in histology whole-slide images (WSIs). We built a pipeline to apply previously validated segmentation models of kidney structures and extract quantitative features from these structures. Such quantitative analysis also requires qualitative inspection of results for quality control, exploration, and communication. We extend the Vitessce web-based visualization tool to enable visualization of segmentations of multiple types of functional tissue units, such as, glomeruli, tubules, arteries/arterioles in the kidney. Moreover, we propose a standard representation for files containing multiple segmentation bitmasks, which we define polymorphically, such that existing formats including OME-TIFF, OME-NGFF, AnnData, MuData, and SpatialData can be used. We demonstrate that these methods enable researchers and the broader public to interactively explore datasets containing multiple segmented entities and associated features, including for exploration of renal morphometry of biopsies from the Kidney Precision Medicine Project (KPMP) and the Human Biomolecular Atlas Program (HuBMAP). [SEP] [HINT] tissue -> Bioinformatics (Syns: tissue paper, weave) | features -> Bioinformatics (Syns: characteristic, lineament, feature of speech) | learning -> Bioinformatics (Syns: take, teach, acquire)",Bioinformatics
"The unprecedented extension of the human lifespan necessitates a parallel evolution in how we quantify the quality of aging and its socioeconomic impact. Traditional metrics focusing on Healthspan (years free of disease) overlook the gradual erosion of physiological capacity that occurs even in the absence of illness, leading to declines in productivity and eventual lack of capacity to work. To address this critical gap, we introduce Peakspan: the age interval during which an individual maintains at least 90% of their peak functional performance in a specific physiological or cognitive domain. Our multi-system analysis reveals a profound misalignment: most biological systems reach maximal capacity in early adulthood, resulting in a Peakspan that is remarkably short relative to the total lifespan. This dissociation means humans now spend the majority of their adult lives in a ""healthy but declined"" state, characterized by a significant functional gap. We argue that extending Peakspan and developing strategies to restore function in post-peak individuals is the functional manifestation of rejuvenative biomedical progress and is essential for sustained economic growth in aging societies. Recognizing and tracking Peakspan, increasingly facilitated by artificial intelligence and foundational models of biological aging, is crucial for developing strategies to compress functional morbidity and maximize human potential across the life course.",Bioinformatics
"The unprecedented extension of the human lifespan necessitates a parallel evolution in how we quantify the quality of aging and its socioeconomic impact. Traditional metrics focusing on Healthspan (years free of disease) overlook the gradual erosion of physiological capacity that occurs even in the absence of illness, leading to declines in productivity and eventual lack of capacity to work. To address this critical gap, we introduce Peakspan: the age interval during which an individual maintains at least 90% of their peak functional performance in a specific physiological or cognitive domain. Our multi-system analysis reveals a profound misalignment: most biological systems reach maximal capacity in early adulthood, resulting in a Peakspan that is remarkably short relative to the total lifespan. This dissociation means humans now spend the majority of their adult lives in a ""healthy but declined"" state, characterized by a significant functional gap. We argue that extending Peakspan and developing strategies to restore function in post-peak individuals is the functional manifestation of rejuvenative biomedical progress and is essential for sustained economic growth in aging societies. Recognizing and tracking Peakspan, increasingly facilitated by artificial intelligence and foundational models of biological aging, is crucial for developing strategies to compress functional morbidity and maximize human potential across the life course. [SEP] [HINT] functional -> Neuroscience (Syns: working, usable, running) | quality -> Bioinformatics (Syns: lineament, tone, calibre) | performance -> Bioinformatics (Syns: functioning, operation, carrying out)",Bioinformatics
"A15 superconductors are distinguished by their high critical temperatures, magnetic fields, and current-carrying capabilities. Among them, Nb$_3$Al is of particular interest for superconducting quantum circuits as a means to extend device operating temperatures, provided that its electrodynamic properties are well understood. Here, we report on the synthesis of Nb$_3$Al thin films by magnetron co-sputtering followed by rapid thermal processing, yielding superconducting transition temperatures above 16~K. Microwire devices patterned from these films exhibit a coherence length of $3.2\,\mathrm{nm}$ and superfluid densities as low as $1.1\times 10^{26}\,\mathrm{m}^{-3}$, suggesting that Nb$_3$Al may enable high kinetic inductance in thinner films. Coplanar waveguide resonators fabricated on Nb$_3$Al demonstrate single-photon internal quality factors up to $2.26\times 10^{5}$. These results establish Nb$_3$Al as a promising material platform for the development of superconducting quantum circuits operating at elevated temperatures, contingent on appropriate control of interfacial chemistry and surface morphology.",Materials Science
"A15 superconductors are distinguished by their high critical temperatures, magnetic fields, and current-carrying capabilities. Among them, Nb$_3$Al is of particular interest for superconducting quantum circuits as a means to extend device operating temperatures, provided that its electrodynamic properties are well understood. Here, we report on the synthesis of Nb$_3$Al thin films by magnetron co-sputtering followed by rapid thermal processing, yielding superconducting transition temperatures above 16~K. Microwire devices patterned from these films exhibit a coherence length of $3.2\,\mathrm{nm}$ and superfluid densities as low as $1.1\times 10^{26}\,\mathrm{m}^{-3}$, suggesting that Nb$_3$Al may enable high kinetic inductance in thinner films. Coplanar waveguide resonators fabricated on Nb$_3$Al demonstrate single-photon internal quality factors up to $2.26\times 10^{5}$. These results establish Nb$_3$Al as a promising material platform for the development of superconducting quantum circuits operating at elevated temperatures, contingent on appropriate control of interfacial chemistry and surface morphology. [SEP] [HINT] transition -> Materials Science (Syns: passage, modulation, changeover) | low -> Materials Science (Syns: low-spirited, scurvy, depressed) | quality -> Bioinformatics (Syns: lineament, tone, calibre)",Materials Science
"Collective behavior pervades biological systems, from flocks of birds to neural assemblies and human societies. Yet, how such collectives acquire functional properties -- such as joint agency or knowledge -- that transcend those of their individual components remains an open question. Here, we combine active inference and information-theoretic analyses to explore how a minimal system of interacting agents can give rise to joint agency and collective knowledge. We model flocking dynamics using multiple active inference agents, each minimizing its own free energy while coupling reciprocally with its neighbors. We show that as agents self-organize, their interactions define higher-order statistical boundaries (Markov blankets) enclosing a ``flock'' that can be treated as an emergent agent with its own sensory, active, and internal states. When exposed to external perturbations (a ``predator''), the flock exhibits faster, coordinated responses than individual agents, reflecting collective sensitivity to environmental change. Crucially, analyses of synergistic information reveal that the flock encodes information about the predator's location that is not accessible to every individual bird, demonstrating implicit collective knowledge. Together, these results show how informational coupling among active inference agents can generate new levels of autonomy and inference, providing a framework for understanding the emergence of (implicit) collective knowledge and joint agency.",Neuroscience
"Collective behavior pervades biological systems, from flocks of birds to neural assemblies and human societies. Yet, how such collectives acquire functional properties -- such as joint agency or knowledge -- that transcend those of their individual components remains an open question. Here, we combine active inference and information-theoretic analyses to explore how a minimal system of interacting agents can give rise to joint agency and collective knowledge. We model flocking dynamics using multiple active inference agents, each minimizing its own free energy while coupling reciprocally with its neighbors. We show that as agents self-organize, their interactions define higher-order statistical boundaries (Markov blankets) enclosing a ``flock'' that can be treated as an emergent agent with its own sensory, active, and internal states. When exposed to external perturbations (a ``predator''), the flock exhibits faster, coordinated responses than individual agents, reflecting collective sensitivity to environmental change. Crucially, analyses of synergistic information reveal that the flock encodes information about the predator's location that is not accessible to every individual bird, demonstrating implicit collective knowledge. Together, these results show how informational coupling among active inference agents can generate new levels of autonomy and inference, providing a framework for understanding the emergence of (implicit) collective knowledge and joint agency. [SEP] [HINT] understanding -> Neuroscience (Syns: savvy, intellect, sympathy) | functional -> Neuroscience (Syns: working, usable, running) | information -> Bioinformatics (Syns: entropy, data, info)",Neuroscience
"Solution-processed electrochromic materials offer high potential for energy-efficient smart windows and displays. Their performance varies with material choice and processing conditions. Electrochromic thin film electrodes require a smooth, defect-free coating for optimal contrast between bleached and colored states. The complexity of optimizing the spin-coated electrochromic thin layer poses challenges for rapid development. This study demonstrates the use of self-driving laboratories to accelerate the development of electrochromic coatings by coupling automation with machine learning. Our system combines automated data acquisition, image processing, spectral analysis, and Bayesian optimization to explore processing parameters efficiently. This approach not only increases throughput but also enables a pointed search for optimal processing parameters. The approach can be applied to various solution-processed materials, highlighting the potential of self-driving labs in enhancing materials discovery and process optimization.",Materials Science
"Solution-processed electrochromic materials offer high potential for energy-efficient smart windows and displays. Their performance varies with material choice and processing conditions. Electrochromic thin film electrodes require a smooth, defect-free coating for optimal contrast between bleached and colored states. The complexity of optimizing the spin-coated electrochromic thin layer poses challenges for rapid development. This study demonstrates the use of self-driving laboratories to accelerate the development of electrochromic coatings by coupling automation with machine learning. Our system combines automated data acquisition, image processing, spectral analysis, and Bayesian optimization to explore processing parameters efficiently. This approach not only increases throughput but also enables a pointed search for optimal processing parameters. The approach can be applied to various solution-processed materials, highlighting the potential of self-driving labs in enhancing materials discovery and process optimization. [SEP] [HINT] processing -> Neuroscience (Syns: work, process, march) | performance -> Bioinformatics (Syns: functioning, operation, carrying out) | materials -> Materials Science (Syns: stuff, cloth, material)",Materials Science
"Understanding the dynamics of large-scale brain models remains a central challenge due to the inherent complexity of these systems. In this work, we explore the emergence of complex spatiotemporal patterns in a large scale-brain model composed of 90 interconnected brain regions coupled through empirically derived anatomical connectivity. An important aspect of our formulation is that the local dynamics of each brain region are described by a next-generation neural mass model, which explicitly captures the macroscopic gamma activity of coupled excitatory and inhibitory neural populations (PING mechanism). We first identify the system's homogeneous states-both resting and oscillatory-and analyze their stability under uniform perturbations. Then, we determine the stability against non-uniform perturbations by obtaining dispersion relations for the perturbation growth rate. This analysis enables us to link unstable directions of the homogeneous solutions to the emergence of rich spatiotemporal patterns, that we characterize by means of Lyapunov exponents and frequency spectrum analysis. Our results show that, compared to previous studies with classical neural mass models, next-generation neural mass models provide a broader dynamical repertoire, both within homogeneous states and in the heterogeneous regime. Additionally, we identify a key role for anatomical connectivity in cross-frequency coupling, allowing for the emergence of gamma oscillations with amplitude modulated by slower rhythms. These findings suggest that such models are not only more biophysically grounded but also particularly well-suited to capture the full complexity of large-scale brain dynamics. Overall, our study advances the analytical understanding of emerging spatiotemporal patterns in whole-brain models.",Neuroscience
"Understanding the dynamics of large-scale brain models remains a central challenge due to the inherent complexity of these systems. In this work, we explore the emergence of complex spatiotemporal patterns in a large scale-brain model composed of 90 interconnected brain regions coupled through empirically derived anatomical connectivity. An important aspect of our formulation is that the local dynamics of each brain region are described by a next-generation neural mass model, which explicitly captures the macroscopic gamma activity of coupled excitatory and inhibitory neural populations (PING mechanism). We first identify the system's homogeneous states-both resting and oscillatory-and analyze their stability under uniform perturbations. Then, we determine the stability against non-uniform perturbations by obtaining dispersion relations for the perturbation growth rate. This analysis enables us to link unstable directions of the homogeneous solutions to the emergence of rich spatiotemporal patterns, that we characterize by means of Lyapunov exponents and frequency spectrum analysis. Our results show that, compared to previous studies with classical neural mass models, next-generation neural mass models provide a broader dynamical repertoire, both within homogeneous states and in the heterogeneous regime. Additionally, we identify a key role for anatomical connectivity in cross-frequency coupling, allowing for the emergence of gamma oscillations with amplitude modulated by slower rhythms. These findings suggest that such models are not only more biophysically grounded but also particularly well-suited to capture the full complexity of large-scale brain dynamics. Overall, our study advances the analytical understanding of emerging spatiotemporal patterns in whole-brain models. [SEP] [HINT] connectivity -> Neuroscience (Syns: ) | understanding -> Neuroscience (Syns: savvy, intellect, sympathy) | complex -> Bioinformatics (Syns: building complex, coordination compound, composite)",Neuroscience
"Diabetes mellitus is a chronic metabolic disorder that necessitates novel therapeutic innovations due to its gradual progression and the onset of various metabolic complications. Research indicates that Ficus religiosa is a conventional medicinal plant that generates bioactive phytochemicals with potential antidiabetic properties. The investigation employs ecosystem-based computational approaches utilizing artificial intelligence to investigate and evaluate compounds derived from Ficus religiosa that exhibit antidiabetic properties. A comprehensive computational procedure incorporated machine learning methodologies, molecular docking techniques, and ADMET prediction systems to assess phytochemical efficacy against the significant antidiabetic enzyme dipeptidyl peptidase-4 (DPP-4). DeepBindGCN and the AutoDock software facilitated the investigation of binding interactions via deep learning technology. Flavonoids and alkaloids have emerged as attractive phytochemicals due to their strong binding interactions and advantageous pharmacological effects, as indicated by the study. The introduction of AI accelerated screening procedures and enhanced accuracy rates, demonstrating its efficacy in researching plant-based antidiabetic agents. The scientific foundation now facilitates future experimental validation of natural product therapies tailored for diabetic management.",Bioinformatics
"Diabetes mellitus is a chronic metabolic disorder that necessitates novel therapeutic innovations due to its gradual progression and the onset of various metabolic complications. Research indicates that Ficus religiosa is a conventional medicinal plant that generates bioactive phytochemicals with potential antidiabetic properties. The investigation employs ecosystem-based computational approaches utilizing artificial intelligence to investigate and evaluate compounds derived from Ficus religiosa that exhibit antidiabetic properties. A comprehensive computational procedure incorporated machine learning methodologies, molecular docking techniques, and ADMET prediction systems to assess phytochemical efficacy against the significant antidiabetic enzyme dipeptidyl peptidase-4 (DPP-4). DeepBindGCN and the AutoDock software facilitated the investigation of binding interactions via deep learning technology. Flavonoids and alkaloids have emerged as attractive phytochemicals due to their strong binding interactions and advantageous pharmacological effects, as indicated by the study. The introduction of AI accelerated screening procedures and enhanced accuracy rates, demonstrating its efficacy in researching plant-based antidiabetic agents. The scientific foundation now facilitates future experimental validation of natural product therapies tailored for diabetic management. [SEP] [HINT] computational -> Neuroscience (Syns: ) | learning -> Bioinformatics (Syns: take, teach, acquire) | molecular -> Bioinformatics (Syns: )",Bioinformatics
"Global pandemics, such as the recent COVID-19 crisis, highlight the need for stochastic epidemic models that can capture the randomness inherent in the spread of disease. Such models must be accompanied by methods for estimating parameters in order to generate fast nowcasts and short-term forecasts that can inform public health decisions. This paper presents a comparison of two advanced Bayesian inference methods: 1) pseudo-marginal particle Markov chain Monte Carlo, short Particle Filters (PF), and 2) Conditional Normalizing Flows (CNF). We investigate their performance on two commonly used compartmental models: a classical Susceptible-Infected-Recovered (SIR) model and a two-variant Susceptible-Exposed-Infected-Recovered (SEIR) model, complemented by an observation model that maps latent trajectories to empirical data. Addressing the challenges of intractable likelihoods for parameter inference in stochastic settings, our analysis highlights how these likelihood-free methods provide accurate and robust inference capabilities. The results of our simulation study further underscore the effectiveness of these approaches in capturing the stochastic dynamics of epidemics, providing prediction capabilities for the control of epidemic outbreaks. Results on an Ethiopian cohort study demonstrate operational robustness under real-world noise and irregular data sampling. To facilitate reuse and to enable building pipelines that ultimately contribute to better informed decision making in public health, we make code and synthetic datasets publicly available.",Bioinformatics
"Global pandemics, such as the recent COVID-19 crisis, highlight the need for stochastic epidemic models that can capture the randomness inherent in the spread of disease. Such models must be accompanied by methods for estimating parameters in order to generate fast nowcasts and short-term forecasts that can inform public health decisions. This paper presents a comparison of two advanced Bayesian inference methods: 1) pseudo-marginal particle Markov chain Monte Carlo, short Particle Filters (PF), and 2) Conditional Normalizing Flows (CNF). We investigate their performance on two commonly used compartmental models: a classical Susceptible-Infected-Recovered (SIR) model and a two-variant Susceptible-Exposed-Infected-Recovered (SEIR) model, complemented by an observation model that maps latent trajectories to empirical data. Addressing the challenges of intractable likelihoods for parameter inference in stochastic settings, our analysis highlights how these likelihood-free methods provide accurate and robust inference capabilities. The results of our simulation study further underscore the effectiveness of these approaches in capturing the stochastic dynamics of epidemics, providing prediction capabilities for the control of epidemic outbreaks. Results on an Ethiopian cohort study demonstrate operational robustness under real-world noise and irregular data sampling. To facilitate reuse and to enable building pipelines that ultimately contribute to better informed decision making in public health, we make code and synthetic datasets publicly available. [SEP] [HINT] used -> Bioinformatics (Syns: utilize, ill-used, apply) | order -> Materials Science (Syns: enjoin, dictate, social club) | datasets -> Bioinformatics (Syns: )",Bioinformatics
"While reinforcement learning algorithms have made significant progress in solving multi-armed bandit problems, they often lack biological plausibility in architecture and dynamics. Here, we propose a bio-inspired neural model based on interacting populations of rate neurons, drawing inspiration from the orbitofrontal cortex and anterior cingulate cortex. Our model reports robust performance across various stochastic bandit problems, matching the effectiveness of standard algorithms such as Thompson Sampling and UCB. Notably, the model exhibits adaptive behavior: employing greedy strategies in low-uncertainty situations while increasing exploratory behavior as uncertainty rises. Through evolutionary optimization, the model's hyperparameters converged to values that align with known synaptic mechanisms, particularly in terms of synapse-dependent neural activity and learning rate adaptation. These findings suggest that biologically-inspired computational architectures can achieve competitive performance while providing insights into neural mechanisms of decision-making under uncertainty.",Neuroscience
"While reinforcement learning algorithms have made significant progress in solving multi-armed bandit problems, they often lack biological plausibility in architecture and dynamics. Here, we propose a bio-inspired neural model based on interacting populations of rate neurons, drawing inspiration from the orbitofrontal cortex and anterior cingulate cortex. Our model reports robust performance across various stochastic bandit problems, matching the effectiveness of standard algorithms such as Thompson Sampling and UCB. Notably, the model exhibits adaptive behavior: employing greedy strategies in low-uncertainty situations while increasing exploratory behavior as uncertainty rises. Through evolutionary optimization, the model's hyperparameters converged to values that align with known synaptic mechanisms, particularly in terms of synapse-dependent neural activity and learning rate adaptation. These findings suggest that biologically-inspired computational architectures can achieve competitive performance while providing insights into neural mechanisms of decision-making under uncertainty. [SEP] [HINT] based -> Bioinformatics (Syns: ground, free-base, base) | computational -> Neuroscience (Syns: ) | learning -> Bioinformatics (Syns: take, teach, acquire)",Neuroscience
"Topological particle-like excitations such as skyrmions and hopfions offer rich opportunities for spintronic and photonic applications. While skyrmions have been extensively studied, the stabilization mechanisms and phase behavior of three-dimensional hopfions remain largely unexplored. Here, we investigate the formation, stability, and interactions of hopfions in thin chiral magnetic films with surface anchoring, using three-dimensional micromagnetic simulations within a material-independent framework applicable to both magnetic and liquid crystalline systems. We identify four distinct types of isolated hopfions, generated by rotating bimeron and finger-like solitons around a central axis. The metastability regions of these precursor textures closely follow the boundaries of modulated finger phases, enabling their size to be continuously tuned through anisotropydriven inflation and collapse. Remarkably, we demonstrate that hopfions near their inflation threshold possess energies comparable with the homogeneous state, allowing them to enclose regions of modulated phases or other solitons, forming higher-order, bag-like domains. In contrast, periodic hopfion lattices remain intrinsically unstable under confinement, spontaneously relaxing into finger phases. These findings establish general principles for stabilizing, tuning, and assembling three-dimensional topological solitons in confined chiral systems, suggesting experimentally accessible routes for texture engineering in liquid crystals via electric-field control.",Materials Science
"Topological particle-like excitations such as skyrmions and hopfions offer rich opportunities for spintronic and photonic applications. While skyrmions have been extensively studied, the stabilization mechanisms and phase behavior of three-dimensional hopfions remain largely unexplored. Here, we investigate the formation, stability, and interactions of hopfions in thin chiral magnetic films with surface anchoring, using three-dimensional micromagnetic simulations within a material-independent framework applicable to both magnetic and liquid crystalline systems. We identify four distinct types of isolated hopfions, generated by rotating bimeron and finger-like solitons around a central axis. The metastability regions of these precursor textures closely follow the boundaries of modulated finger phases, enabling their size to be continuously tuned through anisotropydriven inflation and collapse. Remarkably, we demonstrate that hopfions near their inflation threshold possess energies comparable with the homogeneous state, allowing them to enclose regions of modulated phases or other solitons, forming higher-order, bag-like domains. In contrast, periodic hopfion lattices remain intrinsically unstable under confinement, spontaneously relaxing into finger phases. These findings establish general principles for stabilizing, tuning, and assembling three-dimensional topological solitons in confined chiral systems, suggesting experimentally accessible routes for texture engineering in liquid crystals via electric-field control. [SEP] [HINT] framework -> Bioinformatics (Syns: theoretical account, model, fabric) | using -> Bioinformatics (Syns: utilize, exploitation, apply) | phase -> Materials Science (Syns: stage, phase angle, form)",Materials Science
"Recent studies suggest that the representations learned by large language models (LLMs) are partially aligned to those of the human brain. However, whether and why this alignment score arises from a similar sequence of computations remains elusive. In this study, we explore this question by examining temporally-resolved brain signals of participants listening to 10 hours of an audiobook. We study these neural dynamics jointly with a benchmark encompassing 22 LLMs varying in size and architecture type. Our analyses confirm that LLMs and the brain generate representations in a similar order: specifically, activations in the initial layers of LLMs tend to best align with early brain responses, while the deeper layers of LLMs tend to best align with later brain responses. This brain-LLM alignment is consistent across transformers and recurrent architectures. However, its emergence depends on both model size and context length. Overall, this study sheds light on the sequential nature of computations and the factors underlying the partial convergence between biological and artificial neural networks.",Neuroscience
"Recent studies suggest that the representations learned by large language models (LLMs) are partially aligned to those of the human brain. However, whether and why this alignment score arises from a similar sequence of computations remains elusive. In this study, we explore this question by examining temporally-resolved brain signals of participants listening to 10 hours of an audiobook. We study these neural dynamics jointly with a benchmark encompassing 22 LLMs varying in size and architecture type. Our analyses confirm that LLMs and the brain generate representations in a similar order: specifically, activations in the initial layers of LLMs tend to best align with early brain responses, while the deeper layers of LLMs tend to best align with later brain responses. This brain-LLM alignment is consistent across transformers and recurrent architectures. However, its emergence depends on both model size and context length. Overall, this study sheds light on the sequential nature of computations and the factors underlying the partial convergence between biological and artificial neural networks. [SEP] [HINT] language -> Neuroscience (Syns: linguistic process, linguistic communication, spoken communication) | human -> Neuroscience (Syns: human being, man, homo) | dynamics -> Bioinformatics (Syns: kinetics, dynamic, moral force)",Neuroscience
"Graph-theoretical labeling provides a rigorous mathematical framework for characterizing the structural and functional organization of complex networks. This paper investigates the application of cordial labeling and signed product cordial labeling to brain connectivity graphs, emphasizing their relevance to small-world network models in neuroscience. The cordial condition is interpreted as a measure of structural balance between excitatory and inhibitory neuronal interactions, while the signed product cordial labeling reflects the coexistence of cooperative and antagonistic neural dynamics.",Neuroscience
"Graph-theoretical labeling provides a rigorous mathematical framework for characterizing the structural and functional organization of complex networks. This paper investigates the application of cordial labeling and signed product cordial labeling to brain connectivity graphs, emphasizing their relevance to small-world network models in neuroscience. The cordial condition is interpreted as a measure of structural balance between excitatory and inhibitory neuronal interactions, while the signed product cordial labeling reflects the coexistence of cooperative and antagonistic neural dynamics. [SEP] [HINT] complex -> Bioinformatics (Syns: building complex, coordination compound, composite) | network -> Bioinformatics (Syns: meshwork, electronic network, mesh) | connectivity -> Neuroscience (Syns: )",Neuroscience
"Field theories predict that phase transitions sequentially breaking continuous and discrete symmetries can generate hybrid topological structures in which defects of different dimensionalities merge. We report experimental and numerical studies of hybrid defects in ferroelectric nematic liquid crystals, which undergo a cascaded transition from isotropic liquid to a high-symmetry apolar, and then to a low-symmetry polar nematic phase. By imposing surface anchoring to preset disclination configurations, we directly track the transformation of topological defects across the transition. We show that simple disclinations reproducibly evolve into complex hybrid states, including domain walls terminated by surface disclinations, domain walls decorated with monopoles, and merons-mediated boojums and monopoles. These results provide definitive experimental validation of hybrid defects in a soft matter system and establish ferroelectric nematics as a model platform for exploring and engineering polar defect structures.",Materials Science
"Field theories predict that phase transitions sequentially breaking continuous and discrete symmetries can generate hybrid topological structures in which defects of different dimensionalities merge. We report experimental and numerical studies of hybrid defects in ferroelectric nematic liquid crystals, which undergo a cascaded transition from isotropic liquid to a high-symmetry apolar, and then to a low-symmetry polar nematic phase. By imposing surface anchoring to preset disclination configurations, we directly track the transformation of topological defects across the transition. We show that simple disclinations reproducibly evolve into complex hybrid states, including domain walls terminated by surface disclinations, domain walls decorated with monopoles, and merons-mediated boojums and monopoles. These results provide definitive experimental validation of hybrid defects in a soft matter system and establish ferroelectric nematics as a model platform for exploring and engineering polar defect structures. [SEP] [HINT] field -> Materials Science (Syns: field of honor, line of business, orbit) | transition -> Materials Science (Syns: passage, modulation, changeover) | defect -> Materials Science (Syns: mar, shortcoming, fault)",Materials Science
"Stemming from antiferromagnetic coupling, exchange bias allows inverted hysteresis in a magnetic system. Such room temperature magnetic reversal has yet to be observed in an amorphous antiferromagnet. Furthermore, the impact of this exchange bias effect on its magnetoelectric transport behavior remains a mystery. Here we discovered a zero-field magnetization switching effect in an exchange-biased amorphous antiferromagnet with inverted magnetic hysteresis. This zero-field magnetic reversal was further evidenced by its inverted large anomalous Hall effect. Notably, this collective spin flipping at zero field can occur at room temperature or above room temperature, which may be associated with quantum interference effect due to thermal fluctuation enhanced disorder. Our experimental results offer a way to design room-temperature exchange-biased amorphous antiferromagnets with zero-field multi magnetic-states and large anomalous Hall effect, holding potential for low-power and high-density memory applications.",Materials Science
"Stemming from antiferromagnetic coupling, exchange bias allows inverted hysteresis in a magnetic system. Such room temperature magnetic reversal has yet to be observed in an amorphous antiferromagnet. Furthermore, the impact of this exchange bias effect on its magnetoelectric transport behavior remains a mystery. Here we discovered a zero-field magnetization switching effect in an exchange-biased amorphous antiferromagnet with inverted magnetic hysteresis. This zero-field magnetic reversal was further evidenced by its inverted large anomalous Hall effect. Notably, this collective spin flipping at zero field can occur at room temperature or above room temperature, which may be associated with quantum interference effect due to thermal fluctuation enhanced disorder. Our experimental results offer a way to design room-temperature exchange-biased amorphous antiferromagnets with zero-field multi magnetic-states and large anomalous Hall effect, holding potential for low-power and high-density memory applications. [SEP] [HINT] field -> Materials Science (Syns: field of honor, line of business, orbit) | spin -> Materials Science (Syns: twisting, whirl, tailspin) | transport -> Materials Science (Syns: transferral, enthral, shipping)",Materials Science
"Predicting relaxed atomic structures of chemically complex materials remains a major computational challenge, particularly for high-entropy systems where traditional first-principles methods become prohibitively expensive. We introduce the edge-aware graph attention model, a physics-informed graph neural network tailored for predicting relaxed atomic structures of high-entropy systems. the edge-aware graph attention model employs chemically and geometrically informed descriptors that capture both atomic properties and local structural environments. To effectively capture atomic interactions, our model integrates a multi-head self-attention mechanism that adaptively weighs neighbouring atoms using both node and edge features. This edge-aware attention framework learn complex chemical and structural relationships independent of global orientation or position. We trained and evaluated the edge-aware GAT model on a dataset of carbide systems, spanning binary to high-entropy carbide compositions, and demonstrated its accuracy, convergence efficiency, and transferability. The architecture is lightweight, with a very low computational footprint, making it highly suitable for large-scale materials screening. By providing invariance to rigid-body transformations and leveraging domain-informed attention mechanisms, our model delivers a fast, scalable, and cost-effective alternative to DFT, enabling accelerated discovery and screening of entropy-stabilised materials.",Materials Science
"Predicting relaxed atomic structures of chemically complex materials remains a major computational challenge, particularly for high-entropy systems where traditional first-principles methods become prohibitively expensive. We introduce the edge-aware graph attention model, a physics-informed graph neural network tailored for predicting relaxed atomic structures of high-entropy systems. the edge-aware graph attention model employs chemically and geometrically informed descriptors that capture both atomic properties and local structural environments. To effectively capture atomic interactions, our model integrates a multi-head self-attention mechanism that adaptively weighs neighbouring atoms using both node and edge features. This edge-aware attention framework learn complex chemical and structural relationships independent of global orientation or position. We trained and evaluated the edge-aware GAT model on a dataset of carbide systems, spanning binary to high-entropy carbide compositions, and demonstrated its accuracy, convergence efficiency, and transferability. The architecture is lightweight, with a very low computational footprint, making it highly suitable for large-scale materials screening. By providing invariance to rigid-body transformations and leveraging domain-informed attention mechanisms, our model delivers a fast, scalable, and cost-effective alternative to DFT, enabling accelerated discovery and screening of entropy-stabilised materials. [SEP] [HINT] low -> Materials Science (Syns: low-spirited, scurvy, depressed) | computational -> Neuroscience (Syns: ) | complex -> Bioinformatics (Syns: building complex, coordination compound, composite)",Materials Science
"Halide exchange in lead-based halide perovskites has been studied extensively. While mixed Cl-Br or Br-I alloy compositions can be formed with no miscibility gaps, this is precluded for mixed Cl-I compositions, due to the large difference in Cl and I ionic radii. Here, we exploit perovskite-chalcohalide CsPbCl3-Pb4S3Cl2 heterostructures to study the Cl-I exchange and isolate new types of intermediate structures. The epitaxial interface between the Pb4S3Cl2 chalcohalide and the CsPbCl3 perovskite domain significantly influences the intermediate stages of halide exchange in the perovskite domain, leading to coexisting CsPbCl3 and CsPbI3 domains, thereby delivering segmented CsPbI3-CsPbCl3-Pb4S3Cl2 energetically favorable heterostructures, with partial iodide alloying of the CsPbCl3 domain and at the perovskite-chalcohalide interface. The I:CsPbCl3 domain between CsPbI3 and Pb4S3Cl2 enables a gradual lattice expansion across the heterostructure. This design accommodates interfacial strain, with a 5.6% mismatch at the CsPbCl3-CsPbI3 interface and a 3.4% mismatch at the perovskite-chalcohalide interface. Full halide exchange leads to CsPbI3-Pb4S3Cl2 heterostructures. Both in intermediate and fully exchanged heterostructures, the CsPbI3 domain is emissive. In the intermediate structures, the band alignment between the two perovskite domains is type-I, with carriers photogenerated in the CsPbCl3 domain quickly transferring to the CsPbI3 domain, where they can recombine radiatively.",Materials Science
"Halide exchange in lead-based halide perovskites has been studied extensively. While mixed Cl-Br or Br-I alloy compositions can be formed with no miscibility gaps, this is precluded for mixed Cl-I compositions, due to the large difference in Cl and I ionic radii. Here, we exploit perovskite-chalcohalide CsPbCl3-Pb4S3Cl2 heterostructures to study the Cl-I exchange and isolate new types of intermediate structures. The epitaxial interface between the Pb4S3Cl2 chalcohalide and the CsPbCl3 perovskite domain significantly influences the intermediate stages of halide exchange in the perovskite domain, leading to coexisting CsPbCl3 and CsPbI3 domains, thereby delivering segmented CsPbI3-CsPbCl3-Pb4S3Cl2 energetically favorable heterostructures, with partial iodide alloying of the CsPbCl3 domain and at the perovskite-chalcohalide interface. The I:CsPbCl3 domain between CsPbI3 and Pb4S3Cl2 enables a gradual lattice expansion across the heterostructure. This design accommodates interfacial strain, with a 5.6% mismatch at the CsPbCl3-CsPbI3 interface and a 3.4% mismatch at the perovskite-chalcohalide interface. Full halide exchange leads to CsPbI3-Pb4S3Cl2 heterostructures. Both in intermediate and fully exchanged heterostructures, the CsPbI3 domain is emissive. In the intermediate structures, the band alignment between the two perovskite domains is type-I, with carriers photogenerated in the CsPbCl3 domain quickly transferring to the CsPbI3 domain, where they can recombine radiatively. [SEP] [HINT] perovskite -> Materials Science (Syns: ) | band -> Materials Science (Syns: set, stria, dance orchestra) | lattice -> Materials Science (Syns: grille, fretwork, latticework)",Materials Science
"Diabetic retinopathy (DR), a microvascular complication of diabetes and a leading cause of preventable blindness, is projected to affect more than 130 million individuals worldwide by 2030. Early identification is essential to reduce irreversible vision loss, yet current diagnostic workflows rely on methods such as fundus photography and expert review, which remain costly and resource-intensive. This, combined with DR's asymptomatic nature, results in its underdiagnosis rate of approximately 25 percent. Although convolutional neural networks (CNNs) have demonstrated strong performance in medical imaging tasks, limited interpretability and the absence of uncertainty quantification restrict clinical reliability. Therefore, in this study, a deep ensemble learning framework integrated with uncertainty estimation is introduced to improve robustness, transparency, and scalability in DR detection. The ensemble incorporates seven CNN architectures-ResNet-50, DenseNet-121, MobileNetV3 (Small and Large), and EfficientNet (B0, B2, B3)- whose outputs are fused through an accuracy-weighted majority voting strategy. A probability-weighted entropy metric quantifies prediction uncertainty, enabling low-confidence samples to be excluded or flagged for additional review. Training and validation on 35,000 EyePACS retinal fundus images produced an unfiltered accuracy of 93.70 percent (F1 = 0.9376). Uncertainty-filtering later was conducted to remove unconfident samples, resulting in maximum-accuracy of 99.44 percent (F1 = 0.9932). The framework shows that uncertainty-aware, accuracy-weighted ensembling improves reliability without hindering performance. With confidence-calibrated outputs and a tunable accuracy-coverage trade-off, it offers a generalizable paradigm for deploying trustworthy AI diagnostics in high-risk care.",Bioinformatics
"Diabetic retinopathy (DR), a microvascular complication of diabetes and a leading cause of preventable blindness, is projected to affect more than 130 million individuals worldwide by 2030. Early identification is essential to reduce irreversible vision loss, yet current diagnostic workflows rely on methods such as fundus photography and expert review, which remain costly and resource-intensive. This, combined with DR's asymptomatic nature, results in its underdiagnosis rate of approximately 25 percent. Although convolutional neural networks (CNNs) have demonstrated strong performance in medical imaging tasks, limited interpretability and the absence of uncertainty quantification restrict clinical reliability. Therefore, in this study, a deep ensemble learning framework integrated with uncertainty estimation is introduced to improve robustness, transparency, and scalability in DR detection. The ensemble incorporates seven CNN architectures-ResNet-50, DenseNet-121, MobileNetV3 (Small and Large), and EfficientNet (B0, B2, B3)- whose outputs are fused through an accuracy-weighted majority voting strategy. A probability-weighted entropy metric quantifies prediction uncertainty, enabling low-confidence samples to be excluded or flagged for additional review. Training and validation on 35,000 EyePACS retinal fundus images produced an unfiltered accuracy of 93.70 percent (F1 = 0.9376). Uncertainty-filtering later was conducted to remove unconfident samples, resulting in maximum-accuracy of 99.44 percent (F1 = 0.9932). The framework shows that uncertainty-aware, accuracy-weighted ensembling improves reliability without hindering performance. With confidence-calibrated outputs and a tunable accuracy-coverage trade-off, it offers a generalizable paradigm for deploying trustworthy AI diagnostics in high-risk care. [SEP] [HINT] clinical -> Bioinformatics (Syns: ) | learning -> Bioinformatics (Syns: take, teach, acquire) | networks -> Neuroscience (Syns: network, meshwork, electronic network)",Bioinformatics
"The fluorescence of triplet excitons and color-centers is strongly dependent on magnetic field that mixes the zero field spin eigenstates that determine the radiative recombination rates back into the singlet ground state through spin-orbit coupling. For films of molecules, and polycrystalline color-centers samples an average over molecular orientations has to be performed to model the magneto-fluorescence lineshapes. This limits our analytical understanding of the lineshapes and complicates the analysis of the fluorescence dependence on magnetic field. Here, we present a framework that allows to average over triplet molecular orientations analytically. Our approach provides very accurate numerical routines computing precisely the averages matrix elements that appear in magneto-fluorescence and semi-analytical approximations that can be used to model experimental traces.",Materials Science
"The fluorescence of triplet excitons and color-centers is strongly dependent on magnetic field that mixes the zero field spin eigenstates that determine the radiative recombination rates back into the singlet ground state through spin-orbit coupling. For films of molecules, and polycrystalline color-centers samples an average over molecular orientations has to be performed to model the magneto-fluorescence lineshapes. This limits our analytical understanding of the lineshapes and complicates the analysis of the fluorescence dependence on magnetic field. Here, we present a framework that allows to average over triplet molecular orientations analytically. Our approach provides very accurate numerical routines computing precisely the averages matrix elements that appear in magneto-fluorescence and semi-analytical approximations that can be used to model experimental traces. [SEP] [HINT] used -> Bioinformatics (Syns: utilize, ill-used, apply) | field -> Materials Science (Syns: field of honor, line of business, orbit) | spin -> Materials Science (Syns: twisting, whirl, tailspin)",Materials Science
"The potential of hybrid improper ferroelectrics (HIFs) in electronic and spintronic devices hinges on their ability to switch polarization. Although the coupling between octahedral rotation and tilt is well established, the factors that govern switching barriers remain elusive. In this study, we explore this area to demonstrate the critical role of causal reasoning in uncovering the mechanisms to control the ferroelectric switching barrier in HIFs. By combining causal discovery, causal interventions, and first-principles simulations, we identify tolerance factor, A-site cation radii mismatch, epitaxial strain, and octahedral rotation/tilt as key parameters and quantify how their interplay directly influences switching barrier. Three key insights emerge from our work: (a) the analysis identifies the structural descriptors controlling polarization reversal across a broad family of A-site-layered double perovskites and superlattices, (b) it uncovers non-trivial, material-specific rotation-tilt mechanisms, including a counterintuitive cooperative pathway where both rotation and tilt change while lowering the barrier, an effect mostly inaccessible to conventional Landau or first-principles-based approaches and (c) it maps these material-specific mechanisms to experimentally realizable parameters, showing that epitaxial strain from orthorhombic substrates (e.g., NdScO$_3$, NdGaO$_3$) selectively tunes octahedral distortions to achieve barrier reduction across varied compositions. These results establish actionable, materials-by-design principles linking composition, structure, and strain to polarization switching, while highlighting the potential of causal reasoning to guide intelligent, mechanism-driven strategies for engineering complex functional oxides.",Materials Science
"The potential of hybrid improper ferroelectrics (HIFs) in electronic and spintronic devices hinges on their ability to switch polarization. Although the coupling between octahedral rotation and tilt is well established, the factors that govern switching barriers remain elusive. In this study, we explore this area to demonstrate the critical role of causal reasoning in uncovering the mechanisms to control the ferroelectric switching barrier in HIFs. By combining causal discovery, causal interventions, and first-principles simulations, we identify tolerance factor, A-site cation radii mismatch, epitaxial strain, and octahedral rotation/tilt as key parameters and quantify how their interplay directly influences switching barrier. Three key insights emerge from our work: (a) the analysis identifies the structural descriptors controlling polarization reversal across a broad family of A-site-layered double perovskites and superlattices, (b) it uncovers non-trivial, material-specific rotation-tilt mechanisms, including a counterintuitive cooperative pathway where both rotation and tilt change while lowering the barrier, an effect mostly inaccessible to conventional Landau or first-principles-based approaches and (c) it maps these material-specific mechanisms to experimentally realizable parameters, showing that epitaxial strain from orthorhombic substrates (e.g., NdScO$_3$, NdGaO$_3$) selectively tunes octahedral distortions to achieve barrier reduction across varied compositions. These results establish actionable, materials-by-design principles linking composition, structure, and strain to polarization switching, while highlighting the potential of causal reasoning to guide intelligent, mechanism-driven strategies for engineering complex functional oxides. [SEP] [HINT] electronic -> Materials Science (Syns: ) | functional -> Neuroscience (Syns: working, usable, running) | complex -> Bioinformatics (Syns: building complex, coordination compound, composite)",Materials Science
"We explore whether neural networks can decode brain activity into speech by mapping EEG recordings to audio representations. Using EEG data recorded as subjects listened to natural speech, we train a model with a contrastive CLIP loss to align EEG-derived embeddings with embeddings from a pre-trained transformer-based speech model. Building on the state-of-the-art EEG decoder from Meta, we introduce three architectural modifications: (i) subject-specific attention layers (+0.15% WER improvement), (ii) personalized spatial attention (+0.45%), and (iii) a dual-path RNN with attention (-1.87%). Two of the three modifications improved performance, highlighting the promise of personalized architectures for brain-to-speech decoding and applications in brain-computer interfaces.",Neuroscience
"We explore whether neural networks can decode brain activity into speech by mapping EEG recordings to audio representations. Using EEG data recorded as subjects listened to natural speech, we train a model with a contrastive CLIP loss to align EEG-derived embeddings with embeddings from a pre-trained transformer-based speech model. Building on the state-of-the-art EEG decoder from Meta, we introduce three architectural modifications: (i) subject-specific attention layers (+0.15% WER improvement), (ii) personalized spatial attention (+0.45%), and (iii) a dual-path RNN with attention (-1.87%). Two of the three modifications improved performance, highlighting the promise of personalized architectures for brain-to-speech decoding and applications in brain-computer interfaces. [SEP] [HINT] decoding -> Neuroscience (Syns: decrypt, decipherment, decryption) | networks -> Neuroscience (Syns: network, meshwork, electronic network) | using -> Bioinformatics (Syns: utilize, exploitation, apply)",Neuroscience
"Non-trivial topological phases often emerge in narrow-gap semiconductors with a delicate blend of spin-orbit coupling and electron correlation. The diamond-lattice allotrope of Sn ($α$-Sn) exemplifies this behavior, hosting multiple topological phases that can be tuned by small distortions in the lattice. Despite rapid experimental progress, theoretical descriptions of $α$-Sn lack predictive power and rely mainly on tight-binding models and density functional theory with uncontrolled approximations. We employ first-principles fully self-consistent, relativistic GW (scGW) to overcome these limitations. The scGW recovers the experimentally observed zero-gap semiconductor and the strain-induced topological insulator and Dirac semimetal phases, while also predicting new trivial and topological insulators and a Dirac semimetal phase, further demonstrating the versatility of $α$-Sn for band engineering. Additionally, we propose a robust diagnostic of topological behavior based on a combined analysis of band and orbital-occupation dispersions, tailored for correlated methods where standard mean-field-based topological invariants fall short. Our findings pave the way for studying a broad class of topological materials using accurate first-principles methods beyond density functional theory.",Materials Science
"Non-trivial topological phases often emerge in narrow-gap semiconductors with a delicate blend of spin-orbit coupling and electron correlation. The diamond-lattice allotrope of Sn ($α$-Sn) exemplifies this behavior, hosting multiple topological phases that can be tuned by small distortions in the lattice. Despite rapid experimental progress, theoretical descriptions of $α$-Sn lack predictive power and rely mainly on tight-binding models and density functional theory with uncontrolled approximations. We employ first-principles fully self-consistent, relativistic GW (scGW) to overcome these limitations. The scGW recovers the experimentally observed zero-gap semiconductor and the strain-induced topological insulator and Dirac semimetal phases, while also predicting new trivial and topological insulators and a Dirac semimetal phase, further demonstrating the versatility of $α$-Sn for band engineering. Additionally, we propose a robust diagnostic of topological behavior based on a combined analysis of band and orbital-occupation dispersions, tailored for correlated methods where standard mean-field-based topological invariants fall short. Our findings pave the way for studying a broad class of topological materials using accurate first-principles methods beyond density functional theory. [SEP] [HINT] based -> Bioinformatics (Syns: ground, free-base, base) | functional -> Neuroscience (Syns: working, usable, running) | electron -> Materials Science (Syns: negatron)",Materials Science
"Research on diamond has intensified due to its exceptional thermal, optical, and mechanical properties, making it a key material in quantum technologies and high-power applications. Diamonds with engineered nitrogen-vacancy (NV) centers represent a very sensitive platform for quantum sensing, while high-optical quality diamond windows represent a fundamental safety component inside Electron Cyclotron Resonance Heating (ECRH) systems in nuclear fusion reactors. A major challenge is the development of ultra-low-loss, high-optical-quality single-crystal diamond substrates to meet growing demands for quantum coherence and power handling. Traditionally, dielectric losses ($\tan δ$) in diamonds are evaluated using Fabry-Perot microwave resonators, in which the resonance quality factors Q of the cavity with and without the sample are compared. These devices are limited to resolutions around 10$^{-5}$ by the need to keep the resonator dimensions within a reasonable range. In contrast, superconducting thin-film micro-strip resonators, with Q factors exceeding 10$^6$, are stated to provide higher sensitivity for assessing ultra-low-loss materials. This study examines four diamond samples grown through different processes, analyzing their dielectric losses at extreme low temperatures (sub-Kelvin) within the Two-Level System (TLS) framework. Complementary Raman spectroscopy measurements allowed us not only to associate higher nitrogen content with increased losses, but also to investigate how the different growth process influence the way these defects are incorporated in the crystal lattice.",Materials Science
"Research on diamond has intensified due to its exceptional thermal, optical, and mechanical properties, making it a key material in quantum technologies and high-power applications. Diamonds with engineered nitrogen-vacancy (NV) centers represent a very sensitive platform for quantum sensing, while high-optical quality diamond windows represent a fundamental safety component inside Electron Cyclotron Resonance Heating (ECRH) systems in nuclear fusion reactors. A major challenge is the development of ultra-low-loss, high-optical-quality single-crystal diamond substrates to meet growing demands for quantum coherence and power handling. Traditionally, dielectric losses ($\tan δ$) in diamonds are evaluated using Fabry-Perot microwave resonators, in which the resonance quality factors Q of the cavity with and without the sample are compared. These devices are limited to resolutions around 10$^{-5}$ by the need to keep the resonator dimensions within a reasonable range. In contrast, superconducting thin-film micro-strip resonators, with Q factors exceeding 10$^6$, are stated to provide higher sensitivity for assessing ultra-low-loss materials. This study examines four diamond samples grown through different processes, analyzing their dielectric losses at extreme low temperatures (sub-Kelvin) within the Two-Level System (TLS) framework. Complementary Raman spectroscopy measurements allowed us not only to associate higher nitrogen content with increased losses, but also to investigate how the different growth process influence the way these defects are incorporated in the crystal lattice. [SEP] [HINT] low -> Materials Science (Syns: low-spirited, scurvy, depressed) | quality -> Bioinformatics (Syns: lineament, tone, calibre) | electron -> Materials Science (Syns: negatron)",Materials Science
"The regulator theorem states that, under certain conditions, any optimal controller must embody a model of the system it regulates, grounding the idea that controllers embed, explicitly or implicitly, internal models of the controlled. This principle underpins neuroscience and predictive brain theories like the Free-Energy Principle or Kolmogorov/Algorithmic Agent theory. However, the theorem is only proven in limited settings. Here, we treat the deterministic, closed, coupled world-regulator system $(W,R)$ as a single self-delimiting program $p$ via a constant-size wrapper that produces the world output string~$x$ fed to the regulator. We analyze regulation from the viewpoint of the algorithmic complexity of the output, $K(x)$. We define $R$ to be a \emph{good algorithmic regulator} if it \emph{reduces} the algorithmic complexity of the readout relative to a null (unregulated) baseline $\varnothing$, i.e., \[ Δ= K\big(O_{W,\varnothing}\big) - K\big(O_{W,R}\big) > 0. \] We then prove that the larger $Δ$ is, the more world-regulator pairs with high mutual algorithmic information are favored. More precisely, a complexity gap $Δ> 0$ yields \[ \Pr\big((W,R)\mid x\big) \le C\,2^{\,M(W{:}R)}\,2^{-Δ}, \] making low $M(W{:}R)$ exponentially unlikely as $Δ$ grows. This is an AIT version of the idea that ``the regulator contains a model of the world.'' The framework is distribution-free, applies to individual sequences, and complements the Internal Model Principle. Beyond this necessity claim, the same coding-theorem calculus singles out a \emph{canonical scalar objective} and implicates a \emph{planner}. On the realized episode, a regulator behaves \emph{as if} it minimized the conditional description length of the readout.",Neuroscience
"The regulator theorem states that, under certain conditions, any optimal controller must embody a model of the system it regulates, grounding the idea that controllers embed, explicitly or implicitly, internal models of the controlled. This principle underpins neuroscience and predictive brain theories like the Free-Energy Principle or Kolmogorov/Algorithmic Agent theory. However, the theorem is only proven in limited settings. Here, we treat the deterministic, closed, coupled world-regulator system $(W,R)$ as a single self-delimiting program $p$ via a constant-size wrapper that produces the world output string~$x$ fed to the regulator. We analyze regulation from the viewpoint of the algorithmic complexity of the output, $K(x)$. We define $R$ to be a \emph{good algorithmic regulator} if it \emph{reduces} the algorithmic complexity of the readout relative to a null (unregulated) baseline $\varnothing$, i.e., \[ Δ= K\big(O_{W,\varnothing}\big) - K\big(O_{W,R}\big) > 0. \] We then prove that the larger $Δ$ is, the more world-regulator pairs with high mutual algorithmic information are favored. More precisely, a complexity gap $Δ> 0$ yields \[ \Pr\big((W,R)\mid x\big) \le C\,2^{\,M(W{:}R)}\,2^{-Δ}, \] making low $M(W{:}R)$ exponentially unlikely as $Δ$ grows. This is an AIT version of the idea that ``the regulator contains a model of the world.'' The framework is distribution-free, applies to individual sequences, and complements the Internal Model Principle. Beyond this necessity claim, the same coding-theorem calculus singles out a \emph{canonical scalar objective} and implicates a \emph{planner}. On the realized episode, a regulator behaves \emph{as if} it minimized the conditional description length of the readout. [SEP] [HINT] low -> Materials Science (Syns: low-spirited, scurvy, depressed) | information -> Bioinformatics (Syns: entropy, data, info) | neuroscience -> Neuroscience (Syns: )",Neuroscience
"We propose geometrically nonlinear (finite) continuum models of flexomagnetism based on the Cosserat micropolar and its descendent couple-stress theory. These models introduce the magneto-mechanical interaction by coupling the micro-dislocation tensor of the micropolar model with the magnetisation vector using a Lifshitz invariant. In contrast to conventional formulations that couple strain-gradients to the magnetisation using fourth-order tensors, our approach relies on third-order tensor couplings by virtue of the micro-dislocation being a second-order tensor. Consequently, the models permit centrosymmetric materials with a single new flexomagnetic constant, and more generally allow cubic-symmetric materials with two such constants. We postulate the flexomagnetic action-functionals and derive the corresponding governing equations using both scalar and vectorial magnetic potential formulations, and present numerical results for a nano-beam geometry, confirming the physical plausibility and computational feasibility of the models.",Materials Science
"We propose geometrically nonlinear (finite) continuum models of flexomagnetism based on the Cosserat micropolar and its descendent couple-stress theory. These models introduce the magneto-mechanical interaction by coupling the micro-dislocation tensor of the micropolar model with the magnetisation vector using a Lifshitz invariant. In contrast to conventional formulations that couple strain-gradients to the magnetisation using fourth-order tensors, our approach relies on third-order tensor couplings by virtue of the micro-dislocation being a second-order tensor. Consequently, the models permit centrosymmetric materials with a single new flexomagnetic constant, and more generally allow cubic-symmetric materials with two such constants. We postulate the flexomagnetic action-functionals and derive the corresponding governing equations using both scalar and vectorial magnetic potential formulations, and present numerical results for a nano-beam geometry, confirming the physical plausibility and computational feasibility of the models. [SEP] [HINT] based -> Bioinformatics (Syns: ground, free-base, base) | computational -> Neuroscience (Syns: ) | results -> Bioinformatics (Syns: final result, consequence, resultant role)",Materials Science
"Electroencephalography (EEG)-based wearable brain-computer interfaces (BCIs) face challenges due to low signal-to-noise ratio (SNR) and non-stationary neural activity. We introduce in this manuscript a mathematically rigorous framework that combines data-driven noise interval evaluation with advanced SNR visualization to address these limitations. Analysis of the publicly available Eye-BCI multimodal dataset demonstrates the method's ability to recover canonical P300 characteristics across frequency bands (delta: 0.5-4 Hz, theta: 4-7.5 Hz, broadband: 1-15 Hz), with precise spatiotemporal localization of both P3a (frontocentral) and P3b (parietal) subcomponents. To the best of our knowledge, this is the first study to systematically assess the impact of noise interval selection on EEG signal quality. Cross-session correlations for four different choices of noise intervals spanning from early to late pre-stimulus phases also indicate that alertness and task engagement states modulate noise interval sensitivity, suggesting broader applications for adaptive BCI systems. While validated in healthy participants, our results represent a first step towards providing clinicians with an interpretable tool for detecting neurophysiological abnormalities and provides quantifiable metrics for system optimization.",Neuroscience
"Electroencephalography (EEG)-based wearable brain-computer interfaces (BCIs) face challenges due to low signal-to-noise ratio (SNR) and non-stationary neural activity. We introduce in this manuscript a mathematically rigorous framework that combines data-driven noise interval evaluation with advanced SNR visualization to address these limitations. Analysis of the publicly available Eye-BCI multimodal dataset demonstrates the method's ability to recover canonical P300 characteristics across frequency bands (delta: 0.5-4 Hz, theta: 4-7.5 Hz, broadband: 1-15 Hz), with precise spatiotemporal localization of both P3a (frontocentral) and P3b (parietal) subcomponents. To the best of our knowledge, this is the first study to systematically assess the impact of noise interval selection on EEG signal quality. Cross-session correlations for four different choices of noise intervals spanning from early to late pre-stimulus phases also indicate that alertness and task engagement states modulate noise interval sensitivity, suggesting broader applications for adaptive BCI systems. While validated in healthy participants, our results represent a first step towards providing clinicians with an interpretable tool for detecting neurophysiological abnormalities and provides quantifiable metrics for system optimization. [SEP] [HINT] task -> Neuroscience (Syns: tax, project, chore) | low -> Materials Science (Syns: low-spirited, scurvy, depressed) | results -> Bioinformatics (Syns: final result, consequence, resultant role)",Neuroscience
"Determining the binding pose of a ligand to a protein, known as molecular docking, is a fundamental task in drug discovery. Generative approaches promise faster, improved, and more diverse pose sampling than physics-based methods, but are often hindered by chemically implausible outputs, poor generalisability, and high computational cost. To address these challenges, we introduce a novel fragmentation scheme, leveraging inductive biases from structural chemistry, to decompose ligands into rigid-body fragments. Building on this decomposition, we present SigmaDock, an SE(3) Riemannian diffusion model that generates poses by learning to reassemble these rigid bodies within the binding pocket. By operating at the level of fragments in SE(3), SigmaDock exploits well-established geometric priors while avoiding overly complex diffusion processes and unstable training dynamics. Experimentally, we show SigmaDock achieves state-of-the-art performance, reaching Top-1 success rates (RMSD<2 & PB-valid) above 79.9% on the PoseBusters set, compared to 12.7-30.8% reported by recent deep learning approaches, whilst demonstrating consistent generalisation to unseen proteins. SigmaDock is the first deep learning approach to surpass classical physics-based docking under the PB train-test split, marking a significant leap forward in the reliability and feasibility of deep learning for molecular modelling.",Bioinformatics
"Determining the binding pose of a ligand to a protein, known as molecular docking, is a fundamental task in drug discovery. Generative approaches promise faster, improved, and more diverse pose sampling than physics-based methods, but are often hindered by chemically implausible outputs, poor generalisability, and high computational cost. To address these challenges, we introduce a novel fragmentation scheme, leveraging inductive biases from structural chemistry, to decompose ligands into rigid-body fragments. Building on this decomposition, we present SigmaDock, an SE(3) Riemannian diffusion model that generates poses by learning to reassemble these rigid bodies within the binding pocket. By operating at the level of fragments in SE(3), SigmaDock exploits well-established geometric priors while avoiding overly complex diffusion processes and unstable training dynamics. Experimentally, we show SigmaDock achieves state-of-the-art performance, reaching Top-1 success rates (RMSD<2 & PB-valid) above 79.9% on the PoseBusters set, compared to 12.7-30.8% reported by recent deep learning approaches, whilst demonstrating consistent generalisation to unseen proteins. SigmaDock is the first deep learning approach to surpass classical physics-based docking under the PB train-test split, marking a significant leap forward in the reliability and feasibility of deep learning for molecular modelling. [SEP] [HINT] task -> Neuroscience (Syns: tax, project, chore) | computational -> Neuroscience (Syns: ) | learning -> Bioinformatics (Syns: take, teach, acquire)",Bioinformatics
"Transition metal doping is commonly used for altering the properties of solid-state materials to suit applications in science and technology. Partially filled $d$-shells of transition metal atoms lead to electronic states with diverse spatial and spin symmetries. Chromium(III) cations have shown great potential for designing laser materials and, more recently, for developing spin qubits in quantum applications. They also represent an intriguing class of chemical systems with strongly correlated multi-reference excited states, due to the $d^3$ electron configuration. These states are difficult to describe accurately using single-reference quantum chemical methods such as density functional theory (DFT), the most commonly used method to study the electronic structures of solid-state systems. Recently, the periodic effective Hamiltonian of crystal field (pEHCF) method has been shown to overcome some limitations arising in the calculations of excited $d$-states. In this work, we assess the suitability of DFT and pEHCF to calculate the electronic structure and $d$-$d$ excitations of chromium(III) dopants in wide band gap host materials. The results will aid computational development of novel transition metal-doped materials and provide a deeper understanding of the complex nature of transition metal dopants in solids.",Materials Science
"Transition metal doping is commonly used for altering the properties of solid-state materials to suit applications in science and technology. Partially filled $d$-shells of transition metal atoms lead to electronic states with diverse spatial and spin symmetries. Chromium(III) cations have shown great potential for designing laser materials and, more recently, for developing spin qubits in quantum applications. They also represent an intriguing class of chemical systems with strongly correlated multi-reference excited states, due to the $d^3$ electron configuration. These states are difficult to describe accurately using single-reference quantum chemical methods such as density functional theory (DFT), the most commonly used method to study the electronic structures of solid-state systems. Recently, the periodic effective Hamiltonian of crystal field (pEHCF) method has been shown to overcome some limitations arising in the calculations of excited $d$-states. In this work, we assess the suitability of DFT and pEHCF to calculate the electronic structure and $d$-$d$ excitations of chromium(III) dopants in wide band gap host materials. The results will aid computational development of novel transition metal-doped materials and provide a deeper understanding of the complex nature of transition metal dopants in solids. [SEP] [HINT] used -> Bioinformatics (Syns: utilize, ill-used, apply) | field -> Materials Science (Syns: field of honor, line of business, orbit) | transition -> Materials Science (Syns: passage, modulation, changeover)",Materials Science
"In biological cells, DNA replication is carried out by the replisome, a protein complex encompassing multiple DNA polymerases. DNA replication is semi-discontinuous: a DNA polymerase synthesizes one (leading) strand of the DNA continuously, and another polymerase synthesizes the other (lagging) strand discontinuously. Complex dynamics of the lagging-strand polymerase within the replisome result in the formation of short interim fragments, known as Okazaki fragments, and gaps between them. Although the semi-discontinuous replication is ubiquitous, a detailed characterization of it remains elusive. In this work, we develop a framework to investigate the semi-discontinuous replication by incorporating stochastic dynamics of the lagging-strand polymerase. Computing the size distribution of Okazaki fragments and gaps, we uncover the significance of the polymerase dissociation in shaping them. We apply the method to the previous experiment on the T4 bacteriophage replication system and identify the key parameters governing the polymerase dynamics. These results reveal that the collisions of lagging-strand polymerase with pre-synthesised Okazaki fragments primarily trigger its dissociation from the lagging strand.",Bioinformatics
"In biological cells, DNA replication is carried out by the replisome, a protein complex encompassing multiple DNA polymerases. DNA replication is semi-discontinuous: a DNA polymerase synthesizes one (leading) strand of the DNA continuously, and another polymerase synthesizes the other (lagging) strand discontinuously. Complex dynamics of the lagging-strand polymerase within the replisome result in the formation of short interim fragments, known as Okazaki fragments, and gaps between them. Although the semi-discontinuous replication is ubiquitous, a detailed characterization of it remains elusive. In this work, we develop a framework to investigate the semi-discontinuous replication by incorporating stochastic dynamics of the lagging-strand polymerase. Computing the size distribution of Okazaki fragments and gaps, we uncover the significance of the polymerase dissociation in shaping them. We apply the method to the previous experiment on the T4 bacteriophage replication system and identify the key parameters governing the polymerase dynamics. These results reveal that the collisions of lagging-strand polymerase with pre-synthesised Okazaki fragments primarily trigger its dissociation from the lagging strand. [SEP] [HINT] complex -> Bioinformatics (Syns: building complex, coordination compound, composite) | results -> Bioinformatics (Syns: final result, consequence, resultant role) | framework -> Bioinformatics (Syns: theoretical account, model, fabric)",Bioinformatics
"State-of-the-art superconducting qubits rely on a limited set of thin-film materials. Expanding their materials palette can improve performance, extend operating regimes, and introduce new functionalities, but conventional thin-film fabrication hinders systematic exploration of new material combinations. Van der Waals (vdW) materials offer a highly modular crystalline platform that facilitates such exploration while enabling gate-tunability, higher-temperature operation, and compact qubit geometries. Yet it remains unknown whether a fully vdW superconducting qubit can support quantum coherence and what mechanisms dominate loss at both low and elevated temperatures in such a device. Here we demonstrate quantum-coherent merged-element transmons made entirely from vdW Josephson junctions. These first-generation, fully crystalline qubits achieve microsecond lifetimes in an ultra-compact footprint without external shunt capacitors. Energy relaxation measurements, together with microwave characterization of vdW capacitors, point to dielectric loss as the dominant relaxation channel up to hundreds of millikelvin. These results establish vdW materials as a viable platform for compact superconducting quantum devices.",Materials Science
"State-of-the-art superconducting qubits rely on a limited set of thin-film materials. Expanding their materials palette can improve performance, extend operating regimes, and introduce new functionalities, but conventional thin-film fabrication hinders systematic exploration of new material combinations. Van der Waals (vdW) materials offer a highly modular crystalline platform that facilitates such exploration while enabling gate-tunability, higher-temperature operation, and compact qubit geometries. Yet it remains unknown whether a fully vdW superconducting qubit can support quantum coherence and what mechanisms dominate loss at both low and elevated temperatures in such a device. Here we demonstrate quantum-coherent merged-element transmons made entirely from vdW Josephson junctions. These first-generation, fully crystalline qubits achieve microsecond lifetimes in an ultra-compact footprint without external shunt capacitors. Energy relaxation measurements, together with microwave characterization of vdW capacitors, point to dielectric loss as the dominant relaxation channel up to hundreds of millikelvin. These results establish vdW materials as a viable platform for compact superconducting quantum devices. [SEP] [HINT] low -> Materials Science (Syns: low-spirited, scurvy, depressed) | results -> Bioinformatics (Syns: final result, consequence, resultant role) | materials -> Materials Science (Syns: stuff, cloth, material)",Materials Science
"In this study, we synthesised a phosphonium-based ligand, trimethyl(tetradecyl)phosphonium bromide (TTP-Br), and employed it in the post-synthesis surface treatment of Cs-oleate-capped CsPbBr3 NCs. The photoluminescence quantum yield (PLQY) of the NCs increased from 60% to more than 90%, as a consequence of replacing Cs-oleate with TTP-Br ligand pairs. Density functional theory calculations revealed that TTP+ ions bind to the NC surface by occupying Cs+ surface sites and orienting one of their P-CH3 bonds perpendicular to the surface, akin to quaternary ammonium passivation. Importantly, TTP-Br-capped NCs exhibited higher stability in air compared to didodecyldimethylammonium bromide-capped CsPbBr3 NCs (which is considered a benchmark system), retaining 90% of their PLQY after six weeks of air exposure. Light-emitting diodes fabricated with TTP-Br-capped NCs achieved a maximum external quantum efficiency of 17.2 %, demonstrating the potential of phosphonium-based molecules as surface ligands for CsPbBr3 NCs in optoelectronic applications.",Materials Science
"In this study, we synthesised a phosphonium-based ligand, trimethyl(tetradecyl)phosphonium bromide (TTP-Br), and employed it in the post-synthesis surface treatment of Cs-oleate-capped CsPbBr3 NCs. The photoluminescence quantum yield (PLQY) of the NCs increased from 60% to more than 90%, as a consequence of replacing Cs-oleate with TTP-Br ligand pairs. Density functional theory calculations revealed that TTP+ ions bind to the NC surface by occupying Cs+ surface sites and orienting one of their P-CH3 bonds perpendicular to the surface, akin to quaternary ammonium passivation. Importantly, TTP-Br-capped NCs exhibited higher stability in air compared to didodecyldimethylammonium bromide-capped CsPbBr3 NCs (which is considered a benchmark system), retaining 90% of their PLQY after six weeks of air exposure. Light-emitting diodes fabricated with TTP-Br-capped NCs achieved a maximum external quantum efficiency of 17.2 %, demonstrating the potential of phosphonium-based molecules as surface ligands for CsPbBr3 NCs in optoelectronic applications. [SEP] [HINT] functional -> Neuroscience (Syns: working, usable, running) | theory -> Materials Science (Syns: possibility, hypothesis) | potential -> Bioinformatics (Syns: voltage, potential difference, electric potential)",Materials Science
"A series of SmFeAsO1-xFx (Sm1111) bulk samples are synthesized using an in-situ cubic-anvil high-pressure (CA-HP) technique at 4 GPa and are characterized through structural, microstructural, Raman, transport, and magnetic measurements. A systematic reduction of lattice parameters and unit-cell volume confirms effective fluorine substitution at oxygen sites, while Raman spectroscopy reveals electron doping and subtle changes in local bonding environments. In the underdoped regime, the superconducting transition temperature (Tc) is enhanced by 10-17 K and the critical current density (Jc) is increased by up to an order of magnitude. The upper critical field (Hc2), estimated using the Werthamer-Helfand-Hohenberg model, reaches ~200 T, indicating strong spin paramagnetic effects and multiband superconductivity. Resistive broadening under applied fields follows Arrhenius behavior, with the activation energy showing a power-law field dependence that decreases rapidly at higher fields, consistent with collective vortex pinning. The superconducting phase diagram constructed from Tc and Jc versus fluorine content reveals a dome-like trend, with a maximum Tc of 57 K and Jc of 10^4 A-cm^-2 at the optimal doped region. A direct comparison with CSP samples demonstrates that high-pressure synthesis simultaneously enhances both Tc and Jc across the entire fluorine-doping range. These findings establish high-pressure growth as a highly effective approach for optimizing iron-based superconductors and underscore its potential for both fundamental research and future high field applications.",Materials Science
"A series of SmFeAsO1-xFx (Sm1111) bulk samples are synthesized using an in-situ cubic-anvil high-pressure (CA-HP) technique at 4 GPa and are characterized through structural, microstructural, Raman, transport, and magnetic measurements. A systematic reduction of lattice parameters and unit-cell volume confirms effective fluorine substitution at oxygen sites, while Raman spectroscopy reveals electron doping and subtle changes in local bonding environments. In the underdoped regime, the superconducting transition temperature (Tc) is enhanced by 10-17 K and the critical current density (Jc) is increased by up to an order of magnitude. The upper critical field (Hc2), estimated using the Werthamer-Helfand-Hohenberg model, reaches ~200 T, indicating strong spin paramagnetic effects and multiband superconductivity. Resistive broadening under applied fields follows Arrhenius behavior, with the activation energy showing a power-law field dependence that decreases rapidly at higher fields, consistent with collective vortex pinning. The superconducting phase diagram constructed from Tc and Jc versus fluorine content reveals a dome-like trend, with a maximum Tc of 57 K and Jc of 10^4 A-cm^-2 at the optimal doped region. A direct comparison with CSP samples demonstrates that high-pressure synthesis simultaneously enhances both Tc and Jc across the entire fluorine-doping range. These findings establish high-pressure growth as a highly effective approach for optimizing iron-based superconductors and underscore its potential for both fundamental research and future high field applications. [SEP] [HINT] field -> Materials Science (Syns: field of honor, line of business, orbit) | transition -> Materials Science (Syns: passage, modulation, changeover) | spin -> Materials Science (Syns: twisting, whirl, tailspin)",Materials Science
"Predicting single-cell perturbation outcomes directly advances gene function analysis and facilitates drug candidate selection, making it a key driver of both basic and translational biomedical research. However, a major bottleneck in this task is the unpaired nature of single-cell data, as the same cell cannot be observed both before and after perturbation due to the destructive nature of sequencing. Although some neural generative transport models attempt to tackle unpaired single-cell perturbation data, they either lack explicit conditioning or depend on prior spaces for indirect distribution alignment, limiting precise perturbation modeling. In this work, we approximate Schrödinger Bridge (SB), which defines stochastic dynamic mappings recovering the entropy-regularized optimal transport (OT), to directly align the distributions of control and perturbed single-cell populations across different perturbation conditions. Unlike prior SB approximations that rely on bidirectional modeling to infer optimal source-target sample coupling, we leverage Minibatch-OT based pairing to avoid such bidirectional inference and the associated ill-posedness of defining the reverse process. This pairing directly guides bridge learning, yielding a scalable approximation to the SB. We approximate two SB models, one modeling discrete gene activation states and the other continuous expression distributions. Joint training enables accurate perturbation modeling and captures single-cell heterogeneity. Experiments on public genetic and drug perturbation datasets show that our model effectively captures heterogeneous single-cell responses and achieves state-of-the-art performance.",Bioinformatics
"Predicting single-cell perturbation outcomes directly advances gene function analysis and facilitates drug candidate selection, making it a key driver of both basic and translational biomedical research. However, a major bottleneck in this task is the unpaired nature of single-cell data, as the same cell cannot be observed both before and after perturbation due to the destructive nature of sequencing. Although some neural generative transport models attempt to tackle unpaired single-cell perturbation data, they either lack explicit conditioning or depend on prior spaces for indirect distribution alignment, limiting precise perturbation modeling. In this work, we approximate Schrödinger Bridge (SB), which defines stochastic dynamic mappings recovering the entropy-regularized optimal transport (OT), to directly align the distributions of control and perturbed single-cell populations across different perturbation conditions. Unlike prior SB approximations that rely on bidirectional modeling to infer optimal source-target sample coupling, we leverage Minibatch-OT based pairing to avoid such bidirectional inference and the associated ill-posedness of defining the reverse process. This pairing directly guides bridge learning, yielding a scalable approximation to the SB. We approximate two SB models, one modeling discrete gene activation states and the other continuous expression distributions. Joint training enables accurate perturbation modeling and captures single-cell heterogeneity. Experiments on public genetic and drug perturbation datasets show that our model effectively captures heterogeneous single-cell responses and achieves state-of-the-art performance. [SEP] [HINT] task -> Neuroscience (Syns: tax, project, chore) | based -> Bioinformatics (Syns: ground, free-base, base) | transport -> Materials Science (Syns: transferral, enthral, shipping)",Bioinformatics
"Accurate segmentation and precise morphological analysis of neuronal cells in fluorescence microscopy images are crucial steps in neuroscience and biomedical imaging applications. However, this process is labor-intensive and time-consuming, requiring significant manual effort and expertise to ensure reliable outcomes. This work presents a pipeline for neuron instance segmentation and measurement based on a high-resolution dataset of stem-cell-derived neurons. The proposed method uses YOLOv8, trained on manually annotated microscopy images. The model achieved high segmentation accuracy, exceeding 97%. In addition, the pipeline utilized both ground truth and predicted masks to extract biologically significant features, including cell length, width, area, and grayscale intensity values. The overall accuracy of the extracted morphological measurements reached 75.32%, further supporting the effectiveness of the proposed approach. This integrated framework offers a valuable tool for automated analysis in cell imaging and neuroscience research, reducing the need for manual annotation and enabling scalable, precise quantification of neuron morphology.",Bioinformatics
"Accurate segmentation and precise morphological analysis of neuronal cells in fluorescence microscopy images are crucial steps in neuroscience and biomedical imaging applications. However, this process is labor-intensive and time-consuming, requiring significant manual effort and expertise to ensure reliable outcomes. This work presents a pipeline for neuron instance segmentation and measurement based on a high-resolution dataset of stem-cell-derived neurons. The proposed method uses YOLOv8, trained on manually annotated microscopy images. The model achieved high segmentation accuracy, exceeding 97%. In addition, the pipeline utilized both ground truth and predicted masks to extract biologically significant features, including cell length, width, area, and grayscale intensity values. The overall accuracy of the extracted morphological measurements reached 75.32%, further supporting the effectiveness of the proposed approach. This integrated framework offers a valuable tool for automated analysis in cell imaging and neuroscience research, reducing the need for manual annotation and enabling scalable, precise quantification of neuron morphology. [SEP] [HINT] based -> Bioinformatics (Syns: ground, free-base, base) | work -> Bioinformatics (Syns: work out, process, bring) | including -> Bioinformatics (Syns: admit, include, let in)",Bioinformatics
"Achieving efficient n-type doping in AlN, a representative ultrawide bandgap (UWBG) semiconductor, remains a longstanding challenge that limits its application in high-power electronics and deep-ultraviolet optoelectronics. Conventional dopants in AlN often introduce deep levels or form compensating complexes, leading to low free-carrier concentrations. In this work, we combine first-principles defect calculations with a structural search method tailored to explore metastable configurations to systematically investigate donor-type defects in AlN. Our results reveal that the aluminum interstitial ($Al_i$) can exhibit shallow-donor behavior in specific metastable configurations that were previously overlooked. This discovery expands the understanding of n-type dopability in AlN, and highlights the critical role of metastable defects in modulating electronic properties.",Materials Science
"Achieving efficient n-type doping in AlN, a representative ultrawide bandgap (UWBG) semiconductor, remains a longstanding challenge that limits its application in high-power electronics and deep-ultraviolet optoelectronics. Conventional dopants in AlN often introduce deep levels or form compensating complexes, leading to low free-carrier concentrations. In this work, we combine first-principles defect calculations with a structural search method tailored to explore metastable configurations to systematically investigate donor-type defects in AlN. Our results reveal that the aluminum interstitial ($Al_i$) can exhibit shallow-donor behavior in specific metastable configurations that were previously overlooked. This discovery expands the understanding of n-type dopability in AlN, and highlights the critical role of metastable defects in modulating electronic properties. [SEP] [HINT] low -> Materials Science (Syns: low-spirited, scurvy, depressed) | understanding -> Neuroscience (Syns: savvy, intellect, sympathy) | defect -> Materials Science (Syns: mar, shortcoming, fault)",Materials Science
"Numerous studies have utilized NCBI data for genomic analysis, gene annotation, and identifying disease-associated variants, yet NCBI's epidemiological potential remains underexplored. This study demonstrates how NCBI datasets can be systematically leveraged to extract and interpret infectious disease patterns across spatial and temporal dimensions. Using Enterobacterales as a case study, we analyzed over 477,000 genomic records and metadata, including collection date, location, host species, and isolation source. We compared trends of Escherichia coli and Salmonella in NCBI data with CDC's National Outbreak Reporting System (NORS). While both datasets showed consistent seasonal peaks and foodborne sources, NCBI data revealed broader host species (e.g., wildlife, environmental reservoirs), greater isolate diversity, and finer spatial-temporal resolution. These insights were enabled by our open-source Python package, EpiNCBI_V1, developed for real-time downloading, filtering, and cleaning of pathogen genomic metadata from NCBI. This work highlights the value of integrating genomic repositories into public health analytics to enhance surveillance, outbreak detection, and cross-species transmission tracking globally.",Bioinformatics
"Numerous studies have utilized NCBI data for genomic analysis, gene annotation, and identifying disease-associated variants, yet NCBI's epidemiological potential remains underexplored. This study demonstrates how NCBI datasets can be systematically leveraged to extract and interpret infectious disease patterns across spatial and temporal dimensions. Using Enterobacterales as a case study, we analyzed over 477,000 genomic records and metadata, including collection date, location, host species, and isolation source. We compared trends of Escherichia coli and Salmonella in NCBI data with CDC's National Outbreak Reporting System (NORS). While both datasets showed consistent seasonal peaks and foodborne sources, NCBI data revealed broader host species (e.g., wildlife, environmental reservoirs), greater isolate diversity, and finer spatial-temporal resolution. These insights were enabled by our open-source Python package, EpiNCBI_V1, developed for real-time downloading, filtering, and cleaning of pathogen genomic metadata from NCBI. This work highlights the value of integrating genomic repositories into public health analytics to enhance surveillance, outbreak detection, and cross-species transmission tracking globally. [SEP] [HINT] datasets -> Bioinformatics (Syns: ) | work -> Bioinformatics (Syns: work out, process, bring) | including -> Bioinformatics (Syns: admit, include, let in)",Bioinformatics
"Complex spatial connectivity patterns, such as interictal suppression and ictal propagation, complicate accurate drug-resistant epilepsy (DRE) seizure detection using stereotactic electroencephalography (SEEG) and traditional machine learning methods. Two critical challenges remain:(1)a low signal-to-noise ratio in functional connectivity estimates, making it difficult to learn seizure-related interactions; and (2)expert labels for spatial pathological connectivity patterns are difficult to obtain, meanwhile lacking the patterns' representation to improve seizure detection. To address these issues, we propose a novel node-graph dual contrastive learning framework, Seizure-NGCLNet, to learn SEEG interictal suppression and ictal propagation patterns for detecting DRE seizures with high precision. First, an adaptive graph augmentation strategy guided by centrality metrics is developed to generate seizure-related brain networks. Second, a dual-contrastive learning approach is integrated, combining global graph-level contrast with local node-graph contrast, to encode both spatial structural and semantic epileptogenic features. Third, the pretrained embeddings are fine-tuned via a top-k localized graph attention network to perform the final classification. Extensive experiments on a large-scale public SEEG dataset from 33 DRE patients demonstrate that Seizure-NGCLNet achieves state-of-the-art performance, with an average accuracy of 95.93%, sensitivity of 96.25%, and specificity of 94.12%. Visualizations confirm that the learned embeddings clearly separate ictal from interictal states, reflecting suppression and propagation patterns that correspond to the clinical mechanisms. These results highlight Seizure-NGCLNet's ability to learn interpretable spatial pathological patterns, enhancing both seizure detection and seizure onset zone localization.",Neuroscience
"Complex spatial connectivity patterns, such as interictal suppression and ictal propagation, complicate accurate drug-resistant epilepsy (DRE) seizure detection using stereotactic electroencephalography (SEEG) and traditional machine learning methods. Two critical challenges remain:(1)a low signal-to-noise ratio in functional connectivity estimates, making it difficult to learn seizure-related interactions; and (2)expert labels for spatial pathological connectivity patterns are difficult to obtain, meanwhile lacking the patterns' representation to improve seizure detection. To address these issues, we propose a novel node-graph dual contrastive learning framework, Seizure-NGCLNet, to learn SEEG interictal suppression and ictal propagation patterns for detecting DRE seizures with high precision. First, an adaptive graph augmentation strategy guided by centrality metrics is developed to generate seizure-related brain networks. Second, a dual-contrastive learning approach is integrated, combining global graph-level contrast with local node-graph contrast, to encode both spatial structural and semantic epileptogenic features. Third, the pretrained embeddings are fine-tuned via a top-k localized graph attention network to perform the final classification. Extensive experiments on a large-scale public SEEG dataset from 33 DRE patients demonstrate that Seizure-NGCLNet achieves state-of-the-art performance, with an average accuracy of 95.93%, sensitivity of 96.25%, and specificity of 94.12%. Visualizations confirm that the learned embeddings clearly separate ictal from interictal states, reflecting suppression and propagation patterns that correspond to the clinical mechanisms. These results highlight Seizure-NGCLNet's ability to learn interpretable spatial pathological patterns, enhancing both seizure detection and seizure onset zone localization. [SEP] [HINT] connectivity -> Neuroscience (Syns: ) | low -> Materials Science (Syns: low-spirited, scurvy, depressed) | clinical -> Bioinformatics (Syns: )",Neuroscience
"There is now ample evidence that Motor Imagery (MI) contributes to improve motor performance. Previous studies provided evidence that its effectiveness remains dependent upon specific guidelines and recommendations. The body posture, as well as the context in which MI is performed, are notably critical and should be carefully considered. The present study in young tennis players (n=18) was designed to compare the effectiveness of performing MI of the serve while adopting a loose grip (congruent MI) or holding tightly and squeezing hard the racket (incongruent MI). Data revealed that both MI conditions contributed to enhance the number of successful serves (p<0.001) and the technical quality of the serve (p<0.001). Interestingly, comparing mean serve accuracy scores showed that performance gains were significantly higher in the loose MI group than in the tight MI group (p<0.02). These findings confirm the critical importance of the congruence between the content of the mental representation and the features of the corresponding actual movement. Overall, the present study further highlights the effectiveness of the loose grip while mentally rehearsing the serve, and might thus contribute to update and adjust specific MI guidelines and recommendations.",Neuroscience
"There is now ample evidence that Motor Imagery (MI) contributes to improve motor performance. Previous studies provided evidence that its effectiveness remains dependent upon specific guidelines and recommendations. The body posture, as well as the context in which MI is performed, are notably critical and should be carefully considered. The present study in young tennis players (n=18) was designed to compare the effectiveness of performing MI of the serve while adopting a loose grip (congruent MI) or holding tightly and squeezing hard the racket (incongruent MI). Data revealed that both MI conditions contributed to enhance the number of successful serves (p<0.001) and the technical quality of the serve (p<0.001). Interestingly, comparing mean serve accuracy scores showed that performance gains were significantly higher in the loose MI group than in the tight MI group (p<0.02). These findings confirm the critical importance of the congruence between the content of the mental representation and the features of the corresponding actual movement. Overall, the present study further highlights the effectiveness of the loose grip while mentally rehearsing the serve, and might thus contribute to update and adjust specific MI guidelines and recommendations. [SEP] [HINT] features -> Bioinformatics (Syns: characteristic, lineament, feature of speech) | quality -> Bioinformatics (Syns: lineament, tone, calibre) | performance -> Bioinformatics (Syns: functioning, operation, carrying out)",Neuroscience
"Toward measuring the thermal properties of exfoliated atomically thin materials, we demonstrate simultaneous measurements of the thermal conductivity and specific heat in suspended membranes. We use the 3ω technique applied to quasi-two-dimensional silicon nitride membranes having a metal line heater patterned on the surface to both deliver heat and directly measure the thermal impedance of the membrane at the heating frequency, Z(2ω). We derive an expression for the complex thermal impedance as a function of frequency, approximating the actual rectangular membranes with a one dimensional model. The derivation accounts for potential parasitic heat loss mechanisms including conduction along the heater line, and by the gas load in an imperfect vacuum. Qualitatively, the thermal impedance response resembles a low-pass filter, owing to the combination of the total thermal resistance and total specific heat. Fitting Z(2ω) to measurements across a few decades in frequency, we extract values of the thermal conductivity and specific heat of silicon nitride in agreement with literature values. We also study the dependence on the heating current, and compare to measurements of the thermal conductivity at zero frequency.",Materials Science
"Toward measuring the thermal properties of exfoliated atomically thin materials, we demonstrate simultaneous measurements of the thermal conductivity and specific heat in suspended membranes. We use the 3ω technique applied to quasi-two-dimensional silicon nitride membranes having a metal line heater patterned on the surface to both deliver heat and directly measure the thermal impedance of the membrane at the heating frequency, Z(2ω). We derive an expression for the complex thermal impedance as a function of frequency, approximating the actual rectangular membranes with a one dimensional model. The derivation accounts for potential parasitic heat loss mechanisms including conduction along the heater line, and by the gas load in an imperfect vacuum. Qualitatively, the thermal impedance response resembles a low-pass filter, owing to the combination of the total thermal resistance and total specific heat. Fitting Z(2ω) to measurements across a few decades in frequency, we extract values of the thermal conductivity and specific heat of silicon nitride in agreement with literature values. We also study the dependence on the heating current, and compare to measurements of the thermal conductivity at zero frequency. [SEP] [HINT] complex -> Bioinformatics (Syns: building complex, coordination compound, composite) | dimensional -> Materials Science (Syns: ) | including -> Bioinformatics (Syns: admit, include, let in)",Materials Science
"Recent experiments reveal that task-relevant variables are often encoded in approximately orthogonal subspaces of the neural activity space. These disentangled low-dimensional representations are observed in multiple brain areas and across different species, and are typically the result of a process of abstraction that supports simple forms of out-of-distribution generalization. The mechanisms by which such geometries emerge remain poorly understood, and the mechanisms that have been investigated are typically unsupervised (e.g., based on variational auto-encoders). Here, we show mathematically that abstract representations of latent variables are guaranteed to appear in the last hidden layer of feedforward nonlinear networks when they are trained on tasks that depend directly on these latent variables. These abstract representations reflect the structure of the desired outputs or the semantics of the input stimuli. To investigate the neural representations that emerge in these networks, we develop an analytical framework that maps the optimization over the network weights into a mean-field problem over the distribution of neural preactivations. Applying this framework to a finite-width ReLU network, we find that its hidden layer exhibits an abstract representation at all global minima of the task objective. We further extend these analyses to two broad families of activation functions and deep feedforward architectures, demonstrating that abstract representations naturally arise in all these scenarios. Together, these results provide an explanation for the widely observed abstract representations in both the brain and artificial neural networks, as well as a mathematically tractable toolkit for understanding the emergence of different kinds of representations in task-optimized, feature-learning network models.",Neuroscience
"Recent experiments reveal that task-relevant variables are often encoded in approximately orthogonal subspaces of the neural activity space. These disentangled low-dimensional representations are observed in multiple brain areas and across different species, and are typically the result of a process of abstraction that supports simple forms of out-of-distribution generalization. The mechanisms by which such geometries emerge remain poorly understood, and the mechanisms that have been investigated are typically unsupervised (e.g., based on variational auto-encoders). Here, we show mathematically that abstract representations of latent variables are guaranteed to appear in the last hidden layer of feedforward nonlinear networks when they are trained on tasks that depend directly on these latent variables. These abstract representations reflect the structure of the desired outputs or the semantics of the input stimuli. To investigate the neural representations that emerge in these networks, we develop an analytical framework that maps the optimization over the network weights into a mean-field problem over the distribution of neural preactivations. Applying this framework to a finite-width ReLU network, we find that its hidden layer exhibits an abstract representation at all global minima of the task objective. We further extend these analyses to two broad families of activation functions and deep feedforward architectures, demonstrating that abstract representations naturally arise in all these scenarios. Together, these results provide an explanation for the widely observed abstract representations in both the brain and artificial neural networks, as well as a mathematically tractable toolkit for understanding the emergence of different kinds of representations in task-optimized, feature-learning network models. [SEP] [HINT] task -> Neuroscience (Syns: tax, project, chore) | tasks -> Neuroscience (Syns: tax, task, project) | based -> Bioinformatics (Syns: ground, free-base, base)",Neuroscience
"The spiral handedness of magnetic moments, referred to as chirality, gives rise to emergent electromagnetic phenomena in helimagnets. In insulating helimagnets, known as multiferroics, the cycloidal spin structure induces electric polarization by utilizing the inverse Dzyaloshinskii-Moriya mechanism. Spin-polarized neutron diffraction experiments, which directly probe circular spin arrangements, clearly demonstrated that an electric field controlled the chirality in multiferroic helimagnets. On the other hand, it was unclear until recently how the chirality could be controlled in metallic helimagnets where a large electric field cannot be applied, while the chirality control technique in metallic helimagnets should enable the exploration of chirality-dependent spintronic functionalities. Recently, Jiang et al. succeeded in controlling the chirality of a spiral structure by the simultaneous application of a magnetic field and electric current in a metallic helimagnet, utilizing the nonreciprocal electronic transport as an indirect probe of chirality, highlighting the need for a neutron diffraction experiment that directly probes the chirality. Here, we directly demonstrate the chirality control in a metallic helimagnet YMn$_6$Sn$_6$ by means of spin-polarized neutron diffraction, which should give rise to a firm basis for the development of future helimagnetic spintronics.",Materials Science
"The spiral handedness of magnetic moments, referred to as chirality, gives rise to emergent electromagnetic phenomena in helimagnets. In insulating helimagnets, known as multiferroics, the cycloidal spin structure induces electric polarization by utilizing the inverse Dzyaloshinskii-Moriya mechanism. Spin-polarized neutron diffraction experiments, which directly probe circular spin arrangements, clearly demonstrated that an electric field controlled the chirality in multiferroic helimagnets. On the other hand, it was unclear until recently how the chirality could be controlled in metallic helimagnets where a large electric field cannot be applied, while the chirality control technique in metallic helimagnets should enable the exploration of chirality-dependent spintronic functionalities. Recently, Jiang et al. succeeded in controlling the chirality of a spiral structure by the simultaneous application of a magnetic field and electric current in a metallic helimagnet, utilizing the nonreciprocal electronic transport as an indirect probe of chirality, highlighting the need for a neutron diffraction experiment that directly probes the chirality. Here, we directly demonstrate the chirality control in a metallic helimagnet YMn$_6$Sn$_6$ by means of spin-polarized neutron diffraction, which should give rise to a firm basis for the development of future helimagnetic spintronics. [SEP] [HINT] field -> Materials Science (Syns: field of honor, line of business, orbit) | spin -> Materials Science (Syns: twisting, whirl, tailspin) | transport -> Materials Science (Syns: transferral, enthral, shipping)",Materials Science
"Training recurrent neural networks (RNNs) to perform neuroscience-style tasks has become a popular way to generate hypotheses for how neural circuits in the brain might perform computations. Recent work has demonstrated that task-trained RNNs possess a strong simplicity bias. In particular, this inductive bias often causes RNNs trained on the same task to collapse on effectively the same solution, typically comprised of fixed-point attractors or other low-dimensional dynamical motifs. While such solutions are readily interpretable, this collapse proves counterproductive for the sake of generating a set of genuinely unique hypotheses for how neural computations might be performed. Here we propose Iterative Neural Similarity Deflation (INSD), a simple method to break this inductive bias. By penalizing linear predictivity of neural activity produced by standard task-trained RNNs, we find an alternative class of solutions to classic neuroscience-style RNN tasks. These solutions appear distinct across a battery of analysis techniques, including representational similarity metrics, dynamical systems analysis, and the linear decodability of task-relevant variables. Moreover, these alternative solutions can sometimes achieve superior performance in difficult or out-of-distribution task regimes. Our findings underscore the importance of moving beyond the simplicity bias to uncover richer and more varied models of neural computation.",Neuroscience
"Training recurrent neural networks (RNNs) to perform neuroscience-style tasks has become a popular way to generate hypotheses for how neural circuits in the brain might perform computations. Recent work has demonstrated that task-trained RNNs possess a strong simplicity bias. In particular, this inductive bias often causes RNNs trained on the same task to collapse on effectively the same solution, typically comprised of fixed-point attractors or other low-dimensional dynamical motifs. While such solutions are readily interpretable, this collapse proves counterproductive for the sake of generating a set of genuinely unique hypotheses for how neural computations might be performed. Here we propose Iterative Neural Similarity Deflation (INSD), a simple method to break this inductive bias. By penalizing linear predictivity of neural activity produced by standard task-trained RNNs, we find an alternative class of solutions to classic neuroscience-style RNN tasks. These solutions appear distinct across a battery of analysis techniques, including representational similarity metrics, dynamical systems analysis, and the linear decodability of task-relevant variables. Moreover, these alternative solutions can sometimes achieve superior performance in difficult or out-of-distribution task regimes. Our findings underscore the importance of moving beyond the simplicity bias to uncover richer and more varied models of neural computation. [SEP] [HINT] task -> Neuroscience (Syns: tax, project, chore) | tasks -> Neuroscience (Syns: tax, task, project) | networks -> Neuroscience (Syns: network, meshwork, electronic network)",Neuroscience
"Timelapse images of human induced pluripotent stem cell-derived cardiomyocytes (hiPSC-CMs) provide rich information on cell structure and contractile function. However, it is challenging to reproducibly generate tissue samples and conduct scalable experiments with these cells. The two-dimensional cardiac muscle bundle (2DMB) platform helps address these limitations by standardizing tissue geometry, resulting in physiologic, uniaxial contractions of discrete tissues on an elastomeric substrate with stiffness similar to the heart. 2DMBs are highly conducive to sarcomere imaging using fluorescent reporters, but, due to their larger and more physiologic sarcomere displacements and velocities, prior sarcomere-tracking pipelines have been unreliable. Here, we present adaptations to SarcGraph, an open-source Python package for sarcomere detection and tracking, that enable automated analysis of high-frame-rate 2DMB recordings. Key modifications to the pipeline include: 1) switching to a frame-by-frame sarcomere detection approach and automating tissue segmentation with spatial partitioning, 2) performing Gaussian Process Regression for signal denoising, and 3) incorporating an automatic contractile phase detection pipeline. These enhancements enable the extraction of structural organization and functional contractility metrics for both the whole 2DMB tissue and distinct tissue regions, both in a fully automated manner. We complement this software release with a dataset of 130 example movies of baseline and drug-treated samples disseminated through the Harvard Dataverse. By providing open-source tools and datasets, we aim to enable high-throughput analysis of engineered cardiac tissues and advance collective progress within the hiPSC-CM research community.",Bioinformatics
"Timelapse images of human induced pluripotent stem cell-derived cardiomyocytes (hiPSC-CMs) provide rich information on cell structure and contractile function. However, it is challenging to reproducibly generate tissue samples and conduct scalable experiments with these cells. The two-dimensional cardiac muscle bundle (2DMB) platform helps address these limitations by standardizing tissue geometry, resulting in physiologic, uniaxial contractions of discrete tissues on an elastomeric substrate with stiffness similar to the heart. 2DMBs are highly conducive to sarcomere imaging using fluorescent reporters, but, due to their larger and more physiologic sarcomere displacements and velocities, prior sarcomere-tracking pipelines have been unreliable. Here, we present adaptations to SarcGraph, an open-source Python package for sarcomere detection and tracking, that enable automated analysis of high-frame-rate 2DMB recordings. Key modifications to the pipeline include: 1) switching to a frame-by-frame sarcomere detection approach and automating tissue segmentation with spatial partitioning, 2) performing Gaussian Process Regression for signal denoising, and 3) incorporating an automatic contractile phase detection pipeline. These enhancements enable the extraction of structural organization and functional contractility metrics for both the whole 2DMB tissue and distinct tissue regions, both in a fully automated manner. We complement this software release with a dataset of 130 example movies of baseline and drug-treated samples disseminated through the Harvard Dataverse. By providing open-source tools and datasets, we aim to enable high-throughput analysis of engineered cardiac tissues and advance collective progress within the hiPSC-CM research community. [SEP] [HINT] tissue -> Bioinformatics (Syns: tissue paper, weave) | functional -> Neuroscience (Syns: working, usable, running) | structure -> Bioinformatics (Syns: social system, complex body part, social structure)",Bioinformatics
"Objectives: We present and evaluate a Mamba-based deep-learning model for diagnosis and event-level characterization of sleep disordered breathing based on signals from the ANNE One, a non-intrusive dual-module wireless wearable system measuring chest electrocardiography, triaxial accelerometry, chest and finger temperature, and finger phototplethysmography.   Methods: We obtained concurrent PSG and wearable sensor recordings from 384 adults attending a tertiary care sleep laboratory. Respiratory events in the PSG were manually annotated in accordance with AASM guidelines. Wearable sensor and PSG recordings were automatically aligned based on the ECG signal, alignment confirmed by visual inspection, and PSG-derived respiratory event labels were used to train and evaluate a deep sequential neural network based on the Mamba architecture.   Results: In 57 recordings in our test set (mean age 56, mean AHI 10.8, 43.86\% female) the model-predicted AHI was highly correlated with that derived form the PSG labels (R=0.95, p=8.3e-30, men absolute error 2.83). This performance did not vary with age or sex. At a threshold of AHI$>$5, the model had a sensitivity of 0.96, specificity of 0.87, and kappa of 0.82, and at a threshold of AHI$>$15, the model had a sensitivity of 0.86, specificity of 0.98, and kappa of 0.85. At the level of 30-sec epochs, the model had a sensitivity of 0.93 and specificity of 0.95, with a kappa of 0.68 regarding whether any given epoch contained a respiratory event.   Conclusions: Applied to data from the ANNE One, a Mamba-based deep learning model can accurately predict AHI and identify SDB at clinically relevant thresholds, achieves good epoch- and event-level identification of individual respiratory events, and shows promise at physiological characterization of these events including event type (central vs. other) and event duration.",Bioinformatics
"Objectives: We present and evaluate a Mamba-based deep-learning model for diagnosis and event-level characterization of sleep disordered breathing based on signals from the ANNE One, a non-intrusive dual-module wireless wearable system measuring chest electrocardiography, triaxial accelerometry, chest and finger temperature, and finger phototplethysmography.   Methods: We obtained concurrent PSG and wearable sensor recordings from 384 adults attending a tertiary care sleep laboratory. Respiratory events in the PSG were manually annotated in accordance with AASM guidelines. Wearable sensor and PSG recordings were automatically aligned based on the ECG signal, alignment confirmed by visual inspection, and PSG-derived respiratory event labels were used to train and evaluate a deep sequential neural network based on the Mamba architecture.   Results: In 57 recordings in our test set (mean age 56, mean AHI 10.8, 43.86\% female) the model-predicted AHI was highly correlated with that derived form the PSG labels (R=0.95, p=8.3e-30, men absolute error 2.83). This performance did not vary with age or sex. At a threshold of AHI$>$5, the model had a sensitivity of 0.96, specificity of 0.87, and kappa of 0.82, and at a threshold of AHI$>$15, the model had a sensitivity of 0.86, specificity of 0.98, and kappa of 0.85. At the level of 30-sec epochs, the model had a sensitivity of 0.93 and specificity of 0.95, with a kappa of 0.68 regarding whether any given epoch contained a respiratory event.   Conclusions: Applied to data from the ANNE One, a Mamba-based deep learning model can accurately predict AHI and identify SDB at clinically relevant thresholds, achieves good epoch- and event-level identification of individual respiratory events, and shows promise at physiological characterization of these events including event type (central vs. other) and event duration. [SEP] [HINT] used -> Bioinformatics (Syns: utilize, ill-used, apply) | based -> Bioinformatics (Syns: ground, free-base, base) | learning -> Bioinformatics (Syns: take, teach, acquire)",Bioinformatics
"Purpose: Since its initial release, the aim of Biodose Tools was to offer an easy-to-use platform to perform the mathematical calculations needed in biological dosimetry. This update 3.7.1, mainly focuses on new features related to large-scale emergency responses, like criticality accidents dose estimation and laboratory networks. Material and Methods: Biodose Tools has been developed using the R programming language. The current version (3.7.1) uses the same external dependencies as version 3.6.1 (released November 2022) while integrating three new external packages to support the new functionalities. Results: Version 3.7.1 introduces different new modules: (a) a characteristic limits module that calculates decision thresholds and detection limits following ISO19238:2023 standards, and offers statistical tests to compare rates between suspected exposure cases and control data; (b) an enhanced dose estimation module which supports multiple dose assessments for dicentric and translocation assays for various exposure scenarios (acute, protracted, and highly protracted) as well as whole and partial-body exposures; (c) a criticality accidents module for multiple dose estimations using dicentrics in mixed gamma-neutron exposure scenarios (e.g., nuclear detonations); and (d) an Interlaboratory comparison module that automates the evaluation and comparison of dose estimates across laboratories. Conclusions: Biodose Tools (biodosetools.reneb.bfs.de) continues to evolve in response to the dynamic needs of the biological dosimetry community, contributing to the preparedness and consistency in emergency response and routine applications.",Bioinformatics
"Purpose: Since its initial release, the aim of Biodose Tools was to offer an easy-to-use platform to perform the mathematical calculations needed in biological dosimetry. This update 3.7.1, mainly focuses on new features related to large-scale emergency responses, like criticality accidents dose estimation and laboratory networks. Material and Methods: Biodose Tools has been developed using the R programming language. The current version (3.7.1) uses the same external dependencies as version 3.6.1 (released November 2022) while integrating three new external packages to support the new functionalities. Results: Version 3.7.1 introduces different new modules: (a) a characteristic limits module that calculates decision thresholds and detection limits following ISO19238:2023 standards, and offers statistical tests to compare rates between suspected exposure cases and control data; (b) an enhanced dose estimation module which supports multiple dose assessments for dicentric and translocation assays for various exposure scenarios (acute, protracted, and highly protracted) as well as whole and partial-body exposures; (c) a criticality accidents module for multiple dose estimations using dicentrics in mixed gamma-neutron exposure scenarios (e.g., nuclear detonations); and (d) an Interlaboratory comparison module that automates the evaluation and comparison of dose estimates across laboratories. Conclusions: Biodose Tools (biodosetools.reneb.bfs.de) continues to evolve in response to the dynamic needs of the biological dosimetry community, contributing to the preparedness and consistency in emergency response and routine applications. [SEP] [HINT] features -> Bioinformatics (Syns: characteristic, lineament, feature of speech) | different -> Neuroscience (Syns: unlike, dissimilar) | using -> Bioinformatics (Syns: utilize, exploitation, apply)",Bioinformatics
"The study of cortical dynamics during different states such as decision making, sleep and movement, is an important topic in Neuroscience. Modelling efforts aim to relate the neural rhythms present in cortical recordings to the underlying dynamics responsible for their emergence. We present an effort to characterize the neural activity from the cortex of a mouse during natural sleep, captured through local field potential measurements. Our approach relies on using a discretized Wilson--Cowan Amari neural field model for neural activity, along with a data assimilation method that allows the Bayesian joint estimation of the state and parameters. We demonstrate the feasibility of our approach on synthetic measurements before applying it to a dataset available in literature. Our findings suggest the potential of our approach to characterize the stimulus received by the cortex from other brain regions, while simultaneously inferring a state that aligns with the observed signal.",Neuroscience
"The study of cortical dynamics during different states such as decision making, sleep and movement, is an important topic in Neuroscience. Modelling efforts aim to relate the neural rhythms present in cortical recordings to the underlying dynamics responsible for their emergence. We present an effort to characterize the neural activity from the cortex of a mouse during natural sleep, captured through local field potential measurements. Our approach relies on using a discretized Wilson--Cowan Amari neural field model for neural activity, along with a data assimilation method that allows the Bayesian joint estimation of the state and parameters. We demonstrate the feasibility of our approach on synthetic measurements before applying it to a dataset available in literature. Our findings suggest the potential of our approach to characterize the stimulus received by the cortex from other brain regions, while simultaneously inferring a state that aligns with the observed signal. [SEP] [HINT] field -> Materials Science (Syns: field of honor, line of business, orbit) | cortical -> Neuroscience (Syns: ) | different -> Neuroscience (Syns: unlike, dissimilar)",Neuroscience
"Metal-organic frameworks (MOFs) combine high porosity with structural fragility, raising important questions about their mechanical stability. We develop a rigidity-based framework in which spring networks parameterized by UFF4MOF are used to construct rigidity and dynamical matrices. Large-scale analysis of 5,682 MOFs from the CoRE 2019 database shows that most frameworks are formally over-constrained yet cluster sharply near the isostatic threshold, revealing accidental geometric modes and placing many MOFs near mechanical instability. In the representative case of UiO-66, we show that auxiliary long-range constraints introduced by tuning the neighbor cutoff lift these modes into soft, flat, finite-frequency bands. The results show that rigidity-matrix analysis can rapidly identify MOFs likely to remain mechanically stable. This near-criticality mirrors behavior known from topological mechanics and points to a deeper design principle in porous crystals.",Materials Science
"Metal-organic frameworks (MOFs) combine high porosity with structural fragility, raising important questions about their mechanical stability. We develop a rigidity-based framework in which spring networks parameterized by UFF4MOF are used to construct rigidity and dynamical matrices. Large-scale analysis of 5,682 MOFs from the CoRE 2019 database shows that most frameworks are formally over-constrained yet cluster sharply near the isostatic threshold, revealing accidental geometric modes and placing many MOFs near mechanical instability. In the representative case of UiO-66, we show that auxiliary long-range constraints introduced by tuning the neighbor cutoff lift these modes into soft, flat, finite-frequency bands. The results show that rigidity-matrix analysis can rapidly identify MOFs likely to remain mechanically stable. This near-criticality mirrors behavior known from topological mechanics and points to a deeper design principle in porous crystals. [SEP] [HINT] used -> Bioinformatics (Syns: utilize, ill-used, apply) | networks -> Neuroscience (Syns: network, meshwork, electronic network) | results -> Bioinformatics (Syns: final result, consequence, resultant role)",Materials Science
"Understanding how creativity is represented in the brain's intrinsic functional architecture remains a central challenge in cognitive neuroscience. While resting-state fMRI studies have revealed large-scale network correlates of creative potential, electroencephalography (EEG) offers a temporally precise and scalable approach to capture the fast oscillatory dynamics that underlie spontaneous neural organization. In this study, we used a data-driven network approach to examine whether resting-state EEG connectivity patterns differentiate individuals according to their creative abilities. Creativity was evaluated by: The Inventory of Creative Activities and Achievements (ICAA), The Divergent Association Task (DAT), The Matchstick Arithmetic Puzzles Task (MAPT) and Self-rating (SR) of creative ability in 30 healthy young adults. Graph-theoretical analyses were applied to functional connectivity matrices and clustered based on graph similarity. Two distinct participant clusters emerged, differing systematically across multiple dimensions of creativity. Cluster 1, characterized by consistently higher performance across multiple creativity variables (ICAA, DAT, MAPT and SR), showed broad alpha-band hypoconnectivity, relatively preserved left frontal connectivity and greater network modularity. Cluster 0, associated with lower creativity scores, exhibited stronger overall connectivity strength, reduced modularity and higher local clustering. These findings suggest that resting-state EEG connectivity patterns can index stable cognitive traits such as creativity. More broadly, they point to an intrinsic neural signature of adaptive brain function marked by efficient yet flexible network organization that may support creative and adaptive cognition.",Bioinformatics
"Understanding how creativity is represented in the brain's intrinsic functional architecture remains a central challenge in cognitive neuroscience. While resting-state fMRI studies have revealed large-scale network correlates of creative potential, electroencephalography (EEG) offers a temporally precise and scalable approach to capture the fast oscillatory dynamics that underlie spontaneous neural organization. In this study, we used a data-driven network approach to examine whether resting-state EEG connectivity patterns differentiate individuals according to their creative abilities. Creativity was evaluated by: The Inventory of Creative Activities and Achievements (ICAA), The Divergent Association Task (DAT), The Matchstick Arithmetic Puzzles Task (MAPT) and Self-rating (SR) of creative ability in 30 healthy young adults. Graph-theoretical analyses were applied to functional connectivity matrices and clustered based on graph similarity. Two distinct participant clusters emerged, differing systematically across multiple dimensions of creativity. Cluster 1, characterized by consistently higher performance across multiple creativity variables (ICAA, DAT, MAPT and SR), showed broad alpha-band hypoconnectivity, relatively preserved left frontal connectivity and greater network modularity. Cluster 0, associated with lower creativity scores, exhibited stronger overall connectivity strength, reduced modularity and higher local clustering. These findings suggest that resting-state EEG connectivity patterns can index stable cognitive traits such as creativity. More broadly, they point to an intrinsic neural signature of adaptive brain function marked by efficient yet flexible network organization that may support creative and adaptive cognition. [SEP] [HINT] used -> Bioinformatics (Syns: utilize, ill-used, apply) | task -> Neuroscience (Syns: tax, project, chore) | connectivity -> Neuroscience (Syns: )",Bioinformatics
"Cognitive maps provide a powerful framework for understanding spatial and abstract reasoning in biological and artificial agents. While recent computational models link cognitive maps to hippocampal-entorhinal mechanisms, they often rely on global optimization rules (e.g., backpropagation) that lack biological plausibility. In this work, we propose a novel cognitive architecture for structuring episodic memories into cognitive maps using local, Hebbian-like learning rules, compatible with neural substrate constraints. Our model integrates the Successor Features framework with episodic memories, enabling incremental, online learning through agent-environment interaction. We demonstrate its efficacy in a partially observable grid-world, where the architecture autonomously organizes memories into structured representations without centralized optimization. This work bridges computational neuroscience and AI, offering a biologically grounded approach to cognitive map formation in artificial adaptive agents.",Neuroscience
"Cognitive maps provide a powerful framework for understanding spatial and abstract reasoning in biological and artificial agents. While recent computational models link cognitive maps to hippocampal-entorhinal mechanisms, they often rely on global optimization rules (e.g., backpropagation) that lack biological plausibility. In this work, we propose a novel cognitive architecture for structuring episodic memories into cognitive maps using local, Hebbian-like learning rules, compatible with neural substrate constraints. Our model integrates the Successor Features framework with episodic memories, enabling incremental, online learning through agent-environment interaction. We demonstrate its efficacy in a partially observable grid-world, where the architecture autonomously organizes memories into structured representations without centralized optimization. This work bridges computational neuroscience and AI, offering a biologically grounded approach to cognitive map formation in artificial adaptive agents. [SEP] [HINT] computational -> Neuroscience (Syns: ) | features -> Bioinformatics (Syns: characteristic, lineament, feature of speech) | understanding -> Neuroscience (Syns: savvy, intellect, sympathy)",Neuroscience
"The ideal altermagnets are a class of collinear, crystal-symmetry-enforced fully compensated magnets with nonrelativistic spin-split bands, in which contributions from Berry curvature to magneto-optical effects (MOEs) are strictly forbidden by an effective time-reversal symmetry. Here we show that, in such systems, MOEs are exclusively induced by the quantum metric and, in realistic altermagnets, are typically dominated by it. We refer to Berry-curvature-induced MOEs as conventional MOEs and to quantum-metric-dominated MOEs as unconventional MOEs. We derive general formulas that incorporate both Berry curvature and quantum metric for unconventional MOEs in altermagnets, enabling a quantitative evaluation of their respective contributions. Through symmetry analysis, we prove that ideal altermagnets are constrained to exhibit only unconventional MOEs. Using the three-dimensional canonical altermagnet MnTe and the emerging two-dimensional bilayer twisted altermagnet CrSBr as illustrative examples, we demonstrate that unconventional MOEs are prevalent in altermagnets. Our results establish altermagnets as a natural platform for quantum-metric-driven optical phenomena, substantially broadening the scope of MOEs and providing concrete predictions that can be tested in future experimental studies.",Materials Science
"The ideal altermagnets are a class of collinear, crystal-symmetry-enforced fully compensated magnets with nonrelativistic spin-split bands, in which contributions from Berry curvature to magneto-optical effects (MOEs) are strictly forbidden by an effective time-reversal symmetry. Here we show that, in such systems, MOEs are exclusively induced by the quantum metric and, in realistic altermagnets, are typically dominated by it. We refer to Berry-curvature-induced MOEs as conventional MOEs and to quantum-metric-dominated MOEs as unconventional MOEs. We derive general formulas that incorporate both Berry curvature and quantum metric for unconventional MOEs in altermagnets, enabling a quantitative evaluation of their respective contributions. Through symmetry analysis, we prove that ideal altermagnets are constrained to exhibit only unconventional MOEs. Using the three-dimensional canonical altermagnet MnTe and the emerging two-dimensional bilayer twisted altermagnet CrSBr as illustrative examples, we demonstrate that unconventional MOEs are prevalent in altermagnets. Our results establish altermagnets as a natural platform for quantum-metric-driven optical phenomena, substantially broadening the scope of MOEs and providing concrete predictions that can be tested in future experimental studies. [SEP] [HINT] results -> Bioinformatics (Syns: final result, consequence, resultant role) | using -> Bioinformatics (Syns: utilize, exploitation, apply) | optical -> Materials Science (Syns: ocular, opthalmic, optic)",Materials Science
"This study presents a closed-loop biorefinery strategy that thermochemically upcycles fermentation residues (FRs) from photo-fermentative biohydrogen production (PFHP) into functional biochar catalysts, thereby enhancing the efficiency of the initial PFHP process. Four FRs derived from hydrothermal and ethylene glycol-pretreated corn stover were pyrolyzed at 700°C. Multi-model kinetic analyses revealed diffusion-controlled mechanisms with activation energies ranging from 157 to 278 kJ/mol, while thermodynamic profiling highlighted the influence of feedstock composition on reaction spontaneity and entropy. Pyrolysis effectively restored porosity compromised during fermentation, yielding biochar with tailored properties: microporous BC3 (185 m2/g) from oxygen-rich precursors and mesoporous BC4 (76.58 m2/g) from graphitized residues. When reintroduced into PFHP, BC3 maximized cumulative hydrogen yield (570 mL) via pH buffering, and BC4 achieved the highest production rate (14.91 mL/h) through electron shuttle mechanisms. The integrated process concurrently generated syngas, bio-oil, and catalytic biochar, enabling waste valorization, renewable energy output, and process enhancement within a circular bioeconomy framework.",Materials Science
"This study presents a closed-loop biorefinery strategy that thermochemically upcycles fermentation residues (FRs) from photo-fermentative biohydrogen production (PFHP) into functional biochar catalysts, thereby enhancing the efficiency of the initial PFHP process. Four FRs derived from hydrothermal and ethylene glycol-pretreated corn stover were pyrolyzed at 700°C. Multi-model kinetic analyses revealed diffusion-controlled mechanisms with activation energies ranging from 157 to 278 kJ/mol, while thermodynamic profiling highlighted the influence of feedstock composition on reaction spontaneity and entropy. Pyrolysis effectively restored porosity compromised during fermentation, yielding biochar with tailored properties: microporous BC3 (185 m2/g) from oxygen-rich precursors and mesoporous BC4 (76.58 m2/g) from graphitized residues. When reintroduced into PFHP, BC3 maximized cumulative hydrogen yield (570 mL) via pH buffering, and BC4 achieved the highest production rate (14.91 mL/h) through electron shuttle mechanisms. The integrated process concurrently generated syngas, bio-oil, and catalytic biochar, enabling waste valorization, renewable energy output, and process enhancement within a circular bioeconomy framework. [SEP] [HINT] functional -> Neuroscience (Syns: working, usable, running) | electron -> Materials Science (Syns: negatron) | study -> Bioinformatics (Syns: sketch, meditate, take)",Materials Science
"Accurately predicting individual neurons' responses and spatial functional properties in complex visual tasks remains a key challenge in understanding neural computation. Existing whole-brain connectome models of Drosophila often rely on parameter assumptions or deep learning approaches, yet remain limited in their ability to reliably predict dynamic neuronal responses. We introduce a Multi-Path Aggregation (MPA) framework, based on neural network steady-state theory, to build a whole-brain Visual Function Profiles (VFP) of Drosophila neurons and predict their responses under diverse visual tasks. Unlike conventional methods relying on redundant parameters, MPA combines visual input features with the whole-brain connectome topology. It uses adjacency matrix powers and finite-path optimization to efficiently predict neuronal function, including ON/OFF polarity, direction selectivity, and responses to complex visual stimuli. Our model achieves a Pearson correlation of 0.84+/-0.12 for ON/OFF responses, outperforming existing methods (0.33+/-0.59), and accurately captures neuron functional properties, including luminance and direction preferences, while allowing single-neuron or population-level blockade simulations. Replacing CNN modules with VFP-derived Lobula Columnar(LC) population responses in a Drosophila simulation enables successful navigation and obstacle avoidance, demonstrating the model's effectiveness in guiding embodied behavior. This study establishes a ""connectome-functional profile-behavior"" framework, offering a whole-brain quantitative tool to study Drosophila visual computation and a neuron-level guide for brain-inspired intelligence.",Bioinformatics
"Accurately predicting individual neurons' responses and spatial functional properties in complex visual tasks remains a key challenge in understanding neural computation. Existing whole-brain connectome models of Drosophila often rely on parameter assumptions or deep learning approaches, yet remain limited in their ability to reliably predict dynamic neuronal responses. We introduce a Multi-Path Aggregation (MPA) framework, based on neural network steady-state theory, to build a whole-brain Visual Function Profiles (VFP) of Drosophila neurons and predict their responses under diverse visual tasks. Unlike conventional methods relying on redundant parameters, MPA combines visual input features with the whole-brain connectome topology. It uses adjacency matrix powers and finite-path optimization to efficiently predict neuronal function, including ON/OFF polarity, direction selectivity, and responses to complex visual stimuli. Our model achieves a Pearson correlation of 0.84+/-0.12 for ON/OFF responses, outperforming existing methods (0.33+/-0.59), and accurately captures neuron functional properties, including luminance and direction preferences, while allowing single-neuron or population-level blockade simulations. Replacing CNN modules with VFP-derived Lobula Columnar(LC) population responses in a Drosophila simulation enables successful navigation and obstacle avoidance, demonstrating the model's effectiveness in guiding embodied behavior. This study establishes a ""connectome-functional profile-behavior"" framework, offering a whole-brain quantitative tool to study Drosophila visual computation and a neuron-level guide for brain-inspired intelligence. [SEP] [HINT] tasks -> Neuroscience (Syns: tax, task, project) | based -> Bioinformatics (Syns: ground, free-base, base) | features -> Bioinformatics (Syns: characteristic, lineament, feature of speech)",Bioinformatics
"The great potential of memristive devices for real-world applications still relies on overcoming key technical challenges, including the need for a larger number of stable resistance states, faster switching speeds, lower SET/RESET voltages, improved endurance, and reduced variability. One material optimization strategy that has still been quite overlooked is interface engineering, specifically, tailoring the electrode/dielectric interface to modulate oxygen exchange. Here, we demonstrate that introducing materials with high ionic mobility can significantly expand the accessible oxygen concentration range within the dielectric layer, significantly broadening the memory window. Using SrTiO3-based memristive stacks, we integrated an ion-conducting SrCoO3 interfacial layer to facilitate oxygen transfer, increasing the number of distinguishable resistance states from 8 to 22. This modification also reduced the SET/RESET voltage by 50% and markedly improved device endurance, albeit with a trade-off of reduced state retention. To assess the practical implications of this trade-off, we trained a two-layer fully connected neural network using the experimental SrTiO3/SrCoO3 memristor characteristics on the MNIST handwritten digit dataset. Networks with hidden-layer sizes between 64 and 256 memristive elements achieved classification errors below 7%. The observed temporal drift means the functional state must be updated at intervals of less than 1 h to maintain reliable operation. Finally, we confirmed the transferability of this interface-engineering approach by applying it to HfOx-based devices, achieving a similarly enhanced memory window.",Materials Science
"The great potential of memristive devices for real-world applications still relies on overcoming key technical challenges, including the need for a larger number of stable resistance states, faster switching speeds, lower SET/RESET voltages, improved endurance, and reduced variability. One material optimization strategy that has still been quite overlooked is interface engineering, specifically, tailoring the electrode/dielectric interface to modulate oxygen exchange. Here, we demonstrate that introducing materials with high ionic mobility can significantly expand the accessible oxygen concentration range within the dielectric layer, significantly broadening the memory window. Using SrTiO3-based memristive stacks, we integrated an ion-conducting SrCoO3 interfacial layer to facilitate oxygen transfer, increasing the number of distinguishable resistance states from 8 to 22. This modification also reduced the SET/RESET voltage by 50% and markedly improved device endurance, albeit with a trade-off of reduced state retention. To assess the practical implications of this trade-off, we trained a two-layer fully connected neural network using the experimental SrTiO3/SrCoO3 memristor characteristics on the MNIST handwritten digit dataset. Networks with hidden-layer sizes between 64 and 256 memristive elements achieved classification errors below 7%. The observed temporal drift means the functional state must be updated at intervals of less than 1 h to maintain reliable operation. Finally, we confirmed the transferability of this interface-engineering approach by applying it to HfOx-based devices, achieving a similarly enhanced memory window. [SEP] [HINT] networks -> Neuroscience (Syns: network, meshwork, electronic network) | functional -> Neuroscience (Syns: working, usable, running) | including -> Bioinformatics (Syns: admit, include, let in)",Materials Science
"The notion of synthetic molecular communication (MC) refers to the transmission of information via signaling molecules and is foreseen to enable innovative medical applications in the human cardiovascular system (CVS). Crucially, the design of such applications requires accurate and experimentally validated channel models that characterize the propagation of signaling molecules, not just in individual blood vessels, but in complex vessel networks (VNs), as prevalent in the CVS. However, experimentally validated models for MC in VNs remain scarce. To address this gap, we propose a novel channel model for MC in complex VN topologies, which captures molecular transport via advection, molecular and turbulent diffusion, as well as adsorption and desorption at the vessel walls. We specialize this model for superparamagnetic iron-oxide nanoparticles (SPIONs) as signaling molecules by introducing a new receiver (RX) model for planar coil inductive sensors, enabling end-to-end experimental validation with a dedicated SPION testbed. Validation covers a range of channel topologies, from single-vessel topologies to branched VNs with multiple paths between transmitter (TX) and RX. Additionally, to quantify how the VN topology impacts signal quality, and inspired by multi-path propagation models in conventional wireless communications, we introduce two metrics, namely molecule delay and multi-path spread. We show that these metrics link the VN structure to molecule dispersion induced by the VN and mediately to the resulting signal-to-noise ratio (SNR) at the RX. The proposed VN structure-SNR link is validated experimentally, demonstrating that the proposed framework can support tasks such as optimal sensor placement in the CVS or the identification of suitable testbed topologies for specific SNR requirements. All experimental data are openly available on Zenodo.",Bioinformatics
"The notion of synthetic molecular communication (MC) refers to the transmission of information via signaling molecules and is foreseen to enable innovative medical applications in the human cardiovascular system (CVS). Crucially, the design of such applications requires accurate and experimentally validated channel models that characterize the propagation of signaling molecules, not just in individual blood vessels, but in complex vessel networks (VNs), as prevalent in the CVS. However, experimentally validated models for MC in VNs remain scarce. To address this gap, we propose a novel channel model for MC in complex VN topologies, which captures molecular transport via advection, molecular and turbulent diffusion, as well as adsorption and desorption at the vessel walls. We specialize this model for superparamagnetic iron-oxide nanoparticles (SPIONs) as signaling molecules by introducing a new receiver (RX) model for planar coil inductive sensors, enabling end-to-end experimental validation with a dedicated SPION testbed. Validation covers a range of channel topologies, from single-vessel topologies to branched VNs with multiple paths between transmitter (TX) and RX. Additionally, to quantify how the VN topology impacts signal quality, and inspired by multi-path propagation models in conventional wireless communications, we introduce two metrics, namely molecule delay and multi-path spread. We show that these metrics link the VN structure to molecule dispersion induced by the VN and mediately to the resulting signal-to-noise ratio (SNR) at the RX. The proposed VN structure-SNR link is validated experimentally, demonstrating that the proposed framework can support tasks such as optimal sensor placement in the CVS or the identification of suitable testbed topologies for specific SNR requirements. All experimental data are openly available on Zenodo. [SEP] [HINT] tasks -> Neuroscience (Syns: tax, task, project) | transport -> Materials Science (Syns: transferral, enthral, shipping) | networks -> Neuroscience (Syns: network, meshwork, electronic network)",Bioinformatics
"Achieving robust generalization across individuals remains a major challenge in electroencephalogram based imagined speech decoding due to substantial variability in neural activity patterns. This study examined how training dynamics and lightweight subject specific adaptation influence cross subject performance in a neural decoding framework. A cyclic inter subject training approach, involving shorter per subject training segments and frequent alternation among subjects, led to modest yet consistent improvements in decoding performance across unseen target data. Furthermore, under the subject calibrated leave one subject out scheme, incorporating only 10 % of the target subjects data for calibration achieved an accuracy of 0.781 and an AUC of 0.801, demonstrating the effectiveness of few shot adaptation. These findings suggest that integrating cyclic training with minimal calibration provides a simple and effective strategy for developing scalable, user adaptive brain computer interface systems that balance generalization and personalization.",Neuroscience
"Achieving robust generalization across individuals remains a major challenge in electroencephalogram based imagined speech decoding due to substantial variability in neural activity patterns. This study examined how training dynamics and lightweight subject specific adaptation influence cross subject performance in a neural decoding framework. A cyclic inter subject training approach, involving shorter per subject training segments and frequent alternation among subjects, led to modest yet consistent improvements in decoding performance across unseen target data. Furthermore, under the subject calibrated leave one subject out scheme, incorporating only 10 % of the target subjects data for calibration achieved an accuracy of 0.781 and an AUC of 0.801, demonstrating the effectiveness of few shot adaptation. These findings suggest that integrating cyclic training with minimal calibration provides a simple and effective strategy for developing scalable, user adaptive brain computer interface systems that balance generalization and personalization. [SEP] [HINT] decoding -> Neuroscience (Syns: decrypt, decipherment, decryption) | based -> Bioinformatics (Syns: ground, free-base, base) | performance -> Bioinformatics (Syns: functioning, operation, carrying out)",Neuroscience
"Decoding the heterogeneity of biological neural systems is key to understanding the nervous system's complex dynamical behaviors. This study analyzes the comprehensive Drosophila brain connectome, which is the most recent data set, containing over 130,000 neurons and 50 million synapses. We conducted meticulous analyses of both network and spatial structure. Our findings reveal significant heterogeneity in network properties and distinct spatial clustering across functional regions. Besides, our analysis revealed a modular organizational pattern within the neural network, wherein regions with similar functions exhibited higher connection densities, forming distinct community structures. Moreover, we observed spatial clustering within functional regions but was not statistically significant. Additionally, we identify pervasive bilateral symmetry in network topology and spatial organization. Simulations based on the Kuramoto model demonstrate that the functional asymmetry between cerebral hemispheres arises from disparities in the intrinsic frequencies of neurons rather than from structural asymmetry within the neural network itself. Finally, we develop a 3D connectome visualization tool for detailed mapping of neuronal morphology. These insights advance our understanding of neural network organization and complexity in biological systems.",Neuroscience
"Decoding the heterogeneity of biological neural systems is key to understanding the nervous system's complex dynamical behaviors. This study analyzes the comprehensive Drosophila brain connectome, which is the most recent data set, containing over 130,000 neurons and 50 million synapses. We conducted meticulous analyses of both network and spatial structure. Our findings reveal significant heterogeneity in network properties and distinct spatial clustering across functional regions. Besides, our analysis revealed a modular organizational pattern within the neural network, wherein regions with similar functions exhibited higher connection densities, forming distinct community structures. Moreover, we observed spatial clustering within functional regions but was not statistically significant. Additionally, we identify pervasive bilateral symmetry in network topology and spatial organization. Simulations based on the Kuramoto model demonstrate that the functional asymmetry between cerebral hemispheres arises from disparities in the intrinsic frequencies of neurons rather than from structural asymmetry within the neural network itself. Finally, we develop a 3D connectome visualization tool for detailed mapping of neuronal morphology. These insights advance our understanding of neural network organization and complexity in biological systems. [SEP] [HINT] decoding -> Neuroscience (Syns: decrypt, decipherment, decryption) | based -> Bioinformatics (Syns: ground, free-base, base) | understanding -> Neuroscience (Syns: savvy, intellect, sympathy)",Neuroscience
"We develop and validate a novel spherical radiomics framework for predicting key molecular biomarkers using multiparametric MRI. Conventional Cartesian radiomics extract tumor features on orthogonal grids, which do not fully capture the tumor's radial growth patterns and can be insensitive to evolving molecular signatures. In this study, we analyzed GBM radiomic features on concentric 2D shells, which were then mapped onto 2D planes for radiomics analysis. Radiomic features were extracted using PyRadiomics from four different regions in GBM. Feature selection was performed using ANOVA F-statistics. Classification was conducted with multiple machine-learning models. Model interpretability was evaluated through SHAP analysis, clustering analysis, feature significance profiling, and comparison between radiomic patterns and underlying biological processes. Spherical radiomics consistently outperformed conventional 2D and 3D Cartesian radiomics across all prediction tasks. The best framework reached an AUC of 0.85 for MGMT, 0.80 for EGFR, 0.80 for PTEN, and 0.83 for survival prediction. GLCM-derived features were identified as the most informative predictors. Radial transition analysis using the Mann-Whitney U-test demonstrates that transition slopes between T1-weighted contrast-enhancing and T2/FLAIR hyperintense lesion regions, as well as between T2 intense lesion and a 2 cm peritumoral expansion region, are significantly associated with biomarker status. Furthermore, the observed radiomic changes along the radial direction closely reflected known biological characteristics. Radiomic features extracted on the spherical surfaces at varying radial distances to the GBM tumor centroid are better correlated with important tumor molecular markers and patient survival than the conventional Cartesian analysis.",Bioinformatics
"We develop and validate a novel spherical radiomics framework for predicting key molecular biomarkers using multiparametric MRI. Conventional Cartesian radiomics extract tumor features on orthogonal grids, which do not fully capture the tumor's radial growth patterns and can be insensitive to evolving molecular signatures. In this study, we analyzed GBM radiomic features on concentric 2D shells, which were then mapped onto 2D planes for radiomics analysis. Radiomic features were extracted using PyRadiomics from four different regions in GBM. Feature selection was performed using ANOVA F-statistics. Classification was conducted with multiple machine-learning models. Model interpretability was evaluated through SHAP analysis, clustering analysis, feature significance profiling, and comparison between radiomic patterns and underlying biological processes. Spherical radiomics consistently outperformed conventional 2D and 3D Cartesian radiomics across all prediction tasks. The best framework reached an AUC of 0.85 for MGMT, 0.80 for EGFR, 0.80 for PTEN, and 0.83 for survival prediction. GLCM-derived features were identified as the most informative predictors. Radial transition analysis using the Mann-Whitney U-test demonstrates that transition slopes between T1-weighted contrast-enhancing and T2/FLAIR hyperintense lesion regions, as well as between T2 intense lesion and a 2 cm peritumoral expansion region, are significantly associated with biomarker status. Furthermore, the observed radiomic changes along the radial direction closely reflected known biological characteristics. Radiomic features extracted on the spherical surfaces at varying radial distances to the GBM tumor centroid are better correlated with important tumor molecular markers and patient survival than the conventional Cartesian analysis. [SEP] [HINT] transition -> Materials Science (Syns: passage, modulation, changeover) | features -> Bioinformatics (Syns: characteristic, lineament, feature of speech) | molecular -> Bioinformatics (Syns: )",Bioinformatics
"Physics-informed machine learning (PIML) is emerging as a potentially transformative paradigm for modeling complex biomedical systems by integrating parameterized physical laws with data-driven methods. Here, we review three main classes of PIML frameworks: physics-informed neural networks (PINNs), neural ordinary differential equations (NODEs), and neural operators (NOs), highlighting their growing role in biomedical science and engineering. We begin with PINNs, which embed governing equations into deep learning models and have been successfully applied to biosolid and biofluid mechanics, mechanobiology, and medical imaging among other areas. We then review NODEs, which offer continuous-time modeling, especially suited to dynamic physiological systems, pharmacokinetics, and cell signaling. Finally, we discuss deep NOs as powerful tools for learning mappings between function spaces, enabling efficient simulations across multiscale and spatially heterogeneous biological domains. Throughout, we emphasize applications where physical interpretability, data scarcity, or system complexity make conventional black-box learning insufficient. We conclude by identifying open challenges and future directions for advancing PIML in biomedical science and engineering, including issues of uncertainty quantification, generalization, and integration of PIML and large language models.",Bioinformatics
"Physics-informed machine learning (PIML) is emerging as a potentially transformative paradigm for modeling complex biomedical systems by integrating parameterized physical laws with data-driven methods. Here, we review three main classes of PIML frameworks: physics-informed neural networks (PINNs), neural ordinary differential equations (NODEs), and neural operators (NOs), highlighting their growing role in biomedical science and engineering. We begin with PINNs, which embed governing equations into deep learning models and have been successfully applied to biosolid and biofluid mechanics, mechanobiology, and medical imaging among other areas. We then review NODEs, which offer continuous-time modeling, especially suited to dynamic physiological systems, pharmacokinetics, and cell signaling. Finally, we discuss deep NOs as powerful tools for learning mappings between function spaces, enabling efficient simulations across multiscale and spatially heterogeneous biological domains. Throughout, we emphasize applications where physical interpretability, data scarcity, or system complexity make conventional black-box learning insufficient. We conclude by identifying open challenges and future directions for advancing PIML in biomedical science and engineering, including issues of uncertainty quantification, generalization, and integration of PIML and large language models. [SEP] [HINT] language -> Neuroscience (Syns: linguistic process, linguistic communication, spoken communication) | learning -> Bioinformatics (Syns: take, teach, acquire) | networks -> Neuroscience (Syns: network, meshwork, electronic network)",Bioinformatics
"As data-centric computing advances, energy-efficient interconnects are increasingly critical for AI-driven systems. Traditional metal conductors face severe limitations at nanoscale due to increased resistivity from surface scattering. In response, this study demonstrates the first wafer-scale realization of an amorphous topological semimetal, tantalum phosphide (TaP), grown directly on amorphous SiO2 substrates (without any seed layers) using low-temperature atomic layer deposition (ALD). The resulting TaP films exhibit unconventional resistivity scaling: decreasing resistivity with decreasing thickness, reaching 227 micro-ohm cm at ~2.3 nm film thickness. This behavior, observed without crystalline order or seed layers, indicates dominant surface conduction and establishes ALD-TaP as a promising candidate for back-end-of-line integration. The films also show excellent conformality, stoichiometry control, and thermal stability up to 600 degree C. A two-channel conduction model confirms surface-dominated transport in ultrathin regimes, further supported by enhanced conductivity in multi-stacked configurations. These findings highlight the potential of amorphous topological semimetals for future high-density, low-power electronic interconnects and expand the applicability of ALD for integrating novel quantum materials at scale.",Materials Science
"As data-centric computing advances, energy-efficient interconnects are increasingly critical for AI-driven systems. Traditional metal conductors face severe limitations at nanoscale due to increased resistivity from surface scattering. In response, this study demonstrates the first wafer-scale realization of an amorphous topological semimetal, tantalum phosphide (TaP), grown directly on amorphous SiO2 substrates (without any seed layers) using low-temperature atomic layer deposition (ALD). The resulting TaP films exhibit unconventional resistivity scaling: decreasing resistivity with decreasing thickness, reaching 227 micro-ohm cm at ~2.3 nm film thickness. This behavior, observed without crystalline order or seed layers, indicates dominant surface conduction and establishes ALD-TaP as a promising candidate for back-end-of-line integration. The films also show excellent conformality, stoichiometry control, and thermal stability up to 600 degree C. A two-channel conduction model confirms surface-dominated transport in ultrathin regimes, further supported by enhanced conductivity in multi-stacked configurations. These findings highlight the potential of amorphous topological semimetals for future high-density, low-power electronic interconnects and expand the applicability of ALD for integrating novel quantum materials at scale. [SEP] [HINT] transport -> Materials Science (Syns: transferral, enthral, shipping) | electronic -> Materials Science (Syns: ) | order -> Materials Science (Syns: enjoin, dictate, social club)",Materials Science
"Games have long been a microcosm for studying planning and reasoning in both natural and artificial intelligence, especially with a focus on expert-level or even super-human play. But real life also pushes human intelligence along a different frontier, requiring people to flexibly navigate decision-making problems that they have never thought about before. Here, we use novice gameplay to study how people make decisions and form judgments in new problem settings. We show that people are systematic and adaptively rational in how they play a game for the first time, or evaluate a game (e.g., how fair or how fun it is likely to be) before they have played it even once. We explain these capacities via a computational cognitive model that we call the ""Intuitive Gamer"". The model is based on mechanisms of fast and flat (depth-limited) goal-directed probabilistic simulation--analogous to those used in Monte Carlo tree-search models of expert game-play, but scaled down to use very few stochastic samples, simple goal heuristics for evaluating actions, and no deep search. In a series of large-scale behavioral studies with over 1000 participants and 121 two-player strategic board games (almost all novel to our participants), our model quantitatively captures human judgments and decisions varying the amount and kind of experience people have with a game--from no experience at all (""just thinking""), to a single round of play, to indirect experience watching another person and predicting how they should play--and does so significantly better than much more compute-intensive expert-level models. More broadly, our work offers new insights into how people rapidly evaluate, act, and make suggestions when encountering novel problems, and could inform the design of more flexible and human-like AI systems that can determine not just how to solve new tasks, but whether a task is worth thinking about at all.",Neuroscience
"Games have long been a microcosm for studying planning and reasoning in both natural and artificial intelligence, especially with a focus on expert-level or even super-human play. But real life also pushes human intelligence along a different frontier, requiring people to flexibly navigate decision-making problems that they have never thought about before. Here, we use novice gameplay to study how people make decisions and form judgments in new problem settings. We show that people are systematic and adaptively rational in how they play a game for the first time, or evaluate a game (e.g., how fair or how fun it is likely to be) before they have played it even once. We explain these capacities via a computational cognitive model that we call the ""Intuitive Gamer"". The model is based on mechanisms of fast and flat (depth-limited) goal-directed probabilistic simulation--analogous to those used in Monte Carlo tree-search models of expert game-play, but scaled down to use very few stochastic samples, simple goal heuristics for evaluating actions, and no deep search. In a series of large-scale behavioral studies with over 1000 participants and 121 two-player strategic board games (almost all novel to our participants), our model quantitatively captures human judgments and decisions varying the amount and kind of experience people have with a game--from no experience at all (""just thinking""), to a single round of play, to indirect experience watching another person and predicting how they should play--and does so significantly better than much more compute-intensive expert-level models. More broadly, our work offers new insights into how people rapidly evaluate, act, and make suggestions when encountering novel problems, and could inform the design of more flexible and human-like AI systems that can determine not just how to solve new tasks, but whether a task is worth thinking about at all. [SEP] [HINT] used -> Bioinformatics (Syns: utilize, ill-used, apply) | task -> Neuroscience (Syns: tax, project, chore) | based -> Bioinformatics (Syns: ground, free-base, base)",Neuroscience
"Accurate modeling of neuronal action potential (AP) onset timing is crucial for understanding neural coding of danger signals. Traditional leaky integrate-and-fire (LIF) models, while widely used, exhibit high relative error in predicting AP onset latency, especially under strong or rapidly changing stimuli. Inspired by recent experimental findings and quantum theory, we present a quantum-inspired leaky integrate-and-fire (QI-LIF) model that treats AP onset as a probabilistic event, represented by a Gaussian wave packet in time. This approach captures the biological variability and uncertainty inherent in neuronal firing. We systematically compare the relative error of AP onset predictions between the classical LIF and QI-LIF models using synthetic data from hippocampal and sensory neurons subjected to varying stimulus amplitudes. Our results demonstrate that the QI-LIF model significantly reduces prediction error, particularly for high-intensity stimuli, aligning closely with observed biological responses. This work highlights the potential of quantum-inspired computational frameworks in advancing the accuracy of neural modeling and has implications for quantum engineering approaches to brain-inspired computing.",Neuroscience
"Accurate modeling of neuronal action potential (AP) onset timing is crucial for understanding neural coding of danger signals. Traditional leaky integrate-and-fire (LIF) models, while widely used, exhibit high relative error in predicting AP onset latency, especially under strong or rapidly changing stimuli. Inspired by recent experimental findings and quantum theory, we present a quantum-inspired leaky integrate-and-fire (QI-LIF) model that treats AP onset as a probabilistic event, represented by a Gaussian wave packet in time. This approach captures the biological variability and uncertainty inherent in neuronal firing. We systematically compare the relative error of AP onset predictions between the classical LIF and QI-LIF models using synthetic data from hippocampal and sensory neurons subjected to varying stimulus amplitudes. Our results demonstrate that the QI-LIF model significantly reduces prediction error, particularly for high-intensity stimuli, aligning closely with observed biological responses. This work highlights the potential of quantum-inspired computational frameworks in advancing the accuracy of neural modeling and has implications for quantum engineering approaches to brain-inspired computing. [SEP] [HINT] computational -> Neuroscience (Syns: ) | understanding -> Neuroscience (Syns: savvy, intellect, sympathy) | work -> Bioinformatics (Syns: work out, process, bring)",Neuroscience
"The breaking of spatial inversion symmetry in condensed matter gives rise to intriguing physical properties, such as ferroelectricity, piezoelectricity, spin-momentum locking, and nonreciprocal responses. Here we propose that a concentration gradient, which often persists as a quasi-stable nonequilibrium state with long relaxation times in solids, can serve as a general platform for inversion symmetry breaking. We demonstrate this concept in an epitaxial thin film of the hydrogen-doped SmFeAsO (Sm1111:H) superconductor with a depthwise hydrogen-concentration gradient introduced via an optimized topotactic reaction. This film exhibits nonreciprocal charge transport, meaning that the electrical resistance depends on the direction of the applied current, which serves as a key signature of broken inversion symmetry. A pronounced nonreciprocal signal emerges in the vicinity of the superconducting transition, which we attribute to vortex-motion nonreciprocity arising from an asymmetric pinning landscape created by the hydrogen-concentration gradient. Owing to the high critical temperature of Sm1111:H, vortex-origin nonreciprocity is observed above 40 K, representing the highest temperature reported to date among single bulk materials without an artificially hetero-layered structure. Our findings establish concentration-gradient engineering as a versatile and broadly applicable route for realizing inversion-broken states in otherwise centrosymmetric hosts, opening pathways toward a broader landscape of odd-parity-driven functionalities.",Materials Science
"The breaking of spatial inversion symmetry in condensed matter gives rise to intriguing physical properties, such as ferroelectricity, piezoelectricity, spin-momentum locking, and nonreciprocal responses. Here we propose that a concentration gradient, which often persists as a quasi-stable nonequilibrium state with long relaxation times in solids, can serve as a general platform for inversion symmetry breaking. We demonstrate this concept in an epitaxial thin film of the hydrogen-doped SmFeAsO (Sm1111:H) superconductor with a depthwise hydrogen-concentration gradient introduced via an optimized topotactic reaction. This film exhibits nonreciprocal charge transport, meaning that the electrical resistance depends on the direction of the applied current, which serves as a key signature of broken inversion symmetry. A pronounced nonreciprocal signal emerges in the vicinity of the superconducting transition, which we attribute to vortex-motion nonreciprocity arising from an asymmetric pinning landscape created by the hydrogen-concentration gradient. Owing to the high critical temperature of Sm1111:H, vortex-origin nonreciprocity is observed above 40 K, representing the highest temperature reported to date among single bulk materials without an artificially hetero-layered structure. Our findings establish concentration-gradient engineering as a versatile and broadly applicable route for realizing inversion-broken states in otherwise centrosymmetric hosts, opening pathways toward a broader landscape of odd-parity-driven functionalities. [SEP] [HINT] charge -> Materials Science (Syns: tear, bearing, burster) | materials -> Materials Science (Syns: stuff, cloth, material) | demonstrate -> Bioinformatics (Syns: evidence, march, prove)",Materials Science
"GeSn semiconductors are group-IV isovalent alloys that offer remarkable tunability of optoelectronic properties across the entire infrared spectrum, while remaining fully compatible with silicon processing standards. These attributes make GeSn a promising platform for scalable sensing, imaging, and communication technologies. Yet, the influence of dimensionality on GeSn crystal growth remains poorly understood, limiting the development of integrated nanoscale infrared devices. Here, we reveal the spontaneous formation of hitherto unreported ultra-thin GeSn fins with sub-30 nm thickness during vapor-phase growth on Ge nanowire substrates. A transition from the typical conformal GeSn shell to distinct fin-like structures occurs along the nanowire growth axis and is accompanied by ordered twin defects extending longitudinally and laterally, inducing a transition from diamond to hexagonal-like crystal structure. The fins exhibit uniform Sn incorporation of approximately 16 at.% throughout their volume, indicating high compositional homogeneity. These findings uncover an anisotropic growth regime in metastable GeSn alloys, enriching the fundamental understanding of nanoscale epitaxy.",Materials Science
"GeSn semiconductors are group-IV isovalent alloys that offer remarkable tunability of optoelectronic properties across the entire infrared spectrum, while remaining fully compatible with silicon processing standards. These attributes make GeSn a promising platform for scalable sensing, imaging, and communication technologies. Yet, the influence of dimensionality on GeSn crystal growth remains poorly understood, limiting the development of integrated nanoscale infrared devices. Here, we reveal the spontaneous formation of hitherto unreported ultra-thin GeSn fins with sub-30 nm thickness during vapor-phase growth on Ge nanowire substrates. A transition from the typical conformal GeSn shell to distinct fin-like structures occurs along the nanowire growth axis and is accompanied by ordered twin defects extending longitudinally and laterally, inducing a transition from diamond to hexagonal-like crystal structure. The fins exhibit uniform Sn incorporation of approximately 16 at.% throughout their volume, indicating high compositional homogeneity. These findings uncover an anisotropic growth regime in metastable GeSn alloys, enriching the fundamental understanding of nanoscale epitaxy. [SEP] [HINT] transition -> Materials Science (Syns: passage, modulation, changeover) | understanding -> Neuroscience (Syns: savvy, intellect, sympathy) | processing -> Neuroscience (Syns: work, process, march)",Materials Science
"Single-cell RNA sequencing (scRNA-seq) data simulation is limited by classical methods that rely on linear correlations, failing to capture the intrinsic, nonlinear dependencies. No existing simulator jointly models gene-gene and cell-cell interactions. We introduce qSimCells, a novel quantum computing-based simulator that employs entanglement to model intra- and inter-cellular interactions, generating realistic single-cell transcriptomes with cellular heterogeneity. The core innovation is a quantum kernel that uses a parameterized quantum circuit with CNOT gates to encode complex, nonlinear gene regulatory network (GRN) as well as cell-cell communication topologies with explicit causal directionality. The resulting synthetic data exhibits non-classical dependencies: standard correlation-based analyses (Pearson and Spearman) fail to recover the programmed causal pathways and instead report spurious associations driven by high baseline gene-expression probabilities. Furthermore, applying cell-cell communication detection to the simulated data validates the true mechanistic links, revealing a robust, up to 75-fold relative increase in inferred communication probability only when quantum entanglement is active. These results demonstrate that the quantum kernel is essential for producing high-fidelity ground-truth datasets and highlight the need for advanced inference techniques to capture the complex, non-classical dependencies inherent in gene regulation.",Bioinformatics
"Single-cell RNA sequencing (scRNA-seq) data simulation is limited by classical methods that rely on linear correlations, failing to capture the intrinsic, nonlinear dependencies. No existing simulator jointly models gene-gene and cell-cell interactions. We introduce qSimCells, a novel quantum computing-based simulator that employs entanglement to model intra- and inter-cellular interactions, generating realistic single-cell transcriptomes with cellular heterogeneity. The core innovation is a quantum kernel that uses a parameterized quantum circuit with CNOT gates to encode complex, nonlinear gene regulatory network (GRN) as well as cell-cell communication topologies with explicit causal directionality. The resulting synthetic data exhibits non-classical dependencies: standard correlation-based analyses (Pearson and Spearman) fail to recover the programmed causal pathways and instead report spurious associations driven by high baseline gene-expression probabilities. Furthermore, applying cell-cell communication detection to the simulated data validates the true mechanistic links, revealing a robust, up to 75-fold relative increase in inferred communication probability only when quantum entanglement is active. These results demonstrate that the quantum kernel is essential for producing high-fidelity ground-truth datasets and highlight the need for advanced inference techniques to capture the complex, non-classical dependencies inherent in gene regulation. [SEP] [HINT] datasets -> Bioinformatics (Syns: ) | results -> Bioinformatics (Syns: final result, consequence, resultant role) | existing -> Bioinformatics (Syns: subsist, existent, survive)",Bioinformatics
"Graphical domination was first introduced in [1] in the context of combinatorial threshold-linear networks (CTLNs). There it was shown that when a domination relationship exists between a pair of vertices in a graph, certain fixed points in the corresponding CTLN can be ruled out. Here we prove two new theorems about graphical domination, and show that they apply to a significantly more general class of recurrent networks called generalized CTLNs (gCTLNs). Theorem 1 establishes that if a dominated node is removed from a network, the reduced network has exactly the same fixed points. Theorem 2 tells us that by iteratively removing dominated nodes from an initial graph $G$, the final (irreducible) graph $\widetilde{G}$ is unique. We also introduce another new family of TLNs, called E-I TLNs, consisting of $n$ excitatory nodes and a single inhibitory node providing global inhibition. We provide a concrete mapping between the parameters of gCTLNs and E-I TLNs built from the same graph such that corresponding networks have the same fixed points. We also show that Theorems 1 and 2 apply equally well to E-I TLNs, and that the dynamics of gCTLNs and E-I TLNs with the same underlying graph $G$ exhibit similar behavior that is well predicted by the fixed points of the reduced graph $\widetilde{G}$.",Neuroscience
"Graphical domination was first introduced in [1] in the context of combinatorial threshold-linear networks (CTLNs). There it was shown that when a domination relationship exists between a pair of vertices in a graph, certain fixed points in the corresponding CTLN can be ruled out. Here we prove two new theorems about graphical domination, and show that they apply to a significantly more general class of recurrent networks called generalized CTLNs (gCTLNs). Theorem 1 establishes that if a dominated node is removed from a network, the reduced network has exactly the same fixed points. Theorem 2 tells us that by iteratively removing dominated nodes from an initial graph $G$, the final (irreducible) graph $\widetilde{G}$ is unique. We also introduce another new family of TLNs, called E-I TLNs, consisting of $n$ excitatory nodes and a single inhibitory node providing global inhibition. We provide a concrete mapping between the parameters of gCTLNs and E-I TLNs built from the same graph such that corresponding networks have the same fixed points. We also show that Theorems 1 and 2 apply equally well to E-I TLNs, and that the dynamics of gCTLNs and E-I TLNs with the same underlying graph $G$ exhibit similar behavior that is well predicted by the fixed points of the reduced graph $\widetilde{G}$. [SEP] [HINT] networks -> Neuroscience (Syns: network, meshwork, electronic network) | dynamics -> Bioinformatics (Syns: kinetics, dynamic, moral force) | network -> Bioinformatics (Syns: meshwork, electronic network, mesh)",Neuroscience
"Valvular heart disease is prevalent and a major contributor to heart failure. Valve leaflet strain is a promising metric for evaluating the mechanics underlying the initiation and progression of valvular pathology. However, robust and generalizable methods for noninvasively quantifying valvular strain from clinically acquired patient images remain limited. In this work, we present a novel feature-tracking framework for quantifying leaflet strain in atrioventricular valves using 3D echocardiographic images of pediatric and adult patients. Our method demonstrated superior accuracy in the assessment of anatomical deformation and strain of heart valves compared to other point-based approaches, as verified against a finite element benchmark. Further, our approach can robustly track inter-phase deformation of valves across highly variable morphologies without parameter tuning. Our analysis revealed that a median and interquartile range of the 1st principal strain greater than 0.5 is associated with leaflet billow (prolapse). Further investigation of the biomechanical signatures of heart valve disease has the potential to enhance prognostic assessment and longitudinal evaluation of valvular disease.",Bioinformatics
"Valvular heart disease is prevalent and a major contributor to heart failure. Valve leaflet strain is a promising metric for evaluating the mechanics underlying the initiation and progression of valvular pathology. However, robust and generalizable methods for noninvasively quantifying valvular strain from clinically acquired patient images remain limited. In this work, we present a novel feature-tracking framework for quantifying leaflet strain in atrioventricular valves using 3D echocardiographic images of pediatric and adult patients. Our method demonstrated superior accuracy in the assessment of anatomical deformation and strain of heart valves compared to other point-based approaches, as verified against a finite element benchmark. Further, our approach can robustly track inter-phase deformation of valves across highly variable morphologies without parameter tuning. Our analysis revealed that a median and interquartile range of the 1st principal strain greater than 0.5 is associated with leaflet billow (prolapse). Further investigation of the biomechanical signatures of heart valve disease has the potential to enhance prognostic assessment and longitudinal evaluation of valvular disease. [SEP] [HINT] framework -> Bioinformatics (Syns: theoretical account, model, fabric) | using -> Bioinformatics (Syns: utilize, exploitation, apply) | strain -> Materials Science (Syns: air, stock, form)",Bioinformatics
"Accurate simulations of electric fields (E-fields) in brain stimulation depend on tissue conductivity representations that link macroscopic assumptions with underlying microscopic tissue structure. Mesoscale conductivity variations can produce meaningful changes in E-fields and neural activation thresholds but remain largely absent from standard macroscopic models. Recent microscopic models have suggested substantial local E-field perturbations and could, in principle, inform mesoscale conductivity. However, the quantitative validity of microscopic models is limited by fixation-related tissue distortion and incomplete extracellular-space reconstruction. We outline approaches that bridge macro- and microscales to derive consistent mesoscale conductivity distributions, providing a foundation for accurate multiscale models of E-fields and neural activation in brain stimulation.",Neuroscience
"Accurate simulations of electric fields (E-fields) in brain stimulation depend on tissue conductivity representations that link macroscopic assumptions with underlying microscopic tissue structure. Mesoscale conductivity variations can produce meaningful changes in E-fields and neural activation thresholds but remain largely absent from standard macroscopic models. Recent microscopic models have suggested substantial local E-field perturbations and could, in principle, inform mesoscale conductivity. However, the quantitative validity of microscopic models is limited by fixation-related tissue distortion and incomplete extracellular-space reconstruction. We outline approaches that bridge macro- and microscales to derive consistent mesoscale conductivity distributions, providing a foundation for accurate multiscale models of E-fields and neural activation in brain stimulation. [SEP] [HINT] tissue -> Bioinformatics (Syns: tissue paper, weave) | neural -> Bioinformatics (Syns: neuronic, nervous, neuronal) | models -> Bioinformatics (Syns: framework, modelling, good example)",Neuroscience
"Functional connectivity has been widely investigated to understand brain disease in clinical studies and imaging-based neuroscience, and analyzing changes in functional connectivity has proven to be valuable for understanding and computationally evaluating the effects on brain function caused by diseases or experimental stimuli. By using Mahalanobis data whitening prior to the use of dimensionality reduction algorithms, we are able to distill meaningful information from fMRI signals about subjects and the experimental stimuli used to prompt them. Furthermore, we offer an interpretation of Mahalanobis whitening as a two-stage de-individualization of data which is motivated by similarity as captured by the Bures distance, which is connected to quantum mechanics. These methods have potential to aid discoveries about the mechanisms that link brain function with cognition and behavior and may improve the accuracy and consistency of Alzheimer's diagnosis, especially in the preclinical stage of disease progression.",Bioinformatics
"Functional connectivity has been widely investigated to understand brain disease in clinical studies and imaging-based neuroscience, and analyzing changes in functional connectivity has proven to be valuable for understanding and computationally evaluating the effects on brain function caused by diseases or experimental stimuli. By using Mahalanobis data whitening prior to the use of dimensionality reduction algorithms, we are able to distill meaningful information from fMRI signals about subjects and the experimental stimuli used to prompt them. Furthermore, we offer an interpretation of Mahalanobis whitening as a two-stage de-individualization of data which is motivated by similarity as captured by the Bures distance, which is connected to quantum mechanics. These methods have potential to aid discoveries about the mechanisms that link brain function with cognition and behavior and may improve the accuracy and consistency of Alzheimer's diagnosis, especially in the preclinical stage of disease progression. [SEP] [HINT] used -> Bioinformatics (Syns: utilize, ill-used, apply) | connectivity -> Neuroscience (Syns: ) | clinical -> Bioinformatics (Syns: )",Bioinformatics
"All materials have defects and many contain nanostructures, both of which disrupt chemical bonding - the basis of materials properties. No experimental measurements of bonding electron distributions associated with defects and nanostructures have ever been possible. We present a method enabling such measurements and interrogate nanovoids surrounded by vacancies - the most fundamental of nanostructures and defects - in aluminium. We measure the volume of a vacancy with 3% uncertainty and map vacancy concentrations surrounding nanovoids with nanometre resolution in three dimensions where previously only two-dimensional mapping was possible. We discover that radiation-damaged voids can ""heal"". Our bonding measurements are depth-resolved, vacancy-sensitive, and agree with density functional theory. This work opens bonding electron density measurements to inhomogeneous nanostructured multi-phased materials so that the electronic origins of phenomena such as strengthening, weakening, interface functionality, solute diffusion and phase transformations within them may be revealed.",Materials Science
"All materials have defects and many contain nanostructures, both of which disrupt chemical bonding - the basis of materials properties. No experimental measurements of bonding electron distributions associated with defects and nanostructures have ever been possible. We present a method enabling such measurements and interrogate nanovoids surrounded by vacancies - the most fundamental of nanostructures and defects - in aluminium. We measure the volume of a vacancy with 3% uncertainty and map vacancy concentrations surrounding nanovoids with nanometre resolution in three dimensions where previously only two-dimensional mapping was possible. We discover that radiation-damaged voids can ""heal"". Our bonding measurements are depth-resolved, vacancy-sensitive, and agree with density functional theory. This work opens bonding electron density measurements to inhomogeneous nanostructured multi-phased materials so that the electronic origins of phenomena such as strengthening, weakening, interface functionality, solute diffusion and phase transformations within them may be revealed. [SEP] [HINT] electronic -> Materials Science (Syns: ) | functional -> Neuroscience (Syns: working, usable, running) | electron -> Materials Science (Syns: negatron)",Materials Science
"Mismatch negativity (MMN) in humans reflects deviance detection (DD), a core neural mechanism of predictive processing. However, the fundamental principles by which DD emerges and matures during early cortical development-potentially providing a neuronal scaffold for MMN-remain unclear. Here, we tracked the development of DD in dissociated cortical cultures grown on high-density CMOS microelectrode arrays from 10 to 35 days in vitro (DIV). Cultures were stimulated with oddball and many-standards control paradigms while spontaneous and evoked activity were recorded longitudinally. At early stages, stimulus-evoked responses were confined to fast components reflecting direct activation. From DIV15-20 onward, robust late responses appeared, and deviant stimuli progressively evoked stronger responses than frequent and control stimuli, marking the onset of DD. By DIV30, responses became stronger, faster, and more temporally precise. Neuronal avalanche analysis revealed a gradual transition from subcritical to near-critical dynamics, with cultures exhibiting power-law statistics showing the strongest deviant responses. Nonetheless, DD was also present in non-critical networks, indicating that criticality is not required for its emergence but instead stabilizes and amplifies predictive processing as networks mature. Early oddball experience reinforces the deviant pathway, resulting in faster conduction along those circuits. However, as frequent and deviant pathways become less distinct, the deviance detection index is reduced. Together, these findings demonstrate that DD arises intrinsically through local circuit maturation, while self-organization toward criticality and early experience further refine its strength and timing, providing mechanistic insight into predictive coding in simplified cortical networks and informing the design of adaptive, prediction-sensitive artificial systems.",Neuroscience
"Mismatch negativity (MMN) in humans reflects deviance detection (DD), a core neural mechanism of predictive processing. However, the fundamental principles by which DD emerges and matures during early cortical development-potentially providing a neuronal scaffold for MMN-remain unclear. Here, we tracked the development of DD in dissociated cortical cultures grown on high-density CMOS microelectrode arrays from 10 to 35 days in vitro (DIV). Cultures were stimulated with oddball and many-standards control paradigms while spontaneous and evoked activity were recorded longitudinally. At early stages, stimulus-evoked responses were confined to fast components reflecting direct activation. From DIV15-20 onward, robust late responses appeared, and deviant stimuli progressively evoked stronger responses than frequent and control stimuli, marking the onset of DD. By DIV30, responses became stronger, faster, and more temporally precise. Neuronal avalanche analysis revealed a gradual transition from subcritical to near-critical dynamics, with cultures exhibiting power-law statistics showing the strongest deviant responses. Nonetheless, DD was also present in non-critical networks, indicating that criticality is not required for its emergence but instead stabilizes and amplifies predictive processing as networks mature. Early oddball experience reinforces the deviant pathway, resulting in faster conduction along those circuits. However, as frequent and deviant pathways become less distinct, the deviance detection index is reduced. Together, these findings demonstrate that DD arises intrinsically through local circuit maturation, while self-organization toward criticality and early experience further refine its strength and timing, providing mechanistic insight into predictive coding in simplified cortical networks and informing the design of adaptive, prediction-sensitive artificial systems. [SEP] [HINT] transition -> Materials Science (Syns: passage, modulation, changeover) | cortical -> Neuroscience (Syns: ) | networks -> Neuroscience (Syns: network, meshwork, electronic network)",Neuroscience
"We present an experimental method to determine the refractive index of $Al_{x}Ga_{1-x}As$ (x = 0.0 - 0.5) from 300 K to 4 K across the 500 - 1100 nm wavelength range. The values are extracted from spectroscopically observed microcavity resonances in thin $Al_{x}Ga_{1-x}As$ membranes embedded between fully and partially reflective gold mirrors. Refined Varshni and Paessler models are used to describe temperature-dependent bandgap shifts and material composition. By tracking resonance shifts and benchmarking against finite-difference time-domain simulations, we derive the dispersive optical response with high precision. This yields a quantitatively improved analytical expression for the refractive index of $Al_{x}Ga_{1-x}As$ matching the experimental results with a coefficient of determination as high as $R^2=0.993$, enabling accurate modeling near the band edge at cryogenic temperatures. The method is straightforward and broadly applicable to other semiconductor systems, offering a valuable tool for the design of micro photonic devices such as quantum light sources.",Materials Science
"We present an experimental method to determine the refractive index of $Al_{x}Ga_{1-x}As$ (x = 0.0 - 0.5) from 300 K to 4 K across the 500 - 1100 nm wavelength range. The values are extracted from spectroscopically observed microcavity resonances in thin $Al_{x}Ga_{1-x}As$ membranes embedded between fully and partially reflective gold mirrors. Refined Varshni and Paessler models are used to describe temperature-dependent bandgap shifts and material composition. By tracking resonance shifts and benchmarking against finite-difference time-domain simulations, we derive the dispersive optical response with high precision. This yields a quantitatively improved analytical expression for the refractive index of $Al_{x}Ga_{1-x}As$ matching the experimental results with a coefficient of determination as high as $R^2=0.993$, enabling accurate modeling near the band edge at cryogenic temperatures. The method is straightforward and broadly applicable to other semiconductor systems, offering a valuable tool for the design of micro photonic devices such as quantum light sources. [SEP] [HINT] used -> Bioinformatics (Syns: utilize, ill-used, apply) | results -> Bioinformatics (Syns: final result, consequence, resultant role) | band -> Materials Science (Syns: set, stria, dance orchestra)",Materials Science
"Precisely defining consciousness and identifying the mechanisms that effect it is a long-standing question, particularly relevant with advances in artificial intelligence. The scientific community is divided between physicalism and natural dualism. Physicalism posits consciousness is a physical process that can be modeled computationally; natural dualism rejects this hypothesis. Finding a computational model has proven elusive, particularly because of conflation of consciousness with other cognitive capabilities exhibited by humans, such as intelligence and physiological sensations. Here we show such a computational model that precisely models consciousness, natural or artificial, identifying the structural and functional mechanisms that effect it, confirming the physicalism hypothesis. We found such a model is obtainable when including the underlying (biological or digital) substrate and accounting for reactive behavior in substrate sub-systems (e.g., autonomous physiological responses). Results show that, unlike all other computational processes, consciousness is not independent of its substrate and possessing it is an evolutionary advantage for intelligent entities. Our result shows there is no impediment to the realization of fully artificial consciousness but, surprisingly, that it is also possible to realize artificial intelligence of arbitrary level without consciousness whatsoever, and that there is no advantage in imbuing artificial systems with consciousness.",Neuroscience
"Precisely defining consciousness and identifying the mechanisms that effect it is a long-standing question, particularly relevant with advances in artificial intelligence. The scientific community is divided between physicalism and natural dualism. Physicalism posits consciousness is a physical process that can be modeled computationally; natural dualism rejects this hypothesis. Finding a computational model has proven elusive, particularly because of conflation of consciousness with other cognitive capabilities exhibited by humans, such as intelligence and physiological sensations. Here we show such a computational model that precisely models consciousness, natural or artificial, identifying the structural and functional mechanisms that effect it, confirming the physicalism hypothesis. We found such a model is obtainable when including the underlying (biological or digital) substrate and accounting for reactive behavior in substrate sub-systems (e.g., autonomous physiological responses). Results show that, unlike all other computational processes, consciousness is not independent of its substrate and possessing it is an evolutionary advantage for intelligent entities. Our result shows there is no impediment to the realization of fully artificial consciousness but, surprisingly, that it is also possible to realize artificial intelligence of arbitrary level without consciousness whatsoever, and that there is no advantage in imbuing artificial systems with consciousness. [SEP] [HINT] computational -> Neuroscience (Syns: ) | functional -> Neuroscience (Syns: working, usable, running) | results -> Bioinformatics (Syns: final result, consequence, resultant role)",Neuroscience
"This work provides a theoretical exploration of the thermodynamic stability and magnetic behaviour of previously unknown ternary Li AgII F compounds. Convex-hull analysis shows that all predicted structures lie slightly above the LiF plus AgF2 decomposition line, indicating a natural tendency toward phase separation; nevertheless, their negative formation energies relative to AgF, LiF, and F2 or F suggest that alternative synthetic pathways may be feasible for these compounds. All studied structures show preference for antiferromagnetic ground state. Notably, the triclinic LiAgF3 type2 is predicted to exhibit an exceptionally large superexchange constant, J equal to minus 358 meV, within Ag2F7 dimers, placing it above the strongest known magnetic exchange interactions reported to date.",Materials Science
"This work provides a theoretical exploration of the thermodynamic stability and magnetic behaviour of previously unknown ternary Li AgII F compounds. Convex-hull analysis shows that all predicted structures lie slightly above the LiF plus AgF2 decomposition line, indicating a natural tendency toward phase separation; nevertheless, their negative formation energies relative to AgF, LiF, and F2 or F suggest that alternative synthetic pathways may be feasible for these compounds. All studied structures show preference for antiferromagnetic ground state. Notably, the triclinic LiAgF3 type2 is predicted to exhibit an exceptionally large superexchange constant, J equal to minus 358 meV, within Ag2F7 dimers, placing it above the strongest known magnetic exchange interactions reported to date. [SEP] [HINT] work -> Bioinformatics (Syns: work out, process, bring) | phase -> Materials Science (Syns: stage, phase angle, form) | magnetic -> Materials Science (Syns: charismatic, magnetised, magnetized)",Materials Science
"Several novel methods, including magnetogenetics and magnetoelectric stimulation, use high frequency alternating magnetic fields to precisely manipulate neural activity. To quantify the behavioral effects of such interventions in a freely moving mouse, we developed a dual-channel magnetic chamber, specifically designed for rate-sensitive magnetothermal-genetic stimulation, and adaptable for other uses of alternating magnetic fields. Through an optimized coil design, the system allows independent control of two spatially orthogonal uniform magnetic fields delivered at different frequencies within a 10 cm x 10 cm x 6 cm chamber. The two channels have nominal frequencies of 50 and 550 kHz with peak magnetic field strengths of 88 and 12.5 mT, achieved with resonant coil drives having peak voltages of 1.6 and 1.8 kV and currents of 1.0 and 0.26 kA, respectively. Additionally, a liquid cooling system enables magnetic field generation for second-level duration, and an observation port and camera allow video capture of the animal's behavior within the chamber. The system generates high-amplitude magnetic fields across two widely separated frequency channels with negligible interference (< 1%). Relatively uniform magnetic field distribution (+/-10% across 94% of the chamber volume) is maintained throughout the chamber, and temperature increase of the inner side of the coil enclosure during the operation is limited to < 0.35 °C/s to ensure in vivo safety. Using cobalt-doped and undoped iron oxide nanoparticles, we demonstrate channel-specific heating rates of 3.5 °C/s and 1.5 °C/s, respectively, validating frequency-selectivity. Both channels can run continuously for four seconds stably.",Neuroscience
"Several novel methods, including magnetogenetics and magnetoelectric stimulation, use high frequency alternating magnetic fields to precisely manipulate neural activity. To quantify the behavioral effects of such interventions in a freely moving mouse, we developed a dual-channel magnetic chamber, specifically designed for rate-sensitive magnetothermal-genetic stimulation, and adaptable for other uses of alternating magnetic fields. Through an optimized coil design, the system allows independent control of two spatially orthogonal uniform magnetic fields delivered at different frequencies within a 10 cm x 10 cm x 6 cm chamber. The two channels have nominal frequencies of 50 and 550 kHz with peak magnetic field strengths of 88 and 12.5 mT, achieved with resonant coil drives having peak voltages of 1.6 and 1.8 kV and currents of 1.0 and 0.26 kA, respectively. Additionally, a liquid cooling system enables magnetic field generation for second-level duration, and an observation port and camera allow video capture of the animal's behavior within the chamber. The system generates high-amplitude magnetic fields across two widely separated frequency channels with negligible interference (< 1%). Relatively uniform magnetic field distribution (+/-10% across 94% of the chamber volume) is maintained throughout the chamber, and temperature increase of the inner side of the coil enclosure during the operation is limited to < 0.35 °C/s to ensure in vivo safety. Using cobalt-doped and undoped iron oxide nanoparticles, we demonstrate channel-specific heating rates of 3.5 °C/s and 1.5 °C/s, respectively, validating frequency-selectivity. Both channels can run continuously for four seconds stably. [SEP] [HINT] field -> Materials Science (Syns: field of honor, line of business, orbit) | different -> Neuroscience (Syns: unlike, dissimilar) | including -> Bioinformatics (Syns: admit, include, let in)",Neuroscience
"Since the pioneering works of Peierls, one-dimensional materials have attracted great attention. Still, the synthesis of truly monoatomic chains remains elusive. In this study, we explore a novel path of experimental synthesis of monoatomic one-dimensional chains by their chemical stabilization in ionic compounds. We demonstrate that in synthesized at high pressure sodium halides Na4X5 (X = I, Br, Cl) with hP18 Ga4Ti5-type structures, transfer of valence electrons from cations to anions leads to the formation of halogen chains connected with other atoms only by ionic interaction and having one-dimensional electronic structure. The Peierls physics in the systems is confirmed by theoretical calculations, newly synthesized incommensurately modulated i-hP18-Na4X5 (X = I, Br, Cl) compounds, as well as by the discovered hP36 phases of Na4Cl5 and Na4Br5.",Materials Science
"Since the pioneering works of Peierls, one-dimensional materials have attracted great attention. Still, the synthesis of truly monoatomic chains remains elusive. In this study, we explore a novel path of experimental synthesis of monoatomic one-dimensional chains by their chemical stabilization in ionic compounds. We demonstrate that in synthesized at high pressure sodium halides Na4X5 (X = I, Br, Cl) with hP18 Ga4Ti5-type structures, transfer of valence electrons from cations to anions leads to the formation of halogen chains connected with other atoms only by ionic interaction and having one-dimensional electronic structure. The Peierls physics in the systems is confirmed by theoretical calculations, newly synthesized incommensurately modulated i-hP18-Na4X5 (X = I, Br, Cl) compounds, as well as by the discovered hP36 phases of Na4Cl5 and Na4Br5. [SEP] [HINT] electronic -> Materials Science (Syns: ) | systems -> Bioinformatics (Syns: organization, organisation, system) | materials -> Materials Science (Syns: stuff, cloth, material)",Materials Science
"Markerless motion tracking has advanced rapidly in the past 10 years and currently offers powerful opportunities for behavioural, clinical, and biomechanical research. While several specialised toolkits provide high performance for specific tasks, using existing tools still requires substantial technical expertise. There remains a gap in accessible, integrated solutions that deliver sufficient tracking for non-experts across diverse settings.   TrackStudio was developed to address this gap by combining established open-source tools into a single, modular, GUI-based pipeline that works out of the box. It provides automatic 2D and 3D tracking, calibration, preprocessing, feature extraction, and visualisation without requiring any programming skills. We supply a user guide with practical advice for video acquisition, synchronisation, and setup, alongside documentation of common pitfalls and how to avoid them.   To validate the toolkit, we tested its performance across three environments using either low-cost webcams or high-resolution cameras, including challenging conditions for body position, lightning, and space and obstructions. Across 76 participants, average inter-frame correlations exceeded 0.98 and average triangulation errors remained low (<13.6mm for hand tracking), demonstrating stable and consistent tracking. We further show that the same pipeline can be extended beyond hand tracking to other body and face regions. TrackStudio provides a practical, accessible route into markerless tracking for researchers or laypeople who need reliable performance without specialist expertise.",Bioinformatics
"Markerless motion tracking has advanced rapidly in the past 10 years and currently offers powerful opportunities for behavioural, clinical, and biomechanical research. While several specialised toolkits provide high performance for specific tasks, using existing tools still requires substantial technical expertise. There remains a gap in accessible, integrated solutions that deliver sufficient tracking for non-experts across diverse settings.   TrackStudio was developed to address this gap by combining established open-source tools into a single, modular, GUI-based pipeline that works out of the box. It provides automatic 2D and 3D tracking, calibration, preprocessing, feature extraction, and visualisation without requiring any programming skills. We supply a user guide with practical advice for video acquisition, synchronisation, and setup, alongside documentation of common pitfalls and how to avoid them.   To validate the toolkit, we tested its performance across three environments using either low-cost webcams or high-resolution cameras, including challenging conditions for body position, lightning, and space and obstructions. Across 76 participants, average inter-frame correlations exceeded 0.98 and average triangulation errors remained low (<13.6mm for hand tracking), demonstrating stable and consistent tracking. We further show that the same pipeline can be extended beyond hand tracking to other body and face regions. TrackStudio provides a practical, accessible route into markerless tracking for researchers or laypeople who need reliable performance without specialist expertise. [SEP] [HINT] low -> Materials Science (Syns: low-spirited, scurvy, depressed) | space -> Neuroscience (Syns: distance, place, outer space) | performance -> Bioinformatics (Syns: functioning, operation, carrying out)",Bioinformatics
"Chimeric antigen receptor T-cell (CAR-T) therapy represents a paradigm shift in cancer treatment, yet development timelines of 8-12 years and clinical attrition rates exceeding 40-60% highlight critical inefficiencies in target selection, safety assessment, and molecular optimization. We present Bio AI Agent, a multi-agent artificial intelligence system powered by large language models that enables autonomous CAR-T development through collaborative specialized agents. The system comprises six autonomous agents: Target Selection Agent for multi-parametric antigen prioritization across >10,000 cancer-associated targets, Toxicity Prediction Agent for comprehensive safety profiling integrating tissue expression atlases and pharmacovigilance databases, Molecular Design Agent for rational CAR engineering, Patent Intelligence Agent for freedom-to-operate analysis, Clinical Translation Agent for regulatory compliance, and Decision Orchestration Agent for multi-agent coordination. Retrospective validation demonstrated autonomous identification of high-risk targets including FcRH5 (hepatotoxicity) and CD229 (off-tumor toxicity), patent infringement risks for CD38+SLAMF7 combinations, and generation of comprehensive development roadmaps. By enabling parallel processing, specialized reasoning, and autonomous decision-making superior to monolithic AI systems, Bio AI Agent addresses critical gaps in precision oncology development and has potential to accelerate translation of next-generation immunotherapies from discovery to clinic.",Bioinformatics
"Chimeric antigen receptor T-cell (CAR-T) therapy represents a paradigm shift in cancer treatment, yet development timelines of 8-12 years and clinical attrition rates exceeding 40-60% highlight critical inefficiencies in target selection, safety assessment, and molecular optimization. We present Bio AI Agent, a multi-agent artificial intelligence system powered by large language models that enables autonomous CAR-T development through collaborative specialized agents. The system comprises six autonomous agents: Target Selection Agent for multi-parametric antigen prioritization across >10,000 cancer-associated targets, Toxicity Prediction Agent for comprehensive safety profiling integrating tissue expression atlases and pharmacovigilance databases, Molecular Design Agent for rational CAR engineering, Patent Intelligence Agent for freedom-to-operate analysis, Clinical Translation Agent for regulatory compliance, and Decision Orchestration Agent for multi-agent coordination. Retrospective validation demonstrated autonomous identification of high-risk targets including FcRH5 (hepatotoxicity) and CD229 (off-tumor toxicity), patent infringement risks for CD38+SLAMF7 combinations, and generation of comprehensive development roadmaps. By enabling parallel processing, specialized reasoning, and autonomous decision-making superior to monolithic AI systems, Bio AI Agent addresses critical gaps in precision oncology development and has potential to accelerate translation of next-generation immunotherapies from discovery to clinic. [SEP] [HINT] tissue -> Bioinformatics (Syns: tissue paper, weave) | clinical -> Bioinformatics (Syns: ) | language -> Neuroscience (Syns: linguistic process, linguistic communication, spoken communication)",Bioinformatics
"Quadruple perovskites ACu$_3$Fe$_2$Re$_2$O$_{12}$ attract considerable interest due to their high Curie temperatures (up to $710$K), which strongly depend on the A-site cation. In this work, we employ first-principles calculations to investigate their electronic structure and magnetic exchange interactions. A band mechanism of magnetism that explains the antiferromagnetic character of the exchange interactions and their strong dependence on the filling of the Re $t_{2g}$ states is proposed. These antiferromagnetic interactions stabilize ferrimagnetic ground state. The calculated Curie temperatures, obtained within the Onsager reaction field theory, are in a good agreement with experimental data.",Materials Science
"Quadruple perovskites ACu$_3$Fe$_2$Re$_2$O$_{12}$ attract considerable interest due to their high Curie temperatures (up to $710$K), which strongly depend on the A-site cation. In this work, we employ first-principles calculations to investigate their electronic structure and magnetic exchange interactions. A band mechanism of magnetism that explains the antiferromagnetic character of the exchange interactions and their strong dependence on the filling of the Re $t_{2g}$ states is proposed. These antiferromagnetic interactions stabilize ferrimagnetic ground state. The calculated Curie temperatures, obtained within the Onsager reaction field theory, are in a good agreement with experimental data. [SEP] [HINT] field -> Materials Science (Syns: field of honor, line of business, orbit) | experimental -> Materials Science (Syns: data-based, observational) | states -> Materials Science (Syns: put forward, province, say)",Materials Science
"X-ray diffraction (XRD) peak broadening analysis remains a cornerstone for quantifying crystallite size and lattice microstrain in materials. Among various approaches, the Size Strain Plot (SSP) method is widely employed for its conceptual simplicity and ease of use. However, this study reveals that the equation most commonly applied in SSP analysis is dimensionally inconsistent, a critical flaw that has gone largely unnoticed and replicated across decades of materials research. This pervasive error raises concerns about the validity of a significant body of published microstructural data. By tracing the historical origin of the misformulated equation, we demonstrate how a seemingly minor oversight evolved into a widely accepted standard practice within the field. We then present a dimensionally consistent formulation that restores physical meaning and analytical reliability to the SSP method. The corrected framework re-establishes the SSP approach as a robust and physically valid tool for XRD-based microstructural characterization. \en",Materials Science
"X-ray diffraction (XRD) peak broadening analysis remains a cornerstone for quantifying crystallite size and lattice microstrain in materials. Among various approaches, the Size Strain Plot (SSP) method is widely employed for its conceptual simplicity and ease of use. However, this study reveals that the equation most commonly applied in SSP analysis is dimensionally inconsistent, a critical flaw that has gone largely unnoticed and replicated across decades of materials research. This pervasive error raises concerns about the validity of a significant body of published microstructural data. By tracing the historical origin of the misformulated equation, we demonstrate how a seemingly minor oversight evolved into a widely accepted standard practice within the field. We then present a dimensionally consistent formulation that restores physical meaning and analytical reliability to the SSP method. The corrected framework re-establishes the SSP approach as a robust and physically valid tool for XRD-based microstructural characterization. \en [SEP] [HINT] framework -> Bioinformatics (Syns: theoretical account, model, fabric) | strain -> Materials Science (Syns: air, stock, form) | materials -> Materials Science (Syns: stuff, cloth, material)",Materials Science
"Predictive atomistic simulations have propelled materials discovery, yet routine setup and debugging still demand computer specialists. This know-how gap limits Integrated Computational Materials Engineering (ICME), where state-of-the-art codes exist but remain cumbersome for non-experts. We address this bottleneck with GENIUS, an AI-agentic workflow that fuses a smart Quantum ESPRESSO knowledge graph with a tiered hierarchy of large language models supervised by a finite-state error-recovery machine. Here we show that GENIUS translates free-form human-generated prompts into validated input files that run to completion on $\approx$80% of 295 diverse benchmarks, where 76% are autonomously repaired, with success decaying exponentially to a 7% baseline. Compared with LLM-only baselines, GENIUS halves inference costs and virtually eliminates hallucinations. The framework democratizes electronic-structure DFT simulations by intelligently automating protocol generation, validation, and repair, opening large-scale screening and accelerating ICME design loops across academia and industry worldwide.",Materials Science
"Predictive atomistic simulations have propelled materials discovery, yet routine setup and debugging still demand computer specialists. This know-how gap limits Integrated Computational Materials Engineering (ICME), where state-of-the-art codes exist but remain cumbersome for non-experts. We address this bottleneck with GENIUS, an AI-agentic workflow that fuses a smart Quantum ESPRESSO knowledge graph with a tiered hierarchy of large language models supervised by a finite-state error-recovery machine. Here we show that GENIUS translates free-form human-generated prompts into validated input files that run to completion on $\approx$80% of 295 diverse benchmarks, where 76% are autonomously repaired, with success decaying exponentially to a 7% baseline. Compared with LLM-only baselines, GENIUS halves inference costs and virtually eliminates hallucinations. The framework democratizes electronic-structure DFT simulations by intelligently automating protocol generation, validation, and repair, opening large-scale screening and accelerating ICME design loops across academia and industry worldwide. [SEP] [HINT] dft -> Materials Science (Syns: ) | language -> Neuroscience (Syns: linguistic process, linguistic communication, spoken communication) | computational -> Neuroscience (Syns: )",Materials Science
"The human auditory cortex is topographically organized. Neurons with similar response properties are spatially clustered, forming smooth maps for acoustic features such as frequency in early auditory areas, and modular regions selective for music and speech in higher-order cortex. Yet, evaluations for current computational models of auditory perception do not measure whether such topographic structure is present in a candidate model. Here, we show that cortical topography is not present in the previous best-performing models at predicting human auditory fMRI responses. To encourage the emergence of topographic organization, we adapt a cortical wiring-constraint loss originally designed for visual perception. The new class of topographic auditory models, TopoAudio, are trained to classify speech, and environmental sounds from cochleagram inputs, with an added constraint that nearby units on a 2D cortical sheet develop similar tuning. Despite these additional constraints, TopoAudio achieves high accuracy on benchmark tasks comparable to the unconstrained non-topographic baseline models. Further, TopoAudio predicts the fMRI responses in the brain as well as standard models, but unlike standard models, TopoAudio develops smooth, topographic maps for tonotopy and amplitude modulation (common properties of early auditory representation, as well as clustered response modules for music and speech (higher-order selectivity observed in the human auditory cortex). TopoAudio is the first end-to-end biologically grounded auditory model to exhibit emergent topography, and our results emphasize that a wiring-length constraint can serve as a general-purpose regularization tool to achieve biologically aligned representations.",Neuroscience
"The human auditory cortex is topographically organized. Neurons with similar response properties are spatially clustered, forming smooth maps for acoustic features such as frequency in early auditory areas, and modular regions selective for music and speech in higher-order cortex. Yet, evaluations for current computational models of auditory perception do not measure whether such topographic structure is present in a candidate model. Here, we show that cortical topography is not present in the previous best-performing models at predicting human auditory fMRI responses. To encourage the emergence of topographic organization, we adapt a cortical wiring-constraint loss originally designed for visual perception. The new class of topographic auditory models, TopoAudio, are trained to classify speech, and environmental sounds from cochleagram inputs, with an added constraint that nearby units on a 2D cortical sheet develop similar tuning. Despite these additional constraints, TopoAudio achieves high accuracy on benchmark tasks comparable to the unconstrained non-topographic baseline models. Further, TopoAudio predicts the fMRI responses in the brain as well as standard models, but unlike standard models, TopoAudio develops smooth, topographic maps for tonotopy and amplitude modulation (common properties of early auditory representation, as well as clustered response modules for music and speech (higher-order selectivity observed in the human auditory cortex). TopoAudio is the first end-to-end biologically grounded auditory model to exhibit emergent topography, and our results emphasize that a wiring-length constraint can serve as a general-purpose regularization tool to achieve biologically aligned representations. [SEP] [HINT] tasks -> Neuroscience (Syns: tax, task, project) | computational -> Neuroscience (Syns: ) | features -> Bioinformatics (Syns: characteristic, lineament, feature of speech)",Neuroscience
"Molecular foundation models are rapidly advancing scientific discovery, but their unreliability on out-of-distribution (OOD) samples severely limits their application in high-stakes domains such as drug discovery and protein design. A critical failure mode is chemical hallucination, where models make high-confidence yet entirely incorrect predictions for unknown molecules. To address this challenge, we introduce Molecular Preference-Aligned Instance Ranking (Mole-PAIR), a simple, plug-and-play module that can be flexibly integrated with existing foundation models to improve their reliability on OOD data through cost-effective post-training. Specifically, our method formulates the OOD detection problem as a preference optimization over the estimated OOD affinity between in-distribution (ID) and OOD samples, achieving this goal through a pairwise learning objective. We show that this objective essentially optimizes AUROC, which measures how consistently ID and OOD samples are ranked by the model. Extensive experiments across five real-world molecular datasets demonstrate that our approach significantly improves the OOD detection capabilities of existing molecular foundation models, achieving up to 45.8%, 43.9%, and 24.3% improvements in AUROC under distribution shifts of size, scaffold, and assay, respectively.",Bioinformatics
"Molecular foundation models are rapidly advancing scientific discovery, but their unreliability on out-of-distribution (OOD) samples severely limits their application in high-stakes domains such as drug discovery and protein design. A critical failure mode is chemical hallucination, where models make high-confidence yet entirely incorrect predictions for unknown molecules. To address this challenge, we introduce Molecular Preference-Aligned Instance Ranking (Mole-PAIR), a simple, plug-and-play module that can be flexibly integrated with existing foundation models to improve their reliability on OOD data through cost-effective post-training. Specifically, our method formulates the OOD detection problem as a preference optimization over the estimated OOD affinity between in-distribution (ID) and OOD samples, achieving this goal through a pairwise learning objective. We show that this objective essentially optimizes AUROC, which measures how consistently ID and OOD samples are ranked by the model. Extensive experiments across five real-world molecular datasets demonstrate that our approach significantly improves the OOD detection capabilities of existing molecular foundation models, achieving up to 45.8%, 43.9%, and 24.3% improvements in AUROC under distribution shifts of size, scaffold, and assay, respectively. [SEP] [HINT] learning -> Bioinformatics (Syns: take, teach, acquire) | molecular -> Bioinformatics (Syns: ) | datasets -> Bioinformatics (Syns: )",Bioinformatics
"Many models used in artificial intelligence and cognitive science rely on multi-element patterns stored in ""slots"" - dedicated storage locations - in a digital computer. As biological brains likely lack slots, we consider how they might achieve similar functional outcomes without them by building on the neurally-inspired modern Hopfield network (MHN; Krotov & Hopfield, 2021), which stores patterns in the connection weights of an individual neuron. We propose extensions of this approach to increase its biological plausibility as a model of memory and to capture an important advantage of slot-based computation in contemporary language models. For memory, neuroscience research suggests that the weights of overlapping sparse ensembles of neurons, rather than a dedicated individual neuron, are used to store a memory. We introduce the K-winner MHN, extending the approach to ensembles, and find that within a continual learning regime, the ensemble-based MHN exhibits greater retention of older memories, as measured by the graded sensitivity measure d', than a standard (one-neuron) MHN. Next, we consider the powerful use of slot-based memory in contemporary language models. These models use slots to store long sequences of past inputs and their learned encodings, supporting later predictions and allowing error signals to be transported backward in time to adjust weights underlying the learned encodings of these past inputs. Inspired by these models' successes, we show how the MHN can be extended to capture both of these important functional outcomes. Collectively, our modeling approaches constitute steps towards understanding how biologically plausible mechanisms can support computations that have enabled AI systems to capture human-like abilities that no prior models have been able to achieve.",Neuroscience
"Many models used in artificial intelligence and cognitive science rely on multi-element patterns stored in ""slots"" - dedicated storage locations - in a digital computer. As biological brains likely lack slots, we consider how they might achieve similar functional outcomes without them by building on the neurally-inspired modern Hopfield network (MHN; Krotov & Hopfield, 2021), which stores patterns in the connection weights of an individual neuron. We propose extensions of this approach to increase its biological plausibility as a model of memory and to capture an important advantage of slot-based computation in contemporary language models. For memory, neuroscience research suggests that the weights of overlapping sparse ensembles of neurons, rather than a dedicated individual neuron, are used to store a memory. We introduce the K-winner MHN, extending the approach to ensembles, and find that within a continual learning regime, the ensemble-based MHN exhibits greater retention of older memories, as measured by the graded sensitivity measure d', than a standard (one-neuron) MHN. Next, we consider the powerful use of slot-based memory in contemporary language models. These models use slots to store long sequences of past inputs and their learned encodings, supporting later predictions and allowing error signals to be transported backward in time to adjust weights underlying the learned encodings of these past inputs. Inspired by these models' successes, we show how the MHN can be extended to capture both of these important functional outcomes. Collectively, our modeling approaches constitute steps towards understanding how biologically plausible mechanisms can support computations that have enabled AI systems to capture human-like abilities that no prior models have been able to achieve. [SEP] [HINT] used -> Bioinformatics (Syns: utilize, ill-used, apply) | language -> Neuroscience (Syns: linguistic process, linguistic communication, spoken communication) | understanding -> Neuroscience (Syns: savvy, intellect, sympathy)",Neuroscience
"Blood transfusion remains a cornerstone of modern medicine, saving countless lives daily. Yet the quality of transfused blood varies dramatically among donors-a critical factor often overlooked in clinical practice. Rapid, benchtop, and cost-effective methods for evaluating stored red blood cells (RBCs) at the site of transfusion are lacking, with concerns persisting about the association between metabolic signatures of stored RBC quality and transfusion outcomes. Recent studies utilizing metabolomics approaches to evaluate stored erythrocytes find that donor biology (e.g., genetics, age, lifestyle factors) underlies the heterogeneity associated with blood storage and transfusion. The appreciation of donor-intrinsic factors provides opportunities for precision transfusion medicine approaches for the evaluation of storage quality and prediction of transfusion efficacy. Here we propose a new platform, the Surface Acoustic Wave Hemolysis Assay (SAW-HA), for on-site evaluation of stored RBCs utilizing SAW Hemolysis Temperature (SAWHT) as a marker for RBC quality. We report SAWHT as a mechanism-dependent reproducible methodology for evaluating stored human RBCs up to 42 days. Our results define unique signatures for SAW hemolysis and metabolic profiles in RBCs from two of the six donors in which high body mass index (BMI) and RBC triglycerides associated with increased susceptibility to hemolysis. Metabolic age of the stored RBCs - a recently appreciated predictor of post-transfusion efficacy-reveal that RBCs from the two low SAWHT units were characterized by disrupted redox control, deficient tryptophan metabolism, and high BMI. Together, these findings indicate the potential of the SAW-HA as a point-of-care analysis for transfusion medicine.",Bioinformatics
"Blood transfusion remains a cornerstone of modern medicine, saving countless lives daily. Yet the quality of transfused blood varies dramatically among donors-a critical factor often overlooked in clinical practice. Rapid, benchtop, and cost-effective methods for evaluating stored red blood cells (RBCs) at the site of transfusion are lacking, with concerns persisting about the association between metabolic signatures of stored RBC quality and transfusion outcomes. Recent studies utilizing metabolomics approaches to evaluate stored erythrocytes find that donor biology (e.g., genetics, age, lifestyle factors) underlies the heterogeneity associated with blood storage and transfusion. The appreciation of donor-intrinsic factors provides opportunities for precision transfusion medicine approaches for the evaluation of storage quality and prediction of transfusion efficacy. Here we propose a new platform, the Surface Acoustic Wave Hemolysis Assay (SAW-HA), for on-site evaluation of stored RBCs utilizing SAW Hemolysis Temperature (SAWHT) as a marker for RBC quality. We report SAWHT as a mechanism-dependent reproducible methodology for evaluating stored human RBCs up to 42 days. Our results define unique signatures for SAW hemolysis and metabolic profiles in RBCs from two of the six donors in which high body mass index (BMI) and RBC triglycerides associated with increased susceptibility to hemolysis. Metabolic age of the stored RBCs - a recently appreciated predictor of post-transfusion efficacy-reveal that RBCs from the two low SAWHT units were characterized by disrupted redox control, deficient tryptophan metabolism, and high BMI. Together, these findings indicate the potential of the SAW-HA as a point-of-care analysis for transfusion medicine. [SEP] [HINT] low -> Materials Science (Syns: low-spirited, scurvy, depressed) | clinical -> Bioinformatics (Syns: ) | quality -> Bioinformatics (Syns: lineament, tone, calibre)",Bioinformatics
"The impact of thermal stress on beneficial symbiosis, in the face of rapid climate change, remains poorly understood. We investigate this using the model system, Euprymna scolopes, the Hawaiian Bobtail Squid, and its bioluminescent symbiont, Vibrio fischeri, which enables the squid to camouflage itself through counter-illumination. Successful colonisation of the squid by V. fischeri must occur hours after hatching and is mediated by fluid flow due to respiration within the squid mantle cavity. To study this process, we develop a mathematical model using the Method of Regularised Stokeslets to simulate the flow and resulting bacterial trajectories within the squid. We explore how thermal stress, mediated by physiological changes in respiration, ciliary dynamics, and internal geometry, affects this early colonisation by analysing the time bacteria spend in regions crucial to the establishment of symbiosis in these simulations. A variance-based sensitivity analysis of physiologically relevant parameters on these metrics demonstrates that changes in the breath cycle significantly impact and reduce the time bacteria spend in the critical zone within the squid, hindering colonisation.",Bioinformatics
"The impact of thermal stress on beneficial symbiosis, in the face of rapid climate change, remains poorly understood. We investigate this using the model system, Euprymna scolopes, the Hawaiian Bobtail Squid, and its bioluminescent symbiont, Vibrio fischeri, which enables the squid to camouflage itself through counter-illumination. Successful colonisation of the squid by V. fischeri must occur hours after hatching and is mediated by fluid flow due to respiration within the squid mantle cavity. To study this process, we develop a mathematical model using the Method of Regularised Stokeslets to simulate the flow and resulting bacterial trajectories within the squid. We explore how thermal stress, mediated by physiological changes in respiration, ciliary dynamics, and internal geometry, affects this early colonisation by analysing the time bacteria spend in regions crucial to the establishment of symbiosis in these simulations. A variance-based sensitivity analysis of physiologically relevant parameters on these metrics demonstrates that changes in the breath cycle significantly impact and reduce the time bacteria spend in the critical zone within the squid, hindering colonisation. [SEP] [HINT] using -> Bioinformatics (Syns: utilize, exploitation, apply) | method -> Bioinformatics (Syns: method acting) | thermal -> Materials Science (Syns: thermic, caloric)",Bioinformatics
"Current cancer screening guidelines cover only a few cancer types and rely on narrowly defined criteria such as age or a single risk factor like smoking history, to identify high-risk individuals. Predictive models using electronic health records (EHRs), which capture large-scale longitudinal patient-level health information, may provide a more effective tool for identifying high-risk groups by detecting subtle prediagnostic signals of cancer. Recent advances in large language and foundation models have further expanded this potential, yet evidence remains limited on how useful HER-based models are compared with traditional risk factors currently used in screening guidelines. We systematically evaluated the clinical utility of EHR-based predictive models against traditional risk factors, including gene mutations and family history of cancer, for identifying high-risk individuals across eight major cancers (breast, lung, colorectal, prostate, ovarian, liver, pancreatic, and stomach), using data from the All of Us Research Program, which integrates EHR, genomic, and survey data from over 865,000 participants. Even with a baseline modeling approach, EHR-based models achieved a 3- to 6-fold higher enrichment of true cancer cases among individuals identified as high risk compared with traditional risk factors alone, whether used as a standalone or complementary tool. The EHR foundation model, a state-of-the-art approach trained on comprehensive patient trajectories, further improved predictive performance across 26 cancer types, demonstrating the clinical potential of EHR-based predictive modeling to support more precise and scalable early detection strategies.",Bioinformatics
"Current cancer screening guidelines cover only a few cancer types and rely on narrowly defined criteria such as age or a single risk factor like smoking history, to identify high-risk individuals. Predictive models using electronic health records (EHRs), which capture large-scale longitudinal patient-level health information, may provide a more effective tool for identifying high-risk groups by detecting subtle prediagnostic signals of cancer. Recent advances in large language and foundation models have further expanded this potential, yet evidence remains limited on how useful HER-based models are compared with traditional risk factors currently used in screening guidelines. We systematically evaluated the clinical utility of EHR-based predictive models against traditional risk factors, including gene mutations and family history of cancer, for identifying high-risk individuals across eight major cancers (breast, lung, colorectal, prostate, ovarian, liver, pancreatic, and stomach), using data from the All of Us Research Program, which integrates EHR, genomic, and survey data from over 865,000 participants. Even with a baseline modeling approach, EHR-based models achieved a 3- to 6-fold higher enrichment of true cancer cases among individuals identified as high risk compared with traditional risk factors alone, whether used as a standalone or complementary tool. The EHR foundation model, a state-of-the-art approach trained on comprehensive patient trajectories, further improved predictive performance across 26 cancer types, demonstrating the clinical potential of EHR-based predictive modeling to support more precise and scalable early detection strategies. [SEP] [HINT] used -> Bioinformatics (Syns: utilize, ill-used, apply) | clinical -> Bioinformatics (Syns: ) | language -> Neuroscience (Syns: linguistic process, linguistic communication, spoken communication)",Bioinformatics
"Thin elastic sheets appear in systems ranging from graphene to biological membranes, where phenomena such as wrinkling, folding, and thermal fluctuations originate from geometric nonlinearities. These effects are treated within weakly nonlinear theories, such as the Foppl-von Karman equations, which require small slopes and fail when deflections become large even if strains remain small. We introduce a methodological progress via a geometric reformulation of thin-sheet elasticity based on a stress potential and a curvature potential. This formulation preserves the structure of the classical equations while extending their validity to nonlinear, multivalued configurations, and geometrically frustrated states. The framework provides a unified description of thin-sheet mechanics in regimes inaccessible to existing theories and opens new possibilities for the study of elastic membranes and two-dimensional materials.",Materials Science
"Thin elastic sheets appear in systems ranging from graphene to biological membranes, where phenomena such as wrinkling, folding, and thermal fluctuations originate from geometric nonlinearities. These effects are treated within weakly nonlinear theories, such as the Foppl-von Karman equations, which require small slopes and fail when deflections become large even if strains remain small. We introduce a methodological progress via a geometric reformulation of thin-sheet elasticity based on a stress potential and a curvature potential. This formulation preserves the structure of the classical equations while extending their validity to nonlinear, multivalued configurations, and geometrically frustrated states. The framework provides a unified description of thin-sheet mechanics in regimes inaccessible to existing theories and opens new possibilities for the study of elastic membranes and two-dimensional materials. [SEP] [HINT] based -> Bioinformatics (Syns: ground, free-base, base) | structure -> Bioinformatics (Syns: social system, complex body part, social structure) | systems -> Bioinformatics (Syns: organization, organisation, system)",Materials Science
"We analyze functional magnetic resonance imaging (fMRI) data from the Human Connectome Project (HCP) to match brain activities during a range of cognitive tasks. Our findings demonstrate that even basic linear machine learning models can effectively classify brain states and achieve state-of-the-art accuracy, particularly for tasks related to motor functions and language processing. Feature importance ranking allows to identify distinct sets of brain regions whose activation patterns are uniquely associated with specific cognitive functions. These discriminative features provide strong support for the hypothesis of functional specialization across cortical and subcortical areas of the human brain.   Additionally, we investigate the temporal dynamics of the identified brain regions, demonstrating that the time-dependent structure of fMRI signals are essential for shaping functional connectivity between regions: uncorrelated areas are least important for classification. This temporal perspective provides deeper insights into the formation and modulation of brain neural networks involved in cognitive processing.",Neuroscience
"We analyze functional magnetic resonance imaging (fMRI) data from the Human Connectome Project (HCP) to match brain activities during a range of cognitive tasks. Our findings demonstrate that even basic linear machine learning models can effectively classify brain states and achieve state-of-the-art accuracy, particularly for tasks related to motor functions and language processing. Feature importance ranking allows to identify distinct sets of brain regions whose activation patterns are uniquely associated with specific cognitive functions. These discriminative features provide strong support for the hypothesis of functional specialization across cortical and subcortical areas of the human brain.   Additionally, we investigate the temporal dynamics of the identified brain regions, demonstrating that the time-dependent structure of fMRI signals are essential for shaping functional connectivity between regions: uncorrelated areas are least important for classification. This temporal perspective provides deeper insights into the formation and modulation of brain neural networks involved in cognitive processing. [SEP] [HINT] connectivity -> Neuroscience (Syns: ) | tasks -> Neuroscience (Syns: tax, task, project) | language -> Neuroscience (Syns: linguistic process, linguistic communication, spoken communication)",Neuroscience
"Spatial transcriptomics (ST) measures gene expression at a set of spatial locations in a tissue. Communities of nearby cells that express similar genes form \textit{spatial domains}. Specialized ST clustering algorithms have been developed to identify these spatial domains. These methods often identify spatial domains at a single morphological scale, and interactions across multiple scales are often overlooked. For example, large cellular communities often contain smaller substructures, and heterogeneous frontier regions often lie between homogeneous domains. Topological data analysis (TDA) is an emerging mathematical toolkit that studies the underlying features of data at various geometric scales. It is especially useful for analyzing complex biological datasets with multiscale characteristics. Using TDA, we develop Persistent Homology for Domains at Multiple Scales (PHD-MS) to locate tissue structures that persist across morphological scales. We apply PHD-MS to highlight multiscale spatial domains in several tissue types and ST technologies. We also compare PHD-MS domains against ground-truth domains in expert-annotated tissues, where PHD-MS outperforms traditional clustering approaches. PHD-MS is available as an open-source software package with an interactive graphical user interface for exploring the identified multiscale domains.",Bioinformatics
"Spatial transcriptomics (ST) measures gene expression at a set of spatial locations in a tissue. Communities of nearby cells that express similar genes form \textit{spatial domains}. Specialized ST clustering algorithms have been developed to identify these spatial domains. These methods often identify spatial domains at a single morphological scale, and interactions across multiple scales are often overlooked. For example, large cellular communities often contain smaller substructures, and heterogeneous frontier regions often lie between homogeneous domains. Topological data analysis (TDA) is an emerging mathematical toolkit that studies the underlying features of data at various geometric scales. It is especially useful for analyzing complex biological datasets with multiscale characteristics. Using TDA, we develop Persistent Homology for Domains at Multiple Scales (PHD-MS) to locate tissue structures that persist across morphological scales. We apply PHD-MS to highlight multiscale spatial domains in several tissue types and ST technologies. We also compare PHD-MS domains against ground-truth domains in expert-annotated tissues, where PHD-MS outperforms traditional clustering approaches. PHD-MS is available as an open-source software package with an interactive graphical user interface for exploring the identified multiscale domains. [SEP] [HINT] tissue -> Bioinformatics (Syns: tissue paper, weave) | features -> Bioinformatics (Syns: characteristic, lineament, feature of speech) | complex -> Bioinformatics (Syns: building complex, coordination compound, composite)",Bioinformatics
"Periodic boundary condition (PBC) is a standard approximation for calculating crystalline materials properties. However, a PBC crystal is not the same as the real macroscopic crystal, therefore, if applied indiscriminately, it can lead to erroneous conclusions. For example, unlike other extensive observables such as total energy, the polarization of a macroscopic crystal cannot always be described by a PBC model, because polarization is inherently nonlocal and strongly dependent on surface terminations, irrespective of crystal size, and moreover, the symmetry of the macroscopic crystal can be altered when the PBC is applied to a macroscopic crystal. We demonstrate in this paper that the polarization of a macroscopic crystal receives contributions from both the repeating bulk units and the crystal surfaces, which must be treated on an equal footing. When the combined system of the bulk and its surfaces are taken into account, materials traditionally classified as nonpolar can, in fact, admit polar symmetry, thus explaining why experimentalists have observed polarization in some nominally ``nonpolar'' systems. Our study, thus, clarifies that polarization can only exist in polar group systems and that apparent violations of Neumann's principle reported in some recent works originate from misinterpreting bulk PBC crystal as intrinsic macroscopic crystal, ignoring the contribution from the surfaces. We demonstrate that when the full bulk-plus-surface system is considered, the crystal polarization and symmetry is fully consistent with Neumann's principle.",Materials Science
"Periodic boundary condition (PBC) is a standard approximation for calculating crystalline materials properties. However, a PBC crystal is not the same as the real macroscopic crystal, therefore, if applied indiscriminately, it can lead to erroneous conclusions. For example, unlike other extensive observables such as total energy, the polarization of a macroscopic crystal cannot always be described by a PBC model, because polarization is inherently nonlocal and strongly dependent on surface terminations, irrespective of crystal size, and moreover, the symmetry of the macroscopic crystal can be altered when the PBC is applied to a macroscopic crystal. We demonstrate in this paper that the polarization of a macroscopic crystal receives contributions from both the repeating bulk units and the crystal surfaces, which must be treated on an equal footing. When the combined system of the bulk and its surfaces are taken into account, materials traditionally classified as nonpolar can, in fact, admit polar symmetry, thus explaining why experimentalists have observed polarization in some nominally ``nonpolar'' systems. Our study, thus, clarifies that polarization can only exist in polar group systems and that apparent violations of Neumann's principle reported in some recent works originate from misinterpreting bulk PBC crystal as intrinsic macroscopic crystal, ignoring the contribution from the surfaces. We demonstrate that when the full bulk-plus-surface system is considered, the crystal polarization and symmetry is fully consistent with Neumann's principle. [SEP] [HINT] systems -> Bioinformatics (Syns: organization, organisation, system) | crystal -> Materials Science (Syns: crystallization, quartz, lechatelierite) | materials -> Materials Science (Syns: stuff, cloth, material)",Materials Science
"Superconducting electrides have attracted growing attention for their potential to achieve high superconducting transition temperatures (TC) under pressure. However, many known electrides are chemically reactive and unstable, making high-quality single-crystal growth, characterization, and measurements difficult, and most do not exhibit superconductivity at ambient pressure. In contrast, La3In stands out for its ambient-pressure superconductivity (TC ~ 9.4 K) and the availability of high-quality single crystals. Here, we investigate its low-energy electronic structure using angle-resolved photoemission spectroscopy and first-principles calculations. The bands near the Fermi energy are mainly derived from La 5d and In 5p orbitals. A saddle point is directly observed at the Brillouin zone (BZ) boundary, while a three-dimensional van Hove singularity crosses EF at the BZ corner. First-principles calculations further reveal topological Dirac surface states within the bulk energy gap above EF. The coexistence of a high density of states and in-gap topological surface states near EF suggests that La3In offers a promising platform for tuning superconductivity and exploring possible topological superconducting phases through doping or external pressure.",Materials Science
"Superconducting electrides have attracted growing attention for their potential to achieve high superconducting transition temperatures (TC) under pressure. However, many known electrides are chemically reactive and unstable, making high-quality single-crystal growth, characterization, and measurements difficult, and most do not exhibit superconductivity at ambient pressure. In contrast, La3In stands out for its ambient-pressure superconductivity (TC ~ 9.4 K) and the availability of high-quality single crystals. Here, we investigate its low-energy electronic structure using angle-resolved photoemission spectroscopy and first-principles calculations. The bands near the Fermi energy are mainly derived from La 5d and In 5p orbitals. A saddle point is directly observed at the Brillouin zone (BZ) boundary, while a three-dimensional van Hove singularity crosses EF at the BZ corner. First-principles calculations further reveal topological Dirac surface states within the bulk energy gap above EF. The coexistence of a high density of states and in-gap topological surface states near EF suggests that La3In offers a promising platform for tuning superconductivity and exploring possible topological superconducting phases through doping or external pressure. [SEP] [HINT] transition -> Materials Science (Syns: passage, modulation, changeover) | electronic -> Materials Science (Syns: ) | structure -> Bioinformatics (Syns: social system, complex body part, social structure)",Materials Science
"Geographic atrophy (GA) is a key biomarker of dry age-related macular degeneration (AMD) traditionally identified through color fundus photography. Hyper-transmission defects (hyperTDs), a feature highly correlated with GA, have recently gained prominence in optical coherence tomography (OCT) research. OCT offers cross-sectional imaging of the retina, leading to the development of the terms complete retinal pigment epithelium and outer retinal atrophy (cRORA) to describe specific patterns of structural degeneration. Within the definitions of cRORA three critical lesions are implicated: inner nuclear layer and outer plexiform layer (INL-OPL) subsidence, ellipsoid zone and retinal pigment epithelium (EZ-RPE) disruption, and hyperTDs. To enable the automated quantification of retinal atrophy progression, we propose an AI-based model that segments INL-OPL subsidence, EZ-RPE disruption, and hyperTDs. Additionally, we developed an algorithm that leverages these segmentation results to distinguish cRORA from hyperTDs in the absence of GA. We evaluated our approach on a comprehensive dataset of eyes with AMD and healthy eyes, achieving mean voxel-level F1-scores of 0.76/0.13 (mean/standard deviation) for INL-OPL subsidence, 0.64/0.15 for EZ-RPE disruption, and 0.69/0.04 for hyperTDs. For distinguishing cRORA from hyperTDs, we achieved an average pixel-level F1-score of 0.80/0.12 for segment cRORA from hyperTDs. This method demonstrates significant advances in the quantitative analysis of retinal atrophy, offering a promising tool for improved AMD diagnosis and disease progression monitoring.",Bioinformatics
"Geographic atrophy (GA) is a key biomarker of dry age-related macular degeneration (AMD) traditionally identified through color fundus photography. Hyper-transmission defects (hyperTDs), a feature highly correlated with GA, have recently gained prominence in optical coherence tomography (OCT) research. OCT offers cross-sectional imaging of the retina, leading to the development of the terms complete retinal pigment epithelium and outer retinal atrophy (cRORA) to describe specific patterns of structural degeneration. Within the definitions of cRORA three critical lesions are implicated: inner nuclear layer and outer plexiform layer (INL-OPL) subsidence, ellipsoid zone and retinal pigment epithelium (EZ-RPE) disruption, and hyperTDs. To enable the automated quantification of retinal atrophy progression, we propose an AI-based model that segments INL-OPL subsidence, EZ-RPE disruption, and hyperTDs. Additionally, we developed an algorithm that leverages these segmentation results to distinguish cRORA from hyperTDs in the absence of GA. We evaluated our approach on a comprehensive dataset of eyes with AMD and healthy eyes, achieving mean voxel-level F1-scores of 0.76/0.13 (mean/standard deviation) for INL-OPL subsidence, 0.64/0.15 for EZ-RPE disruption, and 0.69/0.04 for hyperTDs. For distinguishing cRORA from hyperTDs, we achieved an average pixel-level F1-score of 0.80/0.12 for segment cRORA from hyperTDs. This method demonstrates significant advances in the quantitative analysis of retinal atrophy, offering a promising tool for improved AMD diagnosis and disease progression monitoring. [SEP] [HINT] results -> Bioinformatics (Syns: final result, consequence, resultant role) | optical -> Materials Science (Syns: ocular, opthalmic, optic) | specific -> Bioinformatics (Syns: particular)",Bioinformatics
"The statistics of correlations are central quantities characterizing the collective dynamics of recurrent neural networks. We derive exact expressions for the statistics of correlations of nonlinear recurrent networks in the limit of a large number N of neurons, including systematic 1/N corrections. Our approach uses a path-integral representation of the network's stochastic dynamics, which reduces the description to a few collective variables and enables efficient computation. This generalizes previous results on linear networks to include a wide family of nonlinear activation functions, which enter as interaction terms in the path integral. These interactions can resolve the instability of the linear theory and yield a strictly positive participation dimension. We present explicit results for power-law activations, revealing scaling behavior controlled by the network coupling. In addition, we introduce a class of activation functions based on Pade approximants and provide analytic predictions for their correlation statistics. Numerical simulations confirm our theoretical results with excellent agreement.",Neuroscience
"The statistics of correlations are central quantities characterizing the collective dynamics of recurrent neural networks. We derive exact expressions for the statistics of correlations of nonlinear recurrent networks in the limit of a large number N of neurons, including systematic 1/N corrections. Our approach uses a path-integral representation of the network's stochastic dynamics, which reduces the description to a few collective variables and enables efficient computation. This generalizes previous results on linear networks to include a wide family of nonlinear activation functions, which enter as interaction terms in the path integral. These interactions can resolve the instability of the linear theory and yield a strictly positive participation dimension. We present explicit results for power-law activations, revealing scaling behavior controlled by the network coupling. In addition, we introduce a class of activation functions based on Pade approximants and provide analytic predictions for their correlation statistics. Numerical simulations confirm our theoretical results with excellent agreement. [SEP] [HINT] based -> Bioinformatics (Syns: ground, free-base, base) | networks -> Neuroscience (Syns: network, meshwork, electronic network) | results -> Bioinformatics (Syns: final result, consequence, resultant role)",Neuroscience
"Proteins are essential biological macromolecules that execute life functions. Local motifs within protein structures, such as active sites, are the most critical components for linking structure to function and are key to understanding protein evolution and enabling protein engineering. Existing computational methods struggle to identify and compare these local structures, which leaves a significant gap in understanding protein structures and harnessing their functions. This study presents PLASMA, the first deep learning framework for efficient and interpretable residue-level protein substructure alignment. We reformulate the problem as a regularized optimal transport task and leverage differentiable Sinkhorn iterations. For a pair of input protein structures, PLASMA outputs a clear alignment matrix with an interpretable overall similarity score. Through extensive quantitative evaluations and three biological case studies, we demonstrate that PLASMA achieves accurate, lightweight, and interpretable residue-level alignment. Additionally, we introduce PLASMA-PF, a training-free variant that provides a practical alternative when training data are unavailable. Our method addresses a critical gap in protein structure analysis tools and offers new opportunities for functional annotation, evolutionary studies, and structure-based drug design. Reproducibility is ensured via our official implementation at https://github.com/ZW471/PLASMA-Protein-Local-Alignment.git.",Bioinformatics
"Proteins are essential biological macromolecules that execute life functions. Local motifs within protein structures, such as active sites, are the most critical components for linking structure to function and are key to understanding protein evolution and enabling protein engineering. Existing computational methods struggle to identify and compare these local structures, which leaves a significant gap in understanding protein structures and harnessing their functions. This study presents PLASMA, the first deep learning framework for efficient and interpretable residue-level protein substructure alignment. We reformulate the problem as a regularized optimal transport task and leverage differentiable Sinkhorn iterations. For a pair of input protein structures, PLASMA outputs a clear alignment matrix with an interpretable overall similarity score. Through extensive quantitative evaluations and three biological case studies, we demonstrate that PLASMA achieves accurate, lightweight, and interpretable residue-level alignment. Additionally, we introduce PLASMA-PF, a training-free variant that provides a practical alternative when training data are unavailable. Our method addresses a critical gap in protein structure analysis tools and offers new opportunities for functional annotation, evolutionary studies, and structure-based drug design. Reproducibility is ensured via our official implementation at https://github.com/ZW471/PLASMA-Protein-Local-Alignment.git. [SEP] [HINT] task -> Neuroscience (Syns: tax, project, chore) | computational -> Neuroscience (Syns: ) | understanding -> Neuroscience (Syns: savvy, intellect, sympathy)",Bioinformatics
"The forces generated by action potentials in muscle cells shuttle blood, food and waste products throughout the luminal structures of the body. Although non-invasive electrophysiological techniques exist, most mechanosensors cannot access luminal structures non-invasively. Here we introduce non-toxic ingestible mechanosensors to enable the quantitative study of luminal forces and apply them to study feeding in living Caenorhabditis elegans roundworms. These optical 'microgauges' comprise NaY0.8Yb0.18Er0.02F4@NaYF4 upconverting nanoparticles embedded in polystyrene microspheres. Combining optical microscopy and atomic force microscopy to study microgauges in vitro, we show that force evokes a linear and hysteresis-free change in the ratio of emitted red to green light. With fluorescence imaging and non-invasive electrophysiology, we show that adult C. elegans generate bite forces during feeding on the order of 10 micronewtons and that the temporal pattern of force generation is aligned with muscle activity in the feeding organ. Moreover, the bite force we measure corresponds to Hertzian contact stresses in the pressure range used to lyse the bacterial food of the worm. Microgauges have the potential to enable quantitative studies that investigate how neuromuscular stresses are affected by aging, genetic mutations and drug treatments in this organ and other luminal organs.",Bioinformatics
"The forces generated by action potentials in muscle cells shuttle blood, food and waste products throughout the luminal structures of the body. Although non-invasive electrophysiological techniques exist, most mechanosensors cannot access luminal structures non-invasively. Here we introduce non-toxic ingestible mechanosensors to enable the quantitative study of luminal forces and apply them to study feeding in living Caenorhabditis elegans roundworms. These optical 'microgauges' comprise NaY0.8Yb0.18Er0.02F4@NaYF4 upconverting nanoparticles embedded in polystyrene microspheres. Combining optical microscopy and atomic force microscopy to study microgauges in vitro, we show that force evokes a linear and hysteresis-free change in the ratio of emitted red to green light. With fluorescence imaging and non-invasive electrophysiology, we show that adult C. elegans generate bite forces during feeding on the order of 10 micronewtons and that the temporal pattern of force generation is aligned with muscle activity in the feeding organ. Moreover, the bite force we measure corresponds to Hertzian contact stresses in the pressure range used to lyse the bacterial food of the worm. Microgauges have the potential to enable quantitative studies that investigate how neuromuscular stresses are affected by aging, genetic mutations and drug treatments in this organ and other luminal organs. [SEP] [HINT] used -> Bioinformatics (Syns: utilize, ill-used, apply) | order -> Materials Science (Syns: enjoin, dictate, social club) | optical -> Materials Science (Syns: ocular, opthalmic, optic)",Bioinformatics
"Development of spintronic and quantum computing devices increases demand for efficient, energy saving method of spin manipulation at molecular scale. Polyoxovanadate molecular magnets being susceptible to both electric and magnetic fields may serve here as a good base material. In this paper two isostructural anions [V$_{12}$As$_8$O$_{40}$(HCO$_2$)]$^{n-}$ (with $n=3,5$) featuring two different mixed-valence states with itinerant and localized valence electrons are studied. The impact of the electric field on their magnetic properties is investigated by means of two complementary methods informed by magnetic measurements: effective Hamiltonian calculations and density functional theory. It is demonstrated that the magnetoelectric effect in theses molecules is induced mostly by relocation of itinerant electrons, is highly anisotropic, depends on the valence state and can be detected even at room temperature. These findings can pave the way to practical applications in which an electric field control over spin state is required.",Materials Science
"Development of spintronic and quantum computing devices increases demand for efficient, energy saving method of spin manipulation at molecular scale. Polyoxovanadate molecular magnets being susceptible to both electric and magnetic fields may serve here as a good base material. In this paper two isostructural anions [V$_{12}$As$_8$O$_{40}$(HCO$_2$)]$^{n-}$ (with $n=3,5$) featuring two different mixed-valence states with itinerant and localized valence electrons are studied. The impact of the electric field on their magnetic properties is investigated by means of two complementary methods informed by magnetic measurements: effective Hamiltonian calculations and density functional theory. It is demonstrated that the magnetoelectric effect in theses molecules is induced mostly by relocation of itinerant electrons, is highly anisotropic, depends on the valence state and can be detected even at room temperature. These findings can pave the way to practical applications in which an electric field control over spin state is required. [SEP] [HINT] field -> Materials Science (Syns: field of honor, line of business, orbit) | spin -> Materials Science (Syns: twisting, whirl, tailspin) | functional -> Neuroscience (Syns: working, usable, running)",Materials Science
"The primary output of the nervous system is movement and behavior. While recent advances have democratized pose tracking during complex behavior, kinematic trajectories alone provide only indirect access to the underlying control processes. Here we present MIMIC-MJX, a framework for learning biologically-plausible neural control policies from kinematics. MIMIC-MJX models the generative process of motor control by training neural controllers that learn to actuate biomechanically-realistic body models in physics simulation to reproduce real kinematic trajectories. We demonstrate that our implementation is accurate, fast, data-efficient, and generalizable to diverse animal body models. Policies trained with MIMIC-MJX can be utilized to both analyze neural control strategies and simulate behavioral experiments, illustrating its potential as an integrative modeling framework for neuroscience.",Neuroscience
"The primary output of the nervous system is movement and behavior. While recent advances have democratized pose tracking during complex behavior, kinematic trajectories alone provide only indirect access to the underlying control processes. Here we present MIMIC-MJX, a framework for learning biologically-plausible neural control policies from kinematics. MIMIC-MJX models the generative process of motor control by training neural controllers that learn to actuate biomechanically-realistic body models in physics simulation to reproduce real kinematic trajectories. We demonstrate that our implementation is accurate, fast, data-efficient, and generalizable to diverse animal body models. Policies trained with MIMIC-MJX can be utilized to both analyze neural control strategies and simulate behavioral experiments, illustrating its potential as an integrative modeling framework for neuroscience. [SEP] [HINT] learning -> Bioinformatics (Syns: take, teach, acquire) | complex -> Bioinformatics (Syns: building complex, coordination compound, composite) | framework -> Bioinformatics (Syns: theoretical account, model, fabric)",Neuroscience
"Multimodal deep learning (MDL) has emerged as a transformative approach in computational pathology. By integrating complementary information from multiple data sources, MDL models have demonstrated superior predictive performance across diverse clinical tasks compared to unimodal models. However, the assumption that combining modalities inherently improves performance remains largely unexamined. We hypothesise that multimodal gains depend critically on the predictive quality of individual modalities, and that integrating weak modalities may introduce noise rather than complementary information. We test this hypothesis on a prostate cancer dataset with histopathology, radiology, and clinical data to predict time-to-biochemical recurrence. Our results confirm that combining high-performing modalities yield superior performance compared to unimodal approaches. However, integrating a poor-performing modality with other higher-performing modalities degrades predictive accuracy. These findings demonstrate that multimodal benefit requires selective, performance-guided integration rather than indiscriminate modality combination, with implications for MDL design across computational pathology and medical imaging.",Bioinformatics
"Multimodal deep learning (MDL) has emerged as a transformative approach in computational pathology. By integrating complementary information from multiple data sources, MDL models have demonstrated superior predictive performance across diverse clinical tasks compared to unimodal models. However, the assumption that combining modalities inherently improves performance remains largely unexamined. We hypothesise that multimodal gains depend critically on the predictive quality of individual modalities, and that integrating weak modalities may introduce noise rather than complementary information. We test this hypothesis on a prostate cancer dataset with histopathology, radiology, and clinical data to predict time-to-biochemical recurrence. Our results confirm that combining high-performing modalities yield superior performance compared to unimodal approaches. However, integrating a poor-performing modality with other higher-performing modalities degrades predictive accuracy. These findings demonstrate that multimodal benefit requires selective, performance-guided integration rather than indiscriminate modality combination, with implications for MDL design across computational pathology and medical imaging. [SEP] [HINT] tasks -> Neuroscience (Syns: tax, task, project) | clinical -> Bioinformatics (Syns: ) | computational -> Neuroscience (Syns: )",Bioinformatics
"Detecting Lévy flights of cells has been a challenging problem in experiments. The challenge lies in accessing data in spatiotemporal scales across orders of magnitude, which is necessary for reliably extracting a power-law scaling. Differential dynamic microscopy has been shown to be a powerful method that allows one to acquire statistics of cell motion across scales, which is a potentially versatile method for detecting Lévy walks in biological systems. In this article, we extend the differential dynamic microscopy method to self-propelled Lévy particles, whose run-time distribution has a algebraic tail. We validate our protocol using synthetic imaging data and show that a reliable detection of active Lévy particles requires accessing length scales of one order of magnitude larger than its persistence length. Applying the protocol to experimental data of E. coli and E. gracilis, we find that E. coli does not exhibit a signature of Lévy walks, while E. gracilis is better described as active Lévy particles.",Bioinformatics
"Detecting Lévy flights of cells has been a challenging problem in experiments. The challenge lies in accessing data in spatiotemporal scales across orders of magnitude, which is necessary for reliably extracting a power-law scaling. Differential dynamic microscopy has been shown to be a powerful method that allows one to acquire statistics of cell motion across scales, which is a potentially versatile method for detecting Lévy walks in biological systems. In this article, we extend the differential dynamic microscopy method to self-propelled Lévy particles, whose run-time distribution has a algebraic tail. We validate our protocol using synthetic imaging data and show that a reliable detection of active Lévy particles requires accessing length scales of one order of magnitude larger than its persistence length. Applying the protocol to experimental data of E. coli and E. gracilis, we find that E. coli does not exhibit a signature of Lévy walks, while E. gracilis is better described as active Lévy particles. [SEP] [HINT] order -> Materials Science (Syns: enjoin, dictate, social club) | using -> Bioinformatics (Syns: utilize, exploitation, apply) | method -> Bioinformatics (Syns: method acting)",Bioinformatics
"Accurate quantification in positron emission tomography (PET) is essential for accurate diagnostic results and effective treatment tracking. A major issue encountered in PET imaging is attenuation. Attenuation refers to the diminution of photon detected as they traverse biological tissues before reaching detectors. When such corrections are absent or inadequate, this signal degradation can introduce inaccurate quantification, making it difficult to differentiate benign from malignant conditions, and can potentially lead to misdiagnosis. Typically, this correction is done with co-computed Computed Tomography (CT) imaging to obtain structural data for calculating photon attenuation across the body. However, this methodology subjects patients to extra ionizing radiation exposure, suffers from potential spatial misregistration between PET/CT imaging sequences, and demands costly equipment infrastructure. Emerging advances in neural network architectures present an alternative approach via synthetic CT image synthesis. Our investigation reveals that Conditional Denoising Diffusion Probabilistic Models (DDPMs) can generate high quality CT images from non attenuation corrected PET images in order to correct attenuation. By utilizing all three orthogonal views from non-attenuation-corrected PET images, the DDPM approach combined with ensemble voting generates higher quality pseudo-CT images with reduced artifacts and improved slice-to-slice consistency. Results from a study of 159 head scans acquired with the Siemens Biograph Vision PET/CT scanner demonstrate both qualitative and quantitative improvements in pseudo-CT generation. The method achieved a mean absolute error of 32 $\pm$ 10.4 HU on the CT images and an average error of (1.48 $\pm$ 0.68)\% across all regions of interest when comparing PET images reconstructed using the attenuation map of the generated pseudo-CT versus the true CT.",Bioinformatics
"Accurate quantification in positron emission tomography (PET) is essential for accurate diagnostic results and effective treatment tracking. A major issue encountered in PET imaging is attenuation. Attenuation refers to the diminution of photon detected as they traverse biological tissues before reaching detectors. When such corrections are absent or inadequate, this signal degradation can introduce inaccurate quantification, making it difficult to differentiate benign from malignant conditions, and can potentially lead to misdiagnosis. Typically, this correction is done with co-computed Computed Tomography (CT) imaging to obtain structural data for calculating photon attenuation across the body. However, this methodology subjects patients to extra ionizing radiation exposure, suffers from potential spatial misregistration between PET/CT imaging sequences, and demands costly equipment infrastructure. Emerging advances in neural network architectures present an alternative approach via synthetic CT image synthesis. Our investigation reveals that Conditional Denoising Diffusion Probabilistic Models (DDPMs) can generate high quality CT images from non attenuation corrected PET images in order to correct attenuation. By utilizing all three orthogonal views from non-attenuation-corrected PET images, the DDPM approach combined with ensemble voting generates higher quality pseudo-CT images with reduced artifacts and improved slice-to-slice consistency. Results from a study of 159 head scans acquired with the Siemens Biograph Vision PET/CT scanner demonstrate both qualitative and quantitative improvements in pseudo-CT generation. The method achieved a mean absolute error of 32 $\pm$ 10.4 HU on the CT images and an average error of (1.48 $\pm$ 0.68)\% across all regions of interest when comparing PET images reconstructed using the attenuation map of the generated pseudo-CT versus the true CT. [SEP] [HINT] non -> Materials Science (Syns: not) | quality -> Bioinformatics (Syns: lineament, tone, calibre) | order -> Materials Science (Syns: enjoin, dictate, social club)",Bioinformatics
"Primates utilize distributed neural circuits to learn habits in uncertain environments, but the underlying mechanisms remain poorly understood. We propose a formal theory of network energetics explaining how brain states influence sequential behavior. We test our theory on multi-unit recordings from the caudate nucleus and cortical regions of macaques performing a motor habit task. The theory predicts the energy required to transition between brain states represented by trial-specific firing rates across channels, assuming activity spreads through effective connections. We hypothesized that habit formation would correlate with lower control energy. Consistent with this, we observed smaller energy requirements for transitions between similar saccade patterns and those of intermediate complexity, and sessions exploiting fewer patterns. Simulations ruled out confounds from neurons' directional tuning. Finally, virtual lesioning demonstrated robustness of observed relationships between control energy and behavior. This work paves the way for examining how behavior arises from changing activity in distributed circuitry.",Neuroscience
"Primates utilize distributed neural circuits to learn habits in uncertain environments, but the underlying mechanisms remain poorly understood. We propose a formal theory of network energetics explaining how brain states influence sequential behavior. We test our theory on multi-unit recordings from the caudate nucleus and cortical regions of macaques performing a motor habit task. The theory predicts the energy required to transition between brain states represented by trial-specific firing rates across channels, assuming activity spreads through effective connections. We hypothesized that habit formation would correlate with lower control energy. Consistent with this, we observed smaller energy requirements for transitions between similar saccade patterns and those of intermediate complexity, and sessions exploiting fewer patterns. Simulations ruled out confounds from neurons' directional tuning. Finally, virtual lesioning demonstrated robustness of observed relationships between control energy and behavior. This work paves the way for examining how behavior arises from changing activity in distributed circuitry. [SEP] [HINT] transition -> Materials Science (Syns: passage, modulation, changeover) | cortical -> Neuroscience (Syns: ) | work -> Bioinformatics (Syns: work out, process, bring)",Neuroscience
"We propose CITE V.1, an agentic, evidence-grounded framework that leverages Large Language Models (LLMs) to provide transparent and reproducible interpretations of RNA-seq clusters. Unlike existing enrichment-based approaches that reduce results to broad statistical associations and LLM-only models that risk unsupported claims or fabricated citations, CITE V.1 transforms cluster interpretation by producing biologically coherent explanations explicitly anchored in the biomedical literature. The framework orchestrates three specialized agents: a Retriever that gathers domain knowledge from PubMed and UniProt, an Interpreter that formulates functional hypotheses, and Critics that evaluate claims, enforce evidence grounding, and qualify uncertainty through confidence and reliability indicators. Applied to Salmonella enterica RNA-seq data, CITE V.1 generated biologically meaningful insights supported by the literature, while an LLM-only Gemini baseline frequently produced speculative results with false citations. By moving RNA-seq analysis from surface-level enrichment to auditable, interpretable, and evidence-based hypothesis generation, CITE V.1 advances the transparency and reliability of AI in biomedicine.",Bioinformatics
"We propose CITE V.1, an agentic, evidence-grounded framework that leverages Large Language Models (LLMs) to provide transparent and reproducible interpretations of RNA-seq clusters. Unlike existing enrichment-based approaches that reduce results to broad statistical associations and LLM-only models that risk unsupported claims or fabricated citations, CITE V.1 transforms cluster interpretation by producing biologically coherent explanations explicitly anchored in the biomedical literature. The framework orchestrates three specialized agents: a Retriever that gathers domain knowledge from PubMed and UniProt, an Interpreter that formulates functional hypotheses, and Critics that evaluate claims, enforce evidence grounding, and qualify uncertainty through confidence and reliability indicators. Applied to Salmonella enterica RNA-seq data, CITE V.1 generated biologically meaningful insights supported by the literature, while an LLM-only Gemini baseline frequently produced speculative results with false citations. By moving RNA-seq analysis from surface-level enrichment to auditable, interpretable, and evidence-based hypothesis generation, CITE V.1 advances the transparency and reliability of AI in biomedicine. [SEP] [HINT] language -> Neuroscience (Syns: linguistic process, linguistic communication, spoken communication) | functional -> Neuroscience (Syns: working, usable, running) | results -> Bioinformatics (Syns: final result, consequence, resultant role)",Bioinformatics
"The big strides seen in generative AI are not based on somewhat obscure algorithms, but due to clearly defined generative principles. The resulting concrete implementations have proven themselves in large numbers of applications. We suggest that it is imperative to thoroughly investigate which of these generative principles may be operative also in the brain, and hence relevant for cognitive neuroscience. In addition, ML research led to a range of interesting characterizations of neural information processing systems. We discuss five examples, the shortcomings of world modelling, the generation of thought processes, attention, neural scaling laws, and quantization, that illustrate how much neuroscience could potentially learn from ML research.",Neuroscience
"The big strides seen in generative AI are not based on somewhat obscure algorithms, but due to clearly defined generative principles. The resulting concrete implementations have proven themselves in large numbers of applications. We suggest that it is imperative to thoroughly investigate which of these generative principles may be operative also in the brain, and hence relevant for cognitive neuroscience. In addition, ML research led to a range of interesting characterizations of neural information processing systems. We discuss five examples, the shortcomings of world modelling, the generation of thought processes, attention, neural scaling laws, and quantization, that illustrate how much neuroscience could potentially learn from ML research. [SEP] [HINT] based -> Bioinformatics (Syns: ground, free-base, base) | information -> Bioinformatics (Syns: entropy, data, info) | processing -> Neuroscience (Syns: work, process, march)",Neuroscience
"Subtle synthetic variables can have an outsizes influence on the crystal structure and magnetic properties of a material, particularly those of quantum materials. In this work, we investigate the impact of synthesis under a magnetic field (magnetosynthesis) on the crystal structure and magnetic properties of several Cu$^{2+}$ ($S=1/2$) based materials with antiferromagnetic interactions and varying levels of magnetic frustration, from simple antiferromagnets to a quantum spin liquid. We employ small (0.09 - 0.37 T) magnetic fields applied during low-temperature hydrothermal or evaporative synthesis of the simple antiferromagnet CuCl$_2\cdot$2H$_2$O, the canted antiferromagnet (Cu,Zn)$_3$Cl$_4$(OH)$_2\cdot$2H$_2$O, the frustrated and canted antiferromagnet atacamite Cu$_2$(OH)$_3$Cl, and the highly frustrated quantum spin liquid herbertsmithite Cu$_3$Zn(OH)$_6$Cl$_2$. We found that (Cu,Zn)$_3$Cl$_4$(OH)$_2\cdot$2H$_2$O experiences structural changes well above its magnetic transition. Atacamite Cu$_2$(OH)$_3$Cl synthesized under a 0.19 T field experiences a 0.15 K (~3%) decrease in its Néel transition temperature and a significant strengthening of its antiferromagnetic interactions, suggesting that magnetosynthesis can influence the ground state of moderately frustrated materials.",Materials Science
"Subtle synthetic variables can have an outsizes influence on the crystal structure and magnetic properties of a material, particularly those of quantum materials. In this work, we investigate the impact of synthesis under a magnetic field (magnetosynthesis) on the crystal structure and magnetic properties of several Cu$^{2+}$ ($S=1/2$) based materials with antiferromagnetic interactions and varying levels of magnetic frustration, from simple antiferromagnets to a quantum spin liquid. We employ small (0.09 - 0.37 T) magnetic fields applied during low-temperature hydrothermal or evaporative synthesis of the simple antiferromagnet CuCl$_2\cdot$2H$_2$O, the canted antiferromagnet (Cu,Zn)$_3$Cl$_4$(OH)$_2\cdot$2H$_2$O, the frustrated and canted antiferromagnet atacamite Cu$_2$(OH)$_3$Cl, and the highly frustrated quantum spin liquid herbertsmithite Cu$_3$Zn(OH)$_6$Cl$_2$. We found that (Cu,Zn)$_3$Cl$_4$(OH)$_2\cdot$2H$_2$O experiences structural changes well above its magnetic transition. Atacamite Cu$_2$(OH)$_3$Cl synthesized under a 0.19 T field experiences a 0.15 K (~3%) decrease in its Néel transition temperature and a significant strengthening of its antiferromagnetic interactions, suggesting that magnetosynthesis can influence the ground state of moderately frustrated materials. [SEP] [HINT] field -> Materials Science (Syns: field of honor, line of business, orbit) | transition -> Materials Science (Syns: passage, modulation, changeover) | based -> Bioinformatics (Syns: ground, free-base, base)",Materials Science
"We measure the polarization change of a beam reflected from the surface of both crystalline alpha and amorphous SiO2 samples while they are photo-excited by an intense light pulse, at intensities above the nonlinear excitation threshold yet below the damage threshold. The polarization change varies with the angle between the polarization of pump and probe light, but is found to be independent of their orientation relative to the crystal axes. This behavior differs between the reflected and transmitted beams, and can be modeled by taking into account a birefringence induced by the electric field of the pump. These polarization-change effects can be very strong, with polarization rotation exceeding 90°, at pump intensities well below the damage threshold. We also observe a markedly different behavior of the reflected beam depending on whether the material is crystalline or amorphous.",Materials Science
"We measure the polarization change of a beam reflected from the surface of both crystalline alpha and amorphous SiO2 samples while they are photo-excited by an intense light pulse, at intensities above the nonlinear excitation threshold yet below the damage threshold. The polarization change varies with the angle between the polarization of pump and probe light, but is found to be independent of their orientation relative to the crystal axes. This behavior differs between the reflected and transmitted beams, and can be modeled by taking into account a birefringence induced by the electric field of the pump. These polarization-change effects can be very strong, with polarization rotation exceeding 90°, at pump intensities well below the damage threshold. We also observe a markedly different behavior of the reflected beam depending on whether the material is crystalline or amorphous. [SEP] [HINT] field -> Materials Science (Syns: field of honor, line of business, orbit) | different -> Neuroscience (Syns: unlike, dissimilar) | crystal -> Materials Science (Syns: crystallization, quartz, lechatelierite)",Materials Science
"The charge state stability of nitrogen-vacancy (NV) centers critically affects their application as quantum sensors and qubits. Understanding charge state conversion and equilibration is critical not only for NV centers in diamond but also for defects and impurities in wide-bandgap materials in general. The mechanisms by which these centers change charge state upon optical or electronic excitation without the presence of mobile carriers remain unclear, potentially affecting the performance of applications ranging from phosphors to power electronics. Here, we elucidate this issue for the case of photoionization of NV center ensembles. Using pump-probe spectroscopy, we ionize negatively charged NV centers and monitor the recovery of $\NVm$ on timescales of up to several seconds. We find that the recovery rate depends strongly on the concentration of surrounding nitrogen donors. Remarkably, the equilibration dynamics exhibit no discernible dependence on temperature, ruling out thermally activated processes. The multiphonon-assisted electron tunneling model, supported by density-functional calculations, explains the measurements and identifies tunneling as the equilibration mechanism.",Materials Science
"The charge state stability of nitrogen-vacancy (NV) centers critically affects their application as quantum sensors and qubits. Understanding charge state conversion and equilibration is critical not only for NV centers in diamond but also for defects and impurities in wide-bandgap materials in general. The mechanisms by which these centers change charge state upon optical or electronic excitation without the presence of mobile carriers remain unclear, potentially affecting the performance of applications ranging from phosphors to power electronics. Here, we elucidate this issue for the case of photoionization of NV center ensembles. Using pump-probe spectroscopy, we ionize negatively charged NV centers and monitor the recovery of $\NVm$ on timescales of up to several seconds. We find that the recovery rate depends strongly on the concentration of surrounding nitrogen donors. Remarkably, the equilibration dynamics exhibit no discernible dependence on temperature, ruling out thermally activated processes. The multiphonon-assisted electron tunneling model, supported by density-functional calculations, explains the measurements and identifies tunneling as the equilibration mechanism. [SEP] [HINT] understanding -> Neuroscience (Syns: savvy, intellect, sympathy) | charge -> Materials Science (Syns: tear, bearing, burster) | electronic -> Materials Science (Syns: )",Materials Science
"The practical strength of oxide glasses is greatly reduced by surface flaws that form during processing and use. Instrumented indentation can mimic such real-life damage events and induce flaws and cracking under controlled conditions. At the same time, instrumented indentation allows for systematic examination of the deformation and structural changes of the regions of the glass being indented. However, structural probing is nearly always performed after rather than during the sharp contact event, limiting our understanding of the indentation process. To overcome this, we here demonstrate the use of nanofocus X-ray scattering experiments to probe the local mechanical and structural response of vitreous silica during indentation. Two-dimensional mapping of the scattering pattern in the zone below a sharp diamond wedge indenter reveals local changes in the atomic structure and density as well as cracking behavior. These in situ experiments during indentation reveal the formation and evolution of the densification zone and cracking with nanoscale resolution. Understanding the interplay between structural densification and cracking behavior in glasses is deepened through this work, which is crucial for the development of more damage-resistant and thus stronger glasses as well as fundamental understanding of glass deformation mechanisms.",Materials Science
"The practical strength of oxide glasses is greatly reduced by surface flaws that form during processing and use. Instrumented indentation can mimic such real-life damage events and induce flaws and cracking under controlled conditions. At the same time, instrumented indentation allows for systematic examination of the deformation and structural changes of the regions of the glass being indented. However, structural probing is nearly always performed after rather than during the sharp contact event, limiting our understanding of the indentation process. To overcome this, we here demonstrate the use of nanofocus X-ray scattering experiments to probe the local mechanical and structural response of vitreous silica during indentation. Two-dimensional mapping of the scattering pattern in the zone below a sharp diamond wedge indenter reveals local changes in the atomic structure and density as well as cracking behavior. These in situ experiments during indentation reveal the formation and evolution of the densification zone and cracking with nanoscale resolution. Understanding the interplay between structural densification and cracking behavior in glasses is deepened through this work, which is crucial for the development of more damage-resistant and thus stronger glasses as well as fundamental understanding of glass deformation mechanisms. [SEP] [HINT] understanding -> Neuroscience (Syns: savvy, intellect, sympathy) | structure -> Bioinformatics (Syns: social system, complex body part, social structure) | processing -> Neuroscience (Syns: work, process, march)",Materials Science
"We demonstrate that Shannon's information entropy and the thermodynamic entropy of Boltzmann and Gibbs are quantitatively equivalent for real condensed-matter systems. By interpreting atomic configurations as information sources, we compute entropy directly from the compressibility of molecular-dynamics trajectories, without physical partitioning or empirical modeling. A custom lossy-compression algorithm measures the minimum number of bits required to describe a microstate at finite precision, and this bit count maps exactly to thermodynamic entropy through the Shannon-Boltzmann relation. The method reproduces benchmark entropies for metals, semiconductors, oxides, and refractory ceramics in both solid and liquid phases, establishing information as the fundamental quantity underlying thermodynamic disorder. This equivalence unifies information theory and statistical mechanics, providing a general and computationally efficient framework for determining entropies and free energies directly from atomic data.",Materials Science
"We demonstrate that Shannon's information entropy and the thermodynamic entropy of Boltzmann and Gibbs are quantitatively equivalent for real condensed-matter systems. By interpreting atomic configurations as information sources, we compute entropy directly from the compressibility of molecular-dynamics trajectories, without physical partitioning or empirical modeling. A custom lossy-compression algorithm measures the minimum number of bits required to describe a microstate at finite precision, and this bit count maps exactly to thermodynamic entropy through the Shannon-Boltzmann relation. The method reproduces benchmark entropies for metals, semiconductors, oxides, and refractory ceramics in both solid and liquid phases, establishing information as the fundamental quantity underlying thermodynamic disorder. This equivalence unifies information theory and statistical mechanics, providing a general and computationally efficient framework for determining entropies and free energies directly from atomic data. [SEP] [HINT] information -> Bioinformatics (Syns: entropy, data, info) | framework -> Bioinformatics (Syns: theoretical account, model, fabric) | theory -> Materials Science (Syns: possibility, hypothesis)",Materials Science
"Codon usage bias has a crucial impact on the translation efficiency and co-translational folding of proteins, necessitating the algorithmic development of codon optimization/harmonization methods, particularly for heterologous recombinant protein expression. Codon harmonization is especially valuable for proteins sensitive to translation rates, because it can potentially replicate native translation speeds, preserving proper folding and maintaining protein activity. This work proposes a Monte Carlo-based codon harmonization algorithm, MOSAIC (Monte Carlo-based Simulated Annealing for Linked Codons), for the harmonization of a set of linked codons, which differs from conventional codon harmonization, by focusing on the codon sets rather than individual ones. Our MOSAIC demonstrates state-of-the-art performance on ribosomal proteins (S18, S15, S10, and L11) as model systems. Among them, the harmonized gene of RP S18 was expressed and compared with the expression of the wild-type gene. The harmonized gene clearly yielded a larger quantity of the protein, from which the amount of the soluble protein was also significant. These results underscore the potential of the linked codon harmonization approach to enhance the expression and functionality of sensitive proteins, setting the stage for more efficient production of recombinant proteins in various biotechnological and pharmaceutical applications.",Bioinformatics
"Codon usage bias has a crucial impact on the translation efficiency and co-translational folding of proteins, necessitating the algorithmic development of codon optimization/harmonization methods, particularly for heterologous recombinant protein expression. Codon harmonization is especially valuable for proteins sensitive to translation rates, because it can potentially replicate native translation speeds, preserving proper folding and maintaining protein activity. This work proposes a Monte Carlo-based codon harmonization algorithm, MOSAIC (Monte Carlo-based Simulated Annealing for Linked Codons), for the harmonization of a set of linked codons, which differs from conventional codon harmonization, by focusing on the codon sets rather than individual ones. Our MOSAIC demonstrates state-of-the-art performance on ribosomal proteins (S18, S15, S10, and L11) as model systems. Among them, the harmonized gene of RP S18 was expressed and compared with the expression of the wild-type gene. The harmonized gene clearly yielded a larger quantity of the protein, from which the amount of the soluble protein was also significant. These results underscore the potential of the linked codon harmonization approach to enhance the expression and functionality of sensitive proteins, setting the stage for more efficient production of recombinant proteins in various biotechnological and pharmaceutical applications. [SEP] [HINT] work -> Bioinformatics (Syns: work out, process, bring) | performance -> Bioinformatics (Syns: functioning, operation, carrying out) | results -> Bioinformatics (Syns: final result, consequence, resultant role)",Bioinformatics
"Humans intuitively perceive complex social signals in visual scenes, yet it remains unclear whether state-of-the-art AI models encode the same similarity structure. We study (Q1) whether modern video and language models capture human-perceived similarity in social videos, and (Q2) how to instill this structure into models using human behavioral data. To address this, we introduce a new benchmark of over 49,000 odd-one-out similarity judgments on 250 three-second video clips of social interactions, and discover a modality gap: despite the task being visual, caption-based language embeddings align better with human similarity than any pretrained video model. We close this gap by fine-tuning a TimeSformer video model on these human judgments with our novel hybrid triplet-RSA objective using low-rank adaptation (LoRA), aligning pairwise distances to human similarity. This fine-tuning protocol yields significantly improved alignment with human perceptions on held-out videos in terms of both explained variance and odd-one-out triplet accuracy. Variance partitioning shows that the fine-tuned video model increases shared variance with language embeddings and explains additional unique variance not captured by the language model. Finally, we test transfer via linear probes and find that human-similarity fine-tuning strengthens the encoding of social-affective attributes (intimacy, valence, dominance, communication) relative to the pretrained baseline. Overall, our findings highlight a gap in pretrained video models' social recognition and demonstrate that behavior-guided fine-tuning shapes video representations toward human social perception.",Neuroscience
"Humans intuitively perceive complex social signals in visual scenes, yet it remains unclear whether state-of-the-art AI models encode the same similarity structure. We study (Q1) whether modern video and language models capture human-perceived similarity in social videos, and (Q2) how to instill this structure into models using human behavioral data. To address this, we introduce a new benchmark of over 49,000 odd-one-out similarity judgments on 250 three-second video clips of social interactions, and discover a modality gap: despite the task being visual, caption-based language embeddings align better with human similarity than any pretrained video model. We close this gap by fine-tuning a TimeSformer video model on these human judgments with our novel hybrid triplet-RSA objective using low-rank adaptation (LoRA), aligning pairwise distances to human similarity. This fine-tuning protocol yields significantly improved alignment with human perceptions on held-out videos in terms of both explained variance and odd-one-out triplet accuracy. Variance partitioning shows that the fine-tuned video model increases shared variance with language embeddings and explains additional unique variance not captured by the language model. Finally, we test transfer via linear probes and find that human-similarity fine-tuning strengthens the encoding of social-affective attributes (intimacy, valence, dominance, communication) relative to the pretrained baseline. Overall, our findings highlight a gap in pretrained video models' social recognition and demonstrate that behavior-guided fine-tuning shapes video representations toward human social perception. [SEP] [HINT] task -> Neuroscience (Syns: tax, project, chore) | language -> Neuroscience (Syns: linguistic process, linguistic communication, spoken communication) | structure -> Bioinformatics (Syns: social system, complex body part, social structure)",Neuroscience
"Large multi-modal models (LMMs) show increasing performance in realistic visual tasks for images and, more recently, for videos. For example, given a video sequence, such models are able to describe in detail objects, the surroundings and dynamic actions. In this study, we explored the extent to which these models ground their semantic understanding in the actual visual input. Specifically, given sequences of hands interacting with objects, we asked models when and where the interaction begins or ends. For this purpose, we introduce a first of its kind, large-scale dataset with more than 20K annotated interactions on videos from the Something-Something-V2 dataset. 250 AMTurk human annotators labeled core interaction events, particularly when and where objects and agents become attached ('contact') or detached ('release'). We asked two LMMs (Qwen-2.5VL and GPT-4o) to locate these events in short videos, each with a single event. The results show that although the models can reliably name the target objects, identify the action and provide coherent reasoning, they consistently fail to identify the frame where the interaction begins or ends and cannot localize the event within the scene. Our findings suggest that in struggling to pinpoint the moment and location of physical contact that defines the interaction, the models lack the perceptual grounding required for deeper understanding of dynamic scenes.",Neuroscience
"Large multi-modal models (LMMs) show increasing performance in realistic visual tasks for images and, more recently, for videos. For example, given a video sequence, such models are able to describe in detail objects, the surroundings and dynamic actions. In this study, we explored the extent to which these models ground their semantic understanding in the actual visual input. Specifically, given sequences of hands interacting with objects, we asked models when and where the interaction begins or ends. For this purpose, we introduce a first of its kind, large-scale dataset with more than 20K annotated interactions on videos from the Something-Something-V2 dataset. 250 AMTurk human annotators labeled core interaction events, particularly when and where objects and agents become attached ('contact') or detached ('release'). We asked two LMMs (Qwen-2.5VL and GPT-4o) to locate these events in short videos, each with a single event. The results show that although the models can reliably name the target objects, identify the action and provide coherent reasoning, they consistently fail to identify the frame where the interaction begins or ends and cannot localize the event within the scene. Our findings suggest that in struggling to pinpoint the moment and location of physical contact that defines the interaction, the models lack the perceptual grounding required for deeper understanding of dynamic scenes. [SEP] [HINT] tasks -> Neuroscience (Syns: tax, task, project) | understanding -> Neuroscience (Syns: savvy, intellect, sympathy) | performance -> Bioinformatics (Syns: functioning, operation, carrying out)",Neuroscience
"The dynamic reconstruction of surfaces during electrochemical reactions plays a crucial role in determining the performance of electrocatalysts. However, because reconstructions occur at the atomic level, direct observation and elucidation of the underlying mechanism are challenging for conventional powder type catalysts with ill defined lattices. In this study, the catalytically active surface of 3C BaRuO3 (BRO) epitaxial thin films emerges upon the dynamic introduction of surface Ru clusters, for the alkaline hydrogen evolution reaction (HER). Based on the mass activity at overpotential 100 mV, the intrinsic HER performance increases dramatically from 0.11 to 7.72 A/mg immediately after the initial HER cycle and eventually saturates at 1.05 A/mg after continuous operation. The formation of Ru clusters on the catalyst surface, driven by selective Ba leaching under alkaline HER conditions, is observed experimentally. Density functional theory calculations demonstrate that HER activity increased with enhanced H* adsorption owing to the dynamic Ru6 cluster formation. A strategy for stabilizing the 'awakened' active surface of BRO is further proposed by validating that the atomic-scale control of the film thickness can effectively maintain the highly active state. This study offers fundamental insights into the design and stabilization of the highly active Ru-based electrocatalysts for the alkaline HER.",Materials Science
"The dynamic reconstruction of surfaces during electrochemical reactions plays a crucial role in determining the performance of electrocatalysts. However, because reconstructions occur at the atomic level, direct observation and elucidation of the underlying mechanism are challenging for conventional powder type catalysts with ill defined lattices. In this study, the catalytically active surface of 3C BaRuO3 (BRO) epitaxial thin films emerges upon the dynamic introduction of surface Ru clusters, for the alkaline hydrogen evolution reaction (HER). Based on the mass activity at overpotential 100 mV, the intrinsic HER performance increases dramatically from 0.11 to 7.72 A/mg immediately after the initial HER cycle and eventually saturates at 1.05 A/mg after continuous operation. The formation of Ru clusters on the catalyst surface, driven by selective Ba leaching under alkaline HER conditions, is observed experimentally. Density functional theory calculations demonstrate that HER activity increased with enhanced H* adsorption owing to the dynamic Ru6 cluster formation. A strategy for stabilizing the 'awakened' active surface of BRO is further proposed by validating that the atomic-scale control of the film thickness can effectively maintain the highly active state. This study offers fundamental insights into the design and stabilization of the highly active Ru-based electrocatalysts for the alkaline HER. [SEP] [HINT] based -> Bioinformatics (Syns: ground, free-base, base) | functional -> Neuroscience (Syns: working, usable, running) | performance -> Bioinformatics (Syns: functioning, operation, carrying out)",Materials Science
"Silicon carbide (SiC) metal-oxide-semiconductor field-effect-transistors (MOSFETs) enable high-voltage and high-temperature power conversion. Compared to Si devices, they suffer from pronounced gate leakage due to the reduced electron tunneling barrier at the interface between SiC and amorphous silicon dioxide (a-SiO$_2$). We develop a self-consistent, physics-based simulation framework that couples electrostatics, quantum tunneling, carrier transport, impact ionization, and charge trapping for both electrons and holes. The model quantitatively reproduces measured gate-current-voltage characteristics of SiC MOS capacitors over a wide temperature (80-573 K) range and a wide bias range without empirical fitting. Simulations reveal that conduction electrons in a-SiO$_2$ can trigger impact ionization, which generates electron-hole pairs, and leads to capture of holes in the oxide bulk, thereby enhancing gate leakage current. The framework captures these coupled processes across multiple orders of magnitude in time and field, providing predictive capability for oxide reliability. Although demonstrated for SiC devices, the methodology also applies to Si technologies that uses the same gate dielectric.",Materials Science
"Silicon carbide (SiC) metal-oxide-semiconductor field-effect-transistors (MOSFETs) enable high-voltage and high-temperature power conversion. Compared to Si devices, they suffer from pronounced gate leakage due to the reduced electron tunneling barrier at the interface between SiC and amorphous silicon dioxide (a-SiO$_2$). We develop a self-consistent, physics-based simulation framework that couples electrostatics, quantum tunneling, carrier transport, impact ionization, and charge trapping for both electrons and holes. The model quantitatively reproduces measured gate-current-voltage characteristics of SiC MOS capacitors over a wide temperature (80-573 K) range and a wide bias range without empirical fitting. Simulations reveal that conduction electrons in a-SiO$_2$ can trigger impact ionization, which generates electron-hole pairs, and leads to capture of holes in the oxide bulk, thereby enhancing gate leakage current. The framework captures these coupled processes across multiple orders of magnitude in time and field, providing predictive capability for oxide reliability. Although demonstrated for SiC devices, the methodology also applies to Si technologies that uses the same gate dielectric. [SEP] [HINT] charge -> Materials Science (Syns: tear, bearing, burster) | electron -> Materials Science (Syns: negatron) | framework -> Bioinformatics (Syns: theoretical account, model, fabric)",Materials Science
"Axial phonons possessing nonzero angular momentum and resulting magnetic moment can couple to magnetic order. The rich magnetic structures enable phonon angular momentum (PAM) to acquire momentum-space textures analogous to electronic spin structures. However, a systematic framework for classifying these textures, especially their potential higher-order multipolar patterns, has remained elusive. Here, by employing magnetic point group analysis, we develop a complete classification of phonons in collinear magnets, spanning ferro-, antiferro-, and alter-magnets. Our theory distinguishes four fundamental types of magnetic phonons based on symmetry and PAM wave-pattern parity. Strikingly, we reveal a full sequence of axial phonons exhibiting higher-order-wave (from $p$- to $j$-wave) PAM patterns covering both odd and even parities, which we term alteraxial phonons. Our high-throughput calculations predict hundreds of magnetic candidates hosting such alteraxial phonons. Our work establishes a symmetry-guided design principle for axial phonons and related phenomena in magnetic materials.",Materials Science
"Axial phonons possessing nonzero angular momentum and resulting magnetic moment can couple to magnetic order. The rich magnetic structures enable phonon angular momentum (PAM) to acquire momentum-space textures analogous to electronic spin structures. However, a systematic framework for classifying these textures, especially their potential higher-order multipolar patterns, has remained elusive. Here, by employing magnetic point group analysis, we develop a complete classification of phonons in collinear magnets, spanning ferro-, antiferro-, and alter-magnets. Our theory distinguishes four fundamental types of magnetic phonons based on symmetry and PAM wave-pattern parity. Strikingly, we reveal a full sequence of axial phonons exhibiting higher-order-wave (from $p$- to $j$-wave) PAM patterns covering both odd and even parities, which we term alteraxial phonons. Our high-throughput calculations predict hundreds of magnetic candidates hosting such alteraxial phonons. Our work establishes a symmetry-guided design principle for axial phonons and related phenomena in magnetic materials. [SEP] [HINT] phonon -> Materials Science (Syns: ) | based -> Bioinformatics (Syns: ground, free-base, base) | spin -> Materials Science (Syns: twisting, whirl, tailspin)",Materials Science
"Sulfide chalcopyrite Cu(In,Ga)S2 (CIGS) is a wide bandgap semiconductor suitable for the top cell of a tandem solar device. Here we demonstrate significant improvements in absorber quality by alloying with Ag to form (Ag,Cu)(In,Ga)S2 (ACIGS) absorbers. We report the Ag alloying effect on compositional, structural, and optoelectronic properties of absorbers. We demonstrate suppressed bulk recombination and improved carrier lifetime in ACIGS, as a result of improved grain size, porosity reduction and defect passivation. We also show that Ag alloying flattens the Ga gradient. Consideration of this impact of Ag will be necessary in future engineering of the Ga profile to maximize charge carrier collection and avoid interface recombination. Exploiting the beneficial effects of Ag alloying, we report a wide bandgap (1.58 eV) ACIGS solar cell with a high power conversion efficiency of 15.5% and a large open-circuit voltage (VOC) of 948 mV, improving on the reference pure CIGS solar cell, with an 11.2% efficiency and an 821 mV VOC. Ag alloying is a useful route to further increase the efficiency of CIGS solar cells and future tandem devices.",Materials Science
"Sulfide chalcopyrite Cu(In,Ga)S2 (CIGS) is a wide bandgap semiconductor suitable for the top cell of a tandem solar device. Here we demonstrate significant improvements in absorber quality by alloying with Ag to form (Ag,Cu)(In,Ga)S2 (ACIGS) absorbers. We report the Ag alloying effect on compositional, structural, and optoelectronic properties of absorbers. We demonstrate suppressed bulk recombination and improved carrier lifetime in ACIGS, as a result of improved grain size, porosity reduction and defect passivation. We also show that Ag alloying flattens the Ga gradient. Consideration of this impact of Ag will be necessary in future engineering of the Ga profile to maximize charge carrier collection and avoid interface recombination. Exploiting the beneficial effects of Ag alloying, we report a wide bandgap (1.58 eV) ACIGS solar cell with a high power conversion efficiency of 15.5% and a large open-circuit voltage (VOC) of 948 mV, improving on the reference pure CIGS solar cell, with an 11.2% efficiency and an 821 mV VOC. Ag alloying is a useful route to further increase the efficiency of CIGS solar cells and future tandem devices. [SEP] [HINT] charge -> Materials Science (Syns: tear, bearing, burster) | defect -> Materials Science (Syns: mar, shortcoming, fault) | quality -> Bioinformatics (Syns: lineament, tone, calibre)",Materials Science
"Understanding the flexibility of protein-nucleic acid complexes, often characterized by atomic B-factors, is essential for elucidating their structure, dynamics, and functions, such as reactivity and allosteric pathways. Traditional models such as Gaussian Network Models (GNM) and Elastic Network Models (ENM) often fall short in capturing multiscale interactions, especially in large or complex biomolecular systems. In this work, we apply the Persistent Sheaf Laplacian (PSL) framework for the B-factor prediction of protein-nucleic acid complexes. The PSL model integrates multiscale analysis, algebraic topology, combinatoric Laplacians, and sheaf theory for data representation. It reveals topological invariants in its harmonic spectra and captures the homotopic shape evolution of data with its non-harmonic spectra. Its localization enables accurate B-factor predictions. We benchmark our method on three diverse datasets, including protein-RNA and nucleic-acid-only structures, and demonstrate that PSL consistently outperforms existing models such as GNM and multiscale FRI (mFRI), achieving up to a 21% improvement in Pearson correlation coefficient for B-factor prediction. These results highlight the robustness and adaptability of PSL in modeling complex biomolecular interactions and suggest its potential utility in broader applications such as mutation impact analysis and drug design.",Bioinformatics
"Understanding the flexibility of protein-nucleic acid complexes, often characterized by atomic B-factors, is essential for elucidating their structure, dynamics, and functions, such as reactivity and allosteric pathways. Traditional models such as Gaussian Network Models (GNM) and Elastic Network Models (ENM) often fall short in capturing multiscale interactions, especially in large or complex biomolecular systems. In this work, we apply the Persistent Sheaf Laplacian (PSL) framework for the B-factor prediction of protein-nucleic acid complexes. The PSL model integrates multiscale analysis, algebraic topology, combinatoric Laplacians, and sheaf theory for data representation. It reveals topological invariants in its harmonic spectra and captures the homotopic shape evolution of data with its non-harmonic spectra. Its localization enables accurate B-factor predictions. We benchmark our method on three diverse datasets, including protein-RNA and nucleic-acid-only structures, and demonstrate that PSL consistently outperforms existing models such as GNM and multiscale FRI (mFRI), achieving up to a 21% improvement in Pearson correlation coefficient for B-factor prediction. These results highlight the robustness and adaptability of PSL in modeling complex biomolecular interactions and suggest its potential utility in broader applications such as mutation impact analysis and drug design. [SEP] [HINT] understanding -> Neuroscience (Syns: savvy, intellect, sympathy) | complex -> Bioinformatics (Syns: building complex, coordination compound, composite) | results -> Bioinformatics (Syns: final result, consequence, resultant role)",Bioinformatics
"In the locust's lobula giant movement detector neural pathways, four categories of inhibition, i.e., global inhibition, self-inhibition, lateral inhibition, and feed-forward inhibition, have been functionally explored in the context of looming perception. However, their combined influence on shaping selectivity to looming motion remains unclear. Driven by recent physiological advancements, this paper offers new insights into the roles of these inhibitory mechanisms at multiple levels and scales in simulations, refining the specific selectivity for responding only to objects approaching the eyes while remaining unresponsive to other forms of movement. Within a feed-forward, multi-layer neural network framework, global inhibition, lateral inhibition, self-inhibition, and feed-forward inhibition are integrated. Global inhibition acts as an immediate feedback mechanism, normalising light intensities delivered by ommatidia, particularly addressing low-contrast looming. Self-inhibition, modelled numerically for the first time, suppresses translational motion. Lateral inhibition is formed by delayed local excitation spreading across a larger area. Notably, self-inhibition and lateral inhibition are sequential in time and are combined through feed-forward inhibition, which indicates the angular size subtended by moving objects. Together, these inhibitory processes attenuate motion-induced excitation at multiple levels and scales. This research suggests that self-inhibition may act earlier than lateral inhibition to rapidly reduce excitation in situ, thereby suppressing translational motion, and global inhibition can modulate excitation on a finer scale, enhancing selectivity in higher contrast range.",Neuroscience
"In the locust's lobula giant movement detector neural pathways, four categories of inhibition, i.e., global inhibition, self-inhibition, lateral inhibition, and feed-forward inhibition, have been functionally explored in the context of looming perception. However, their combined influence on shaping selectivity to looming motion remains unclear. Driven by recent physiological advancements, this paper offers new insights into the roles of these inhibitory mechanisms at multiple levels and scales in simulations, refining the specific selectivity for responding only to objects approaching the eyes while remaining unresponsive to other forms of movement. Within a feed-forward, multi-layer neural network framework, global inhibition, lateral inhibition, self-inhibition, and feed-forward inhibition are integrated. Global inhibition acts as an immediate feedback mechanism, normalising light intensities delivered by ommatidia, particularly addressing low-contrast looming. Self-inhibition, modelled numerically for the first time, suppresses translational motion. Lateral inhibition is formed by delayed local excitation spreading across a larger area. Notably, self-inhibition and lateral inhibition are sequential in time and are combined through feed-forward inhibition, which indicates the angular size subtended by moving objects. Together, these inhibitory processes attenuate motion-induced excitation at multiple levels and scales. This research suggests that self-inhibition may act earlier than lateral inhibition to rapidly reduce excitation in situ, thereby suppressing translational motion, and global inhibition can modulate excitation on a finer scale, enhancing selectivity in higher contrast range. [SEP] [HINT] specific -> Bioinformatics (Syns: particular) | neural -> Bioinformatics (Syns: neuronic, nervous, neuronal) | network -> Bioinformatics (Syns: meshwork, electronic network, mesh)",Neuroscience
"In this paper, the thermal and structural properties of Cu-Au (Copper-Gold) Janus nanoparticles with a diameter of 5 nm are investigated by using molecular dynamics (MD) simulations within the interactions defined by the many-body embedded atom model (EAM). A set of nanoparticle models has been constructed, with varying Cu and Au ratios. MD method is carried out to calculate the melting temperature, heat capacity, radial distribution function (RDF), Lindemann index, mean square displacement (MSD), and diffusion coefficients of these models. The findings demonstrate that nanoparticles rich in Cu exhibit a higher melting temperature and more defined phase transitions. In contrast, structures rich in gold exhibited reduced melting temperatures and showed surface-initiated melting behaviours. MD study highlights that the thermal stability and atomic mobility of Cu-Au Janus nanoparticles depend on the composition ratio and the dispersion of materials.",Materials Science
"In this paper, the thermal and structural properties of Cu-Au (Copper-Gold) Janus nanoparticles with a diameter of 5 nm are investigated by using molecular dynamics (MD) simulations within the interactions defined by the many-body embedded atom model (EAM). A set of nanoparticle models has been constructed, with varying Cu and Au ratios. MD method is carried out to calculate the melting temperature, heat capacity, radial distribution function (RDF), Lindemann index, mean square displacement (MSD), and diffusion coefficients of these models. The findings demonstrate that nanoparticles rich in Cu exhibit a higher melting temperature and more defined phase transitions. In contrast, structures rich in gold exhibited reduced melting temperatures and showed surface-initiated melting behaviours. MD study highlights that the thermal stability and atomic mobility of Cu-Au Janus nanoparticles depend on the composition ratio and the dispersion of materials. [SEP] [HINT] molecular -> Bioinformatics (Syns: ) | using -> Bioinformatics (Syns: utilize, exploitation, apply) | method -> Bioinformatics (Syns: method acting)",Materials Science
"In this study, the dynamic oxidation state changes of pure Pt and 50at% PtPd alloy catalysts were investigated during a temperature ramp from 80 to 450 C under a reactive gas mixture of 500 ppm NO and 3 % Oxygen in Nitrogen atmosphere. These changes are closely correlated with variations in NO conversion efficiency. Sharp tip specimens were prepared from Pt and PtPd alloy wires by electrochemical polishing and Focused Ion Beam annular milling, with the hemispherical apex serving as a model for nanoscale catalyst surfaces. The samples were exposed to the reactive atmosphere in a dedicated reaction chamber and subsequently analyzed using atom probe tomography. Effective oxide thicknesses and three-dimensional surface morphology were quantitatively evaluated. A pronounced decrease in oxide thickness was observed during the first cooling and second heating cycles, particularly below 200 C, indicating reversible redox behavior on both Pt and PtPd alloy surfaces. This behavior correlates with the inverse hysteresis of NO conversion measured for both systems, suggesting that the redox reversibility is driven primarily by reaction kinetics rather than thermodynamic stability.",Materials Science
"In this study, the dynamic oxidation state changes of pure Pt and 50at% PtPd alloy catalysts were investigated during a temperature ramp from 80 to 450 C under a reactive gas mixture of 500 ppm NO and 3 % Oxygen in Nitrogen atmosphere. These changes are closely correlated with variations in NO conversion efficiency. Sharp tip specimens were prepared from Pt and PtPd alloy wires by electrochemical polishing and Focused Ion Beam annular milling, with the hemispherical apex serving as a model for nanoscale catalyst surfaces. The samples were exposed to the reactive atmosphere in a dedicated reaction chamber and subsequently analyzed using atom probe tomography. Effective oxide thicknesses and three-dimensional surface morphology were quantitatively evaluated. A pronounced decrease in oxide thickness was observed during the first cooling and second heating cycles, particularly below 200 C, indicating reversible redox behavior on both Pt and PtPd alloy surfaces. This behavior correlates with the inverse hysteresis of NO conversion measured for both systems, suggesting that the redox reversibility is driven primarily by reaction kinetics rather than thermodynamic stability. [SEP] [HINT] using -> Bioinformatics (Syns: utilize, exploitation, apply) | model -> Bioinformatics (Syns: exemplary, framework, modelling) | temperature -> Materials Science (Syns: )",Materials Science
"Discovering nonlinear optical (NLO) materials with strong shift current response, particularly in the infrared (IR) regime, is essential for next-generation optoelectronics yet remains highly challenging in both experiments and theory, which still largely relies on case by case studies. Here, we employ a high-throughput screening strategy, applying a multi-step filter to the Materials Project database (>154,000 materials), which yielded 2,519 candidate materials for detailed first-principle evaluation. From these calculations, we identify 32 NLO materials with strong shift current response ($σ$ > 100 $μA/V^2$). Our work reveals that layered structures with $C_{3v}$ symmetry and heavy $p$-block elements (e.g. Te, Sb) exhibit apparent superiority in enhancing shift current. More importantly, 9 of these compounds show shift current response peaks in the IR region, with the strongest reaching 616 $μA/V^2$, holding significant application potential in fields such as IR photodetection, sensing, and energy harvesting. Beyond identifying promising candidates, this work establishes a comprehensive and high-quality first-principles dataset for NLO response, providing a solid foundation for future AI-driven screening and accelerated discovery of high-performance NLO materials, as demonstrated by a prototype machine-learning application.",Materials Science
"Discovering nonlinear optical (NLO) materials with strong shift current response, particularly in the infrared (IR) regime, is essential for next-generation optoelectronics yet remains highly challenging in both experiments and theory, which still largely relies on case by case studies. Here, we employ a high-throughput screening strategy, applying a multi-step filter to the Materials Project database (>154,000 materials), which yielded 2,519 candidate materials for detailed first-principle evaluation. From these calculations, we identify 32 NLO materials with strong shift current response ($σ$ > 100 $μA/V^2$). Our work reveals that layered structures with $C_{3v}$ symmetry and heavy $p$-block elements (e.g. Te, Sb) exhibit apparent superiority in enhancing shift current. More importantly, 9 of these compounds show shift current response peaks in the IR region, with the strongest reaching 616 $μA/V^2$, holding significant application potential in fields such as IR photodetection, sensing, and energy harvesting. Beyond identifying promising candidates, this work establishes a comprehensive and high-quality first-principles dataset for NLO response, providing a solid foundation for future AI-driven screening and accelerated discovery of high-performance NLO materials, as demonstrated by a prototype machine-learning application. [SEP] [HINT] work -> Bioinformatics (Syns: work out, process, bring) | optical -> Materials Science (Syns: ocular, opthalmic, optic) | materials -> Materials Science (Syns: stuff, cloth, material)",Materials Science
"While machine learning has transformed polymer design by enabling rapid property prediction and candidate generation, translating these designs into experimentally realizable materials remains a critical challenge. Traditionally, the synthesis of target polymers has relied heavily on expert intuition and prior experience. The lack of automated retrosynthetic tools to assist chemists, limit the rapid practical impact of data-driven polymer discovery. To expedite lab-scale validation and beyond, we present a retrosynthetic framework that leverages large language models (LLMs) to guide polymer synthesis. Our approach, which we call polyRETRO, involves two key steps: 1) predicting the most likely polymerization reaction class of a target polymer and 2) identifying the underlying chemical transformation templates and the corresponding monomers, using primarily natural-language based constructs. This LLM-driven framework enables direct retrosynthetic analysis given just the target polymer SMILES string. polyRETRO constitutes a initial step towards a scalable, interpretable, and generalizable approach to bridge the gap between computational design and experimental synthesis.",Materials Science
"While machine learning has transformed polymer design by enabling rapid property prediction and candidate generation, translating these designs into experimentally realizable materials remains a critical challenge. Traditionally, the synthesis of target polymers has relied heavily on expert intuition and prior experience. The lack of automated retrosynthetic tools to assist chemists, limit the rapid practical impact of data-driven polymer discovery. To expedite lab-scale validation and beyond, we present a retrosynthetic framework that leverages large language models (LLMs) to guide polymer synthesis. Our approach, which we call polyRETRO, involves two key steps: 1) predicting the most likely polymerization reaction class of a target polymer and 2) identifying the underlying chemical transformation templates and the corresponding monomers, using primarily natural-language based constructs. This LLM-driven framework enables direct retrosynthetic analysis given just the target polymer SMILES string. polyRETRO constitutes a initial step towards a scalable, interpretable, and generalizable approach to bridge the gap between computational design and experimental synthesis. [SEP] [HINT] based -> Bioinformatics (Syns: ground, free-base, base) | language -> Neuroscience (Syns: linguistic process, linguistic communication, spoken communication) | computational -> Neuroscience (Syns: )",Materials Science
"Background: Coordinated control of eye and hand movements is critical for nearly all goal-directed actions, underpinning tasks ranging from simple object manipulation to complex tool use. This coordination relies on temporal coupling between reach and saccade. Stroke disrupts this process at several levels. Methods: We conducted a comparative eye-tracking study on patients with history of stroke vs. control performing various tasks. We used the Kinereach motion-tracking system with integrated eye-tracking functionality for data collection. Results: Stroke participants showed a flat distribution of saccade timing, with no clear peak or alignment to the onset of the reach. In terms of spatial performance, reach gain, the primary index of functional accuracy, revealed that stroke participants reaches were significantly hypometric compared to those of controls. In the segmented look-then-reach condition, stroke participants demonstrated a restoration of a unimodal saccade timing distribution, time-locked to the saccade cue. Conclusion: Our findings highlight a dissociation between motor execution and coordination in stroke, emphasizing that intact movement components do not guarantee intact motor integration. By identifying a reversible, cue-sensitive disruption in saccade timing linked specifically to its coordination within a reaching movement, this work points toward new opportunities for rehabilitation aimed not only at motor strength and speed, but at training and re-establishing the natural temporal structure of action.",Neuroscience
"Background: Coordinated control of eye and hand movements is critical for nearly all goal-directed actions, underpinning tasks ranging from simple object manipulation to complex tool use. This coordination relies on temporal coupling between reach and saccade. Stroke disrupts this process at several levels. Methods: We conducted a comparative eye-tracking study on patients with history of stroke vs. control performing various tasks. We used the Kinereach motion-tracking system with integrated eye-tracking functionality for data collection. Results: Stroke participants showed a flat distribution of saccade timing, with no clear peak or alignment to the onset of the reach. In terms of spatial performance, reach gain, the primary index of functional accuracy, revealed that stroke participants reaches were significantly hypometric compared to those of controls. In the segmented look-then-reach condition, stroke participants demonstrated a restoration of a unimodal saccade timing distribution, time-locked to the saccade cue. Conclusion: Our findings highlight a dissociation between motor execution and coordination in stroke, emphasizing that intact movement components do not guarantee intact motor integration. By identifying a reversible, cue-sensitive disruption in saccade timing linked specifically to its coordination within a reaching movement, this work points toward new opportunities for rehabilitation aimed not only at motor strength and speed, but at training and re-establishing the natural temporal structure of action. [SEP] [HINT] used -> Bioinformatics (Syns: utilize, ill-used, apply) | tasks -> Neuroscience (Syns: tax, task, project) | functional -> Neuroscience (Syns: working, usable, running)",Neuroscience
"Fast, and accurate prediction of ionic migration barriers ($E_m$) is crucial for designing next-generation battery materials that combine high energy density with facile ion transport. Given the computational costs associated with estimating $E_m$ using conventional density functional theory (DFT) based nudged elastic band (NEB) calculations, we benchmark the accuracy in $E_m$ and geometry predictions of five foundational machine learned interatomic potentials (MLIPs), which can potentially accelerate predictions of ionic transport. Specifically, we assess the accuracy of MACE-MP-0, Orb-v3, SevenNet, CHGNet, and M3GNet models, coupled with the NEB framework, against DFT-NEB-calculated $E_m$ across a diverse set of battery-relevant chemistries and structures. Notably, MACE-MP-0 and Orb-v3 exhibit the lowest mean absolute errors in $E_m$ predictions across the entire dataset and over data points that are not outliers, respectively. Importantly, Orb-v3 and SevenNet classify `good' versus `bad' ionic conductors with an accuracy of $>$82\%, based on a threshold $E_m$ of 500~meV, indicating their utility in high-throughput screening approaches. Notably, intermediate images generated by MACE-MP-0 and SevenNet provide better initial guesses relative to conventional interpolation techniques in $>$71\% of structures, offering a practical route to accelerate subsequent DFT-NEB relaxations. Finally, we observe that accurate $E_m$ predictions by MLIPs are not correlated with accurate (local) geometry predictions. Our work establishes the use-cases, accuracies, and limitations of foundational MLIPs in estimating $E_m$ and should serve as a base for accelerating the discovery of novel ionic conductors for batteries and beyond.",Materials Science
"Fast, and accurate prediction of ionic migration barriers ($E_m$) is crucial for designing next-generation battery materials that combine high energy density with facile ion transport. Given the computational costs associated with estimating $E_m$ using conventional density functional theory (DFT) based nudged elastic band (NEB) calculations, we benchmark the accuracy in $E_m$ and geometry predictions of five foundational machine learned interatomic potentials (MLIPs), which can potentially accelerate predictions of ionic transport. Specifically, we assess the accuracy of MACE-MP-0, Orb-v3, SevenNet, CHGNet, and M3GNet models, coupled with the NEB framework, against DFT-NEB-calculated $E_m$ across a diverse set of battery-relevant chemistries and structures. Notably, MACE-MP-0 and Orb-v3 exhibit the lowest mean absolute errors in $E_m$ predictions across the entire dataset and over data points that are not outliers, respectively. Importantly, Orb-v3 and SevenNet classify `good' versus `bad' ionic conductors with an accuracy of $>$82\%, based on a threshold $E_m$ of 500~meV, indicating their utility in high-throughput screening approaches. Notably, intermediate images generated by MACE-MP-0 and SevenNet provide better initial guesses relative to conventional interpolation techniques in $>$71\% of structures, offering a practical route to accelerate subsequent DFT-NEB relaxations. Finally, we observe that accurate $E_m$ predictions by MLIPs are not correlated with accurate (local) geometry predictions. Our work establishes the use-cases, accuracies, and limitations of foundational MLIPs in estimating $E_m$ and should serve as a base for accelerating the discovery of novel ionic conductors for batteries and beyond. [SEP] [HINT] based -> Bioinformatics (Syns: ground, free-base, base) | computational -> Neuroscience (Syns: ) | functional -> Neuroscience (Syns: working, usable, running)",Materials Science
"We develop a microscopic theory of magnon-exciton drag effect in a bilayer van der Waals antiferromagnetic semiconductor CrSBr. Effective exciton-magnon coupling arises from an orbital mechanism: Magnons tilt the layer magnetizations, enabling charge carrier tunneling that mixes intra- and interlayer excitons and thereby modulate the exciton energy. We derive the effective Hamiltonian of exciton-magnon coupling, based on our calculation of the magnon spectrum taking into account short-range exchange interaction between Cr-ion spins, single-ion anisotropy, and long-range dipole-dipole interactions. The latter produces a negative group velocity of magnons at small wavevectors. We show that despite rather small renormalization of exciton's energy and effective mass by the exciton-magnon interaction, the three key two-magnon processes: exciton-magnon scattering, two-magnon absorption by exciton, and two-magnon emission are highly efficient. By solving the Boltzmann kinetic equation, we evaluate short exciton-magnon scattering time which is in the sub-ps range and strongly decreases with the increase of magnon population. Hence, exciton-magnon scattering is likely to be dominant over other scattering processes related to the exciton-phonon and exciton-disorder interactions. We demonstrate that magnons can efficiently drag excitons, resulting in a large and nearly isotropic exciton propagation that can significantly exceed the intrinsic anisotropic diffusion. Our results provide a theoretical basis for recent observations of anomalous exciton transport in CrSBr [F. Dirnberger, et al., Nat. Nano. (2025)] and establish magnon-exciton drag as a powerful mechanism for controlling exciton propagation in magnetic systems.",Materials Science
"We develop a microscopic theory of magnon-exciton drag effect in a bilayer van der Waals antiferromagnetic semiconductor CrSBr. Effective exciton-magnon coupling arises from an orbital mechanism: Magnons tilt the layer magnetizations, enabling charge carrier tunneling that mixes intra- and interlayer excitons and thereby modulate the exciton energy. We derive the effective Hamiltonian of exciton-magnon coupling, based on our calculation of the magnon spectrum taking into account short-range exchange interaction between Cr-ion spins, single-ion anisotropy, and long-range dipole-dipole interactions. The latter produces a negative group velocity of magnons at small wavevectors. We show that despite rather small renormalization of exciton's energy and effective mass by the exciton-magnon interaction, the three key two-magnon processes: exciton-magnon scattering, two-magnon absorption by exciton, and two-magnon emission are highly efficient. By solving the Boltzmann kinetic equation, we evaluate short exciton-magnon scattering time which is in the sub-ps range and strongly decreases with the increase of magnon population. Hence, exciton-magnon scattering is likely to be dominant over other scattering processes related to the exciton-phonon and exciton-disorder interactions. We demonstrate that magnons can efficiently drag excitons, resulting in a large and nearly isotropic exciton propagation that can significantly exceed the intrinsic anisotropic diffusion. Our results provide a theoretical basis for recent observations of anomalous exciton transport in CrSBr [F. Dirnberger, et al., Nat. Nano. (2025)] and establish magnon-exciton drag as a powerful mechanism for controlling exciton propagation in magnetic systems. [SEP] [HINT] based -> Bioinformatics (Syns: ground, free-base, base) | transport -> Materials Science (Syns: transferral, enthral, shipping) | charge -> Materials Science (Syns: tear, bearing, burster)",Materials Science
"Generating whole-brain 4D fMRI sequences conditioned on cognitive tasks remains challenging due to the high-dimensional, heterogeneous BOLD dynamics across subjects/acquisitions and the lack of neuroscience-grounded validation. We introduce the first diffusion transformer for voxelwise 4D fMRI conditional generation, combining 3D VQ-GAN latent compression with a CNN-Transformer backbone and strong task conditioning via AdaLN-Zero and cross-attention. On HCP task fMRI, our model reproduces task-evoked activation maps, preserves the inter-task representational structure observed in real data (RSA), achieves perfect condition specificity, and aligns ROI time-courses with canonical hemodynamic responses. Performance improves predictably with scale, reaching task-evoked map correlation of 0.83 and RSA of 0.98, consistently surpassing a U-Net baseline on all metrics. By coupling latent diffusion with a scalable backbone and strong conditioning, this work establishes a practical path to conditional 4D fMRI synthesis, paving the way for future applications such as virtual experiments, cross-site harmonization, and principled augmentation for downstream neuroimaging models.",Neuroscience
"Generating whole-brain 4D fMRI sequences conditioned on cognitive tasks remains challenging due to the high-dimensional, heterogeneous BOLD dynamics across subjects/acquisitions and the lack of neuroscience-grounded validation. We introduce the first diffusion transformer for voxelwise 4D fMRI conditional generation, combining 3D VQ-GAN latent compression with a CNN-Transformer backbone and strong task conditioning via AdaLN-Zero and cross-attention. On HCP task fMRI, our model reproduces task-evoked activation maps, preserves the inter-task representational structure observed in real data (RSA), achieves perfect condition specificity, and aligns ROI time-courses with canonical hemodynamic responses. Performance improves predictably with scale, reaching task-evoked map correlation of 0.83 and RSA of 0.98, consistently surpassing a U-Net baseline on all metrics. By coupling latent diffusion with a scalable backbone and strong conditioning, this work establishes a practical path to conditional 4D fMRI synthesis, paving the way for future applications such as virtual experiments, cross-site harmonization, and principled augmentation for downstream neuroimaging models. [SEP] [HINT] task -> Neuroscience (Syns: tax, project, chore) | tasks -> Neuroscience (Syns: tax, task, project) | structure -> Bioinformatics (Syns: social system, complex body part, social structure)",Neuroscience
"This review provides an introduction to the essential physics of soft adhesion, including the thermodynamics of adhesion and wetting, the mechanics of contact with deformable materials, and the material properties that most affect interfacial interactions with soft solid gels and elastomers. Throughout, we emphasize both foundational physics and current experimental and theoretical research in these areas. We conclude with a practical overview of standard experimental test methods for characterizing soft adhesion. The physical understanding developed herein provides the basis for understanding the mechanics of contact with soft materials.",Materials Science
"This review provides an introduction to the essential physics of soft adhesion, including the thermodynamics of adhesion and wetting, the mechanics of contact with deformable materials, and the material properties that most affect interfacial interactions with soft solid gels and elastomers. Throughout, we emphasize both foundational physics and current experimental and theoretical research in these areas. We conclude with a practical overview of standard experimental test methods for characterizing soft adhesion. The physical understanding developed herein provides the basis for understanding the mechanics of contact with soft materials. [SEP] [HINT] material -> Materials Science (Syns: stuff, cloth, real) | experimental -> Materials Science (Syns: data-based, observational) | including -> Bioinformatics (Syns: admit, include, let in)",Materials Science
"Background: Upper-limb weakness and tremor (4--12 Hz) limit activities of daily living (ADL) and reduce adherence to home rehabilitation. Objective: To assess technical feasibility and clinician-relevant signals of a sensor-fused wearable targeting the triceps brachii and extensor pollicis brevis. Methods: A lightweight node integrates surface EMG (1 kHz), IMU (100--200 Hz), and flex/force sensors with on-device INT8 inference (Tiny 1D-CNN/Transformer) and a safety-bounded assist policy (angle/torque/jerk limits; stall/time-out). Healthy adults (n = 12) performed three ADL-like tasks. Primary outcomes: Tremor Index (TI), range of motion (ROM), repetitions (Reps min$^{-1}$). Secondary: EMG median-frequency slope (fatigue trend), closed-loop latency, session completion, and device-related adverse events. Analyses used subject-level paired medians with BCa 95\% CIs; exact Wilcoxon $p$-values are reported in the Results. Results: Assistance was associated with lower tremor prominence and improved task throughput: TI decreased by $-0.092$ (95\% CI [$-0.102$, $-0.079$]), ROM increased by $+12.65\%$ (95\% CI [$+8.43$, $+13.89$]), and Reps rose by $+2.99$ min$^{-1}$ (95\% CI [$+2.61$, $+3.35$]). Median on-device latency was 8.7 ms at a 100 Hz loop rate; all sessions were completed with no device-related adverse events. Conclusions: Multimodal sensing with low-latency, safety-bounded assistance produced improved movement quality (TI $\downarrow$) and throughput (ROM, Reps $\uparrow$) in a pilot technical-feasibility setting, supporting progression to IRB-approved patient studies. Trial registration: Not applicable (pilot non-clinical).",Neuroscience
"Background: Upper-limb weakness and tremor (4--12 Hz) limit activities of daily living (ADL) and reduce adherence to home rehabilitation. Objective: To assess technical feasibility and clinician-relevant signals of a sensor-fused wearable targeting the triceps brachii and extensor pollicis brevis. Methods: A lightweight node integrates surface EMG (1 kHz), IMU (100--200 Hz), and flex/force sensors with on-device INT8 inference (Tiny 1D-CNN/Transformer) and a safety-bounded assist policy (angle/torque/jerk limits; stall/time-out). Healthy adults (n = 12) performed three ADL-like tasks. Primary outcomes: Tremor Index (TI), range of motion (ROM), repetitions (Reps min$^{-1}$). Secondary: EMG median-frequency slope (fatigue trend), closed-loop latency, session completion, and device-related adverse events. Analyses used subject-level paired medians with BCa 95\% CIs; exact Wilcoxon $p$-values are reported in the Results. Results: Assistance was associated with lower tremor prominence and improved task throughput: TI decreased by $-0.092$ (95\% CI [$-0.102$, $-0.079$]), ROM increased by $+12.65\%$ (95\% CI [$+8.43$, $+13.89$]), and Reps rose by $+2.99$ min$^{-1}$ (95\% CI [$+2.61$, $+3.35$]). Median on-device latency was 8.7 ms at a 100 Hz loop rate; all sessions were completed with no device-related adverse events. Conclusions: Multimodal sensing with low-latency, safety-bounded assistance produced improved movement quality (TI $\downarrow$) and throughput (ROM, Reps $\uparrow$) in a pilot technical-feasibility setting, supporting progression to IRB-approved patient studies. Trial registration: Not applicable (pilot non-clinical). [SEP] [HINT] used -> Bioinformatics (Syns: utilize, ill-used, apply) | task -> Neuroscience (Syns: tax, project, chore) | quality -> Bioinformatics (Syns: lineament, tone, calibre)",Neuroscience
"Chemical pretrained models, sometimes referred to as foundation models, are receiving considerable interest for drug discovery applications. The general chemical knowledge extracted from self-supervised training has the potential to improve predictions for critical drug discovery endpoints, including on-target potency and ADMET properties. Multi-task learning has previously been successfully leveraged to improve predictive models. Here, we show that enabling multitasking in finetuning of chemical pretrained graph neural network models such as Kinetic GROVER Multi-Task (KERMT), an enhanced version of the GROVER model, and Knowledge-guided Pre-training of Graph Transformer (KGPT) significantly improves performance over non-pretrained graph neural network models. Surprisingly, we find that the performance improvement from finetuning KERMT in a multitask manner is most significant at larger data sizes. Additionally, we publish two multitask ADMET data splits to enable more accurate benchmarking of multitask deep learning methods for drug property prediction. Finally, we provide an accelerated implementation of the KERMT model on GitHub, unlocking large-scale pretraining, finetuning, and inference in industrial drug discovery workflows.",Bioinformatics
"Chemical pretrained models, sometimes referred to as foundation models, are receiving considerable interest for drug discovery applications. The general chemical knowledge extracted from self-supervised training has the potential to improve predictions for critical drug discovery endpoints, including on-target potency and ADMET properties. Multi-task learning has previously been successfully leveraged to improve predictive models. Here, we show that enabling multitasking in finetuning of chemical pretrained graph neural network models such as Kinetic GROVER Multi-Task (KERMT), an enhanced version of the GROVER model, and Knowledge-guided Pre-training of Graph Transformer (KGPT) significantly improves performance over non-pretrained graph neural network models. Surprisingly, we find that the performance improvement from finetuning KERMT in a multitask manner is most significant at larger data sizes. Additionally, we publish two multitask ADMET data splits to enable more accurate benchmarking of multitask deep learning methods for drug property prediction. Finally, we provide an accelerated implementation of the KERMT model on GitHub, unlocking large-scale pretraining, finetuning, and inference in industrial drug discovery workflows. [SEP] [HINT] learning -> Bioinformatics (Syns: take, teach, acquire) | performance -> Bioinformatics (Syns: functioning, operation, carrying out) | including -> Bioinformatics (Syns: admit, include, let in)",Bioinformatics
"High-resolution transmission electron microscopy (HRTEM) is crucial for observing material's structural and morphological evolution at Angstrom scales, but the electron beam can alter these processes. Devices such as CMOS-based direct-electron detectors operating in electron-counting mode can be utilized to substantially reduce the electron dosage. However, the resulting images often lead to low signal-to-noise ratio, which requires frame integration that sacrifices temporal resolution. Several machine learning (ML) models have been recently developed to successfully denoise HRTEM images. Yet, these models are often computationally expensive and their inference speeds on GPUs are outpaced by the imaging speed of advanced detectors, precluding in situ analysis. Furthermore, the performance of these denoising models on datasets with imaging conditions that deviate from the training datasets have not been evaluated. To mitigate these gaps, we propose a new self-supervised ML denoising pipeline specifically designed for time-series HRTEM images. This pipeline integrates a blind-spot convolution neural network with pre-processing and post-processing steps including drift correction and low-pass filtering. Results demonstrate that our model outperforms various other ML and non-ML denoising methods in noise reduction and contrast enhancement, leading to improved visual clarity of atomic features. Additionally, the model is drastically faster than U-Net-based ML models and demonstrates excellent out-of-distribution generalization. The model's computational inference speed is in the order of milliseconds per image, rendering it suitable for application in in-situ HRTEM experiments.",Materials Science
"High-resolution transmission electron microscopy (HRTEM) is crucial for observing material's structural and morphological evolution at Angstrom scales, but the electron beam can alter these processes. Devices such as CMOS-based direct-electron detectors operating in electron-counting mode can be utilized to substantially reduce the electron dosage. However, the resulting images often lead to low signal-to-noise ratio, which requires frame integration that sacrifices temporal resolution. Several machine learning (ML) models have been recently developed to successfully denoise HRTEM images. Yet, these models are often computationally expensive and their inference speeds on GPUs are outpaced by the imaging speed of advanced detectors, precluding in situ analysis. Furthermore, the performance of these denoising models on datasets with imaging conditions that deviate from the training datasets have not been evaluated. To mitigate these gaps, we propose a new self-supervised ML denoising pipeline specifically designed for time-series HRTEM images. This pipeline integrates a blind-spot convolution neural network with pre-processing and post-processing steps including drift correction and low-pass filtering. Results demonstrate that our model outperforms various other ML and non-ML denoising methods in noise reduction and contrast enhancement, leading to improved visual clarity of atomic features. Additionally, the model is drastically faster than U-Net-based ML models and demonstrates excellent out-of-distribution generalization. The model's computational inference speed is in the order of milliseconds per image, rendering it suitable for application in in-situ HRTEM experiments. [SEP] [HINT] low -> Materials Science (Syns: low-spirited, scurvy, depressed) | computational -> Neuroscience (Syns: ) | learning -> Bioinformatics (Syns: take, teach, acquire)",Materials Science
"Functional brain connectivity changes dynamically over time, making its representation challenging for learning on non-Euclidean data. We present a framework that encodes dynamic functional connectivity as an image representation of evolving network topology. Persistent graph homology summarizes global organization across scales, yielding Wasserstein distance-preserving embeddings stable under resolution changes. Stacking these embeddings forms a topological image that captures temporal reconfiguration of brain networks. This design enables convolutional architectures and transfer learning from pretrained foundational models to operate effectively under limited and imbalanced data. Applied to early Alzheimer's detection, the approach achieves clinically meaningful accuracy, establishing a principled foundation for imaging dynamic brain topology.",Neuroscience
"Functional brain connectivity changes dynamically over time, making its representation challenging for learning on non-Euclidean data. We present a framework that encodes dynamic functional connectivity as an image representation of evolving network topology. Persistent graph homology summarizes global organization across scales, yielding Wasserstein distance-preserving embeddings stable under resolution changes. Stacking these embeddings forms a topological image that captures temporal reconfiguration of brain networks. This design enables convolutional architectures and transfer learning from pretrained foundational models to operate effectively under limited and imbalanced data. Applied to early Alzheimer's detection, the approach achieves clinically meaningful accuracy, establishing a principled foundation for imaging dynamic brain topology. [SEP] [HINT] connectivity -> Neuroscience (Syns: ) | learning -> Bioinformatics (Syns: take, teach, acquire) | functional -> Neuroscience (Syns: working, usable, running)",Neuroscience
"Brain disorders are an umbrella term for a group of neurological and psychiatric conditions that have a major effect on thinking, feeling, and acting. These conditions encompass a wide range of conditions. The illnesses in question pose significant difficulties not only for individuals, but also for healthcare systems all across the world. In this study, we explore the capability of explainable machine learning for classification of people who suffer from brain disorders. This is accomplished by the utilization of brain connection map, also referred as connectome, derived from functional magnetic resonance imaging (fMRI) data. In order to analyze features that are based on the connectome, we investigated several different feature selection procedures. These strategies included the Least Absolute Shrinkage and Selection Operator (LASSO), Relief, and Analysis of Variance (ANOVA), in addition to a logistic regression (LR) classifier. First and foremost, the purpose was to evaluate and contrast the classification accuracy of different feature selection methods in terms of distinguishing healthy controls from diseased individuals. The evaluation of the stability of the traits that were chosen was the second objective. The identification of the regions of the brain that have an effect on the classification was the third main objective. When applied to the UCLA dataset, the LASSO approach, which is our most effective strategy, produced a classification accuracy of 91.85% and a stability index of 0.74, which is greater than the results obtained by other approaches: Relief and ANOVA. These methods are effective in locating trustworthy biomarkers, which adds to the development of connectome-based classification in the context of issues that impact the brain.",Neuroscience
"Brain disorders are an umbrella term for a group of neurological and psychiatric conditions that have a major effect on thinking, feeling, and acting. These conditions encompass a wide range of conditions. The illnesses in question pose significant difficulties not only for individuals, but also for healthcare systems all across the world. In this study, we explore the capability of explainable machine learning for classification of people who suffer from brain disorders. This is accomplished by the utilization of brain connection map, also referred as connectome, derived from functional magnetic resonance imaging (fMRI) data. In order to analyze features that are based on the connectome, we investigated several different feature selection procedures. These strategies included the Least Absolute Shrinkage and Selection Operator (LASSO), Relief, and Analysis of Variance (ANOVA), in addition to a logistic regression (LR) classifier. First and foremost, the purpose was to evaluate and contrast the classification accuracy of different feature selection methods in terms of distinguishing healthy controls from diseased individuals. The evaluation of the stability of the traits that were chosen was the second objective. The identification of the regions of the brain that have an effect on the classification was the third main objective. When applied to the UCLA dataset, the LASSO approach, which is our most effective strategy, produced a classification accuracy of 91.85% and a stability index of 0.74, which is greater than the results obtained by other approaches: Relief and ANOVA. These methods are effective in locating trustworthy biomarkers, which adds to the development of connectome-based classification in the context of issues that impact the brain. [SEP] [HINT] based -> Bioinformatics (Syns: ground, free-base, base) | features -> Bioinformatics (Syns: characteristic, lineament, feature of speech) | learning -> Bioinformatics (Syns: take, teach, acquire)",Neuroscience
"Seagrass meadows contribute to the conservation of marine ecosystems, reduction in global warming impacts and pathogen controls. However, the decline in seagrass habitats due to environmental loads has become an urgent global issue. One way to address this issue is to better understand healthy seagrass habitats. Here, we estimate the structural characteristics of symbiotic and metabolic systems in sediments from eight coastal regions of Japan, with each region containing both seagrass-covered areas and adjacent unvegetated areas. Notably, seagrasses commonly maintain a balanced symbiotic relationship characterized by a positive association with cable bacteria (Desulfobulbaceae), nitrogen-cycling bacteria (Hyphomonadaceae), and coral algae (Corallinophycidae) and a negative association with diatoms (Diatomea). Furthermore, seagrass growth conditions influence metabolic pathways by activating nitrogen-related metabolism while attenuating methanogenesis. Our findings highlight the crucial roles of marine plants and their symbiotic systems in ensuring environmental conservation within the context of blue carbon storage across environmental gradients.",Bioinformatics
"Seagrass meadows contribute to the conservation of marine ecosystems, reduction in global warming impacts and pathogen controls. However, the decline in seagrass habitats due to environmental loads has become an urgent global issue. One way to address this issue is to better understand healthy seagrass habitats. Here, we estimate the structural characteristics of symbiotic and metabolic systems in sediments from eight coastal regions of Japan, with each region containing both seagrass-covered areas and adjacent unvegetated areas. Notably, seagrasses commonly maintain a balanced symbiotic relationship characterized by a positive association with cable bacteria (Desulfobulbaceae), nitrogen-cycling bacteria (Hyphomonadaceae), and coral algae (Corallinophycidae) and a negative association with diatoms (Diatomea). Furthermore, seagrass growth conditions influence metabolic pathways by activating nitrogen-related metabolism while attenuating methanogenesis. Our findings highlight the crucial roles of marine plants and their symbiotic systems in ensuring environmental conservation within the context of blue carbon storage across environmental gradients. [SEP] [HINT] systems -> Bioinformatics (Syns: organization, organisation, system) | structural -> Materials Science (Syns: geomorphologic, morphologic, morphological) | findings -> Neuroscience (Syns: determination, finding)",Bioinformatics
"Perovskite-inspired materials have emerged as promising candidates for both outdoor and indoor photovoltaic applications owing to their favorable optoelectronic properties and reduced toxicity. Here, we employ the experimentally realized AgBiI$_4$ double salt as a structural prototype and replace Bi$^{3+}$ with In$^{3+}$ to design a novel lead-free halide compound, AgInI$_4$. First-principles calculations predict that AgInI$_4$ is both chemically and dynamically stable, exhibiting a direct band gap of 1.72 eV, comparable to its bismuth analogue. However, its predicted photovoltaic performance, evaluated using the spectroscopic limited maximum efficiency metric, is lower under both solar and LED illumination. This reduction arises primarily from symmetry-forbidden optical transitions and the absence of Bi-derived 6s$^2$ lone-pair states at the valence band maximum. High-throughput screening of the Ag-In-I ternary phase-space reveals several more stable and metastable compounds that fall into two structural families: tetrahedrally and octahedrally coordinated, with characteristic band gaps near 3.0 eV and 2.0 eV, respectively. Despite multiple synthetic attempts, the predicted AgInI$_4$ phase could not be experimentally realized, underscoring the challenges of stabilizing indium-based halide double salts. While these materials are unlikely to serve as efficient photovoltaic absorbers, their tunable band gaps and stability make them promising candidates for charge transport and other optoelectronic applications.",Materials Science
"Perovskite-inspired materials have emerged as promising candidates for both outdoor and indoor photovoltaic applications owing to their favorable optoelectronic properties and reduced toxicity. Here, we employ the experimentally realized AgBiI$_4$ double salt as a structural prototype and replace Bi$^{3+}$ with In$^{3+}$ to design a novel lead-free halide compound, AgInI$_4$. First-principles calculations predict that AgInI$_4$ is both chemically and dynamically stable, exhibiting a direct band gap of 1.72 eV, comparable to its bismuth analogue. However, its predicted photovoltaic performance, evaluated using the spectroscopic limited maximum efficiency metric, is lower under both solar and LED illumination. This reduction arises primarily from symmetry-forbidden optical transitions and the absence of Bi-derived 6s$^2$ lone-pair states at the valence band maximum. High-throughput screening of the Ag-In-I ternary phase-space reveals several more stable and metastable compounds that fall into two structural families: tetrahedrally and octahedrally coordinated, with characteristic band gaps near 3.0 eV and 2.0 eV, respectively. Despite multiple synthetic attempts, the predicted AgInI$_4$ phase could not be experimentally realized, underscoring the challenges of stabilizing indium-based halide double salts. While these materials are unlikely to serve as efficient photovoltaic absorbers, their tunable band gaps and stability make them promising candidates for charge transport and other optoelectronic applications. [SEP] [HINT] transport -> Materials Science (Syns: transferral, enthral, shipping) | charge -> Materials Science (Syns: tear, bearing, burster) | using -> Bioinformatics (Syns: utilize, exploitation, apply)",Materials Science
"A fundamental challenge in protein design is the trade-off between generating structural diversity while preserving motif biological function. Current state-of-the-art methods, such as partial diffusion in RFdiffusion, often fail to resolve this trade-off: small perturbations yield motifs nearly identical to the native structure, whereas larger perturbations violate the geometric constraints necessary for biological function. We introduce Protein Generation with Embedding Learning (PGEL), a general framework that learns high-dimensional embeddings encoding sequence and structural features of a target motif in the representation space of a diffusion model's frozen denoiser, and then enhances motif diversity by introducing controlled perturbations in the embedding space. PGEL is thus able to loosen geometric constraints while satisfying typical design metrics, leading to more diverse yet viable structures. We demonstrate PGEL on three representative cases: a monomer, a protein-protein interface, and a cancer-related transcription factor complex. In all cases, PGEL achieves greater structural diversity, better designability, and improved self-consistency, as compared to partial diffusion. Our results establish PGEL as a general strategy for embedding-driven protein generation allowing for systematic, viable diversification of functional motifs.",Bioinformatics
"A fundamental challenge in protein design is the trade-off between generating structural diversity while preserving motif biological function. Current state-of-the-art methods, such as partial diffusion in RFdiffusion, often fail to resolve this trade-off: small perturbations yield motifs nearly identical to the native structure, whereas larger perturbations violate the geometric constraints necessary for biological function. We introduce Protein Generation with Embedding Learning (PGEL), a general framework that learns high-dimensional embeddings encoding sequence and structural features of a target motif in the representation space of a diffusion model's frozen denoiser, and then enhances motif diversity by introducing controlled perturbations in the embedding space. PGEL is thus able to loosen geometric constraints while satisfying typical design metrics, leading to more diverse yet viable structures. We demonstrate PGEL on three representative cases: a monomer, a protein-protein interface, and a cancer-related transcription factor complex. In all cases, PGEL achieves greater structural diversity, better designability, and improved self-consistency, as compared to partial diffusion. Our results establish PGEL as a general strategy for embedding-driven protein generation allowing for systematic, viable diversification of functional motifs. [SEP] [HINT] features -> Bioinformatics (Syns: characteristic, lineament, feature of speech) | learning -> Bioinformatics (Syns: take, teach, acquire) | space -> Neuroscience (Syns: distance, place, outer space)",Bioinformatics
"Accurate temperature mapping at the nanoscale is a critical challenge in modern science and technology, as conventional methods fail at these dimensions. To address this challenge, we demonstrate a highly sensitive nanothermometer using anti-Stokes photoluminescence, also known as photoluminescence upconversion (UPL), in monolayer tungsten disulfide ($\mathrm{WS_2}$). Leveraging the direct band gap and strong exciton-phonon coupling in the two-dimensional monolayers, we achieve an exceptional relative sensitivity above $4\%\,\mathrm{K}^{-1}$ across the 300 K to 425 K range, ranking it among the best-performing materials reported. A strong resonantly enhanced UPL is observed, confirming the central role of optical phonons in the upconversion mechanism. Furthermore, we introduce a new analytical model to quantitatively describe the UPL process, taking into account the interplay of phonon populations, bandgap narrowing, and substrate effects, which predicts resonant temperatures and provides a framework with broad applicability to any material exhibiting an anti-Stokes photoluminescence response. To demonstrate its use as a high-resolution optical thermometer, we map a $20\,^{\circ}\mathrm{C}$ thermal gradient across a $20\,μ\mathrm{m}$ long monolayer with a spatial resolution of $1\,μ\mathrm{m}$. With its high sensitivity, strong signal, and excellent reproducibility, our work establishes monolayer transition metal dichalcogenide as a leading platform for non-invasive thermal sensing in advanced microelectronic and biological systems.",Materials Science
"Accurate temperature mapping at the nanoscale is a critical challenge in modern science and technology, as conventional methods fail at these dimensions. To address this challenge, we demonstrate a highly sensitive nanothermometer using anti-Stokes photoluminescence, also known as photoluminescence upconversion (UPL), in monolayer tungsten disulfide ($\mathrm{WS_2}$). Leveraging the direct band gap and strong exciton-phonon coupling in the two-dimensional monolayers, we achieve an exceptional relative sensitivity above $4\%\,\mathrm{K}^{-1}$ across the 300 K to 425 K range, ranking it among the best-performing materials reported. A strong resonantly enhanced UPL is observed, confirming the central role of optical phonons in the upconversion mechanism. Furthermore, we introduce a new analytical model to quantitatively describe the UPL process, taking into account the interplay of phonon populations, bandgap narrowing, and substrate effects, which predicts resonant temperatures and provides a framework with broad applicability to any material exhibiting an anti-Stokes photoluminescence response. To demonstrate its use as a high-resolution optical thermometer, we map a $20\,^{\circ}\mathrm{C}$ thermal gradient across a $20\,μ\mathrm{m}$ long monolayer with a spatial resolution of $1\,μ\mathrm{m}$. With its high sensitivity, strong signal, and excellent reproducibility, our work establishes monolayer transition metal dichalcogenide as a leading platform for non-invasive thermal sensing in advanced microelectronic and biological systems. [SEP] [HINT] transition -> Materials Science (Syns: passage, modulation, changeover) | phonon -> Materials Science (Syns: ) | work -> Bioinformatics (Syns: work out, process, bring)",Materials Science
"The cerebral cortex spontaneously displays different patterns of activity that evolve over time according to the brain state. Sleep, wakefulness, resting states, and attention are examples of a wide spectrum of physiological states that can be sustained by the same structural network. Furthermore, additional states are generated by drugs (e.g., different levels of anesthesia) or by pathological conditions (e.g., brain lesions, disorders of consciousness). While the significance of understanding brain states in relation to brain dynamics and behavior has become increasingly evident over the past two decades, a unified definition of brain states remains elusive. In this review, we focus on two extremes of this spectrum: synchronous versus asynchronous states. These functional states predominantly underlie unconsciousness and consciousness, respectively, although exceptions exist. Our aim is to integrate data from different levels into a multiscale understanding, ranging from local circuits to whole-brain dynamics, including properties such as cortical complexity, functional connectivity, synchronization, wave propagation, and excitatory-inhibitory balance that vary across states and characterize them. Experimental and clinical data, as well as computational models (at micro-, meso-, and macrocortical levels) associated with the discussed brain states, are made available to readers.",Neuroscience
"The cerebral cortex spontaneously displays different patterns of activity that evolve over time according to the brain state. Sleep, wakefulness, resting states, and attention are examples of a wide spectrum of physiological states that can be sustained by the same structural network. Furthermore, additional states are generated by drugs (e.g., different levels of anesthesia) or by pathological conditions (e.g., brain lesions, disorders of consciousness). While the significance of understanding brain states in relation to brain dynamics and behavior has become increasingly evident over the past two decades, a unified definition of brain states remains elusive. In this review, we focus on two extremes of this spectrum: synchronous versus asynchronous states. These functional states predominantly underlie unconsciousness and consciousness, respectively, although exceptions exist. Our aim is to integrate data from different levels into a multiscale understanding, ranging from local circuits to whole-brain dynamics, including properties such as cortical complexity, functional connectivity, synchronization, wave propagation, and excitatory-inhibitory balance that vary across states and characterize them. Experimental and clinical data, as well as computational models (at micro-, meso-, and macrocortical levels) associated with the discussed brain states, are made available to readers. [SEP] [HINT] clinical -> Bioinformatics (Syns: ) | computational -> Neuroscience (Syns: ) | understanding -> Neuroscience (Syns: savvy, intellect, sympathy)",Neuroscience
"High-resolution neural datasets enable foundation models for the next generation of brain-computer interfaces and neurological treatments. The community requires rigorous benchmarks to discriminate between competing modeling approaches, yet no standardized evaluation frameworks exist for intracranial EEG (iEEG) recordings. To address this gap, we present Neuroprobe: a suite of decoding tasks for studying multi-modal language processing in the brain. Unlike scalp EEG, intracranial EEG requires invasive surgery to implant electrodes that record neural activity directly from the brain with minimal signal distortion. Neuroprobe is built on the BrainTreebank dataset, which consists of 40 hours of iEEG recordings from 10 human subjects performing a naturalistic movie viewing task. Neuroprobe serves two critical functions. First, it is a mine from which neuroscience insights can be drawn. Its high temporal and spatial resolution allows researchers to systematically determine when and where computations for each aspect of language processing occur in the brain by measuring the decodability of each feature across time and all electrode locations. Using Neuroprobe, we visualize how information flows from the superior temporal gyrus to the prefrontal cortex, and the progression from simple auditory features to more complex language features in a purely data-driven manner. Second, as the field moves toward neural foundation models, Neuroprobe provides a rigorous framework for comparing competing architectures and training protocols. We found that the linear baseline is surprisingly strong, beating frontier foundation models on many tasks. Neuroprobe is designed with computational efficiency and ease of use in mind. We make the code for Neuroprobe openly available and maintain a public leaderboard, aiming to enable rapid progress in the field of iEEG foundation models, at https://neuroprobe.dev/",Neuroscience
"High-resolution neural datasets enable foundation models for the next generation of brain-computer interfaces and neurological treatments. The community requires rigorous benchmarks to discriminate between competing modeling approaches, yet no standardized evaluation frameworks exist for intracranial EEG (iEEG) recordings. To address this gap, we present Neuroprobe: a suite of decoding tasks for studying multi-modal language processing in the brain. Unlike scalp EEG, intracranial EEG requires invasive surgery to implant electrodes that record neural activity directly from the brain with minimal signal distortion. Neuroprobe is built on the BrainTreebank dataset, which consists of 40 hours of iEEG recordings from 10 human subjects performing a naturalistic movie viewing task. Neuroprobe serves two critical functions. First, it is a mine from which neuroscience insights can be drawn. Its high temporal and spatial resolution allows researchers to systematically determine when and where computations for each aspect of language processing occur in the brain by measuring the decodability of each feature across time and all electrode locations. Using Neuroprobe, we visualize how information flows from the superior temporal gyrus to the prefrontal cortex, and the progression from simple auditory features to more complex language features in a purely data-driven manner. Second, as the field moves toward neural foundation models, Neuroprobe provides a rigorous framework for comparing competing architectures and training protocols. We found that the linear baseline is surprisingly strong, beating frontier foundation models on many tasks. Neuroprobe is designed with computational efficiency and ease of use in mind. We make the code for Neuroprobe openly available and maintain a public leaderboard, aiming to enable rapid progress in the field of iEEG foundation models, at https://neuroprobe.dev/ [SEP] [HINT] field -> Materials Science (Syns: field of honor, line of business, orbit) | decoding -> Neuroscience (Syns: decrypt, decipherment, decryption) | tasks -> Neuroscience (Syns: tax, task, project)",Neuroscience
"Neurons in cortical areas often integrate signals from different origins. In the primary visual cortex (V1), neural responses are modulated by non-visual context such as the animal's position. However, the spatial profile of these position signals across the environment remains unknown. Here, we propose a new framework to disentangle visual and spatial contributions in virtual reality. This method relies on two principles: 1) a virtual corridor design that decorrelates vision and space through targeted cue repetitions and manipulations and 2) a Generalized Linear Model (GLM) that explicitly estimates visual contributions in retinotopic rather than environmental coordinates. In simulations, we demonstrate that this framework is highly specific (recovering spatial modulation only when present) and effectively captures the profile and weight of spatial gain fields across the environment. When applied to V1 recordings from mice navigating the virtual corridor, the model isolated significant spatial components in a substantial fraction of V1 neurons. The recovered spatial components exhibited heterogeneous, often multi-peaked, profiles. Application of this framework to large-scale recordings may provide a robust approach to characterize the nature of spatial signals modulating sensory processing across brain areas.",Neuroscience
"Neurons in cortical areas often integrate signals from different origins. In the primary visual cortex (V1), neural responses are modulated by non-visual context such as the animal's position. However, the spatial profile of these position signals across the environment remains unknown. Here, we propose a new framework to disentangle visual and spatial contributions in virtual reality. This method relies on two principles: 1) a virtual corridor design that decorrelates vision and space through targeted cue repetitions and manipulations and 2) a Generalized Linear Model (GLM) that explicitly estimates visual contributions in retinotopic rather than environmental coordinates. In simulations, we demonstrate that this framework is highly specific (recovering spatial modulation only when present) and effectively captures the profile and weight of spatial gain fields across the environment. When applied to V1 recordings from mice navigating the virtual corridor, the model isolated significant spatial components in a substantial fraction of V1 neurons. The recovered spatial components exhibited heterogeneous, often multi-peaked, profiles. Application of this framework to large-scale recordings may provide a robust approach to characterize the nature of spatial signals modulating sensory processing across brain areas. [SEP] [HINT] cortical -> Neuroscience (Syns: ) | space -> Neuroscience (Syns: distance, place, outer space) | processing -> Neuroscience (Syns: work, process, march)",Neuroscience
"Despite the general assumption that completely locked-in state (CLIS) patients remain conscious and aware of their environment, the effectiveness of brain-computer interfaces (BCIs) in facilitating communication has been limited, as reported both in the literature and in our own findings. This limitation is likely attributable to impairments in executive functions, working memory, and vigilance, which appear to hinder the establishment of reliable BCI-based communication. The main goal of this research is to develop a neurophysiological report designed to support the evaluation of the cognitive state of these individuals and determine their ability to interact with BCIs. To achieve this, we designed a set of paradigms to assess CLIS patients at the reflexive and perceptual levels, based on neural responses associated with sensory and perceptual processing, including Mismatch Negativity (MMN), Steady State Auditory Evoked Potential (SSAEP), and Steady State Visual Evoked Potential (SSVEP). Pilot testing with five healthy participants demonstrates the feasibility of generating a neurophysiological report for cognitive assessment at both levels.",Neuroscience
"Despite the general assumption that completely locked-in state (CLIS) patients remain conscious and aware of their environment, the effectiveness of brain-computer interfaces (BCIs) in facilitating communication has been limited, as reported both in the literature and in our own findings. This limitation is likely attributable to impairments in executive functions, working memory, and vigilance, which appear to hinder the establishment of reliable BCI-based communication. The main goal of this research is to develop a neurophysiological report designed to support the evaluation of the cognitive state of these individuals and determine their ability to interact with BCIs. To achieve this, we designed a set of paradigms to assess CLIS patients at the reflexive and perceptual levels, based on neural responses associated with sensory and perceptual processing, including Mismatch Negativity (MMN), Steady State Auditory Evoked Potential (SSAEP), and Steady State Visual Evoked Potential (SSVEP). Pilot testing with five healthy participants demonstrates the feasibility of generating a neurophysiological report for cognitive assessment at both levels. [SEP] [HINT] based -> Bioinformatics (Syns: ground, free-base, base) | including -> Bioinformatics (Syns: admit, include, let in) | visual -> Neuroscience (Syns: optical, ocular, optic)",Neuroscience
"Entangled structures such as textiles, polymer networks, and architected metamaterials are often doubly periodic. Due to this property and their finite transverse thickness, the symmetries of these materials are described by the crystallographic layer groups. While orbifold notation provides a compact topological description and classification of the planar wallpaper groups, no analogous framework has been available for the spatial layer groups. In this article we develop an orbifold theory in three dimensions and introduce a complete set of Conway-type symbols for all layer groups. To illustrate its applicability, we analyze several knitted fabric motifs and show how their layer-group symmetries are naturally expressed in this new orbifold notation. This work establishes a foundation for the topological classification of doubly periodic structures beyond the planar setting and supports structure-function analysis in layered materials.",Materials Science
"Entangled structures such as textiles, polymer networks, and architected metamaterials are often doubly periodic. Due to this property and their finite transverse thickness, the symmetries of these materials are described by the crystallographic layer groups. While orbifold notation provides a compact topological description and classification of the planar wallpaper groups, no analogous framework has been available for the spatial layer groups. In this article we develop an orbifold theory in three dimensions and introduce a complete set of Conway-type symbols for all layer groups. To illustrate its applicability, we analyze several knitted fabric motifs and show how their layer-group symmetries are naturally expressed in this new orbifold notation. This work establishes a foundation for the topological classification of doubly periodic structures beyond the planar setting and supports structure-function analysis in layered materials. [SEP] [HINT] work -> Bioinformatics (Syns: work out, process, bring) | framework -> Bioinformatics (Syns: theoretical account, model, fabric) | theory -> Materials Science (Syns: possibility, hypothesis)",Materials Science
"Personalized oncology aims to tailor treatment strategies to the unique molecular and clinical profiles of individual patients, moving beyond the traditional paradigm of treating the disease not the patient. Achieving this vision requires the integration and interpretation of vast, heterogeneous biomedical data within a meaningful scientific framework. Knowledge graphs, structured according to biomedical ontologies, offer a powerful approach to contextualize and interconnect diverse datasets, enabling more precise and informed clinical decision-making.   We present ECKO (Explainable Clinical Knowledge for Oncology), a comprehensive knowledge graph that integrates 33 biomedical ontologies and aggregates data from multiple studies to create a unified resource optimized for data-driven clinical applications in oncology. Designed to support personalized drug recommendations, ECKO facilitates the identification of optimal therapeutic options by linking patient-specific molecular data to relevant pharmacological knowledge. It provides transparent, interpretable explanations for drug recommendations, fostering greater trust and understanding among clinicians and researchers. This resource represents a significant advancement toward explainable, scalable, and clinically actionable personalized medicine in oncology, with potential applications in biomarker discovery, treatment optimization, and translational research.",Bioinformatics
"Personalized oncology aims to tailor treatment strategies to the unique molecular and clinical profiles of individual patients, moving beyond the traditional paradigm of treating the disease not the patient. Achieving this vision requires the integration and interpretation of vast, heterogeneous biomedical data within a meaningful scientific framework. Knowledge graphs, structured according to biomedical ontologies, offer a powerful approach to contextualize and interconnect diverse datasets, enabling more precise and informed clinical decision-making.   We present ECKO (Explainable Clinical Knowledge for Oncology), a comprehensive knowledge graph that integrates 33 biomedical ontologies and aggregates data from multiple studies to create a unified resource optimized for data-driven clinical applications in oncology. Designed to support personalized drug recommendations, ECKO facilitates the identification of optimal therapeutic options by linking patient-specific molecular data to relevant pharmacological knowledge. It provides transparent, interpretable explanations for drug recommendations, fostering greater trust and understanding among clinicians and researchers. This resource represents a significant advancement toward explainable, scalable, and clinically actionable personalized medicine in oncology, with potential applications in biomarker discovery, treatment optimization, and translational research. [SEP] [HINT] clinical -> Bioinformatics (Syns: ) | understanding -> Neuroscience (Syns: savvy, intellect, sympathy) | molecular -> Bioinformatics (Syns: )",Bioinformatics
"Altermagnets and fully-compensated ferrimagnets are two canonical classes of zero-net-moment magnets. An altermagnetic (AM) half-metal cannot exist due to its AM spin splitting, while a fully-compensated ferrimagnetic (FC-FIM) metal seems impossible to realize because both spin channels remain gapless. Here, we propose that an FC-FIM metal can be realized by breaking the rotational or mirror symmetry that links two spin-opposite magnetic atoms in an AM metal. We further demonstrate that charge-carrier doping is fundamentally unable to generate a net magnetic moment in an altermagnet, whereas such a net moment can be readily induced in a fully-compensated ferrimagnet. We use the AM monolayer $\mathrm{Cr_2O}$ as a concrete example to validate our proposal. Either electric field or uniaxial strain can break the $S_{4z}$ symmetry of $\mathrm{Cr_2O}$, thereby inducing a transition from an AM metal to an FC-FIM metal. Uniaxial strain plus carrier doping creates a net moment in an altermagnet, and the so-called piezomagnetism is essentially a strain-driven switch from altermagnetism to fully-compensated ferrimagnetism. By analogy, we advance the concept of electromagnetism: an electric field drives the transition from altermagnetism to fully-compensated ferrimagnetism, and subsequent charge-carrier doping stabilizes a net magnetization. Our work provides a roadmap for further exploring the connection and distinction between altermagnet and fully-compensated ferrimagnet, and confirms the feasibility of FC-FIM metal.",Materials Science
"Altermagnets and fully-compensated ferrimagnets are two canonical classes of zero-net-moment magnets. An altermagnetic (AM) half-metal cannot exist due to its AM spin splitting, while a fully-compensated ferrimagnetic (FC-FIM) metal seems impossible to realize because both spin channels remain gapless. Here, we propose that an FC-FIM metal can be realized by breaking the rotational or mirror symmetry that links two spin-opposite magnetic atoms in an AM metal. We further demonstrate that charge-carrier doping is fundamentally unable to generate a net magnetic moment in an altermagnet, whereas such a net moment can be readily induced in a fully-compensated ferrimagnet. We use the AM monolayer $\mathrm{Cr_2O}$ as a concrete example to validate our proposal. Either electric field or uniaxial strain can break the $S_{4z}$ symmetry of $\mathrm{Cr_2O}$, thereby inducing a transition from an AM metal to an FC-FIM metal. Uniaxial strain plus carrier doping creates a net moment in an altermagnet, and the so-called piezomagnetism is essentially a strain-driven switch from altermagnetism to fully-compensated ferrimagnetism. By analogy, we advance the concept of electromagnetism: an electric field drives the transition from altermagnetism to fully-compensated ferrimagnetism, and subsequent charge-carrier doping stabilizes a net magnetization. Our work provides a roadmap for further exploring the connection and distinction between altermagnet and fully-compensated ferrimagnet, and confirms the feasibility of FC-FIM metal. [SEP] [HINT] field -> Materials Science (Syns: field of honor, line of business, orbit) | transition -> Materials Science (Syns: passage, modulation, changeover) | spin -> Materials Science (Syns: twisting, whirl, tailspin)",Materials Science
"Non-ordinary states of consciousness (NOC) provide an opportunity to experience highly intense, unique, and perceptually rich subjective states. The neural mechanisms supporting these experiences remain poorly understood. This study examined brain activity associated with a self-induced, substance-free NOC known as Auto-Induced Cognitive Trance (AICT). Twenty-seven trained participants underwent high-density electroencephalography (EEG) recordings during rest and AICT. We analyzed the aperiodic component of the power spectrum (1/f), Lempel-Ziv complexity, and sample entropy from five-minute signal segments. A machine learning approach was used to classify rest and AICT, identify discriminative features, and localize their sources. We also compared EEG metrics across conditions and assessed whether baseline activity predicted the magnitude of change during AICT. Classification analyses revealed condition-specific differences in spectral exponents, complexity, and entropy. The aperiodic component showed the strongest discriminative power, followed by entropy and complexity. Source localization highlighted frontal regions, the posterior cingulate cortex, and the left parietal cortex as key contributors to the AICT state. Baseline neural activity in frontal and parietal regions predicted individual variability in the transition from rest to AICT. These findings indicate that AICT engages brain regions implicated in rich subjective experiences and provide mechanistic insights into how self-induced trance states influence neural functioning.",Neuroscience
"Non-ordinary states of consciousness (NOC) provide an opportunity to experience highly intense, unique, and perceptually rich subjective states. The neural mechanisms supporting these experiences remain poorly understood. This study examined brain activity associated with a self-induced, substance-free NOC known as Auto-Induced Cognitive Trance (AICT). Twenty-seven trained participants underwent high-density electroencephalography (EEG) recordings during rest and AICT. We analyzed the aperiodic component of the power spectrum (1/f), Lempel-Ziv complexity, and sample entropy from five-minute signal segments. A machine learning approach was used to classify rest and AICT, identify discriminative features, and localize their sources. We also compared EEG metrics across conditions and assessed whether baseline activity predicted the magnitude of change during AICT. Classification analyses revealed condition-specific differences in spectral exponents, complexity, and entropy. The aperiodic component showed the strongest discriminative power, followed by entropy and complexity. Source localization highlighted frontal regions, the posterior cingulate cortex, and the left parietal cortex as key contributors to the AICT state. Baseline neural activity in frontal and parietal regions predicted individual variability in the transition from rest to AICT. These findings indicate that AICT engages brain regions implicated in rich subjective experiences and provide mechanistic insights into how self-induced trance states influence neural functioning. [SEP] [HINT] used -> Bioinformatics (Syns: utilize, ill-used, apply) | transition -> Materials Science (Syns: passage, modulation, changeover) | learning -> Bioinformatics (Syns: take, teach, acquire)",Neuroscience
"The development of multicellular organisms entails a deep connection between time-dependent biochemical processes taking place at the subcellular level, and the resulting macroscopic phenotypes that arise in populations of up to trillions of cells. A statistical mechanics of developmental processes would help to understand how microscopic genotypes map onto macroscopic phenotypes, a general goal across biology. Here we follow this approach, hypothesizing that development should be understood as a thermodynamic transition between non-equilibrium states. We test this hypothesis in the context of the fruit fly, Drosophila melanogaster, a model organism used widely in genetics and developmental biology for over a century. Applying a variety of information-theoretic measures to public transcriptomics datasets of whole fly embryos during development, we show that the global temporal dynamics of gene expression can be understood as a process that probabilistically guides embryonic dynamics across macroscopic phenotypic stages. In particular, we demonstrate signatures of irreversibility in the information complexity of transcriptomic dynamics, as measured mainly by the permutation entropy of indexed ensembles (PI entropy). Our results show that the dynamics of PI entropy correlate strongly with developmental stages. Overall, this is a test case in applying information complexity analysis to relate the statistical mechanics of biomarkers to macroscopic developmental dynamics.",Bioinformatics
"The development of multicellular organisms entails a deep connection between time-dependent biochemical processes taking place at the subcellular level, and the resulting macroscopic phenotypes that arise in populations of up to trillions of cells. A statistical mechanics of developmental processes would help to understand how microscopic genotypes map onto macroscopic phenotypes, a general goal across biology. Here we follow this approach, hypothesizing that development should be understood as a thermodynamic transition between non-equilibrium states. We test this hypothesis in the context of the fruit fly, Drosophila melanogaster, a model organism used widely in genetics and developmental biology for over a century. Applying a variety of information-theoretic measures to public transcriptomics datasets of whole fly embryos during development, we show that the global temporal dynamics of gene expression can be understood as a process that probabilistically guides embryonic dynamics across macroscopic phenotypic stages. In particular, we demonstrate signatures of irreversibility in the information complexity of transcriptomic dynamics, as measured mainly by the permutation entropy of indexed ensembles (PI entropy). Our results show that the dynamics of PI entropy correlate strongly with developmental stages. Overall, this is a test case in applying information complexity analysis to relate the statistical mechanics of biomarkers to macroscopic developmental dynamics. [SEP] [HINT] used -> Bioinformatics (Syns: utilize, ill-used, apply) | transition -> Materials Science (Syns: passage, modulation, changeover) | information -> Bioinformatics (Syns: entropy, data, info)",Bioinformatics
"Motor adaptation is a learning process that enables humans to regain proficiency when sensorimotor conditions are sustainably altered. Many studies have documented the properties of motor adaptation, yet the underlying mechanisms of motor adaptation remain imperfectly understood. In this study, we propose a computational analysis of adaptation to a visuomotor rotation task and examine it through an experiment. Our analysis suggests that two distinct processes contribute to produce adaptation: one which straightens trajectories, and another which redirects trajectories. We designed a visuomotor rotation task in a 3D virtual environment where human participants performed a pointing task using a head-mounted display controller represented by a cursor that was visually rotated by an angular deviation relative to its actual position. We observed that: (1) the trajectories were initially curved and misdirected, and became straighter and better directed with learning; (2) the straightening process occurred faster than the redirection process. These findings are consistent with our computational analysis and disclose a new and different perspective on motor adaptation.",Neuroscience
"Motor adaptation is a learning process that enables humans to regain proficiency when sensorimotor conditions are sustainably altered. Many studies have documented the properties of motor adaptation, yet the underlying mechanisms of motor adaptation remain imperfectly understood. In this study, we propose a computational analysis of adaptation to a visuomotor rotation task and examine it through an experiment. Our analysis suggests that two distinct processes contribute to produce adaptation: one which straightens trajectories, and another which redirects trajectories. We designed a visuomotor rotation task in a 3D virtual environment where human participants performed a pointing task using a head-mounted display controller represented by a cursor that was visually rotated by an angular deviation relative to its actual position. We observed that: (1) the trajectories were initially curved and misdirected, and became straighter and better directed with learning; (2) the straightening process occurred faster than the redirection process. These findings are consistent with our computational analysis and disclose a new and different perspective on motor adaptation. [SEP] [HINT] task -> Neuroscience (Syns: tax, project, chore) | computational -> Neuroscience (Syns: ) | learning -> Bioinformatics (Syns: take, teach, acquire)",Neuroscience
"We propose a framework for constructing combinatorial complexes (CCs) from fMRI time series data that captures both pairwise and higher-order neural interactions through information-theoretic measures, bridging topological deep learning and network neuroscience. Current graph-based representations of brain networks systematically miss the higher-order dependencies that characterize neural complexity, where information processing often involves synergistic interactions that cannot be decomposed into pairwise relationships. Unlike topological lifting approaches that map relational structures into higher-order domains, our method directly constructs CCs from statistical dependencies in the data. Our CCs generalize graphs by incorporating higher-order cells that represent collective dependencies among brain regions, naturally accommodating the multi-scale, hierarchical nature of neural processing. The framework constructs data-driven combinatorial complexes using O-information and S-information measures computed from fMRI signals, preserving both pairwise connections and higher-order cells (e.g., triplets, quadruplets) based on synergistic dependencies. Using NetSim simulations as a controlled proof-of-concept dataset, we demonstrate our CC construction pipeline and show how both pairwise and higher-order dependencies in neural time series can be quantified and represented within a unified structure. This work provides a framework for brain network representation that preserves fundamental higher-order structure invisible to traditional graph methods, and enables the application of topological deep learning (TDL) architectures to neural data.",Neuroscience
"We propose a framework for constructing combinatorial complexes (CCs) from fMRI time series data that captures both pairwise and higher-order neural interactions through information-theoretic measures, bridging topological deep learning and network neuroscience. Current graph-based representations of brain networks systematically miss the higher-order dependencies that characterize neural complexity, where information processing often involves synergistic interactions that cannot be decomposed into pairwise relationships. Unlike topological lifting approaches that map relational structures into higher-order domains, our method directly constructs CCs from statistical dependencies in the data. Our CCs generalize graphs by incorporating higher-order cells that represent collective dependencies among brain regions, naturally accommodating the multi-scale, hierarchical nature of neural processing. The framework constructs data-driven combinatorial complexes using O-information and S-information measures computed from fMRI signals, preserving both pairwise connections and higher-order cells (e.g., triplets, quadruplets) based on synergistic dependencies. Using NetSim simulations as a controlled proof-of-concept dataset, we demonstrate our CC construction pipeline and show how both pairwise and higher-order dependencies in neural time series can be quantified and represented within a unified structure. This work provides a framework for brain network representation that preserves fundamental higher-order structure invisible to traditional graph methods, and enables the application of topological deep learning (TDL) architectures to neural data. [SEP] [HINT] based -> Bioinformatics (Syns: ground, free-base, base) | learning -> Bioinformatics (Syns: take, teach, acquire) | networks -> Neuroscience (Syns: network, meshwork, electronic network)",Neuroscience
"Transition metal dichalcogenides (TMDs) have emerged as a promising class of materials for spintronics, with the aim of promoting efficient spin-charge conversion (SCC) in TMD/ferromagnet (FM)-based devices. The MoTe$_2$ semimetal with distorted orthorhombic crystal structure in the 1T$'$ phase has gathered particular attention due to its high spin-orbit coupling and reconfigurability as a type-II Weyl semimetal close to room temperature. Here, we report on the role of chemically grown 1T$'$-MoTe$_2$ thin films in inducing SCC in 1T$'$-MoTe$_2$/FM heterostructures as measured at room temperature. Ferromagnetic resonance (FMR) and electrically detected spin-pumping FMR measurements performed on 1T$'$-MoTe$_2$/Co/Au and 1T$'$-MoTe$_2$/Au/Co/Au heterostructures reveal a spin-mixing conductance value of up to $\sim1.6 \times 10^{20}~\mathrm{m^{-2}}$ and a spin Hall angle of $1.7\%$. These findings position MoTe$_2$ thin films as a competitive spin-charge conversion option compared to other functional materials (e.g., heavy metals, topological insulators), highlighting their potential for future applications in spintronic devices.",Materials Science
"Transition metal dichalcogenides (TMDs) have emerged as a promising class of materials for spintronics, with the aim of promoting efficient spin-charge conversion (SCC) in TMD/ferromagnet (FM)-based devices. The MoTe$_2$ semimetal with distorted orthorhombic crystal structure in the 1T$'$ phase has gathered particular attention due to its high spin-orbit coupling and reconfigurability as a type-II Weyl semimetal close to room temperature. Here, we report on the role of chemically grown 1T$'$-MoTe$_2$ thin films in inducing SCC in 1T$'$-MoTe$_2$/FM heterostructures as measured at room temperature. Ferromagnetic resonance (FMR) and electrically detected spin-pumping FMR measurements performed on 1T$'$-MoTe$_2$/Co/Au and 1T$'$-MoTe$_2$/Au/Co/Au heterostructures reveal a spin-mixing conductance value of up to $\sim1.6 \times 10^{20}~\mathrm{m^{-2}}$ and a spin Hall angle of $1.7\%$. These findings position MoTe$_2$ thin films as a competitive spin-charge conversion option compared to other functional materials (e.g., heavy metals, topological insulators), highlighting their potential for future applications in spintronic devices. [SEP] [HINT] transition -> Materials Science (Syns: passage, modulation, changeover) | spin -> Materials Science (Syns: twisting, whirl, tailspin) | functional -> Neuroscience (Syns: working, usable, running)",Materials Science
"The chemical interaction between Mo and Ru layers in multilayer structures depending on the thickness ratio ($Γ$) was carried out using X-ray photoelectron spectroscopy (XPS), X-ray diffraction (XRD) and X-ray reflectometry (XRR). The results showed significant interaction of materials inside multilayer structures with the formation of ruthenium borides, with an increase in the B4C layer thickness (a decrease in the $Γ$ parameter) leading to the formation of ruthenium borides of different stoichiometry. The introduction of a carbon barrier layer at the Ru-on-B4C interface resulted in significant suppression of ruthenium boride formation. The thermal stability of the B4C/Ru system was also studied upon annealing at 400$^{\circ}$C for 1 hour before and after the introduction of the carbon barrier layer. It was shown that the introduction of a carbon barrier layer at the Ru-on-B4C interface increases the thermal stability of the system, which makes this system more suitable for use in optical systems exposed to long-term radiation. The obtained results are important for the development of highly efficient multilayer mirrors used in EUV lithography and X-ray optics.",Materials Science
"The chemical interaction between Mo and Ru layers in multilayer structures depending on the thickness ratio ($Γ$) was carried out using X-ray photoelectron spectroscopy (XPS), X-ray diffraction (XRD) and X-ray reflectometry (XRR). The results showed significant interaction of materials inside multilayer structures with the formation of ruthenium borides, with an increase in the B4C layer thickness (a decrease in the $Γ$ parameter) leading to the formation of ruthenium borides of different stoichiometry. The introduction of a carbon barrier layer at the Ru-on-B4C interface resulted in significant suppression of ruthenium boride formation. The thermal stability of the B4C/Ru system was also studied upon annealing at 400$^{\circ}$C for 1 hour before and after the introduction of the carbon barrier layer. It was shown that the introduction of a carbon barrier layer at the Ru-on-B4C interface increases the thermal stability of the system, which makes this system more suitable for use in optical systems exposed to long-term radiation. The obtained results are important for the development of highly efficient multilayer mirrors used in EUV lithography and X-ray optics. [SEP] [HINT] used -> Bioinformatics (Syns: utilize, ill-used, apply) | results -> Bioinformatics (Syns: final result, consequence, resultant role) | systems -> Bioinformatics (Syns: organization, organisation, system)",Materials Science
"This study investigates the causal neural dynamics by which affordance representations influence action language comprehension. In this study, 18 participants observed stimuli displayed in two conditions during the experiment: text-only (e.g., `Hit with a hammer') and video+text (visual clips with matching phrases). EEG data were recorded from 32 channels and analyzed for event-related potentials and source localization using LORETA, which identified four left-hemisphere regions of interest: the Lateral Occipital Cortex (LOC), Posterior Superior Temporal Gyrus (pSTG), Ventral Premotor Cortex (PMv), and Inferior Parietal Lobule (IPL). A space of dynamic causal modeling (DCM) was constructed with driving inputs to LOC and pSTG, and multiple connectivity configurations were tested. Bayesian Model Selection revealed a dominant model in which PMv causally influenced IPL and pSTG, reflecting a feedforward architecture from affordance-related motor regions to semantic hubs. Bayesian Model Averaging further confirmed strong endogenous connections from LOC to PMv and IPL, and significant modulation from PMv to IPL. These findings provide direct evidence that affordance processing in premotor regions drives action language understanding by engaging downstream parietal and temporal areas. The results support grounded cognition theories and offer a mechanistic account of how sensorimotor information contributes to linguistic comprehension.",Neuroscience
"This study investigates the causal neural dynamics by which affordance representations influence action language comprehension. In this study, 18 participants observed stimuli displayed in two conditions during the experiment: text-only (e.g., `Hit with a hammer') and video+text (visual clips with matching phrases). EEG data were recorded from 32 channels and analyzed for event-related potentials and source localization using LORETA, which identified four left-hemisphere regions of interest: the Lateral Occipital Cortex (LOC), Posterior Superior Temporal Gyrus (pSTG), Ventral Premotor Cortex (PMv), and Inferior Parietal Lobule (IPL). A space of dynamic causal modeling (DCM) was constructed with driving inputs to LOC and pSTG, and multiple connectivity configurations were tested. Bayesian Model Selection revealed a dominant model in which PMv causally influenced IPL and pSTG, reflecting a feedforward architecture from affordance-related motor regions to semantic hubs. Bayesian Model Averaging further confirmed strong endogenous connections from LOC to PMv and IPL, and significant modulation from PMv to IPL. These findings provide direct evidence that affordance processing in premotor regions drives action language understanding by engaging downstream parietal and temporal areas. The results support grounded cognition theories and offer a mechanistic account of how sensorimotor information contributes to linguistic comprehension. [SEP] [HINT] connectivity -> Neuroscience (Syns: ) | language -> Neuroscience (Syns: linguistic process, linguistic communication, spoken communication) | understanding -> Neuroscience (Syns: savvy, intellect, sympathy)",Neuroscience
"Purpose: To improve the accuracy of multiparametric estimation, including myelin water fraction (MWF) quantification, and reduce scan time in 3D-QALAS by optimizing sequence parameters, using a self-supervised multilayer perceptron network. Methods: We jointly optimize flip angles, T2 preparation durations, and sequence gaps for T1 recovery using a self-supervised MLP trained to minimize a Cramer-Rao bound-based loss function, with explicit constraints on total scan time. The optimization targets white matter, gray matter, and myelin water tissues, and its performance was validated through simulation, phantom, and in vivo experiments. Results: Building on our previously proposed MWF-QALAS method for simultaneous MWF, T1, and T2 mapping, the optimized sequence reduces the number of readouts from six to five and achieves a scan time nearly one minute shorter, while also yielding higher T1 and T2 accuracy and improved MWF maps. This sequence enables simultaneous multiparametric quantification, including MWF, at 1 mm isotropic resolution within 3 minutes and 30 seconds. Conclusion: This study demonstrated that optimizing sequence parameters using a self-supervised MLP network improved T1, T2 and MWF estimation accuracy, while reducing scan time.",Bioinformatics
"Purpose: To improve the accuracy of multiparametric estimation, including myelin water fraction (MWF) quantification, and reduce scan time in 3D-QALAS by optimizing sequence parameters, using a self-supervised multilayer perceptron network. Methods: We jointly optimize flip angles, T2 preparation durations, and sequence gaps for T1 recovery using a self-supervised MLP trained to minimize a Cramer-Rao bound-based loss function, with explicit constraints on total scan time. The optimization targets white matter, gray matter, and myelin water tissues, and its performance was validated through simulation, phantom, and in vivo experiments. Results: Building on our previously proposed MWF-QALAS method for simultaneous MWF, T1, and T2 mapping, the optimized sequence reduces the number of readouts from six to five and achieves a scan time nearly one minute shorter, while also yielding higher T1 and T2 accuracy and improved MWF maps. This sequence enables simultaneous multiparametric quantification, including MWF, at 1 mm isotropic resolution within 3 minutes and 30 seconds. Conclusion: This study demonstrated that optimizing sequence parameters using a self-supervised MLP network improved T1, T2 and MWF estimation accuracy, while reducing scan time. [SEP] [HINT] performance -> Bioinformatics (Syns: functioning, operation, carrying out) | including -> Bioinformatics (Syns: admit, include, let in) | using -> Bioinformatics (Syns: utilize, exploitation, apply)",Bioinformatics
"Transition state or minimum energy path finding methods constitute a routine component of the computational chemistry toolkit. Standard analysis involves trajectories conventionally plotted in terms of the relative energy to the initial state against a cumulative displacement variable, or the image number. These dimensional reductions obscure structural rearrangements in high dimensions and may often be trajectory dependent. This precludes the ability to compare optimization trajectories of different methods beyond the number of calculations, time taken, and final saddle geometry. We present a method mapping trajectories onto a two-dimension surface defined by a permutation corrected root mean square deviation from the reactant and product configurations. Energy is represented as an interpolated color-mapped surface constructed from all optimization steps using radial basis functions. This representation highlights optimization trajectories, identifies endpoint basins, and diagnoses convergence concerns invisible in one-dimensional profiles. We validate the framework on a cycloaddition reaction, showing that a machine-learned potential saddle and density functional theory reference lie on comparable energy contours despite geometric displacements.",Materials Science
"Transition state or minimum energy path finding methods constitute a routine component of the computational chemistry toolkit. Standard analysis involves trajectories conventionally plotted in terms of the relative energy to the initial state against a cumulative displacement variable, or the image number. These dimensional reductions obscure structural rearrangements in high dimensions and may often be trajectory dependent. This precludes the ability to compare optimization trajectories of different methods beyond the number of calculations, time taken, and final saddle geometry. We present a method mapping trajectories onto a two-dimension surface defined by a permutation corrected root mean square deviation from the reactant and product configurations. Energy is represented as an interpolated color-mapped surface constructed from all optimization steps using radial basis functions. This representation highlights optimization trajectories, identifies endpoint basins, and diagnoses convergence concerns invisible in one-dimensional profiles. We validate the framework on a cycloaddition reaction, showing that a machine-learned potential saddle and density functional theory reference lie on comparable energy contours despite geometric displacements. [SEP] [HINT] transition -> Materials Science (Syns: passage, modulation, changeover) | computational -> Neuroscience (Syns: ) | functional -> Neuroscience (Syns: working, usable, running)",Materials Science
"This paper studies linear mathematical modeling of brain's cortical dynamics using electroencephalography (EEG) data in an experiment with continuous exogenous input. The EEG data were recorded while participants were seated with their wrist strapped to a haptic manipulator. The manipulator imposed a continuous multisine angular perturbation to the wrist as the exogenous input to the brain. We show that subspace identification, in particular the PO-MOESP algorithm, leads to a linear time-invariant state-space model that accurately represents the measurements, in a latent space, assuming that the EEG data are the models' output. The model is verified and validated using data from seven participants. Moreover, we construct linear maps to relate the latent space dynamics to the neural source space. We show that findings by our model align with those identified in previous studies.",Neuroscience
"This paper studies linear mathematical modeling of brain's cortical dynamics using electroencephalography (EEG) data in an experiment with continuous exogenous input. The EEG data were recorded while participants were seated with their wrist strapped to a haptic manipulator. The manipulator imposed a continuous multisine angular perturbation to the wrist as the exogenous input to the brain. We show that subspace identification, in particular the PO-MOESP algorithm, leads to a linear time-invariant state-space model that accurately represents the measurements, in a latent space, assuming that the EEG data are the models' output. The model is verified and validated using data from seven participants. Moreover, we construct linear maps to relate the latent space dynamics to the neural source space. We show that findings by our model align with those identified in previous studies. [SEP] [HINT] cortical -> Neuroscience (Syns: ) | space -> Neuroscience (Syns: distance, place, outer space) | using -> Bioinformatics (Syns: utilize, exploitation, apply)",Neuroscience
"Understanding how subjective experience arises from information processing remains a central challenge in neuroscience, cognitive science, and AI research. The Modular Consciousness Theory (MCT) proposes a biologically grounded and computationally explicit framework in which consciousness is a discrete sequence of Integrated Informational States (IISs). Each IIS is a packet of integrated information tagged with a multidimensional density vector that quantifies informational richness. Its magnitude correlates with subjective intensity, shaping memory, behavior, and continuity of experience. Inputs from body and environment are adaptively filtered, processed by modules (abstraction, narration, evaluation, self-evaluation), and integrated into an IIS. The resulting packet, tagged with its density vector, is transmitted to behavioral readiness, memory, and decision-making modules, closing the loop. This explains why strongly tagged states exert greater influence on long-term memory and action. Unlike Global Workspace Theory, Integrated Information Theory, or Higher-Order Thought, MCT specifies a full computational pipeline producing discrete informational units with quantifiable internal structure. Subjectivity is reframed as a correlate of the density-tagging signal with functional consequences. MCT generates testable predictions, such as stress enhancing memory encoding, and provides a naturalistic blueprint for both biological and artificial architectures. Consciousness, in this view, is not an irreducible essence but an evolvable, quantifiable, and constructible feature of complex information processing.",Neuroscience
"Understanding how subjective experience arises from information processing remains a central challenge in neuroscience, cognitive science, and AI research. The Modular Consciousness Theory (MCT) proposes a biologically grounded and computationally explicit framework in which consciousness is a discrete sequence of Integrated Informational States (IISs). Each IIS is a packet of integrated information tagged with a multidimensional density vector that quantifies informational richness. Its magnitude correlates with subjective intensity, shaping memory, behavior, and continuity of experience. Inputs from body and environment are adaptively filtered, processed by modules (abstraction, narration, evaluation, self-evaluation), and integrated into an IIS. The resulting packet, tagged with its density vector, is transmitted to behavioral readiness, memory, and decision-making modules, closing the loop. This explains why strongly tagged states exert greater influence on long-term memory and action. Unlike Global Workspace Theory, Integrated Information Theory, or Higher-Order Thought, MCT specifies a full computational pipeline producing discrete informational units with quantifiable internal structure. Subjectivity is reframed as a correlate of the density-tagging signal with functional consequences. MCT generates testable predictions, such as stress enhancing memory encoding, and provides a naturalistic blueprint for both biological and artificial architectures. Consciousness, in this view, is not an irreducible essence but an evolvable, quantifiable, and constructible feature of complex information processing. [SEP] [HINT] computational -> Neuroscience (Syns: ) | understanding -> Neuroscience (Syns: savvy, intellect, sympathy) | functional -> Neuroscience (Syns: working, usable, running)",Neuroscience
"Recent breakthroughs in generative modeling have demonstrated remarkable capabilities in molecular generation, yet the integration of comprehensive biomedical knowledge into these models has remained an untapped frontier. In this study, we introduce K-DREAM (Knowledge-Driven Embedding-Augmented Model), a novel framework that leverages knowledge graphs to augment diffusion-based generative models for drug discovery. By embedding structured information from large-scale knowledge graphs, K-DREAM directs molecular generation toward candidates with higher biological relevance and therapeutic suitability. This integration ensures that the generated molecules are aligned with specific therapeutic targets, moving beyond traditional heuristic-driven approaches. In targeted drug design tasks, K-DREAM generates drug candidates with improved binding affinities and predicted efficacy, surpassing current state-of-the-art generative models. It also demonstrates flexibility by producing molecules designed for multiple targets, enabling applications to complex disease mechanisms. These results highlight the utility of knowledge-enhanced generative models in rational drug design and their relevance to practical therapeutic development.",Bioinformatics
"Recent breakthroughs in generative modeling have demonstrated remarkable capabilities in molecular generation, yet the integration of comprehensive biomedical knowledge into these models has remained an untapped frontier. In this study, we introduce K-DREAM (Knowledge-Driven Embedding-Augmented Model), a novel framework that leverages knowledge graphs to augment diffusion-based generative models for drug discovery. By embedding structured information from large-scale knowledge graphs, K-DREAM directs molecular generation toward candidates with higher biological relevance and therapeutic suitability. This integration ensures that the generated molecules are aligned with specific therapeutic targets, moving beyond traditional heuristic-driven approaches. In targeted drug design tasks, K-DREAM generates drug candidates with improved binding affinities and predicted efficacy, surpassing current state-of-the-art generative models. It also demonstrates flexibility by producing molecules designed for multiple targets, enabling applications to complex disease mechanisms. These results highlight the utility of knowledge-enhanced generative models in rational drug design and their relevance to practical therapeutic development. [SEP] [HINT] information -> Bioinformatics (Syns: entropy, data, info) | complex -> Bioinformatics (Syns: building complex, coordination compound, composite) | molecular -> Bioinformatics (Syns: )",Bioinformatics
"The Machine Consciousness Hypothesis states that consciousness is a substrate-free functional property of computational systems capable of second-order perception. I propose a research program to investigate this idea in silico by studying how collective self-models (coherent, self-referential representations) emerge from distributed learning systems embedded within universal self-organizing environments. The theory outlined here starts from the supposition that consciousness is an emergent property of collective intelligence systems undergoing synchronization of prediction through communication. It is not an epiphenomenon of individual modeling but a property of the language that a system evolves to internally describe itself. For a model of base reality, I begin with a minimal but general computational world: a cellular automaton, which exhibits both computational irreducibility and local reducibility. On top of this computational substrate, I introduce a network of local, predictive, representational (neural) models capable of communication and adaptation. I use this layered model to study how collective intelligence gives rise to self-representation as a direct consequence of inter-agent alignment. I suggest that consciousness does not emerge from modeling per se, but from communication. It arises from the noisy, lossy exchange of predictive messages between groups of local observers describing persistent patterns in the underlying computational substrate (base reality). It is through this representational dialogue that a shared model arises, aligning many partial views of the world. The broader goal is to develop empirically testable theories of machine consciousness, by studying how internal self-models may form in distributed systems without centralized control.",Neuroscience
"The Machine Consciousness Hypothesis states that consciousness is a substrate-free functional property of computational systems capable of second-order perception. I propose a research program to investigate this idea in silico by studying how collective self-models (coherent, self-referential representations) emerge from distributed learning systems embedded within universal self-organizing environments. The theory outlined here starts from the supposition that consciousness is an emergent property of collective intelligence systems undergoing synchronization of prediction through communication. It is not an epiphenomenon of individual modeling but a property of the language that a system evolves to internally describe itself. For a model of base reality, I begin with a minimal but general computational world: a cellular automaton, which exhibits both computational irreducibility and local reducibility. On top of this computational substrate, I introduce a network of local, predictive, representational (neural) models capable of communication and adaptation. I use this layered model to study how collective intelligence gives rise to self-representation as a direct consequence of inter-agent alignment. I suggest that consciousness does not emerge from modeling per se, but from communication. It arises from the noisy, lossy exchange of predictive messages between groups of local observers describing persistent patterns in the underlying computational substrate (base reality). It is through this representational dialogue that a shared model arises, aligning many partial views of the world. The broader goal is to develop empirically testable theories of machine consciousness, by studying how internal self-models may form in distributed systems without centralized control. [SEP] [HINT] language -> Neuroscience (Syns: linguistic process, linguistic communication, spoken communication) | computational -> Neuroscience (Syns: ) | learning -> Bioinformatics (Syns: take, teach, acquire)",Neuroscience
"Computation fundamentally separates time from space: nondeterministic search is exponential in time but polynomially simulable in space (Savitch's Theorem). We propose that the brain physically instantiates a biological variant of this theorem through Memory-Amortized Inference (MAI), creating a geometry of certainty from the chaos of exploration. We formalize the cortical algorithm as a recursive topological transformation of flow into scaffold:$H_{odd}^{(k)} \xrightarrow{\text{Condense}} H_{even}^{(k+1)}$, where a stable, high-frequency cycle ($β_1$) at level $k$ is collapsed into a static atomic unit ($β_0$) at level $k+1$. Through this Topological Trinity (Search $\to$ Closure $\to$ Condensation), the system amortizes the thermodynamic cost of inference. By reducing complex homological loops into zero-dimensional defects (memory granules), the cortex converts high-entropy parallel search into low-entropy serial navigation. This mechanism builds a ``Tower of Scaffolds'' that achieves structural parity with the environment, allowing linear cortical growth to yield exponential representational reach. However, this efficiency imposes a strict limit: the same metric contraction that enables \emph{generalization} (valid manifold folding) inevitably risks \emph{hallucination} (homological collapse). We conclude that intelligence is the art of navigating this trade-off, where the ``Geometry of Certainty'' is defined by the precise threshold between necessary abstraction and topological error.",Neuroscience
"Computation fundamentally separates time from space: nondeterministic search is exponential in time but polynomially simulable in space (Savitch's Theorem). We propose that the brain physically instantiates a biological variant of this theorem through Memory-Amortized Inference (MAI), creating a geometry of certainty from the chaos of exploration. We formalize the cortical algorithm as a recursive topological transformation of flow into scaffold:$H_{odd}^{(k)} \xrightarrow{\text{Condense}} H_{even}^{(k+1)}$, where a stable, high-frequency cycle ($β_1$) at level $k$ is collapsed into a static atomic unit ($β_0$) at level $k+1$. Through this Topological Trinity (Search $\to$ Closure $\to$ Condensation), the system amortizes the thermodynamic cost of inference. By reducing complex homological loops into zero-dimensional defects (memory granules), the cortex converts high-entropy parallel search into low-entropy serial navigation. This mechanism builds a ``Tower of Scaffolds'' that achieves structural parity with the environment, allowing linear cortical growth to yield exponential representational reach. However, this efficiency imposes a strict limit: the same metric contraction that enables \emph{generalization} (valid manifold folding) inevitably risks \emph{hallucination} (homological collapse). We conclude that intelligence is the art of navigating this trade-off, where the ``Geometry of Certainty'' is defined by the precise threshold between necessary abstraction and topological error. [SEP] [HINT] cortical -> Neuroscience (Syns: ) | space -> Neuroscience (Syns: distance, place, outer space) | complex -> Bioinformatics (Syns: building complex, coordination compound, composite)",Neuroscience
"EasyVitessce is a Python package that turns existing static Scanpy and SpatialData plots into interactive visualizations by virtue of adding a single line of Python code. The package uses Vitessce internally to render interactive plots, and abstracts away technical details involved with configuration of Vitessce. The resulting interactive plots can be viewed in computational notebook environments or their configurations can be exported for usage in other contexts such as web applications, enhancing the utility of popular Scverse Python plotting APIs. EasyVitessce is released under the MIT License and available on the Python Package Index (PyPI). The source code is publicly available on GitHub.",Bioinformatics
"EasyVitessce is a Python package that turns existing static Scanpy and SpatialData plots into interactive visualizations by virtue of adding a single line of Python code. The package uses Vitessce internally to render interactive plots, and abstracts away technical details involved with configuration of Vitessce. The resulting interactive plots can be viewed in computational notebook environments or their configurations can be exported for usage in other contexts such as web applications, enhancing the utility of popular Scverse Python plotting APIs. EasyVitessce is released under the MIT License and available on the Python Package Index (PyPI). The source code is publicly available on GitHub. [SEP] [HINT] single -> Bioinformatics (Syns: undivided, exclusive, bingle) | computational -> Neuroscience (Syns: ) | existing -> Bioinformatics (Syns: subsist, existent, survive)",Bioinformatics
"Topology, as a mathematical concept, has been introduced into condensed matter physics since the discovery of quantum Hall effect, which characterizes new physical scenario beyond the Landau theory. The topologically protected physical quantities, such as the dissipationless quantum transport of edge/surface states as well as magnetic/dipole quasi-particles like skyrmions/bimerons, have attracted great research enthusiasms in the past decades. In recent years, another kind of topology in condensed matter was revealed in the magnetoelectric parameter space of multiferroics, which deepens our understanding of magnetoelectric physics. This topical review summarizes recent advances in this area, involving three type-II multiferroics. With magnetism-induced ferroelectricity, topological behaviors can be manifested during the magnetoelectric switching processes driven by magnetic/electric fields, such as Roman-surface/Riemann-surface magnetoelectricity and magnetic crankshaft. These exotic topological magnetoelectric behaviors may be helpful to pursuit energy-efficient and precise-control devices for spintronics and quantum computing.",Materials Science
"Topology, as a mathematical concept, has been introduced into condensed matter physics since the discovery of quantum Hall effect, which characterizes new physical scenario beyond the Landau theory. The topologically protected physical quantities, such as the dissipationless quantum transport of edge/surface states as well as magnetic/dipole quasi-particles like skyrmions/bimerons, have attracted great research enthusiasms in the past decades. In recent years, another kind of topology in condensed matter was revealed in the magnetoelectric parameter space of multiferroics, which deepens our understanding of magnetoelectric physics. This topical review summarizes recent advances in this area, involving three type-II multiferroics. With magnetism-induced ferroelectricity, topological behaviors can be manifested during the magnetoelectric switching processes driven by magnetic/electric fields, such as Roman-surface/Riemann-surface magnetoelectricity and magnetic crankshaft. These exotic topological magnetoelectric behaviors may be helpful to pursuit energy-efficient and precise-control devices for spintronics and quantum computing. [SEP] [HINT] understanding -> Neuroscience (Syns: savvy, intellect, sympathy) | transport -> Materials Science (Syns: transferral, enthral, shipping) | space -> Neuroscience (Syns: distance, place, outer space)",Materials Science
"Equimolar ratio high-entropy perovskite ceramics (HEPCs) have attracted much attention due to their excellent magnetization intensity. To further enhance their magnetization intensities, (Ln0.2La0.2Nd0.2Sm0.2Eu0.2)MnO3 (Ln = Dy, Ho and Er, labeled as Ln-LNSEMO) HEPCs are designed based on the configuration entropy Sconfig, tolerance factor t, and mismatch degree. Single-phase HEPCs are synthesized by the solid-phase method in this work, in which the effects of the heavy rare-earth elements Dy, Ho and Er on the structure and magnetic properties of Ln-LNSEMO are systematically studied. The results show that all Ln-LNSEMO HEPCs exhibit high crystallinity and maintain excellent structural stability after sintering at 1250 degree centigrade for 16 h. Ln-LNSEMO HEPCs exhibit significant lattice distortion effects, with smooth surface morphology, clearly distinguishable grain boundaries, and irregular polygonal shapes. The three high-entropy ceramic samples exhibit hysteresis behavior at T = 5 K, with the Curie temperature TC decreasing as the radius of the introduced rare-earth ions decreases, while the saturation magnetization and coercivity increase accordingly. When the average ionic radius of A-site decreases, the interaction between their valence electrons and local electrons in the crystal increases, thereby enhancing the conversion of electrons to oriented magnetic moments under an external magnetic field. Thus, Er-LNSEMO HEPC shows a higher saturation magnetization strength (42.8 emu/g) and coercivity (2.09 kOe) than the other samples, which is attributed to the strong magnetic crystal anisotropy, larger lattice distortion (0.00652), smaller average grain size (440.49 plus or minus 22.02 nm), unit cell volume (229.432 A3) and A-site average ion radius (1.24 A) of its magnet. The Er-LNSEMO HEPC has potential applications in magnetic recording materials.",Materials Science
"Equimolar ratio high-entropy perovskite ceramics (HEPCs) have attracted much attention due to their excellent magnetization intensity. To further enhance their magnetization intensities, (Ln0.2La0.2Nd0.2Sm0.2Eu0.2)MnO3 (Ln = Dy, Ho and Er, labeled as Ln-LNSEMO) HEPCs are designed based on the configuration entropy Sconfig, tolerance factor t, and mismatch degree. Single-phase HEPCs are synthesized by the solid-phase method in this work, in which the effects of the heavy rare-earth elements Dy, Ho and Er on the structure and magnetic properties of Ln-LNSEMO are systematically studied. The results show that all Ln-LNSEMO HEPCs exhibit high crystallinity and maintain excellent structural stability after sintering at 1250 degree centigrade for 16 h. Ln-LNSEMO HEPCs exhibit significant lattice distortion effects, with smooth surface morphology, clearly distinguishable grain boundaries, and irregular polygonal shapes. The three high-entropy ceramic samples exhibit hysteresis behavior at T = 5 K, with the Curie temperature TC decreasing as the radius of the introduced rare-earth ions decreases, while the saturation magnetization and coercivity increase accordingly. When the average ionic radius of A-site decreases, the interaction between their valence electrons and local electrons in the crystal increases, thereby enhancing the conversion of electrons to oriented magnetic moments under an external magnetic field. Thus, Er-LNSEMO HEPC shows a higher saturation magnetization strength (42.8 emu/g) and coercivity (2.09 kOe) than the other samples, which is attributed to the strong magnetic crystal anisotropy, larger lattice distortion (0.00652), smaller average grain size (440.49 plus or minus 22.02 nm), unit cell volume (229.432 A3) and A-site average ion radius (1.24 A) of its magnet. The Er-LNSEMO HEPC has potential applications in magnetic recording materials. [SEP] [HINT] based -> Bioinformatics (Syns: ground, free-base, base) | perovskite -> Materials Science (Syns: ) | structure -> Bioinformatics (Syns: social system, complex body part, social structure)",Materials Science
"Humans can quickly and effortlessly extract a variety of information about others' social interactions from visual input, ranging from visuospatial cues like whether two people are facing each other to higher-level information. Yet, the computations supporting these abilities remain poorly understood, and social interaction recognition continues to challenge even the most advanced AI vision systems. Here, we hypothesized that humans rely on 3D visuospatial pose information to make social interaction judgments, which is absent in most AI vision models. To test this, we combined state-of-the-art pose and depth estimation algorithms to extract 3D joint positions of people in short video clips depicting everyday human actions and compared their ability to predict human social interaction judgments with current AI vision models. Strikingly, 3D joint positions outperformed most current AI vision models, revealing that key social information is available in explicit body position but not in the learned features of most vision models, including even the layer-wise embeddings of the pose models used to extract joint positions. To uncover the critical pose features humans use to make social judgments, we derived a compact set of 3D social pose features describing only the 3D position and direction of faces in the videos. We found that these minimal descriptors matched the predictive strength of the full set of 3D joints and significantly improved the performance of off-the-shelf AI vision models when combined with their embeddings. Moreover, the degree to which 3D social pose features were represented in each off-the-shelf AI vision model predicted the model's ability to match human social judgments. Together, our findings provide strong evidence that human social scene understanding relies on explicit representations of 3D pose and can be supported by simple, structured visuospatial primitives.",Neuroscience
"Humans can quickly and effortlessly extract a variety of information about others' social interactions from visual input, ranging from visuospatial cues like whether two people are facing each other to higher-level information. Yet, the computations supporting these abilities remain poorly understood, and social interaction recognition continues to challenge even the most advanced AI vision systems. Here, we hypothesized that humans rely on 3D visuospatial pose information to make social interaction judgments, which is absent in most AI vision models. To test this, we combined state-of-the-art pose and depth estimation algorithms to extract 3D joint positions of people in short video clips depicting everyday human actions and compared their ability to predict human social interaction judgments with current AI vision models. Strikingly, 3D joint positions outperformed most current AI vision models, revealing that key social information is available in explicit body position but not in the learned features of most vision models, including even the layer-wise embeddings of the pose models used to extract joint positions. To uncover the critical pose features humans use to make social judgments, we derived a compact set of 3D social pose features describing only the 3D position and direction of faces in the videos. We found that these minimal descriptors matched the predictive strength of the full set of 3D joints and significantly improved the performance of off-the-shelf AI vision models when combined with their embeddings. Moreover, the degree to which 3D social pose features were represented in each off-the-shelf AI vision model predicted the model's ability to match human social judgments. Together, our findings provide strong evidence that human social scene understanding relies on explicit representations of 3D pose and can be supported by simple, structured visuospatial primitives. [SEP] [HINT] used -> Bioinformatics (Syns: utilize, ill-used, apply) | features -> Bioinformatics (Syns: characteristic, lineament, feature of speech) | understanding -> Neuroscience (Syns: savvy, intellect, sympathy)",Neuroscience
"Recovering unbiased properties from biased or perturbed simulations is a central challenge in rare-event sampling. Classical Girsanov Reweighting (GR) offers a principled solution by yielding exact pathwise probability ratios between perturbed and reference processes. However, the variance of GR weights grows rapidly with time, rendering it impractical for long-horizon reweighting. We introduce Marginal Girsanov Reweighting (MGR), which mitigates variance explosion by marginalizing over intermediate paths, producing stable and scalable weights for long-timescale dynamics. Experiments demonstrate that MGR (i) accurately recovers kinetic properties from umbrella-sampling trajectories in molecular dynamics, and (ii) enables efficient Bayesian parameter inference for stochastic differential equations with temporally sparse observations.",Bioinformatics
"Recovering unbiased properties from biased or perturbed simulations is a central challenge in rare-event sampling. Classical Girsanov Reweighting (GR) offers a principled solution by yielding exact pathwise probability ratios between perturbed and reference processes. However, the variance of GR weights grows rapidly with time, rendering it impractical for long-horizon reweighting. We introduce Marginal Girsanov Reweighting (MGR), which mitigates variance explosion by marginalizing over intermediate paths, producing stable and scalable weights for long-timescale dynamics. Experiments demonstrate that MGR (i) accurately recovers kinetic properties from umbrella-sampling trajectories in molecular dynamics, and (ii) enables efficient Bayesian parameter inference for stochastic differential equations with temporally sparse observations. [SEP] [HINT] molecular -> Bioinformatics (Syns: ) | demonstrate -> Bioinformatics (Syns: evidence, march, prove) | properties -> Materials Science (Syns: place, prop, property)",Bioinformatics
"A critical visual computation is to construct global scene properties from activities of early visual cortical neurons which have small receptive fields. Such a computation is enabled by contextual influences, through which a neuron's response to visual inputs is influenced by contextual inputs outside its classical receptive fields. Accordingly, neurons can signal global properties including visual saliencies and figure-ground relationships. Many believe that intracortical axons conduct signals too slowly to bring the contextual information from receptive fields of other neurons. A popular opinion is that much of the contextual influences arise from feedback from higher visual areas whose neurons have larger receptive fields. This paper re-examines pre-existing data to reveal these unexpected findings: the conduction speed of V1 intracortical axons increases approximately linearly with the conduction distance, and is sufficiently high for conveying the contextual influences. Recognizing the importance of intracortical contribution to critical visual computations should enable fresh progress in answering long-standing questions.",Neuroscience
"A critical visual computation is to construct global scene properties from activities of early visual cortical neurons which have small receptive fields. Such a computation is enabled by contextual influences, through which a neuron's response to visual inputs is influenced by contextual inputs outside its classical receptive fields. Accordingly, neurons can signal global properties including visual saliencies and figure-ground relationships. Many believe that intracortical axons conduct signals too slowly to bring the contextual information from receptive fields of other neurons. A popular opinion is that much of the contextual influences arise from feedback from higher visual areas whose neurons have larger receptive fields. This paper re-examines pre-existing data to reveal these unexpected findings: the conduction speed of V1 intracortical axons increases approximately linearly with the conduction distance, and is sufficiently high for conveying the contextual influences. Recognizing the importance of intracortical contribution to critical visual computations should enable fresh progress in answering long-standing questions. [SEP] [HINT] cortical -> Neuroscience (Syns: ) | information -> Bioinformatics (Syns: entropy, data, info) | including -> Bioinformatics (Syns: admit, include, let in)",Neuroscience
"At HVEI-2012, I presented a neurobiologically-based model for trichromatic color sensations in humans, mapping the neural substrate for color sensations to V1-L4: the thalamic recipient layer of the primary visual cortex. In this paper, I propose that V1-L4 itself consists of three distinct sub-layers that directly correspond to the three primary color sensations: blue, red, and green. Furthermore, I apply this model to three aspects of color vision: the three-dimensional (3D) color solid, dichromatism, and ocular agnosticism. Regarding these aspects further: (1) 3D color solid: V1-L4 is known to exhibit a gradient of cell densities from its outermost layer (i.e., its pia side) to its innermost layer (i.e., its white matter side). Taken together with the proposition that the population size of a cell assembly directly corresponds with the magnitude of a color sensation, it can be inferred that the neurobiologically-based color solid is a tilted cuboid. (2) Chromatic color blindness: Using deuteranopia as an example, at the retinal level, M-cones are lost and replaced by L-cones. However, at the cortical level, deuteranopia manifests as a fusion of the two bottom layers of V1-L4. (3) Ocular agnosticism: Although color sensation is monocular, we normally are not aware of which eye we are seeing with. This visual phenomenon can be explained by the nature of ocular integration within V1-L4. A neurobiologically-based model for human color sensations could significantly contribute to future engineering efforts aimed at enhancing human color experiences.",Neuroscience
"At HVEI-2012, I presented a neurobiologically-based model for trichromatic color sensations in humans, mapping the neural substrate for color sensations to V1-L4: the thalamic recipient layer of the primary visual cortex. In this paper, I propose that V1-L4 itself consists of three distinct sub-layers that directly correspond to the three primary color sensations: blue, red, and green. Furthermore, I apply this model to three aspects of color vision: the three-dimensional (3D) color solid, dichromatism, and ocular agnosticism. Regarding these aspects further: (1) 3D color solid: V1-L4 is known to exhibit a gradient of cell densities from its outermost layer (i.e., its pia side) to its innermost layer (i.e., its white matter side). Taken together with the proposition that the population size of a cell assembly directly corresponds with the magnitude of a color sensation, it can be inferred that the neurobiologically-based color solid is a tilted cuboid. (2) Chromatic color blindness: Using deuteranopia as an example, at the retinal level, M-cones are lost and replaced by L-cones. However, at the cortical level, deuteranopia manifests as a fusion of the two bottom layers of V1-L4. (3) Ocular agnosticism: Although color sensation is monocular, we normally are not aware of which eye we are seeing with. This visual phenomenon can be explained by the nature of ocular integration within V1-L4. A neurobiologically-based model for human color sensations could significantly contribute to future engineering efforts aimed at enhancing human color experiences. [SEP] [HINT] cortical -> Neuroscience (Syns: ) | human -> Neuroscience (Syns: human being, man, homo) | visual -> Neuroscience (Syns: optical, ocular, optic)",Neuroscience
"The development of new battery materials, particularly novel cathode chemistries, is essential for enabling next generation energy storage technologies. In this work, we set up a screening procedure on the Energy-GNoME database for identifying novel cathode candidates. We use MACE foundational models as a first layer of screening, we assess dynamical stability and estimate the average voltage and gravimetric energy density. Following that, we apply physically motivated reasoning to identify the most promising candidates. Furthermore, we refine the average voltage prediction of selected promising candidates using DFT+U and provide the list of selected materials using this protocol. This work delivers two key outcomes: validation of the foundational MACE models high-throughput screening approach and suggestions for cathode candidates for the development of next-generation batteries. Finally, a fair comparison between the MACE predictions and the readily available figures of merit reported in the Energy GNoME database is demonstrated on the examined materials.",Materials Science
"The development of new battery materials, particularly novel cathode chemistries, is essential for enabling next generation energy storage technologies. In this work, we set up a screening procedure on the Energy-GNoME database for identifying novel cathode candidates. We use MACE foundational models as a first layer of screening, we assess dynamical stability and estimate the average voltage and gravimetric energy density. Following that, we apply physically motivated reasoning to identify the most promising candidates. Furthermore, we refine the average voltage prediction of selected promising candidates using DFT+U and provide the list of selected materials using this protocol. This work delivers two key outcomes: validation of the foundational MACE models high-throughput screening approach and suggestions for cathode candidates for the development of next-generation batteries. Finally, a fair comparison between the MACE predictions and the readily available figures of merit reported in the Energy GNoME database is demonstrated on the examined materials. [SEP] [HINT] work -> Bioinformatics (Syns: work out, process, bring) | using -> Bioinformatics (Syns: utilize, exploitation, apply) | materials -> Materials Science (Syns: stuff, cloth, material)",Materials Science
"Predicting the glass-forming ability (GFA) of chemical compositions remains a fundamental challenge in materials science, especially for oxide glasses with broad compositional diversity. Traditional empirical and thermodynamic approaches often fail to capture the complex, nonlinear factors governing vitrification. In this study, we applied two ensemble machine learning algorithms-Random Forest (RF) and Extreme Gradient Boosting (XGB)-to the glass_ternary_hipt dataset to predict the GFA of ternary oxide glasses directly from composition-derived descriptors. Both models achieved excellent predictive accuracy (R^2 > 0.92, MAE < 0.04), confirming that GFA is learnable from compositional features alone. Feature importance analysis revealed that electronegativity variance, atomic size mismatch, and valence electron descriptors are the most influential factors, while cohesive energy and ionic radius provided secondary contributions. These chemically interpretable features align with established theories of glass formation, thereby bridging predictive performance with physical understanding. The novelty of this work lies in systematically extending ML-based predictive modeling to ternary oxide glasses, a class less studied compared to metallic and binary systems. Our results demonstrate that ensemble learning not only enables accurate GFA prediction but also provides actionable insights for designing new glass compositions with enhanced stability.",Materials Science
"Predicting the glass-forming ability (GFA) of chemical compositions remains a fundamental challenge in materials science, especially for oxide glasses with broad compositional diversity. Traditional empirical and thermodynamic approaches often fail to capture the complex, nonlinear factors governing vitrification. In this study, we applied two ensemble machine learning algorithms-Random Forest (RF) and Extreme Gradient Boosting (XGB)-to the glass_ternary_hipt dataset to predict the GFA of ternary oxide glasses directly from composition-derived descriptors. Both models achieved excellent predictive accuracy (R^2 > 0.92, MAE < 0.04), confirming that GFA is learnable from compositional features alone. Feature importance analysis revealed that electronegativity variance, atomic size mismatch, and valence electron descriptors are the most influential factors, while cohesive energy and ionic radius provided secondary contributions. These chemically interpretable features align with established theories of glass formation, thereby bridging predictive performance with physical understanding. The novelty of this work lies in systematically extending ML-based predictive modeling to ternary oxide glasses, a class less studied compared to metallic and binary systems. Our results demonstrate that ensemble learning not only enables accurate GFA prediction but also provides actionable insights for designing new glass compositions with enhanced stability. [SEP] [HINT] features -> Bioinformatics (Syns: characteristic, lineament, feature of speech) | learning -> Bioinformatics (Syns: take, teach, acquire) | electron -> Materials Science (Syns: negatron)",Materials Science
"Hybrid heterostructures composed of graphene and perovskite oxides provide a promising platform for exploiting synergetic interfacial functionalities. Conventional fabrication methods of the hybrid heterostructures rely on transferring graphene grown on metallic substrates-- a process that is time-consuming, labor-intensive, and prone to introducing numerous defects. In this study, we present a universal, catalyst-free method for the direct growth of graphene on insulating substrates by employing three different perovskite oxide substrates (SrTiO$_3$, LaAlO$_3$, and (La$_{0.18}$Sr$_{0.82}$)(Al$_{0.59}$Ta$_{0.41}$)O$_3$) using atmospheric chemical vapor deposition. Comprehensive characterization via Raman spectroscopy, X-ray spectroscopy, scanning probe microscopy, and electron microscopy confirmed the formation of a uniform, continuous monolayer graphene on all substrates. We identified that growth temperature critically governs graphene quality, as excessive active species may lead to secondary nucleation and the formation of multilayer graphene. Notably, all substrates shared the same optimal growth conditions. Low-temperature Raman spectroscopy and scanning tunneling microscopy of the graphene/SrTiO$_3$ hybrid heterostructure revealed cooperative phenomena, including substrate-induced lattice-phonon and electron-phonon coupling. Our work establishes a reproducible, transfer-free fabrication route for graphene/perovskite oxide hybrid heterostructures and provides empirical support for the universal growth of graphene on insulating substrates.",Materials Science
"Hybrid heterostructures composed of graphene and perovskite oxides provide a promising platform for exploiting synergetic interfacial functionalities. Conventional fabrication methods of the hybrid heterostructures rely on transferring graphene grown on metallic substrates-- a process that is time-consuming, labor-intensive, and prone to introducing numerous defects. In this study, we present a universal, catalyst-free method for the direct growth of graphene on insulating substrates by employing three different perovskite oxide substrates (SrTiO$_3$, LaAlO$_3$, and (La$_{0.18}$Sr$_{0.82}$)(Al$_{0.59}$Ta$_{0.41}$)O$_3$) using atmospheric chemical vapor deposition. Comprehensive characterization via Raman spectroscopy, X-ray spectroscopy, scanning probe microscopy, and electron microscopy confirmed the formation of a uniform, continuous monolayer graphene on all substrates. We identified that growth temperature critically governs graphene quality, as excessive active species may lead to secondary nucleation and the formation of multilayer graphene. Notably, all substrates shared the same optimal growth conditions. Low-temperature Raman spectroscopy and scanning tunneling microscopy of the graphene/SrTiO$_3$ hybrid heterostructure revealed cooperative phenomena, including substrate-induced lattice-phonon and electron-phonon coupling. Our work establishes a reproducible, transfer-free fabrication route for graphene/perovskite oxide hybrid heterostructures and provides empirical support for the universal growth of graphene on insulating substrates. [SEP] [HINT] perovskite -> Materials Science (Syns: ) | electron -> Materials Science (Syns: negatron) | work -> Bioinformatics (Syns: work out, process, bring)",Materials Science
"As the emerging ferroelectric (FE) materials, the ultrathin two-dimensional (2D) sliding ferroelectrics without phase-matching bottleneck, usually exhibit the pronounced second harmonic generation (SHG) responses. Despite the structural polarity of sliding ferroelectrics can be precisely detected via SHG characterizations, distinguishing the orientations of sliding ferroelectricity based on SHG responses has rarely been realized, as SHG intensities for upward and downward polarization states are supposed to be same. In current work, combining computational simulations and experimental characterizations, the orientation of sliding ferroelectricity is demonstrated to be readily distinguishable via SHG responses in 2D SnP2S6 (SnP2Se6), a new sliding FE material. Specifically, owing to the unique symmetry operation within FE-SnP2S6 (SnP2Se6), the intersection between \c{hi}xxx and \c{hi}yyy SHG susceptibility coefficients with opposite signs leads to the effective rotation of SHG polar directions upon switching of sliding ferroelectricity. Moreover, the remarkable dependence of SHG polar directions on the orientation of sliding ferroelectricity is further validated by experimental characterizations performed on SnP2S6 crystal in a single FE domain structural form. This work opens up the avenue for in-situ detecting the ferroelectricity orientation of 2D sliding ferroelectrics based on SHG nonlinear optical responses, and also demonstrates the controllable optical nonlinearly for new ""slidetronics"" applications.",Materials Science
"As the emerging ferroelectric (FE) materials, the ultrathin two-dimensional (2D) sliding ferroelectrics without phase-matching bottleneck, usually exhibit the pronounced second harmonic generation (SHG) responses. Despite the structural polarity of sliding ferroelectrics can be precisely detected via SHG characterizations, distinguishing the orientations of sliding ferroelectricity based on SHG responses has rarely been realized, as SHG intensities for upward and downward polarization states are supposed to be same. In current work, combining computational simulations and experimental characterizations, the orientation of sliding ferroelectricity is demonstrated to be readily distinguishable via SHG responses in 2D SnP2S6 (SnP2Se6), a new sliding FE material. Specifically, owing to the unique symmetry operation within FE-SnP2S6 (SnP2Se6), the intersection between \c{hi}xxx and \c{hi}yyy SHG susceptibility coefficients with opposite signs leads to the effective rotation of SHG polar directions upon switching of sliding ferroelectricity. Moreover, the remarkable dependence of SHG polar directions on the orientation of sliding ferroelectricity is further validated by experimental characterizations performed on SnP2S6 crystal in a single FE domain structural form. This work opens up the avenue for in-situ detecting the ferroelectricity orientation of 2D sliding ferroelectrics based on SHG nonlinear optical responses, and also demonstrates the controllable optical nonlinearly for new ""slidetronics"" applications. [SEP] [HINT] based -> Bioinformatics (Syns: ground, free-base, base) | computational -> Neuroscience (Syns: ) | work -> Bioinformatics (Syns: work out, process, bring)",Materials Science
"Larval zebrafish hunting provides a tractable setting to study how ecological and energetic constraints shape adaptive behavior in both biological brains and artificial agents. Here we develop a minimal agent-based model, training recurrent policies with deep reinforcement learning in a bout-based zebrafish simulator. Despite its simplicity, the model reproduces hallmark hunting behaviors -- including eye vergence-linked pursuit, speed modulation, and stereotyped approach trajectories -- that closely match real larval zebrafish. Quantitative trajectory analyses show that pursuit bouts systematically reduce prey angle by roughly half before strike, consistent with measurements. Virtual experiments and parameter sweeps vary ecological and energetic constraints, bout kinematics (coupled vs. uncoupled turns and forward motion), and environmental factors such as food density, food speed, and vergence limits. These manipulations reveal how constraints and environments shape pursuit dynamics, strike success, and abort rates, yielding falsifiable predictions for neuroscience experiments. These sweeps identify a compact set of constraints -- binocular sensing, the coupling of forward speed and turning in bout kinematics, and modest energetic costs on locomotion and vergence -- that are sufficient for zebrafish-like hunting to emerge. Strikingly, these behaviors arise in minimal agents without detailed biomechanics, fluid dynamics, circuit realism, or imitation learning from real zebrafish data. Taken together, this work provides a normative account of zebrafish hunting as the optimal balance between energetic cost and sensory benefit, highlighting the trade-offs that structure vergence and trajectory dynamics. We establish a virtual lab that narrows the experimental search space and generates falsifiable predictions about behavior and neural coding.",Neuroscience
"Larval zebrafish hunting provides a tractable setting to study how ecological and energetic constraints shape adaptive behavior in both biological brains and artificial agents. Here we develop a minimal agent-based model, training recurrent policies with deep reinforcement learning in a bout-based zebrafish simulator. Despite its simplicity, the model reproduces hallmark hunting behaviors -- including eye vergence-linked pursuit, speed modulation, and stereotyped approach trajectories -- that closely match real larval zebrafish. Quantitative trajectory analyses show that pursuit bouts systematically reduce prey angle by roughly half before strike, consistent with measurements. Virtual experiments and parameter sweeps vary ecological and energetic constraints, bout kinematics (coupled vs. uncoupled turns and forward motion), and environmental factors such as food density, food speed, and vergence limits. These manipulations reveal how constraints and environments shape pursuit dynamics, strike success, and abort rates, yielding falsifiable predictions for neuroscience experiments. These sweeps identify a compact set of constraints -- binocular sensing, the coupling of forward speed and turning in bout kinematics, and modest energetic costs on locomotion and vergence -- that are sufficient for zebrafish-like hunting to emerge. Strikingly, these behaviors arise in minimal agents without detailed biomechanics, fluid dynamics, circuit realism, or imitation learning from real zebrafish data. Taken together, this work provides a normative account of zebrafish hunting as the optimal balance between energetic cost and sensory benefit, highlighting the trade-offs that structure vergence and trajectory dynamics. We establish a virtual lab that narrows the experimental search space and generates falsifiable predictions about behavior and neural coding. [SEP] [HINT] learning -> Bioinformatics (Syns: take, teach, acquire) | space -> Neuroscience (Syns: distance, place, outer space) | structure -> Bioinformatics (Syns: social system, complex body part, social structure)",Neuroscience
"Nematic elastomers are a particular class of liquid crystal elastomers (LCEs) that exhibit both liquid-crystalline order and rubber (entropic) elasticity. This combination makes them stimuli-responsive soft materials with a number of unusual thermo-mechanical properties. They have been proposed for various applications, including soft robotics, enhanced adhesion, and impact resistance. This paper presents a new experimental setup and a comprehensive dataset characterizing the soft behavior of nematic elastomers over a range of temperatures and strain rates. We also fit the results to a recently developed model of nematic elastomers.",Materials Science
"Nematic elastomers are a particular class of liquid crystal elastomers (LCEs) that exhibit both liquid-crystalline order and rubber (entropic) elasticity. This combination makes them stimuli-responsive soft materials with a number of unusual thermo-mechanical properties. They have been proposed for various applications, including soft robotics, enhanced adhesion, and impact resistance. This paper presents a new experimental setup and a comprehensive dataset characterizing the soft behavior of nematic elastomers over a range of temperatures and strain rates. We also fit the results to a recently developed model of nematic elastomers. [SEP] [HINT] order -> Materials Science (Syns: enjoin, dictate, social club) | experimental -> Materials Science (Syns: data-based, observational) | results -> Bioinformatics (Syns: final result, consequence, resultant role)",Materials Science
"The compressive and post-buckling behavior of Ti2C and Ti2CO2 MXene nanosheets is studied using large-scale reactive molecular dynamics simulations. Nanosheets are subjected to uniaxial, biaxial, and shear loads to investigate their buckling modes, atomic-level deformation mechanisms, and failure characteristics. The results indicate that classical continuum mechanics significantly overestimates the buckling strains. Nanosheets exhibit higher resistance to buckling along the armchair direction than along the zigzag direction. Although atomic-scale defects reduce the buckling stress, they influence deformation only locally and do not alter the global buckling mode shapes. Lateral confinement pressure, such as that caused by polymerization-induced shrinkage in MXene-polymer composites, substantially increases the buckling stress. Oxygen surface termination increases the buckling stress from approximately 1 GPa to 3.5 GPa and reduces directional anisotropy in the elastic response. Under large compressive strains, Ti2CO2 nanosheets fracture, whereas Ti2C nanosheets retain structural integrity at strains exceeding 0.35. Atomistic analysis reveals opposite stress states in the top and bottom Ti layers due to curvature-induced strain gradients. Under biaxial compression, the nanosheet buckles in a dome-like shape, whereas shear loads produce elliptical deflection modes. The presented findings stimulate future studies on MXene morphological transformations, such as the development of nanotube, nanoscroll, and folded architectures.",Materials Science
"The compressive and post-buckling behavior of Ti2C and Ti2CO2 MXene nanosheets is studied using large-scale reactive molecular dynamics simulations. Nanosheets are subjected to uniaxial, biaxial, and shear loads to investigate their buckling modes, atomic-level deformation mechanisms, and failure characteristics. The results indicate that classical continuum mechanics significantly overestimates the buckling strains. Nanosheets exhibit higher resistance to buckling along the armchair direction than along the zigzag direction. Although atomic-scale defects reduce the buckling stress, they influence deformation only locally and do not alter the global buckling mode shapes. Lateral confinement pressure, such as that caused by polymerization-induced shrinkage in MXene-polymer composites, substantially increases the buckling stress. Oxygen surface termination increases the buckling stress from approximately 1 GPa to 3.5 GPa and reduces directional anisotropy in the elastic response. Under large compressive strains, Ti2CO2 nanosheets fracture, whereas Ti2C nanosheets retain structural integrity at strains exceeding 0.35. Atomistic analysis reveals opposite stress states in the top and bottom Ti layers due to curvature-induced strain gradients. Under biaxial compression, the nanosheet buckles in a dome-like shape, whereas shear loads produce elliptical deflection modes. The presented findings stimulate future studies on MXene morphological transformations, such as the development of nanotube, nanoscroll, and folded architectures. [SEP] [HINT] molecular -> Bioinformatics (Syns: ) | results -> Bioinformatics (Syns: final result, consequence, resultant role) | using -> Bioinformatics (Syns: utilize, exploitation, apply)",Materials Science
"Memristors have emerged as ideal components for modeling synaptic connections in neural networks due to their ability to emulate synaptic plasticity and memory effects. Discrete models of memristor-coupled neurons are crucial for simplifying computations and efficiently analyzing large-scale neural networks. Furthermore, incorporating fractional-order calculus into discrete models enhances their capacity to capture the memory and hereditary properties inherent in biological neurons, thus reducing numerical discretization errors compared to integer-order models. Despite this potential, discrete fractional-order neural models coupled through memristors have received limited attention. To address this gap, we introduce two novel discrete fractional-order neural systems. The first system consists of two Rulkov neurons coupled via dual memristors to emulate synaptic functions. The second system expands this configuration into a ring-shaped network of neurons consisting of multiple similar subnetworks. We present a novel theorem that defines stability regions for discrete fractional-order systems, applicable to both proposed models. Integrating discrete fractional-order calculus into memristor-coupled neural models provides a foundation for more accurate and efficient simulations of neural dynamics. This work advances the understanding of neural network stability and paves the way for future research into efficient neural computations.",Neuroscience
"Memristors have emerged as ideal components for modeling synaptic connections in neural networks due to their ability to emulate synaptic plasticity and memory effects. Discrete models of memristor-coupled neurons are crucial for simplifying computations and efficiently analyzing large-scale neural networks. Furthermore, incorporating fractional-order calculus into discrete models enhances their capacity to capture the memory and hereditary properties inherent in biological neurons, thus reducing numerical discretization errors compared to integer-order models. Despite this potential, discrete fractional-order neural models coupled through memristors have received limited attention. To address this gap, we introduce two novel discrete fractional-order neural systems. The first system consists of two Rulkov neurons coupled via dual memristors to emulate synaptic functions. The second system expands this configuration into a ring-shaped network of neurons consisting of multiple similar subnetworks. We present a novel theorem that defines stability regions for discrete fractional-order systems, applicable to both proposed models. Integrating discrete fractional-order calculus into memristor-coupled neural models provides a foundation for more accurate and efficient simulations of neural dynamics. This work advances the understanding of neural network stability and paves the way for future research into efficient neural computations. [SEP] [HINT] understanding -> Neuroscience (Syns: savvy, intellect, sympathy) | networks -> Neuroscience (Syns: network, meshwork, electronic network) | work -> Bioinformatics (Syns: work out, process, bring)",Neuroscience
"The Fe-O system is fundamental to understanding the composition and properties of the Earth's core. Recent studies have suggested the possible existence of stable, iron-rich FenO compounds at around 215 GPa. Here, we performed crystal-structure searches and fully anharmonic free-energy calculations to investigate the Fe-FeO system under inner-core conditions. We identified Fe2O as a stable phase and constructed its high P-T phase diagram. Fe2O undergoes a hexagonal-to-tetragonal transition with increasing pressure and temperature. It remains thermodynamically stable against decomposition into Fe and FeO from 200 to 400 GPa and at high temperatures. Although oxygen has been considered nearly absent in the inner core due to its limited solubility, these results suggest that oxygen can, in fact, be incorporated into the solid inner core in the form of an Fe+Fe2O mixture, and can match PREM densities for 53 mol% Fe2O. Our work has the potential to lead to a significant revision of the current understanding of the core's structure and composition.",Materials Science
"The Fe-O system is fundamental to understanding the composition and properties of the Earth's core. Recent studies have suggested the possible existence of stable, iron-rich FenO compounds at around 215 GPa. Here, we performed crystal-structure searches and fully anharmonic free-energy calculations to investigate the Fe-FeO system under inner-core conditions. We identified Fe2O as a stable phase and constructed its high P-T phase diagram. Fe2O undergoes a hexagonal-to-tetragonal transition with increasing pressure and temperature. It remains thermodynamically stable against decomposition into Fe and FeO from 200 to 400 GPa and at high temperatures. Although oxygen has been considered nearly absent in the inner core due to its limited solubility, these results suggest that oxygen can, in fact, be incorporated into the solid inner core in the form of an Fe+Fe2O mixture, and can match PREM densities for 53 mol% Fe2O. Our work has the potential to lead to a significant revision of the current understanding of the core's structure and composition. [SEP] [HINT] transition -> Materials Science (Syns: passage, modulation, changeover) | understanding -> Neuroscience (Syns: savvy, intellect, sympathy) | structure -> Bioinformatics (Syns: social system, complex body part, social structure)",Materials Science
"4E views of cognition seek to replace many of the long-held assumptions of tra- ditional cognitive science. One of the most radical shifts is the rejection of the sandwich model of cognition [8], which holds that mental processes are located be- tween action and perception. Subversion of such a long-held assumption requires an accessible theoretical alternative with firm experimental support. One unifying thread among the emerging 4E camps is their shared insistence that sensorimotor contingencies (SMCs) are such an alternative.",Neuroscience
"4E views of cognition seek to replace many of the long-held assumptions of tra- ditional cognitive science. One of the most radical shifts is the rejection of the sandwich model of cognition [8], which holds that mental processes are located be- tween action and perception. Subversion of such a long-held assumption requires an accessible theoretical alternative with firm experimental support. One unifying thread among the emerging 4E camps is their shared insistence that sensorimotor contingencies (SMCs) are such an alternative. [SEP] [HINT] experimental -> Materials Science (Syns: data-based, observational) | cognitive -> Neuroscience (Syns: ) | model -> Bioinformatics (Syns: exemplary, framework, modelling)",Neuroscience
"Excitons, the correlated electron-hole pairs governing optical and transport properties in organic semiconductors, have long resisted direct experimental access to their full quantum-mechanical wave functions. Here, we use femtosecond time-resolved photoemission orbital tomography (trPOT), combining high-harmonic probe pulses with time- and momentum-resolved photoelectron spectroscopy, to directly image the momentum-space distribution and ultrafast dynamics of excitons in $α$-sexithiophene thin films. We introduce a quantitative model that enables reconstruction of the exciton wave function in real space, including both its spatial extent and its internal phase structure. The reconstructed wave function reveals coherent delocalization across approximately three molecular units and exhibits a characteristic phase modulation, consistent with ab initio calculations within the framework of many-body perturbation theory. Time-resolved measurements further show a $\sim 20$\% contraction of the exciton radius within 400 fs, providing direct evidence of self-trapping driven by exciton-phonon coupling. These results establish trPOT as a general and experimentally accessible approach for resolving exciton wave functions -- with spatial, phase, and temporal sensitivity -- in a broad class of molecular and low-dimensional materials.",Materials Science
"Excitons, the correlated electron-hole pairs governing optical and transport properties in organic semiconductors, have long resisted direct experimental access to their full quantum-mechanical wave functions. Here, we use femtosecond time-resolved photoemission orbital tomography (trPOT), combining high-harmonic probe pulses with time- and momentum-resolved photoelectron spectroscopy, to directly image the momentum-space distribution and ultrafast dynamics of excitons in $α$-sexithiophene thin films. We introduce a quantitative model that enables reconstruction of the exciton wave function in real space, including both its spatial extent and its internal phase structure. The reconstructed wave function reveals coherent delocalization across approximately three molecular units and exhibits a characteristic phase modulation, consistent with ab initio calculations within the framework of many-body perturbation theory. Time-resolved measurements further show a $\sim 20$\% contraction of the exciton radius within 400 fs, providing direct evidence of self-trapping driven by exciton-phonon coupling. These results establish trPOT as a general and experimentally accessible approach for resolving exciton wave functions -- with spatial, phase, and temporal sensitivity -- in a broad class of molecular and low-dimensional materials. [SEP] [HINT] transport -> Materials Science (Syns: transferral, enthral, shipping) | molecular -> Bioinformatics (Syns: ) | results -> Bioinformatics (Syns: final result, consequence, resultant role)",Materials Science
"Recent breakthroughs in artificial intelligence (AI) are reshaping the way we construct computational counterparts of the brain, giving rise to a new class of ``surrogate brains''. In contrast to conventional hypothesis-driven biophysical models, the AI-based surrogate brain encompasses a broad spectrum of data-driven approaches to solve the inverse problem, with the primary objective of accurately predicting future whole-brain dynamics with historical data. Here, we introduce a unified framework of constructing an AI-based surrogate brain that integrates forward modeling, inverse problem solving, and model evaluation. Leveraging the expressive power of AI models and large-scale brain data, surrogate brains open a new window for decoding neural systems and forecasting complex dynamics with high dimensionality, nonlinearity, and adaptability. We highlight that the learned surrogate brain serves as a simulation platform for dynamical systems analysis, virtual perturbation, and model-guided neurostimulation. We envision that the AI-based surrogate brain will provide a functional bridge between theoretical neuroscience and translational neuroengineering.",Neuroscience
"Recent breakthroughs in artificial intelligence (AI) are reshaping the way we construct computational counterparts of the brain, giving rise to a new class of ``surrogate brains''. In contrast to conventional hypothesis-driven biophysical models, the AI-based surrogate brain encompasses a broad spectrum of data-driven approaches to solve the inverse problem, with the primary objective of accurately predicting future whole-brain dynamics with historical data. Here, we introduce a unified framework of constructing an AI-based surrogate brain that integrates forward modeling, inverse problem solving, and model evaluation. Leveraging the expressive power of AI models and large-scale brain data, surrogate brains open a new window for decoding neural systems and forecasting complex dynamics with high dimensionality, nonlinearity, and adaptability. We highlight that the learned surrogate brain serves as a simulation platform for dynamical systems analysis, virtual perturbation, and model-guided neurostimulation. We envision that the AI-based surrogate brain will provide a functional bridge between theoretical neuroscience and translational neuroengineering. [SEP] [HINT] decoding -> Neuroscience (Syns: decrypt, decipherment, decryption) | computational -> Neuroscience (Syns: ) | functional -> Neuroscience (Syns: working, usable, running)",Neuroscience
"Among van der Waals crystals, transition metal trihalide VI3 has driven attention for its magnetic and orbital properties. However, its chemical instability under ambient conditions make its exploitation challenging for technological implementation. In this context, here we show how synchrotron radiation soft X-rays partially restore stoichiometric chemical and electronic properties of VI3 crystals. By combining X-ray absorption and X-ray photoemission spectroscopies, we show as-cleaved and aged (in ultra-high vacuum conditions) chemical degradation of VI3 crystal surface, with the formation of vanadates, and its, at least partial, recovery under high-flux soft X-ray beam exposure, revealing that superficial hygroscopic contamination couples relatively weakly to the crystal surface.",Materials Science
"Among van der Waals crystals, transition metal trihalide VI3 has driven attention for its magnetic and orbital properties. However, its chemical instability under ambient conditions make its exploitation challenging for technological implementation. In this context, here we show how synchrotron radiation soft X-rays partially restore stoichiometric chemical and electronic properties of VI3 crystals. By combining X-ray absorption and X-ray photoemission spectroscopies, we show as-cleaved and aged (in ultra-high vacuum conditions) chemical degradation of VI3 crystal surface, with the formation of vanadates, and its, at least partial, recovery under high-flux soft X-ray beam exposure, revealing that superficial hygroscopic contamination couples relatively weakly to the crystal surface. [SEP] [HINT] transition -> Materials Science (Syns: passage, modulation, changeover) | electronic -> Materials Science (Syns: ) | metal -> Materials Science (Syns: metallic element, metallic, alloy)",Materials Science
"T cells are central to the adaptive immune response, capable of detecting pathogenic antigens while ignoring healthy tissues with remarkable specificity and sensitivity. Quantitatively understanding how T cell receptors (TCRs) discriminate among antigens requires biophysical models and theoretical analysis of signaling networks. Here, we review current theoretical frameworks of antigen recognition in the context of modern experimental and computational advances. Antigen potency spans a continuum and exhibits nonlinear effects within complex mixtures, challenging discrete classification and simple threshold-based models. This complexity motivates the development of models such as adaptive kinetic proofreading, which integrate both activating and inhibitory signals. Advances in high-throughput technologies now generate large-scale, quantitative datasets, enabling the refinement of such models through statistical and machine learning approaches. This convergence of theory, data, and computation promises deeper insights into immune decision-making and opens new avenues for rational immunotherapy design.",Bioinformatics
"T cells are central to the adaptive immune response, capable of detecting pathogenic antigens while ignoring healthy tissues with remarkable specificity and sensitivity. Quantitatively understanding how T cell receptors (TCRs) discriminate among antigens requires biophysical models and theoretical analysis of signaling networks. Here, we review current theoretical frameworks of antigen recognition in the context of modern experimental and computational advances. Antigen potency spans a continuum and exhibits nonlinear effects within complex mixtures, challenging discrete classification and simple threshold-based models. This complexity motivates the development of models such as adaptive kinetic proofreading, which integrate both activating and inhibitory signals. Advances in high-throughput technologies now generate large-scale, quantitative datasets, enabling the refinement of such models through statistical and machine learning approaches. This convergence of theory, data, and computation promises deeper insights into immune decision-making and opens new avenues for rational immunotherapy design. [SEP] [HINT] computational -> Neuroscience (Syns: ) | understanding -> Neuroscience (Syns: savvy, intellect, sympathy) | learning -> Bioinformatics (Syns: take, teach, acquire)",Bioinformatics
"Current spinal pain management procedures, such as radiofrequency ablation (RFA) and epidural steroid injection (ESI), rely on fluoroscopy for needle placement which exposes patients and physicians to ionizing radiation. In this paper, we investigate a radiation-free surgical navigation system for spinal pain management procedures that combines magnetic resonance imaging (MRI) with fiducial ArUco marker-based augmented reality (AR). High-resolution MRI scans of a lumbar spinal phantom were obtained and assembled as a surface mesh. Laplacian smoothing algorithms were then applied to smoothen the surface and improve the model fidelity. A commercially available stereo camera (ZED2) was used to track single or dual fiducial ArUco markers on the patient to determine the patient's real-time pose. Custom AR software was applied to overlay the MRI image onto the patient, allowing the physician to see not only the outer surface of the patient but also the complete anatomy of the patient below the surface. Needle-insertion trials on a 3D-printed 3-vertebra phantom showed that dual-ArUco marker tracking increased the accuracy of needle insertions and reduced the average needle misplacement distance compared to single-ArUco marker procedures. The average needle misplacement is comparable to the average deviation of 2 mm for conventional epidural techniques using fluoroscopy. Our radiation-free system demonstrates promise to serve as an alternative to fluoroscopy by improving image-guided spinal navigation.",Bioinformatics
"Current spinal pain management procedures, such as radiofrequency ablation (RFA) and epidural steroid injection (ESI), rely on fluoroscopy for needle placement which exposes patients and physicians to ionizing radiation. In this paper, we investigate a radiation-free surgical navigation system for spinal pain management procedures that combines magnetic resonance imaging (MRI) with fiducial ArUco marker-based augmented reality (AR). High-resolution MRI scans of a lumbar spinal phantom were obtained and assembled as a surface mesh. Laplacian smoothing algorithms were then applied to smoothen the surface and improve the model fidelity. A commercially available stereo camera (ZED2) was used to track single or dual fiducial ArUco markers on the patient to determine the patient's real-time pose. Custom AR software was applied to overlay the MRI image onto the patient, allowing the physician to see not only the outer surface of the patient but also the complete anatomy of the patient below the surface. Needle-insertion trials on a 3D-printed 3-vertebra phantom showed that dual-ArUco marker tracking increased the accuracy of needle insertions and reduced the average needle misplacement distance compared to single-ArUco marker procedures. The average needle misplacement is comparable to the average deviation of 2 mm for conventional epidural techniques using fluoroscopy. Our radiation-free system demonstrates promise to serve as an alternative to fluoroscopy by improving image-guided spinal navigation. [SEP] [HINT] used -> Bioinformatics (Syns: utilize, ill-used, apply) | using -> Bioinformatics (Syns: utilize, exploitation, apply) | imaging -> Bioinformatics (Syns: imagery, imagination, visualise)",Bioinformatics
"We report the synthesis and physical properties of a polycrystalline, hexagonal boride YRu$_3$B$_2$. Our resistivity and heat capacity measurements indicate that YRu$_3$B$_2$ is a weakly coupled superconductor, with critical temperature $T_c$ = 0.63 K and upper critical field $μ_0 H_{c2}$ (0)=0.11 T. Density functional theory calculations, together with chemical-bonding analysis, reveal that the electronic states at and near the Fermi energy level are dominated by the Ru kagome sublattice.",Materials Science
"We report the synthesis and physical properties of a polycrystalline, hexagonal boride YRu$_3$B$_2$. Our resistivity and heat capacity measurements indicate that YRu$_3$B$_2$ is a weakly coupled superconductor, with critical temperature $T_c$ = 0.63 K and upper critical field $μ_0 H_{c2}$ (0)=0.11 T. Density functional theory calculations, together with chemical-bonding analysis, reveal that the electronic states at and near the Fermi energy level are dominated by the Ru kagome sublattice. [SEP] [HINT] measurements -> Materials Science (Syns: mensuration, measure, measurement) | temperature -> Materials Science (Syns: ) | field -> Materials Science (Syns: field of honor, line of business, orbit)",Materials Science
"Two-dimensional (2D) silicides are an emerging class of materials whose magnetic and relativistic properties remain largely unexplored. Using first-principles calculations, we investigate how electric-field modulation and transition-metal doping influence the magnetic exchange, magnetocrystalline anisotropy, and antisymmetric Dzyaloshinskii-Moriya interaction (DMI) in monolayer Ti2Si. Pristine Ti2Si is a dynamically stable ferromagnetic metal with in-plane anisotropy and centrosymmetric bonding, which suppresses DMI even under strong perpendicular electric fields. To overcome this symmetry constraint, we introduce Pt and Co substitution at Ti sites. Co enhances the magnetic exchange, whereas Pt provides strong spin orbit coupling (SOC), and the combined chemical asymmetry breaks inversion symmetry sufficiently to induce a sizable DMI. A Wannier-based tight-binding model captures the orbital-resolved superexchange pathways and reveals a clear hierarchy between a weak Si-mediated channel and a dominant Pt-mediated interlayer channel. First-principles calculations confirm that the Pt-assisted pathway governs the magnitude and sign of the total DMI. Among all configurations, Pt0.5CoTi0.5Si exhibits the strongest chiral interaction, with its intralayer and interlayer contributions favoring opposite rotation senses, namely counterclockwise (CCW) and clockwise (CW). Our results establish chemically engineered Ti2Si monolayers as a promising platform for realizing and tuning chiral magnetic textures in 2D silicides.",Materials Science
"Two-dimensional (2D) silicides are an emerging class of materials whose magnetic and relativistic properties remain largely unexplored. Using first-principles calculations, we investigate how electric-field modulation and transition-metal doping influence the magnetic exchange, magnetocrystalline anisotropy, and antisymmetric Dzyaloshinskii-Moriya interaction (DMI) in monolayer Ti2Si. Pristine Ti2Si is a dynamically stable ferromagnetic metal with in-plane anisotropy and centrosymmetric bonding, which suppresses DMI even under strong perpendicular electric fields. To overcome this symmetry constraint, we introduce Pt and Co substitution at Ti sites. Co enhances the magnetic exchange, whereas Pt provides strong spin orbit coupling (SOC), and the combined chemical asymmetry breaks inversion symmetry sufficiently to induce a sizable DMI. A Wannier-based tight-binding model captures the orbital-resolved superexchange pathways and reveals a clear hierarchy between a weak Si-mediated channel and a dominant Pt-mediated interlayer channel. First-principles calculations confirm that the Pt-assisted pathway governs the magnitude and sign of the total DMI. Among all configurations, Pt0.5CoTi0.5Si exhibits the strongest chiral interaction, with its intralayer and interlayer contributions favoring opposite rotation senses, namely counterclockwise (CCW) and clockwise (CW). Our results establish chemically engineered Ti2Si monolayers as a promising platform for realizing and tuning chiral magnetic textures in 2D silicides. [SEP] [HINT] spin -> Materials Science (Syns: twisting, whirl, tailspin) | results -> Bioinformatics (Syns: final result, consequence, resultant role) | metal -> Materials Science (Syns: metallic element, metallic, alloy)",Materials Science
"The NIH Human BioMolecular Atlas Program (HuBMAP) Data Portal (https://portal.hubmapconsortium.org/) serves as a comprehensive repository for multi-modal spatial and single-cell data from healthy human tissues. This resource facilitates the NIH HuBMAP consortium's mission to create a widely accessible multi-scale spatial atlas of the healthy human body at single-cell resolution. As of October 2025, the portal hosts 5,032 datasets from 22 different data types spanning 27 organ classes across 310 donors. The portal's infrastructure and user interfaces enable efficient visualization and analysis directly in web browsers through integrated collaborative Jupyter workspaces and interactive Vitessce visualizations for over 1,500 non-spatial, 2D, and 3D spatial datasets. Uniform processing pipelines and rigorous quality control processes ensure comparability of results from different laboratories, organs, and donors for large-scale analyses, while externally processed, community-contributed datasets (EPICs) provide complementary perspectives. The portal interface supports both metadata- and data-driven search functionalities, bulk downloads, and integrated data collections, including supplementary data and visualizations for consortium publications.",Bioinformatics
"The NIH Human BioMolecular Atlas Program (HuBMAP) Data Portal (https://portal.hubmapconsortium.org/) serves as a comprehensive repository for multi-modal spatial and single-cell data from healthy human tissues. This resource facilitates the NIH HuBMAP consortium's mission to create a widely accessible multi-scale spatial atlas of the healthy human body at single-cell resolution. As of October 2025, the portal hosts 5,032 datasets from 22 different data types spanning 27 organ classes across 310 donors. The portal's infrastructure and user interfaces enable efficient visualization and analysis directly in web browsers through integrated collaborative Jupyter workspaces and interactive Vitessce visualizations for over 1,500 non-spatial, 2D, and 3D spatial datasets. Uniform processing pipelines and rigorous quality control processes ensure comparability of results from different laboratories, organs, and donors for large-scale analyses, while externally processed, community-contributed datasets (EPICs) provide complementary perspectives. The portal interface supports both metadata- and data-driven search functionalities, bulk downloads, and integrated data collections, including supplementary data and visualizations for consortium publications. [SEP] [HINT] quality -> Bioinformatics (Syns: lineament, tone, calibre) | processing -> Neuroscience (Syns: work, process, march) | datasets -> Bioinformatics (Syns: )",Bioinformatics
"The prevalence of online learning poses a vital challenge in real-time monitoring of students' concentration. Traditional methods such as questionnaire assessments require manual intervention, and webcam-based monitoring fails to provide accurate insights about learners' mental focus as it is deceived by mere screen fixation without cognitive engagement. Existing BCI-based approaches lack real-time validation and evaluation procedures. To address these limitations, a Brain-Computer Interface (BCI) system is developed using a non-invasive Electroencephalogram (EEG) headband, FocusCalm, to record brainwave activity under attentive and non-attentive states. 20 minutes of data were collected from each of 20 participants watching a pre-recorded educational video. The data validation employed a novel intra-video questionnaire assessment. Subsequently, collected signals were segmented (sliding window), filtered (Butterworth bandpass), and cleaned (removal of high-amplitude and EOG artifacts such as eye blinks). Time, frequency, wavelet, and statistical features were extracted, followed by recursive feature elimination (RFE) with support vector machines (SVMs) to classify attention and non-attention states. The leave-one-subject-out (LOSO) cross-validation accuracy was found to be 88.77%. The system provides feedback alerts upon detection of a non-attention state and maintains focus profile logs. A pilot study was conducted to evaluate the effectiveness of real-time feedback. Five participants underwent a 10-minute session comprising a 5-minute baseline phase devoid of feedback, succeeded by a 5-minute feedback phase, during which alerts were activated if participants exhibited inattention for approximately 8 consecutive seconds. A paired t-test (t = 5.73, p = 0.007) indicated a statistically significant improvement in concentration during the feedback phase.",Neuroscience
"The prevalence of online learning poses a vital challenge in real-time monitoring of students' concentration. Traditional methods such as questionnaire assessments require manual intervention, and webcam-based monitoring fails to provide accurate insights about learners' mental focus as it is deceived by mere screen fixation without cognitive engagement. Existing BCI-based approaches lack real-time validation and evaluation procedures. To address these limitations, a Brain-Computer Interface (BCI) system is developed using a non-invasive Electroencephalogram (EEG) headband, FocusCalm, to record brainwave activity under attentive and non-attentive states. 20 minutes of data were collected from each of 20 participants watching a pre-recorded educational video. The data validation employed a novel intra-video questionnaire assessment. Subsequently, collected signals were segmented (sliding window), filtered (Butterworth bandpass), and cleaned (removal of high-amplitude and EOG artifacts such as eye blinks). Time, frequency, wavelet, and statistical features were extracted, followed by recursive feature elimination (RFE) with support vector machines (SVMs) to classify attention and non-attention states. The leave-one-subject-out (LOSO) cross-validation accuracy was found to be 88.77%. The system provides feedback alerts upon detection of a non-attention state and maintains focus profile logs. A pilot study was conducted to evaluate the effectiveness of real-time feedback. Five participants underwent a 10-minute session comprising a 5-minute baseline phase devoid of feedback, succeeded by a 5-minute feedback phase, during which alerts were activated if participants exhibited inattention for approximately 8 consecutive seconds. A paired t-test (t = 5.73, p = 0.007) indicated a statistically significant improvement in concentration during the feedback phase. [SEP] [HINT] features -> Bioinformatics (Syns: characteristic, lineament, feature of speech) | learning -> Bioinformatics (Syns: take, teach, acquire) | using -> Bioinformatics (Syns: utilize, exploitation, apply)",Neuroscience
"Calibrating mathematical models of biological processes is essential for achieving predictive accuracy and gaining mechanistic insight. However, this task remains challenging due to limited and noisy data, significant biological variability, and the computational complexity of the models themselves. In this method's article, we explore a range of approaches for parameter inference in partial differential equation (PDE) models of biological systems. We introduce a unified mathematical framework, the Correlation Integral Likelihood (CIL) method, for parameter estimation in systems exhibiting heterogeneous or chaotic dynamics, encompassing both pattern formation models and individual-based models. Departing from classical Bayesian inverse problem methodologies, we motivate the development of the CIL method, demonstrate its versatility, and highlight illustrative applications within mathematical biology. Furthermore, we compare stochastic sampling strategies, such as Markov Chain Monte Carlo (MCMC), with deterministic gradient flow approaches, highlighting how these methods can be integrated within the proposed framework to enhance inference performance. Our work provides a practical and theoretically grounded toolbox for researchers seeking to calibrate complex biological models using incomplete, noisy, or heterogeneous data, thereby advancing both the predictive capability and mechanistic understanding of such systems.",Bioinformatics
"Calibrating mathematical models of biological processes is essential for achieving predictive accuracy and gaining mechanistic insight. However, this task remains challenging due to limited and noisy data, significant biological variability, and the computational complexity of the models themselves. In this method's article, we explore a range of approaches for parameter inference in partial differential equation (PDE) models of biological systems. We introduce a unified mathematical framework, the Correlation Integral Likelihood (CIL) method, for parameter estimation in systems exhibiting heterogeneous or chaotic dynamics, encompassing both pattern formation models and individual-based models. Departing from classical Bayesian inverse problem methodologies, we motivate the development of the CIL method, demonstrate its versatility, and highlight illustrative applications within mathematical biology. Furthermore, we compare stochastic sampling strategies, such as Markov Chain Monte Carlo (MCMC), with deterministic gradient flow approaches, highlighting how these methods can be integrated within the proposed framework to enhance inference performance. Our work provides a practical and theoretically grounded toolbox for researchers seeking to calibrate complex biological models using incomplete, noisy, or heterogeneous data, thereby advancing both the predictive capability and mechanistic understanding of such systems. [SEP] [HINT] task -> Neuroscience (Syns: tax, project, chore) | computational -> Neuroscience (Syns: ) | understanding -> Neuroscience (Syns: savvy, intellect, sympathy)",Bioinformatics
"Recurrent neural networks with balanced excitation and inhibition exhibit irregular asynchronous dynamics, which is fundamental for cortical computations. Classical balance mechanisms require strong external inputs to sustain finite firing rates, raising concerns about their biological plausibility. Here, we investigate an alternative mechanism based on short-term synaptic depression (STD) acting on excitatory-excitatory synapses, which dynamically balances the network activity without the need of external inputs. By employing numerical simulations and theoretical investigations we characterize the dynamics of a massively coupled network made up of $N$ rate-neuron models. Depending on the synaptic strength $J_0$, the network exhibits two distinct regimes: at sufficiently small $J_0$, it converges to a homogeneous fixed point, while for sufficiently large $J_0$, it exhibits Rate Chaos. For finite networks, we observe several different routes to chaos depending on the network realization. The width of the transition region separating the homogeneous stable solution from Rate Chaos appears to shrink for increasing $N$ and eventually to vanish in the thermodynamic limit. The characterization of the Rate Chaos regime performed by employing Dynamical Mean Field approaches allow us on one side to confirm that this novel balancing mechanism is able to sustain finite irregular activity even in the thermodynamic limit, and on the other side to reveal that the balancing occurs via dynamic cancellation of the input correlations generated by the massive coupling. Our findings show that STD provides an intrinsic self-regulating mechanism for balanced networks, sustaining irregular yet stable activity without the need of biologically unrealistic inputs. This work extends the balanced network paradigm, offering insights into how cortical circuits could maintain robust dynamics via synaptic adaptation.",Neuroscience
"Recurrent neural networks with balanced excitation and inhibition exhibit irregular asynchronous dynamics, which is fundamental for cortical computations. Classical balance mechanisms require strong external inputs to sustain finite firing rates, raising concerns about their biological plausibility. Here, we investigate an alternative mechanism based on short-term synaptic depression (STD) acting on excitatory-excitatory synapses, which dynamically balances the network activity without the need of external inputs. By employing numerical simulations and theoretical investigations we characterize the dynamics of a massively coupled network made up of $N$ rate-neuron models. Depending on the synaptic strength $J_0$, the network exhibits two distinct regimes: at sufficiently small $J_0$, it converges to a homogeneous fixed point, while for sufficiently large $J_0$, it exhibits Rate Chaos. For finite networks, we observe several different routes to chaos depending on the network realization. The width of the transition region separating the homogeneous stable solution from Rate Chaos appears to shrink for increasing $N$ and eventually to vanish in the thermodynamic limit. The characterization of the Rate Chaos regime performed by employing Dynamical Mean Field approaches allow us on one side to confirm that this novel balancing mechanism is able to sustain finite irregular activity even in the thermodynamic limit, and on the other side to reveal that the balancing occurs via dynamic cancellation of the input correlations generated by the massive coupling. Our findings show that STD provides an intrinsic self-regulating mechanism for balanced networks, sustaining irregular yet stable activity without the need of biologically unrealistic inputs. This work extends the balanced network paradigm, offering insights into how cortical circuits could maintain robust dynamics via synaptic adaptation. [SEP] [HINT] field -> Materials Science (Syns: field of honor, line of business, orbit) | transition -> Materials Science (Syns: passage, modulation, changeover) | based -> Bioinformatics (Syns: ground, free-base, base)",Neuroscience
"We present a framework that combines Large Language Models with computational image analytics for non-invasive, zero-shot prediction of IDH mutation status in brain gliomas. For each subject, coregistered multi-parametric MRI scans and multi-class tumor segmentation maps were processed to extract interpretable semantic (visual) attributes and quantitative features, serialized in a standardized JSON file, and used to query GPT 4o and GPT 5 without fine-tuning. We evaluated this framework on six publicly available datasets (N = 1427) and results showcased high accuracy and balanced classification performance across heterogeneous cohorts, even in the absence of manual annotations. GPT 5 outperformed GPT 4o in context-driven phenotype interpretation. Volumetric features emerged as the most important predictors, supplemented by subtype-specific imaging markers and clinical information. Our results demonstrate the potential of integrating LLM-based reasoning with computational image analytics for precise, non-invasive tumor genotyping, advancing diagnostic strategies in neuro-oncology. The code is available at https://github.com/ATPLab-LUMS/CIM-LLM.",Bioinformatics
"We present a framework that combines Large Language Models with computational image analytics for non-invasive, zero-shot prediction of IDH mutation status in brain gliomas. For each subject, coregistered multi-parametric MRI scans and multi-class tumor segmentation maps were processed to extract interpretable semantic (visual) attributes and quantitative features, serialized in a standardized JSON file, and used to query GPT 4o and GPT 5 without fine-tuning. We evaluated this framework on six publicly available datasets (N = 1427) and results showcased high accuracy and balanced classification performance across heterogeneous cohorts, even in the absence of manual annotations. GPT 5 outperformed GPT 4o in context-driven phenotype interpretation. Volumetric features emerged as the most important predictors, supplemented by subtype-specific imaging markers and clinical information. Our results demonstrate the potential of integrating LLM-based reasoning with computational image analytics for precise, non-invasive tumor genotyping, advancing diagnostic strategies in neuro-oncology. The code is available at https://github.com/ATPLab-LUMS/CIM-LLM. [SEP] [HINT] used -> Bioinformatics (Syns: utilize, ill-used, apply) | clinical -> Bioinformatics (Syns: ) | language -> Neuroscience (Syns: linguistic process, linguistic communication, spoken communication)",Bioinformatics
"Recent advances in neural interfacing have enabled significant improvements in human-computer interaction, rehabilitation, and neuromuscular diagnostics. Motor unit (MU) decomposition from surface electromyography (sEMG) is a key technique for extracting neural drive information, but traditional blind source separation (BSS) methods fail to incorporate biophysical constraints, limiting their accuracy and interpretability. In this work, we introduce a novel Biophysical-Model-Informed Source Separation (BMISS) framework, which integrates anatomically accurate forward EMG models into the decomposition process. By leveraging MRI-based anatomical reconstructions and generative modeling, our approach enables direct inversion of a biophysically accurate forward model to estimate both neural drive and motor neuron properties in an unsupervised manner. Empirical validation in a controlled simulated setting demonstrates that BMISS achieves higher fidelity motor unit estimation while significantly reducing computational cost compared to traditional methods. This framework paves the way for non-invasive, personalized neuromuscular assessments, with potential applications in clinical diagnostics, prosthetic control, and neurorehabilitation.",Neuroscience
"Recent advances in neural interfacing have enabled significant improvements in human-computer interaction, rehabilitation, and neuromuscular diagnostics. Motor unit (MU) decomposition from surface electromyography (sEMG) is a key technique for extracting neural drive information, but traditional blind source separation (BSS) methods fail to incorporate biophysical constraints, limiting their accuracy and interpretability. In this work, we introduce a novel Biophysical-Model-Informed Source Separation (BMISS) framework, which integrates anatomically accurate forward EMG models into the decomposition process. By leveraging MRI-based anatomical reconstructions and generative modeling, our approach enables direct inversion of a biophysically accurate forward model to estimate both neural drive and motor neuron properties in an unsupervised manner. Empirical validation in a controlled simulated setting demonstrates that BMISS achieves higher fidelity motor unit estimation while significantly reducing computational cost compared to traditional methods. This framework paves the way for non-invasive, personalized neuromuscular assessments, with potential applications in clinical diagnostics, prosthetic control, and neurorehabilitation. [SEP] [HINT] clinical -> Bioinformatics (Syns: ) | computational -> Neuroscience (Syns: ) | framework -> Bioinformatics (Syns: theoretical account, model, fabric)",Neuroscience
"PbTiO$_3$ is a ferroelectric perovskite semiconductor with favourable electronic and optical properties, making it suitable for a wide range of applications, including photo-catalysis and (opto)electronic devices. Despite its relevance, an accurate ab-initio description of the optical absorption spectrum and of the impact of ferroelectric distortion on the excitonic properties is still lacking. We combine $G_0W_0$ and Bethe-Salpeter Equation calculations to investigate the electronic and optical properties of PbTiO$_3$, tracking the evolution of its excitonic spectrum along the transition from the cubic paraelectric to the tetragonal ferroelectric phase. As the polar distortion increases, the first absorption peak of the cubic phase splits into two distinct features due to symmetry breaking, which partially lifts the degeneracy of the underlying excitonic state. Crucially, the distortion further introduces an in-plane/out-of-plane anisotropy in the spectra and controls the energy separation between the resulting excitonic branches. These findings highlight the potential for tuning the optical absorption properties of PbTiO$_3$ via the application of an external electric field.",Materials Science
"PbTiO$_3$ is a ferroelectric perovskite semiconductor with favourable electronic and optical properties, making it suitable for a wide range of applications, including photo-catalysis and (opto)electronic devices. Despite its relevance, an accurate ab-initio description of the optical absorption spectrum and of the impact of ferroelectric distortion on the excitonic properties is still lacking. We combine $G_0W_0$ and Bethe-Salpeter Equation calculations to investigate the electronic and optical properties of PbTiO$_3$, tracking the evolution of its excitonic spectrum along the transition from the cubic paraelectric to the tetragonal ferroelectric phase. As the polar distortion increases, the first absorption peak of the cubic phase splits into two distinct features due to symmetry breaking, which partially lifts the degeneracy of the underlying excitonic state. Crucially, the distortion further introduces an in-plane/out-of-plane anisotropy in the spectra and controls the energy separation between the resulting excitonic branches. These findings highlight the potential for tuning the optical absorption properties of PbTiO$_3$ via the application of an external electric field. [SEP] [HINT] transition -> Materials Science (Syns: passage, modulation, changeover) | features -> Bioinformatics (Syns: characteristic, lineament, feature of speech) | perovskite -> Materials Science (Syns: )",Materials Science
"Designing metal-organic frameworks (MOFs) synthesis protocols is currently largely driven by trial-and-error, since we lack fundamental understanding of the molecular level mechanisms that underlie their self-assembly processes. Previous works have studied the nucleation of MOFs, but their growth has never been studied by means of computer simulations, which provide molecular level detail. In this work, we combine constant chemical potential simulations with a particle insertion method to model the growth of the ZIF-8 MOF at varying synthesis temperatures and concentrations of the reactants. Non-classical growth mechanisms triggered by oligomer attachments were detected, with a higher predominance in the most concentrated setups. The newly formed layers preserve the pore-like density profile of the seed crystal but contain defective sites characterized by the presence of 3, 5 and 7 membered rings, typical of amorphous phases. Compared to the amorphous intermediate species obtained at the nucleation part of the self-assembly process previously investigated in our group [Chem. Mater., doi: 10.1021/acs.chemmater.5c02028, 2025], larger-sized rings are more common in the grown layer. Moreover, these are favored by increasing reactant concentration and temperature, as is the degree of deviation with respect to the original crystal structure. We computed growth rates for the steady-state regime, and the non-linear tendency with respect to concentration leads us to hypothesize that in these conditions the growth is controlled by the adsorption rather than by the diffusion processes.",Materials Science
"Designing metal-organic frameworks (MOFs) synthesis protocols is currently largely driven by trial-and-error, since we lack fundamental understanding of the molecular level mechanisms that underlie their self-assembly processes. Previous works have studied the nucleation of MOFs, but their growth has never been studied by means of computer simulations, which provide molecular level detail. In this work, we combine constant chemical potential simulations with a particle insertion method to model the growth of the ZIF-8 MOF at varying synthesis temperatures and concentrations of the reactants. Non-classical growth mechanisms triggered by oligomer attachments were detected, with a higher predominance in the most concentrated setups. The newly formed layers preserve the pore-like density profile of the seed crystal but contain defective sites characterized by the presence of 3, 5 and 7 membered rings, typical of amorphous phases. Compared to the amorphous intermediate species obtained at the nucleation part of the self-assembly process previously investigated in our group [Chem. Mater., doi: 10.1021/acs.chemmater.5c02028, 2025], larger-sized rings are more common in the grown layer. Moreover, these are favored by increasing reactant concentration and temperature, as is the degree of deviation with respect to the original crystal structure. We computed growth rates for the steady-state regime, and the non-linear tendency with respect to concentration leads us to hypothesize that in these conditions the growth is controlled by the adsorption rather than by the diffusion processes. [SEP] [HINT] understanding -> Neuroscience (Syns: savvy, intellect, sympathy) | molecular -> Bioinformatics (Syns: ) | crystal -> Materials Science (Syns: crystallization, quartz, lechatelierite)",Materials Science
"The use of differential phase contrast (DPC) in scanning transmission electron microscopy (STEM) has shown much promise for directly investigating the functional properties of a material system, leveraging the natural coupling between the electron probe and atomic-scale electric fields to map the electrostatic configuration within a sample. However, the high sensitivity of these measurements makes them particularly vulnerable to variations in both sample properties and the configuration of the instrument, stressing the need for robust methodologies to ensure more accurate analyses. In this work, the influence of key instrumental parameters - probe convergence angle, defocus and two-fold astigmatism - on atomic-resolution segmented-detector DPC-STEM measurements is evaluated through extensive image simulations. Results show that the limit of interpretability for a 21 mrad defocused probe is found at a magnitude of 4 nm, where electrostatic field magnitude can be underestimated by about 16 % in overfocus and just above 10 % in underfocus. Equivalent results for a 30 mrad probe demonstrate underestimated values around 30 % at overfocus and 20 % for underfocus, at a lower interpretability limit of 3 nm. Two-fold astigmatism introduces orientation dependent variations that surpass 40 % for magnitudes below 3 nm, but a reduction in sensitivity to the aberration is observed when oriented along detector-segment edges. Overall, the analysis confirms the sensitivity and usefulness of the scattergram-based method and underscores the importance of optimized instrumental alignment for accurate CoM based STEM imaging.",Materials Science
"The use of differential phase contrast (DPC) in scanning transmission electron microscopy (STEM) has shown much promise for directly investigating the functional properties of a material system, leveraging the natural coupling between the electron probe and atomic-scale electric fields to map the electrostatic configuration within a sample. However, the high sensitivity of these measurements makes them particularly vulnerable to variations in both sample properties and the configuration of the instrument, stressing the need for robust methodologies to ensure more accurate analyses. In this work, the influence of key instrumental parameters - probe convergence angle, defocus and two-fold astigmatism - on atomic-resolution segmented-detector DPC-STEM measurements is evaluated through extensive image simulations. Results show that the limit of interpretability for a 21 mrad defocused probe is found at a magnitude of 4 nm, where electrostatic field magnitude can be underestimated by about 16 % in overfocus and just above 10 % in underfocus. Equivalent results for a 30 mrad probe demonstrate underestimated values around 30 % at overfocus and 20 % for underfocus, at a lower interpretability limit of 3 nm. Two-fold astigmatism introduces orientation dependent variations that surpass 40 % for magnitudes below 3 nm, but a reduction in sensitivity to the aberration is observed when oriented along detector-segment edges. Overall, the analysis confirms the sensitivity and usefulness of the scattergram-based method and underscores the importance of optimized instrumental alignment for accurate CoM based STEM imaging. [SEP] [HINT] field -> Materials Science (Syns: field of honor, line of business, orbit) | based -> Bioinformatics (Syns: ground, free-base, base) | functional -> Neuroscience (Syns: working, usable, running)",Materials Science
"In magnetic topological materials, time-reversal symmetry breaking gives rise to topological point and line nodes with distinctive signatures in the anomalous Hall and anomalous Nernst conductivity that satisfy the well-known Mott relation. However, this relationship can fail for doping-dependent transport measurements of materials with complex magnetism, topology, and electronic correlations. In this work, we present transport measurements of the correlated topological metal UCoAl doped with Ru, which appear to violate the Mott relation. We develop a model that captures the evolution of Stoner magnetism and topological Weyl points as a function of doping. Using this model, we show how the correlated flat band in this material pins the Weyl points to the Fermi energy, and demonstrate how this explains the unusual doping-dependent behavior of the anomalous Hall and anomalous Nernst conductivities in this material, while the Mott relation is in fact satisfied at each doping level.",Materials Science
"In magnetic topological materials, time-reversal symmetry breaking gives rise to topological point and line nodes with distinctive signatures in the anomalous Hall and anomalous Nernst conductivity that satisfy the well-known Mott relation. However, this relationship can fail for doping-dependent transport measurements of materials with complex magnetism, topology, and electronic correlations. In this work, we present transport measurements of the correlated topological metal UCoAl doped with Ru, which appear to violate the Mott relation. We develop a model that captures the evolution of Stoner magnetism and topological Weyl points as a function of doping. Using this model, we show how the correlated flat band in this material pins the Weyl points to the Fermi energy, and demonstrate how this explains the unusual doping-dependent behavior of the anomalous Hall and anomalous Nernst conductivities in this material, while the Mott relation is in fact satisfied at each doping level. [SEP] [HINT] transport -> Materials Science (Syns: transferral, enthral, shipping) | electronic -> Materials Science (Syns: ) | complex -> Bioinformatics (Syns: building complex, coordination compound, composite)",Materials Science
"All-electrical methods for nucleating, detecting, and manipulating spin textures in two-dimensional (2D) van der Waals (vdW) magnets can serve as fundamental building blocks for multi-state spintronic memory, logic, and neuromorphic computing applications. Unlike conventional ferromagnets, vdW ferromagnets such as Fe5GeTe2 with strong Dzyaloshinskii-Moriya interactions stabilize nanoscale chiral spin textures, including skyrmions and stripe domains. However, the sub-100 nm size of these spin textures has limited their study to sophisticated microscopy techniques. Here, we demonstrate all-electrical detection of spin textures in vdW itinerant ferromagnet Fe5GeTe2 using pure spin transport in a lateral graphene spin-valve device at room temperature. By engineering nanoscale constrictions or notches in Fe5GeTe2, we create spin textures that inject distinct spin polarizations into the graphene channel, where they are nonlocally sensed by a reference conventional ferromagnetic detector at room temperature. This enables the observation of anomalous multi-level spin-valve switching and Hanle spin precession signals, which are due to unique spin textures in Fe5GeTe2 and in sharp contrast to single-domains and conventional magnet-based devices. This all-electrical approach can provide direct access to the spin textures on an integrated 2D spintronic circuit without the need for ex-situ microscopic characterizations.",Materials Science
"All-electrical methods for nucleating, detecting, and manipulating spin textures in two-dimensional (2D) van der Waals (vdW) magnets can serve as fundamental building blocks for multi-state spintronic memory, logic, and neuromorphic computing applications. Unlike conventional ferromagnets, vdW ferromagnets such as Fe5GeTe2 with strong Dzyaloshinskii-Moriya interactions stabilize nanoscale chiral spin textures, including skyrmions and stripe domains. However, the sub-100 nm size of these spin textures has limited their study to sophisticated microscopy techniques. Here, we demonstrate all-electrical detection of spin textures in vdW itinerant ferromagnet Fe5GeTe2 using pure spin transport in a lateral graphene spin-valve device at room temperature. By engineering nanoscale constrictions or notches in Fe5GeTe2, we create spin textures that inject distinct spin polarizations into the graphene channel, where they are nonlocally sensed by a reference conventional ferromagnetic detector at room temperature. This enables the observation of anomalous multi-level spin-valve switching and Hanle spin precession signals, which are due to unique spin textures in Fe5GeTe2 and in sharp contrast to single-domains and conventional magnet-based devices. This all-electrical approach can provide direct access to the spin textures on an integrated 2D spintronic circuit without the need for ex-situ microscopic characterizations. [SEP] [HINT] spin -> Materials Science (Syns: twisting, whirl, tailspin) | transport -> Materials Science (Syns: transferral, enthral, shipping) | including -> Bioinformatics (Syns: admit, include, let in)",Materials Science
"Advances in AI have introduced several strong models in computational pathology to usher it into the era of multi-modal diagnosis, analysis, and interpretation. However, the current pathology-specific visual language models still lack capacities in making diagnosis with rigorous reasoning paths as well as handling divergent tasks, and thus challenges of building AI Copilots for real scenarios still exist. Here we introduce TeamPath, an AI system powered by reinforcement learning and router-enhanced solutions based on large-scale histopathology multimodal datasets, to work as a virtual assistant for expert-level disease diagnosis, patch-level information summarization, and cross-modality generation to integrate transcriptomic information for the clinical usage. We also collaborate with pathologists from Yale School of Medicine to demonstrate that TeamPath can assist them in working more efficiently by identifying and correcting expert conclusions and reasoning paths. Overall, TeamPath can flexibly choose the best settings according to the needs, and serve as an innovative and reliable system for information communication across different modalities and experts.",Bioinformatics
"Advances in AI have introduced several strong models in computational pathology to usher it into the era of multi-modal diagnosis, analysis, and interpretation. However, the current pathology-specific visual language models still lack capacities in making diagnosis with rigorous reasoning paths as well as handling divergent tasks, and thus challenges of building AI Copilots for real scenarios still exist. Here we introduce TeamPath, an AI system powered by reinforcement learning and router-enhanced solutions based on large-scale histopathology multimodal datasets, to work as a virtual assistant for expert-level disease diagnosis, patch-level information summarization, and cross-modality generation to integrate transcriptomic information for the clinical usage. We also collaborate with pathologists from Yale School of Medicine to demonstrate that TeamPath can assist them in working more efficiently by identifying and correcting expert conclusions and reasoning paths. Overall, TeamPath can flexibly choose the best settings according to the needs, and serve as an innovative and reliable system for information communication across different modalities and experts. [SEP] [HINT] based -> Bioinformatics (Syns: ground, free-base, base) | clinical -> Bioinformatics (Syns: ) | language -> Neuroscience (Syns: linguistic process, linguistic communication, spoken communication)",Bioinformatics
"Background: Non-linear alterations in brain network connectivity may represent early neural signatures of Alzheimer's disease (AD) pathology in cognitively normal older adults. Understanding these changes and their cognitive relevance could provide sensitive biomarkers for early detection. Most prior studies recruited participants from memory clinics, often with subjective memory concerns, limiting generalizability.   Methods: We examined 14 large-scale functional brain networks in 968 cognitively normal older adults recruited from the community using resting-state functional MRI, cerebrospinal fluid (CSF) biomarkers (amyloid-$β$ 1-42 [A$β$], total tau, phosphorylated tau 181), and neuropsychological assessments. Functional networks were identified using group independent component analysis.   Results: Inverted U-shaped associations between CSF A$β$ and functional connectivity were observed in the precuneus network and ventral default mode network (DMN), but not in the dorsal DMN, indicating network-specific vulnerability to early amyloid pathology. Higher connectivity in A$β$-related networks, including dorsal and ventral DMN, precuneus, and posterior salience networks, was associated with better visual memory, visuospatial, and executive performance. No significant relationships were observed between CSF tau and functional connectivity.   Conclusions: Using a large, community-based cohort, we demonstrate that non-linear alterations in functional connectivity occur in specific networks even during the asymptomatic phase of AD. Moreover, A$β$-related network connectivity is cognitively relevant, highlighting functional brain networks as promising imaging markers for early detection and prognosis of AD.",Neuroscience
"Background: Non-linear alterations in brain network connectivity may represent early neural signatures of Alzheimer's disease (AD) pathology in cognitively normal older adults. Understanding these changes and their cognitive relevance could provide sensitive biomarkers for early detection. Most prior studies recruited participants from memory clinics, often with subjective memory concerns, limiting generalizability.   Methods: We examined 14 large-scale functional brain networks in 968 cognitively normal older adults recruited from the community using resting-state functional MRI, cerebrospinal fluid (CSF) biomarkers (amyloid-$β$ 1-42 [A$β$], total tau, phosphorylated tau 181), and neuropsychological assessments. Functional networks were identified using group independent component analysis.   Results: Inverted U-shaped associations between CSF A$β$ and functional connectivity were observed in the precuneus network and ventral default mode network (DMN), but not in the dorsal DMN, indicating network-specific vulnerability to early amyloid pathology. Higher connectivity in A$β$-related networks, including dorsal and ventral DMN, precuneus, and posterior salience networks, was associated with better visual memory, visuospatial, and executive performance. No significant relationships were observed between CSF tau and functional connectivity.   Conclusions: Using a large, community-based cohort, we demonstrate that non-linear alterations in functional connectivity occur in specific networks even during the asymptomatic phase of AD. Moreover, A$β$-related network connectivity is cognitively relevant, highlighting functional brain networks as promising imaging markers for early detection and prognosis of AD. [SEP] [HINT] connectivity -> Neuroscience (Syns: ) | understanding -> Neuroscience (Syns: savvy, intellect, sympathy) | networks -> Neuroscience (Syns: network, meshwork, electronic network)",Neuroscience
"Modeling dynamical systems and unraveling their underlying causal relationships is central to many domains in the natural sciences. Various physical systems, such as those arising in cell biology, are inherently high-dimensional and stochastic in nature, and admit only partial, noisy state measurements. This poses a significant challenge for addressing the problems of modeling the underlying dynamics and inferring the network structure of these systems. Existing methods are typically tailored either for structure learning or modeling dynamics at the population level, but are limited in their ability to address both problems together. In this work, we address both problems simultaneously: we present StructureFlow, a novel and principled simulation-free approach for jointly learning the structure and stochastic population dynamics of physical systems. We showcase the utility of StructureFlow for the tasks of structure learning from interventions and dynamical (trajectory) inference of conditional population dynamics. We empirically evaluate our approach on high-dimensional synthetic systems, a set of biologically plausible simulated systems, and an experimental single-cell dataset. We show that StructureFlow can learn the structure of underlying systems while simultaneously modeling their conditional population dynamics -- a key step toward the mechanistic understanding of systems behavior.",Bioinformatics
"Modeling dynamical systems and unraveling their underlying causal relationships is central to many domains in the natural sciences. Various physical systems, such as those arising in cell biology, are inherently high-dimensional and stochastic in nature, and admit only partial, noisy state measurements. This poses a significant challenge for addressing the problems of modeling the underlying dynamics and inferring the network structure of these systems. Existing methods are typically tailored either for structure learning or modeling dynamics at the population level, but are limited in their ability to address both problems together. In this work, we address both problems simultaneously: we present StructureFlow, a novel and principled simulation-free approach for jointly learning the structure and stochastic population dynamics of physical systems. We showcase the utility of StructureFlow for the tasks of structure learning from interventions and dynamical (trajectory) inference of conditional population dynamics. We empirically evaluate our approach on high-dimensional synthetic systems, a set of biologically plausible simulated systems, and an experimental single-cell dataset. We show that StructureFlow can learn the structure of underlying systems while simultaneously modeling their conditional population dynamics -- a key step toward the mechanistic understanding of systems behavior. [SEP] [HINT] tasks -> Neuroscience (Syns: tax, task, project) | understanding -> Neuroscience (Syns: savvy, intellect, sympathy) | learning -> Bioinformatics (Syns: take, teach, acquire)",Bioinformatics
"Memory effects arise in many complex systems, from protein folding, to the spreading of epidemics and financial decisions. While so-called non-Markovian dynamics is common in larger systems with interacting components, observations in fundamental physical systems have been confined to specifically engineered cases. Here, we report the experimental observation of non-Markovian dynamics in an elemental material, crystalline cobalt. By driving this material with an intense terahertz electromagnetic field, we bring its magnetisation into a non-equilibrium state and follow its evolution. We measure the sample's low temperature magnetic response in the time domain which leads to an unexpectedly rich multi-peaked spectrum in the Fourier domain, that cannot be explained by established models. We use open quantum system theory, which predicts a non-Markovian memory kernel in the dynamical equations to capture the fundamental interaction between the spin system and the phonon bath. Simulations based on this theory produce a multi-peaked spectrum, which matches the measured one. Our non-Markovian approach is also able to reproduce the modification of the spectrum at higher temperatures. Our findings demonstrate that non-Markovian effects are observable at a much more fundamental level than previously thought, opening the door to their exploration and control in a broad range of condensed matter systems.",Materials Science
"Memory effects arise in many complex systems, from protein folding, to the spreading of epidemics and financial decisions. While so-called non-Markovian dynamics is common in larger systems with interacting components, observations in fundamental physical systems have been confined to specifically engineered cases. Here, we report the experimental observation of non-Markovian dynamics in an elemental material, crystalline cobalt. By driving this material with an intense terahertz electromagnetic field, we bring its magnetisation into a non-equilibrium state and follow its evolution. We measure the sample's low temperature magnetic response in the time domain which leads to an unexpectedly rich multi-peaked spectrum in the Fourier domain, that cannot be explained by established models. We use open quantum system theory, which predicts a non-Markovian memory kernel in the dynamical equations to capture the fundamental interaction between the spin system and the phonon bath. Simulations based on this theory produce a multi-peaked spectrum, which matches the measured one. Our non-Markovian approach is also able to reproduce the modification of the spectrum at higher temperatures. Our findings demonstrate that non-Markovian effects are observable at a much more fundamental level than previously thought, opening the door to their exploration and control in a broad range of condensed matter systems. [SEP] [HINT] phonon -> Materials Science (Syns: ) | low -> Materials Science (Syns: low-spirited, scurvy, depressed) | based -> Bioinformatics (Syns: ground, free-base, base)",Materials Science
"Tailoring the chemical composition of a high entropy oxide (HEO) is a powerful approach to enhancing desirable material properties. However, the targeted synthesis of HEO materials is often hindered by competing stabilizing and destabilizing factors, which are difficult to predict. This work examines the effects of increased configurational entropy on the phase formation and stability of four notable complex oxide families: perovskite ($AB$O$_3$), pyrochlore ($A_2B_2$O$_7$), Ruddlesden-Popper ($A_2B$O$_4$), and zirconium tungstate ($AB_2$O$_8$). Each of these structures has a tetravalent cation site, which we attempt to substitute with an entropic mixture of four cations, benchmarked by the parallel synthesis of a non-disordered reference compound. While all four target high entropy materials can be expected to form based on ionic radii criteria, only the high entropy perovskite Ba(Ti,Zr,Hf,Sn)O$_3$ is successfully synthesized. In the case of the pyrochlore, an entropy-stabilized defect fluorite is formed instead, while the Ruddlesden-Popper phase co-exists with multiple competing phases. For the tungstate, an unexpected deep eutectic point between the precursors results in melting that precedes the formation of a high entropy phase. Our case studies therefore illustrate that the stability of HEOs cannot be straightforwardly predicted based on ionic radii, lattice geometry, and charge-balancing considerations alone due to the underlying complexity of the interactions between the many chemical constituents.",Materials Science
"Tailoring the chemical composition of a high entropy oxide (HEO) is a powerful approach to enhancing desirable material properties. However, the targeted synthesis of HEO materials is often hindered by competing stabilizing and destabilizing factors, which are difficult to predict. This work examines the effects of increased configurational entropy on the phase formation and stability of four notable complex oxide families: perovskite ($AB$O$_3$), pyrochlore ($A_2B_2$O$_7$), Ruddlesden-Popper ($A_2B$O$_4$), and zirconium tungstate ($AB_2$O$_8$). Each of these structures has a tetravalent cation site, which we attempt to substitute with an entropic mixture of four cations, benchmarked by the parallel synthesis of a non-disordered reference compound. While all four target high entropy materials can be expected to form based on ionic radii criteria, only the high entropy perovskite Ba(Ti,Zr,Hf,Sn)O$_3$ is successfully synthesized. In the case of the pyrochlore, an entropy-stabilized defect fluorite is formed instead, while the Ruddlesden-Popper phase co-exists with multiple competing phases. For the tungstate, an unexpected deep eutectic point between the precursors results in melting that precedes the formation of a high entropy phase. Our case studies therefore illustrate that the stability of HEOs cannot be straightforwardly predicted based on ionic radii, lattice geometry, and charge-balancing considerations alone due to the underlying complexity of the interactions between the many chemical constituents. [SEP] [HINT] based -> Bioinformatics (Syns: ground, free-base, base) | perovskite -> Materials Science (Syns: ) | defect -> Materials Science (Syns: mar, shortcoming, fault)",Materials Science
"In the algorithmic (Kolmogorov) view, agents are programs that track and compress sensory streams using generative programs. We propose a framework where the relevant structural prior is simplicity (Solomonoff) understood as \emph{compositional symmetry}: natural streams are well described by (local) actions of finite-parameter Lie pseudogroups on geometrically and topologically complex low-dimensional configuration manifolds (latent spaces). Modeling the agent as a generic neural dynamical system coupled to such streams, we show that accurate world-tracking imposes (i) \emph{structural constraints} -- equivariance of the agent's constitutive equations and readouts -- and (ii) \emph{dynamical constraints}: under static inputs, symmetry induces conserved quantities (Noether-style labels) in the agent dynamics and confines trajectories to reduced invariant manifolds; under slow drift, these manifolds move but remain low-dimensional. This yields a hierarchy of reduced manifolds aligned with the compositional factorization of the pseudogroup, providing a geometric account of the ``blessing of compositionality'' in deep models. We connect these ideas to the Spencer formalism for Lie pseudogroups and formulate a symmetry-based, self-contained version of predictive coding in which higher layers receive only \emph{coarse-grained residual transformations} (prediction-error coordinates) along symmetry directions unresolved at lower layers.",Neuroscience
"In the algorithmic (Kolmogorov) view, agents are programs that track and compress sensory streams using generative programs. We propose a framework where the relevant structural prior is simplicity (Solomonoff) understood as \emph{compositional symmetry}: natural streams are well described by (local) actions of finite-parameter Lie pseudogroups on geometrically and topologically complex low-dimensional configuration manifolds (latent spaces). Modeling the agent as a generic neural dynamical system coupled to such streams, we show that accurate world-tracking imposes (i) \emph{structural constraints} -- equivariance of the agent's constitutive equations and readouts -- and (ii) \emph{dynamical constraints}: under static inputs, symmetry induces conserved quantities (Noether-style labels) in the agent dynamics and confines trajectories to reduced invariant manifolds; under slow drift, these manifolds move but remain low-dimensional. This yields a hierarchy of reduced manifolds aligned with the compositional factorization of the pseudogroup, providing a geometric account of the ``blessing of compositionality'' in deep models. We connect these ideas to the Spencer formalism for Lie pseudogroups and formulate a symmetry-based, self-contained version of predictive coding in which higher layers receive only \emph{coarse-grained residual transformations} (prediction-error coordinates) along symmetry directions unresolved at lower layers. [SEP] [HINT] complex -> Bioinformatics (Syns: building complex, coordination compound, composite) | framework -> Bioinformatics (Syns: theoretical account, model, fabric) | using -> Bioinformatics (Syns: utilize, exploitation, apply)",Neuroscience
"Two-dimensional (2D) molybdenum disulfide (MoS2) nanosheets have attracted attention as a promising and cost-effective alternative catalyst for the hydrogen evolution reaction (HER). However, their aggregation and poor conductivity limit their catalytic activity. Consequently, researchers are exploring ways to improve the conductivity and density of electroactive edges of MoS2 through hybridization with akin advanced 2D materials. Here, reduced graphene oxide (rGO) nanosheets are added to a liquid-phase-exfoliated MoS2 dispersion to create drop-casting hybrid MoS2@rGO electrodes for HER. The findings reveal the formation of ~1.1 nm-thick MoS2 bilayers, with the catalytic performance of MoS2@rGO dependent on the degree of graphene oxide reduction. The rGO moderate reduction prevents the MoS2 bilayers from restacking, improves conductivity, retains oxygenated groups that enhance interlayer spacing, and exposes more electroactive edges. When hybridized with rGO crafted at optimal reduction time, the hybrid system eclipses the efficiency of pristine MoS2 bilayers by attaining the lowest overpotential (~70 mV) and the lowest Tafel slope (~46 mV dec-1). This shows that MoS2 bilayers hybridized with rGO offer a promising method to outperform the electrocatalytic efficiency of MoS2-based electrodes. These findings expand opportunities for future strain engineering, defect engineering, and high-end twist-angle assemblies for hybrid systems combining MoS2 bilayers and rGO.",Materials Science
"Two-dimensional (2D) molybdenum disulfide (MoS2) nanosheets have attracted attention as a promising and cost-effective alternative catalyst for the hydrogen evolution reaction (HER). However, their aggregation and poor conductivity limit their catalytic activity. Consequently, researchers are exploring ways to improve the conductivity and density of electroactive edges of MoS2 through hybridization with akin advanced 2D materials. Here, reduced graphene oxide (rGO) nanosheets are added to a liquid-phase-exfoliated MoS2 dispersion to create drop-casting hybrid MoS2@rGO electrodes for HER. The findings reveal the formation of ~1.1 nm-thick MoS2 bilayers, with the catalytic performance of MoS2@rGO dependent on the degree of graphene oxide reduction. The rGO moderate reduction prevents the MoS2 bilayers from restacking, improves conductivity, retains oxygenated groups that enhance interlayer spacing, and exposes more electroactive edges. When hybridized with rGO crafted at optimal reduction time, the hybrid system eclipses the efficiency of pristine MoS2 bilayers by attaining the lowest overpotential (~70 mV) and the lowest Tafel slope (~46 mV dec-1). This shows that MoS2 bilayers hybridized with rGO offer a promising method to outperform the electrocatalytic efficiency of MoS2-based electrodes. These findings expand opportunities for future strain engineering, defect engineering, and high-end twist-angle assemblies for hybrid systems combining MoS2 bilayers and rGO. [SEP] [HINT] defect -> Materials Science (Syns: mar, shortcoming, fault) | performance -> Bioinformatics (Syns: functioning, operation, carrying out) | systems -> Bioinformatics (Syns: organization, organisation, system)",Materials Science
"Functional and structural connectivity (FC/SC) are key multimodal biomarkers for brain analysis, yet their clinical utility is hindered by costly acquisition, complex preprocessing, and frequent missing modalities. Existing foundation models either process single modalities or lack explicit mechanisms for cross-modal and cross-scale consistency. We propose BrainCSD, a hierarchical mixture-of-experts (MoE) foundation model that jointly synthesizes FC/SC biomarkers and supports downstream decoding tasks (diagnosis and prediction). BrainCSD features three neuroanatomically grounded components: (1) a ROI-specific MoE that aligns regional activations from canonical networks (e.g., DMN, FPN) with a global atlas via contrastive consistency; (2) a Encoding-Activation MOE that models dynamic cross-time/gradient dependencies in fMRI/dMRI; and (3) a network-aware refinement MoE that enforces structural priors and symmetry at individual and population levels. Evaluated on the datasets under complete and missing-modality settings, BrainCSD achieves SOTA results: 95.6\% accuracy for MCI vs. CN classification without FC, low synthesis error (FC RMSE: 0.038; SC RMSE: 0.006), brain age prediction (MAE: 4.04 years), and MMSE score estimation (MAE: 1.72 points). Code is available in \href{https://github.com/SXR3015/BrainCSD}{BrainCSD}",Neuroscience
"Functional and structural connectivity (FC/SC) are key multimodal biomarkers for brain analysis, yet their clinical utility is hindered by costly acquisition, complex preprocessing, and frequent missing modalities. Existing foundation models either process single modalities or lack explicit mechanisms for cross-modal and cross-scale consistency. We propose BrainCSD, a hierarchical mixture-of-experts (MoE) foundation model that jointly synthesizes FC/SC biomarkers and supports downstream decoding tasks (diagnosis and prediction). BrainCSD features three neuroanatomically grounded components: (1) a ROI-specific MoE that aligns regional activations from canonical networks (e.g., DMN, FPN) with a global atlas via contrastive consistency; (2) a Encoding-Activation MOE that models dynamic cross-time/gradient dependencies in fMRI/dMRI; and (3) a network-aware refinement MoE that enforces structural priors and symmetry at individual and population levels. Evaluated on the datasets under complete and missing-modality settings, BrainCSD achieves SOTA results: 95.6\% accuracy for MCI vs. CN classification without FC, low synthesis error (FC RMSE: 0.038; SC RMSE: 0.006), brain age prediction (MAE: 4.04 years), and MMSE score estimation (MAE: 1.72 points). Code is available in \href{https://github.com/SXR3015/BrainCSD}{BrainCSD} [SEP] [HINT] connectivity -> Neuroscience (Syns: ) | decoding -> Neuroscience (Syns: decrypt, decipherment, decryption) | tasks -> Neuroscience (Syns: tax, task, project)",Neuroscience
"Auditory sensory overload affects 50-70% of individuals with Autism Spectrum Disorder (ASD), yet existing approaches, such as mechanistic models (Hodgkin Huxley type, Wilson Cowan, excitation inhibition balance), clinical tools (EEG/MEG, Sensory Profile scales), and ML methods (Neural ODEs, predictive coding), either assume fixed parameters or lack interpretability, missing autism heterogeneity. We present a Scientific Machine Learning approach using Universal Differential Equations (UDEs) to model sensory adaptation dynamics in autism. Our framework combines ordinary differential equations grounded in biophysics with neural networks to capture both mechanistic understanding and individual variability. We demonstrate that UDEs achieve a 90.8% improvement over pure Neural ODEs while using 73.5% fewer parameters. The model successfully recovers physiological parameters within the 2% error and provides a quantitative risk assessment for sensory overload, predicting 17.2% risk for pulse stimuli with specific temporal patterns. This framework establishes foundations for personalized, evidence-based interventions in autism, with direct applications to wearable technology and clinical practice.",Neuroscience
"Auditory sensory overload affects 50-70% of individuals with Autism Spectrum Disorder (ASD), yet existing approaches, such as mechanistic models (Hodgkin Huxley type, Wilson Cowan, excitation inhibition balance), clinical tools (EEG/MEG, Sensory Profile scales), and ML methods (Neural ODEs, predictive coding), either assume fixed parameters or lack interpretability, missing autism heterogeneity. We present a Scientific Machine Learning approach using Universal Differential Equations (UDEs) to model sensory adaptation dynamics in autism. Our framework combines ordinary differential equations grounded in biophysics with neural networks to capture both mechanistic understanding and individual variability. We demonstrate that UDEs achieve a 90.8% improvement over pure Neural ODEs while using 73.5% fewer parameters. The model successfully recovers physiological parameters within the 2% error and provides a quantitative risk assessment for sensory overload, predicting 17.2% risk for pulse stimuli with specific temporal patterns. This framework establishes foundations for personalized, evidence-based interventions in autism, with direct applications to wearable technology and clinical practice. [SEP] [HINT] clinical -> Bioinformatics (Syns: ) | understanding -> Neuroscience (Syns: savvy, intellect, sympathy) | learning -> Bioinformatics (Syns: take, teach, acquire)",Neuroscience
"We present a GPU-portable implementation of a real-space density functional theory (DFT) code ``QUMASUN'' and benchmark it on the new Plasma Simulator featuring Intel Xeon 6980P CPUs, and AMD MI300A GPUs. Additional tests were performed on an NVIDIA GH200 GPU. In particular MI300A supports unified memory and GH200 supports coherent memory interconnect, simplifying GPU porting. A lightweight C++ lambda-based layer enables CPU, CUDA, and HIP execution without OpenMP/OpenACC preprocessor directives. For diamond (216 atoms) and tungsten (128 atoms) systems, MI300A and GH200 achieve 2.0-2.8 $\times$ and 2.3-2.4 $\times$ speedups over a 256-core Xeon node. The compute-bound kernels, which are fast Fourier transforms (FFT), dense matrix-matrix multiplications (GEMM) and eigenvalue solver, show substantial acceleration on both GPUs, indicating that the present GPU-portable approach can benefit a wide range of plasma-fusion simulation codes beyond DFT.",Materials Science
"We present a GPU-portable implementation of a real-space density functional theory (DFT) code ``QUMASUN'' and benchmark it on the new Plasma Simulator featuring Intel Xeon 6980P CPUs, and AMD MI300A GPUs. Additional tests were performed on an NVIDIA GH200 GPU. In particular MI300A supports unified memory and GH200 supports coherent memory interconnect, simplifying GPU porting. A lightweight C++ lambda-based layer enables CPU, CUDA, and HIP execution without OpenMP/OpenACC preprocessor directives. For diamond (216 atoms) and tungsten (128 atoms) systems, MI300A and GH200 achieve 2.0-2.8 $\times$ and 2.3-2.4 $\times$ speedups over a 256-core Xeon node. The compute-bound kernels, which are fast Fourier transforms (FFT), dense matrix-matrix multiplications (GEMM) and eigenvalue solver, show substantial acceleration on both GPUs, indicating that the present GPU-portable approach can benefit a wide range of plasma-fusion simulation codes beyond DFT. [SEP] [HINT] functional -> Neuroscience (Syns: working, usable, running) | theory -> Materials Science (Syns: possibility, hypothesis) | density -> Materials Science (Syns: tightness, concentration, compactness)",Materials Science
"Heterostructured (HS) materials exhibit excellent mechanical properties, combining high strength and significant ductility. Hetero-deformation-induced (HDI) hardening and strain de-localization are key to their strength-ductility synergy. However, existing models often fall short in addressing these aspects. In this work, a coupled framework integrating strain gradient crystal plasticity and phase field damage models is developed. The interface dominated HDI hardening in HS laminates is handled by introducing a heterogeneity coefficient into the back stress. The phase field model accounts for defect energy-driven damage and accurately represents the materials ductile damage behavior by accounting for effects of microstructure on crack initiation and propagation. Simulation results on HS laminates align well with experimental results and reflect the distribution of geometrically necessary dislocations and back stresses at interfaces between regions with dissimilar microstructure. Crack initiation and propagation are accurately described, providing valuable insights into fracture behavior. The model can predict how strength and ductility change upon variations of the HS laminate microstructure, thus providing an essential tool for microstructure optimization. This work enhances the understanding of deformation mechanisms in HS laminates and provides valuable insights for design and optimization of this class of materials.",Materials Science
"Heterostructured (HS) materials exhibit excellent mechanical properties, combining high strength and significant ductility. Hetero-deformation-induced (HDI) hardening and strain de-localization are key to their strength-ductility synergy. However, existing models often fall short in addressing these aspects. In this work, a coupled framework integrating strain gradient crystal plasticity and phase field damage models is developed. The interface dominated HDI hardening in HS laminates is handled by introducing a heterogeneity coefficient into the back stress. The phase field model accounts for defect energy-driven damage and accurately represents the materials ductile damage behavior by accounting for effects of microstructure on crack initiation and propagation. Simulation results on HS laminates align well with experimental results and reflect the distribution of geometrically necessary dislocations and back stresses at interfaces between regions with dissimilar microstructure. Crack initiation and propagation are accurately described, providing valuable insights into fracture behavior. The model can predict how strength and ductility change upon variations of the HS laminate microstructure, thus providing an essential tool for microstructure optimization. This work enhances the understanding of deformation mechanisms in HS laminates and provides valuable insights for design and optimization of this class of materials. [SEP] [HINT] field -> Materials Science (Syns: field of honor, line of business, orbit) | understanding -> Neuroscience (Syns: savvy, intellect, sympathy) | defect -> Materials Science (Syns: mar, shortcoming, fault)",Materials Science
"Prenatal maternal stress (PS) is a risk factor for adverse offspring neurodevelopment. Heart rate variability (HRV) complexity provides a non-invasive marker of maternal autonomic regulation and may be influenced by mind--body interventions such as Yoga. In this quasi-randomized controlled trial, 28 chronically stressed pregnant women were followed from the second trimester until birth: 14 participated in weekly Hatha Yoga with electrocardiogram (ECG) recordings, and 14 received standard obstetric care with monthly ECGs. Group allocation was based on availability, with participants unaware of their assignment at enrollment. HRV complexity was assessed first with Sample Entropy and Entropy Rate and then expanded to 94 HRV metrics spanning temporal, frequency, nonlinear, and information-theoretical domains. All metrics were covariate-adjusted (maternal age, BMI, gestational age), standardized, and analyzed using timepoint-specific principal component analysis (PCA). From this, a unified HRV index was derived. Analyses revealed that HRV metric relationships changed dynamically across pregnancy, with PCA loadings shifting from frequency toward complexity measures in late gestation. The mixed effects model identified a significant time x group interaction effect (p = 0.041). These findings suggest a restructuring of HRV signal-analytical domains with advancing pregnancy attributable to Yoga and highlight the utility of advanced HRV analysis frameworks for future, larger trials.",Bioinformatics
"Prenatal maternal stress (PS) is a risk factor for adverse offspring neurodevelopment. Heart rate variability (HRV) complexity provides a non-invasive marker of maternal autonomic regulation and may be influenced by mind--body interventions such as Yoga. In this quasi-randomized controlled trial, 28 chronically stressed pregnant women were followed from the second trimester until birth: 14 participated in weekly Hatha Yoga with electrocardiogram (ECG) recordings, and 14 received standard obstetric care with monthly ECGs. Group allocation was based on availability, with participants unaware of their assignment at enrollment. HRV complexity was assessed first with Sample Entropy and Entropy Rate and then expanded to 94 HRV metrics spanning temporal, frequency, nonlinear, and information-theoretical domains. All metrics were covariate-adjusted (maternal age, BMI, gestational age), standardized, and analyzed using timepoint-specific principal component analysis (PCA). From this, a unified HRV index was derived. Analyses revealed that HRV metric relationships changed dynamically across pregnancy, with PCA loadings shifting from frequency toward complexity measures in late gestation. The mixed effects model identified a significant time x group interaction effect (p = 0.041). These findings suggest a restructuring of HRV signal-analytical domains with advancing pregnancy attributable to Yoga and highlight the utility of advanced HRV analysis frameworks for future, larger trials. [SEP] [HINT] based -> Bioinformatics (Syns: ground, free-base, base) | using -> Bioinformatics (Syns: utilize, exploitation, apply) | findings -> Neuroscience (Syns: determination, finding)",Bioinformatics
"Non-invasive Brain-Computer Interfaces (BCIs) based on Code-Modulated Visual Evoked Potentials (C-VEPs) require highly robust decoding methods to address temporal variability and session-dependent noise in EEG signals. This study proposes and evaluates several deep learning architectures, including convolutional neural networks (CNNs) for 63-bit m-sequence reconstruction and classification, and Siamese networks for similarity-based decoding, alongside canonical correlation analysis (CCA) baselines. EEG data were recorded from 13 healthy adults under single-target flicker stimulation. The proposed deep models significantly outperformed traditional approaches, with distance-based decoding using Earth Mover's Distance (EMD) and constrained EMD showing greater robustness to latency variations than Euclidean and Mahalanobis metrics. Temporal data augmentation with small shifts further improved generalization across sessions. Among all models, the multi-class Siamese network achieved the best overall performance with an average accuracy of 96.89%, demonstrating the potential of data-driven deep architectures for reliable, single-trial C-VEP decoding in adaptive non-invasive BCI systems.",Neuroscience
"Non-invasive Brain-Computer Interfaces (BCIs) based on Code-Modulated Visual Evoked Potentials (C-VEPs) require highly robust decoding methods to address temporal variability and session-dependent noise in EEG signals. This study proposes and evaluates several deep learning architectures, including convolutional neural networks (CNNs) for 63-bit m-sequence reconstruction and classification, and Siamese networks for similarity-based decoding, alongside canonical correlation analysis (CCA) baselines. EEG data were recorded from 13 healthy adults under single-target flicker stimulation. The proposed deep models significantly outperformed traditional approaches, with distance-based decoding using Earth Mover's Distance (EMD) and constrained EMD showing greater robustness to latency variations than Euclidean and Mahalanobis metrics. Temporal data augmentation with small shifts further improved generalization across sessions. Among all models, the multi-class Siamese network achieved the best overall performance with an average accuracy of 96.89%, demonstrating the potential of data-driven deep architectures for reliable, single-trial C-VEP decoding in adaptive non-invasive BCI systems. [SEP] [HINT] decoding -> Neuroscience (Syns: decrypt, decipherment, decryption) | based -> Bioinformatics (Syns: ground, free-base, base) | learning -> Bioinformatics (Syns: take, teach, acquire)",Neuroscience
"As a core technology for green chemical synthesis and electrochemical energy storage, electrocatalysis is central to decarbonization strategies aimed at combating climate change. In this context, computational and machine learning driven catalyst discovery has emerged as a major research focus. These approaches frequently use the thermodynamic overpotential, calculated from adsorption free energies of reaction intermediates, as a key parameter in their analysis. In this paper, we explore the large-scale applicability of such overpotential estimates for identifying good catalyst candidates by using datasets from the Open Catalyst Project (OC20 and OC22). We start by quantifying the uncertainty in predicting adsorption energies using \textit{ab initio} methods and find that $\sim$0.3-0.5 eV is a conservative estimate for a single adsorption energy prediction. We then compute the overpotential of all materials in the OC20 and OC22 datasets for the hydrogen and oxygen evolution reactions. We find that while the overpotential allows the identification of known good catalysts such as platinum and iridium oxides, the uncertainty is large enough to misclassify a broad fraction of the datasets as ``good'', which limits its value as a screening criterion. These results question the reliance on overpotential estimation as a primary evaluation metric to sort through catalyst candidates and calls for a shift in focus in the computational catalysis and machine learning communities towards other metrics such as synthesizability, stability, lifetime or affordability.",Materials Science
"As a core technology for green chemical synthesis and electrochemical energy storage, electrocatalysis is central to decarbonization strategies aimed at combating climate change. In this context, computational and machine learning driven catalyst discovery has emerged as a major research focus. These approaches frequently use the thermodynamic overpotential, calculated from adsorption free energies of reaction intermediates, as a key parameter in their analysis. In this paper, we explore the large-scale applicability of such overpotential estimates for identifying good catalyst candidates by using datasets from the Open Catalyst Project (OC20 and OC22). We start by quantifying the uncertainty in predicting adsorption energies using \textit{ab initio} methods and find that $\sim$0.3-0.5 eV is a conservative estimate for a single adsorption energy prediction. We then compute the overpotential of all materials in the OC20 and OC22 datasets for the hydrogen and oxygen evolution reactions. We find that while the overpotential allows the identification of known good catalysts such as platinum and iridium oxides, the uncertainty is large enough to misclassify a broad fraction of the datasets as ``good'', which limits its value as a screening criterion. These results question the reliance on overpotential estimation as a primary evaluation metric to sort through catalyst candidates and calls for a shift in focus in the computational catalysis and machine learning communities towards other metrics such as synthesizability, stability, lifetime or affordability. [SEP] [HINT] computational -> Neuroscience (Syns: ) | learning -> Bioinformatics (Syns: take, teach, acquire) | datasets -> Bioinformatics (Syns: )",Materials Science
"We present a straightforward analytical-numerical methodology for determining polynomially complete and irreducible scalar-valued invariant sets for anisotropic hyperelasticity. By applying the proposed technique, we obtain irreducible integrity bases for all common anisotropies in hyperelasticity via the structural tensor concept, i.e., invariants are formed from a measure of deformation (symmetric 2nd order tensor) and a set of structural tensors describing the material's symmetry. Our work covers results for the 11 types of anisotropy that arise from the classical 7 crystal systems, as well as findings for 4 additional non-crystal anisotropies derived from the cylindrical, spherical, and icosahedral symmetry systems. Polynomial completeness and irreducibility of the proposed integrity bases are proven using the Molien series and, in addition, with established results for scalar-valued invariant sets from the literature. Furthermore, we derive relationships between a set of multiple structural tensors that specify a symmetry group and a description using only a single structural tensor. Both can be used to construct irreducible integrity bases by applying the proposed analytical-numerical method. The provided invariant sets are of great importance for modeling anisotropic materials via the structural tensor concept using both classical models as well as modern approaches based on machine learning. Alongside the results presented, this article also aims to provide an introductory overview of the complex field of modeling anisotropic materials.",Materials Science
"We present a straightforward analytical-numerical methodology for determining polynomially complete and irreducible scalar-valued invariant sets for anisotropic hyperelasticity. By applying the proposed technique, we obtain irreducible integrity bases for all common anisotropies in hyperelasticity via the structural tensor concept, i.e., invariants are formed from a measure of deformation (symmetric 2nd order tensor) and a set of structural tensors describing the material's symmetry. Our work covers results for the 11 types of anisotropy that arise from the classical 7 crystal systems, as well as findings for 4 additional non-crystal anisotropies derived from the cylindrical, spherical, and icosahedral symmetry systems. Polynomial completeness and irreducibility of the proposed integrity bases are proven using the Molien series and, in addition, with established results for scalar-valued invariant sets from the literature. Furthermore, we derive relationships between a set of multiple structural tensors that specify a symmetry group and a description using only a single structural tensor. Both can be used to construct irreducible integrity bases by applying the proposed analytical-numerical method. The provided invariant sets are of great importance for modeling anisotropic materials via the structural tensor concept using both classical models as well as modern approaches based on machine learning. Alongside the results presented, this article also aims to provide an introductory overview of the complex field of modeling anisotropic materials. [SEP] [HINT] used -> Bioinformatics (Syns: utilize, ill-used, apply) | field -> Materials Science (Syns: field of honor, line of business, orbit) | based -> Bioinformatics (Syns: ground, free-base, base)",Materials Science
"Human skin acts as a dynamic biomechanical interface that conveys critical physiological and behavioural information through spatiotemporally distributed deformations. Due to the limited capabilities of current sensing technologies, the spatiotemporal diversity of its mechanical cues has remained underutilised to date, preventing these mechanisms from being used to capture and decode the full spectrum of underlying physiological states. In this work, we define this heterogeneous set of mechanical signals as mechanodermal activity (MDA) and introduce the biomimetic metamaterial-based interface (BMMI), an engineered auxetic metamaterial substrate that reproduces the microrelief and mechanoreceptor architecture of natural skin. The BMMI allows selective capture of diverse MDA signals from adjacent skin regions with simultaneous signal amplification and noise suppression, and permits straightforward modulation to accommodate various scenarios. Combined with bespoke algorithms, the wireless BMMI device decodes MDA accurately and robustly for multimodal communication interfaces, unleashing applications in healthcare monitoring and human-machine interaction.",Neuroscience
"Human skin acts as a dynamic biomechanical interface that conveys critical physiological and behavioural information through spatiotemporally distributed deformations. Due to the limited capabilities of current sensing technologies, the spatiotemporal diversity of its mechanical cues has remained underutilised to date, preventing these mechanisms from being used to capture and decode the full spectrum of underlying physiological states. In this work, we define this heterogeneous set of mechanical signals as mechanodermal activity (MDA) and introduce the biomimetic metamaterial-based interface (BMMI), an engineered auxetic metamaterial substrate that reproduces the microrelief and mechanoreceptor architecture of natural skin. The BMMI allows selective capture of diverse MDA signals from adjacent skin regions with simultaneous signal amplification and noise suppression, and permits straightforward modulation to accommodate various scenarios. Combined with bespoke algorithms, the wireless BMMI device decodes MDA accurately and robustly for multimodal communication interfaces, unleashing applications in healthcare monitoring and human-machine interaction. [SEP] [HINT] used -> Bioinformatics (Syns: utilize, ill-used, apply) | information -> Bioinformatics (Syns: entropy, data, info) | human -> Neuroscience (Syns: human being, man, homo)",Neuroscience
"Light-emitting diodes (LEDs) based on halide perovskite nanocrystals have attracted extensive attention due to their considerable luminescence efficiency, wide color gamut, high color purity, and facile material synthesis. Since the first demonstration of LEDs based on MAPbBr3 nanocrystals were reported in 2014, the community has witnessed a rapid development in their performances. In this review, we provide a historical perspective of the development of LEDs based on halide perovskite nanocrystals and then present a comprehensive survey of current strategies to high-efficiency lead-based perovskite nanocrystals LEDs, including synthesis optimization, ion doping/alloying and shell coating. We then review the basic characteristics and emission mechanisms of lead-free perovskite and perovskite-related nanocrystals emitters in environmentally friendly LEDs, from the standpoint of different emission colors. Finally, we cover the progress in LED applications and provide an outlook of the opportunities and challenges for future developments in this field.",Materials Science
"Light-emitting diodes (LEDs) based on halide perovskite nanocrystals have attracted extensive attention due to their considerable luminescence efficiency, wide color gamut, high color purity, and facile material synthesis. Since the first demonstration of LEDs based on MAPbBr3 nanocrystals were reported in 2014, the community has witnessed a rapid development in their performances. In this review, we provide a historical perspective of the development of LEDs based on halide perovskite nanocrystals and then present a comprehensive survey of current strategies to high-efficiency lead-based perovskite nanocrystals LEDs, including synthesis optimization, ion doping/alloying and shell coating. We then review the basic characteristics and emission mechanisms of lead-free perovskite and perovskite-related nanocrystals emitters in environmentally friendly LEDs, from the standpoint of different emission colors. Finally, we cover the progress in LED applications and provide an outlook of the opportunities and challenges for future developments in this field. [SEP] [HINT] based -> Bioinformatics (Syns: ground, free-base, base) | perovskite -> Materials Science (Syns: ) | including -> Bioinformatics (Syns: admit, include, let in)",Materials Science
"We develop a phenomenological Ginzburg-Landau (GL) framework for high-$T_c$ cuprates in which a short-range modulation of the electronic charge density couples to a $d$-wave superconducting condensate. The resulting modulated electron lattice (MEL) state is distinct from long-range static charge density wave order: it is short range, partially phase coherent, and linked to superconducting coherence. A preferred wave vector $q^{\ast} \approx 0.3$ reciprocal lattice units along the Cu-O bond direction emerges from the interplay between a momentum-dependent susceptibility and bond-stretching phonons, consistent with neutron and x-ray data on YBa$_2$Cu$_3$O$_{7-δ}$ and related cuprates. The GL free energy contains coupled $d$-wave superconducting and charge sectors with parameters constrained by optimally doped YBa$_2$Cu$_3$O$_{7-δ}$. We identify an MEL enhancement window in doping, temperature, MEL correlation length, and disorder where a coherence linked modulation enhances the superfluid stiffness. Classical Monte Carlo simulations yield an in-plane stiffness enhancement of order ten percent, which we treat as a qualitative prediction to be tested by self-consistent Bogoliubov de Gennes calculations. The MEL framework yields falsifiable experimental signatures. For scanning tunneling spectroscopy in Bi-based cuprates we highlight two predictions: the Fourier-transformed local density of states should exhibit a $q^{\ast} \approx 0.3$ peak whose spectral weight sharpens as superconducting phase coherence develops below $T_c$, in contrast to static charge scenarios, and the local gap magnitude $Δ(r)$ should correlate positively with the local MEL amplitude. The framework implies correlations between MEL correlation length, superfluid stiffness, disorder, and vortex pinning, and organizes cuprate observations into testable STM/STS predictions.",Materials Science
"We develop a phenomenological Ginzburg-Landau (GL) framework for high-$T_c$ cuprates in which a short-range modulation of the electronic charge density couples to a $d$-wave superconducting condensate. The resulting modulated electron lattice (MEL) state is distinct from long-range static charge density wave order: it is short range, partially phase coherent, and linked to superconducting coherence. A preferred wave vector $q^{\ast} \approx 0.3$ reciprocal lattice units along the Cu-O bond direction emerges from the interplay between a momentum-dependent susceptibility and bond-stretching phonons, consistent with neutron and x-ray data on YBa$_2$Cu$_3$O$_{7-δ}$ and related cuprates. The GL free energy contains coupled $d$-wave superconducting and charge sectors with parameters constrained by optimally doped YBa$_2$Cu$_3$O$_{7-δ}$. We identify an MEL enhancement window in doping, temperature, MEL correlation length, and disorder where a coherence linked modulation enhances the superfluid stiffness. Classical Monte Carlo simulations yield an in-plane stiffness enhancement of order ten percent, which we treat as a qualitative prediction to be tested by self-consistent Bogoliubov de Gennes calculations. The MEL framework yields falsifiable experimental signatures. For scanning tunneling spectroscopy in Bi-based cuprates we highlight two predictions: the Fourier-transformed local density of states should exhibit a $q^{\ast} \approx 0.3$ peak whose spectral weight sharpens as superconducting phase coherence develops below $T_c$, in contrast to static charge scenarios, and the local gap magnitude $Δ(r)$ should correlate positively with the local MEL amplitude. The framework implies correlations between MEL correlation length, superfluid stiffness, disorder, and vortex pinning, and organizes cuprate observations into testable STM/STS predictions. [SEP] [HINT] charge -> Materials Science (Syns: tear, bearing, burster) | electronic -> Materials Science (Syns: ) | electron -> Materials Science (Syns: negatron)",Materials Science
"Kinetic modeling enables \textit{in vivo} quantification of tracer uptake and glucose metabolism in [${}^{18}$F]Fluorodeoxyglucose ([${}^{18}$F]FDG) dynamic positron emission tomography (dPET) imaging of mice. However, kinetic modeling requires the accurate determination of the arterial input function (AIF) during imaging, which is time-consuming and invasive. Recent studies have shown the efficacy of using deep learning to directly predict the input function, surpassing established methods such as the image-derived input function (IDIF). In this work, we trained a physics-informed deep learning-based input function prediction model (PIDLIF) to estimate the AIF directly from the PET images, incorporating a kinetic modeling loss during training. The proposed method uses a two-tissue compartment model over two regions, the myocardium and brain of the mice, and is trained on a dataset of 70 [${}^{18}$F]FDG dPET images of mice accompanied by the measured AIF during imaging. The proposed method had comparable performance to the network without a physics-informed loss, and when sudden movement causing blurring in the images was simulated, the PIDLIF model maintained high performance in severe cases of image degradation. The proposed physics-informed method exhibits an improved robustness that is promoted by physically constraining the problem, enforcing consistency for out-of-distribution samples. In conclusion, the PIDLIF model offers insight into the effects of leveraging physiological distribution mechanics in mice to guide a deep learning-based AIF prediction network in images with severe degradation as a result of blurring due to movement during imaging.",Bioinformatics
"Kinetic modeling enables \textit{in vivo} quantification of tracer uptake and glucose metabolism in [${}^{18}$F]Fluorodeoxyglucose ([${}^{18}$F]FDG) dynamic positron emission tomography (dPET) imaging of mice. However, kinetic modeling requires the accurate determination of the arterial input function (AIF) during imaging, which is time-consuming and invasive. Recent studies have shown the efficacy of using deep learning to directly predict the input function, surpassing established methods such as the image-derived input function (IDIF). In this work, we trained a physics-informed deep learning-based input function prediction model (PIDLIF) to estimate the AIF directly from the PET images, incorporating a kinetic modeling loss during training. The proposed method uses a two-tissue compartment model over two regions, the myocardium and brain of the mice, and is trained on a dataset of 70 [${}^{18}$F]FDG dPET images of mice accompanied by the measured AIF during imaging. The proposed method had comparable performance to the network without a physics-informed loss, and when sudden movement causing blurring in the images was simulated, the PIDLIF model maintained high performance in severe cases of image degradation. The proposed physics-informed method exhibits an improved robustness that is promoted by physically constraining the problem, enforcing consistency for out-of-distribution samples. In conclusion, the PIDLIF model offers insight into the effects of leveraging physiological distribution mechanics in mice to guide a deep learning-based AIF prediction network in images with severe degradation as a result of blurring due to movement during imaging. [SEP] [HINT] learning -> Bioinformatics (Syns: take, teach, acquire) | performance -> Bioinformatics (Syns: functioning, operation, carrying out) | using -> Bioinformatics (Syns: utilize, exploitation, apply)",Bioinformatics
"Lung cancer is a primary contributor to cancer-related mortality globally, highlighting the necessity for precise early detection of pulmonary nodules through low-dose CT (LDCT) imaging. Deep learning methods have improved nodule detection and classification; however, their performance is frequently limited by the availability of annotated data and variability among imaging centers. This research presents a CT-driven, semi-supervised framework utilizing the Inf-Net architecture to enhance lung nodule analysis with minimal annotation. The model incorporates multi-scale feature aggregation, Reverse Attention refinement, and pseudo-labeling to efficiently utilize unlabeled CT slices. Experiments conducted on subsets of the LUNA16 dataset indicate that the supervised Inf-Net attains a score of 0.825 on 10,000 labeled slices. In contrast, the semi-supervised variant achieves a score of 0.784 on 20,000 slices that include both labeled and pseudo-labeled data, thus surpassing its supervised baseline of 0.755. This study presents a conceptual framework for the integration of genomic biomarkers with CT-derived features, facilitating the development of future multimodal, biologically informed CAD systems. The proposed semi-supervised Inf-Net framework improves CT-based lung nodule assessment and lays the groundwork for flexible multi-omics diagnostic models.",Bioinformatics
"Lung cancer is a primary contributor to cancer-related mortality globally, highlighting the necessity for precise early detection of pulmonary nodules through low-dose CT (LDCT) imaging. Deep learning methods have improved nodule detection and classification; however, their performance is frequently limited by the availability of annotated data and variability among imaging centers. This research presents a CT-driven, semi-supervised framework utilizing the Inf-Net architecture to enhance lung nodule analysis with minimal annotation. The model incorporates multi-scale feature aggregation, Reverse Attention refinement, and pseudo-labeling to efficiently utilize unlabeled CT slices. Experiments conducted on subsets of the LUNA16 dataset indicate that the supervised Inf-Net attains a score of 0.825 on 10,000 labeled slices. In contrast, the semi-supervised variant achieves a score of 0.784 on 20,000 slices that include both labeled and pseudo-labeled data, thus surpassing its supervised baseline of 0.755. This study presents a conceptual framework for the integration of genomic biomarkers with CT-derived features, facilitating the development of future multimodal, biologically informed CAD systems. The proposed semi-supervised Inf-Net framework improves CT-based lung nodule assessment and lays the groundwork for flexible multi-omics diagnostic models. [SEP] [HINT] learning -> Bioinformatics (Syns: take, teach, acquire) | performance -> Bioinformatics (Syns: functioning, operation, carrying out) | framework -> Bioinformatics (Syns: theoretical account, model, fabric)",Bioinformatics
"We report the synthesis of nanocrystal heterostructures composed of CsPbCl3 and PbS domains sharing an epitaxial interface. We were able to promote the growth of a PbS domain (in competition with the more commonly observed Pb4S3Cl2 one) on top of the CsPbCl3 domain by employing Mn2$^+$ ions, the latter acting most likely as scavengers of Cl$^-$ ions. Complete suppression of the Pb4S3Cl2 domain growth was then achieved by additionally selecting an appropriate sulfur source (bis(trimethylsilyl)sulfide, which also acted as scavenger of Cl$^-$ ions), and reaction temperature. In the heterostructures, emission from the perovskite domain was quenched, while emission from the PbS domain was observed, pointing to a type-I band alignment, as confirmed by calculations. These heterostructures in turn could be exploited to prepare second-generation heterostructures through selective ion exchange on the individual domains (halide ion exchange on CsPbCl3, cation exchange on PbS). We demonstrate the cases of Cl$^-$ to Br$^-$ and Pb2$^+$ to Cu$^+$ exchanges, which deliver CsPbBr3@PbS and CsPbCl3@Cu2-xS epitaxial heterostructures, respectively.",Materials Science
"We report the synthesis of nanocrystal heterostructures composed of CsPbCl3 and PbS domains sharing an epitaxial interface. We were able to promote the growth of a PbS domain (in competition with the more commonly observed Pb4S3Cl2 one) on top of the CsPbCl3 domain by employing Mn2$^+$ ions, the latter acting most likely as scavengers of Cl$^-$ ions. Complete suppression of the Pb4S3Cl2 domain growth was then achieved by additionally selecting an appropriate sulfur source (bis(trimethylsilyl)sulfide, which also acted as scavenger of Cl$^-$ ions), and reaction temperature. In the heterostructures, emission from the perovskite domain was quenched, while emission from the PbS domain was observed, pointing to a type-I band alignment, as confirmed by calculations. These heterostructures in turn could be exploited to prepare second-generation heterostructures through selective ion exchange on the individual domains (halide ion exchange on CsPbCl3, cation exchange on PbS). We demonstrate the cases of Cl$^-$ to Br$^-$ and Pb2$^+$ to Cu$^+$ exchanges, which deliver CsPbBr3@PbS and CsPbCl3@Cu2-xS epitaxial heterostructures, respectively. [SEP] [HINT] perovskite -> Materials Science (Syns: ) | band -> Materials Science (Syns: set, stria, dance orchestra) | demonstrate -> Bioinformatics (Syns: evidence, march, prove)",Materials Science
"Neural synchronization is central to cognition However, incomplete synchronization often produces chimera states where coherent and incoherent dynamics coexist. While previous studies have explored such patterns using networks of coupled oscillators, it remains unclear why neurons commit to communication or how chimera states persist. Here, we investigate the coevolution of neuronal phases and communication strategies on directed, weighted networks, where interaction payoffs depend on phase alignment and may be asymmetric due to unilateral communication. We find that both connection weights and directionality influence the stability of communicative strategies -- and, consequently, full synchronization -- as well as the strategic nature of neuronal interactions. Applying our framework to the C. elegans connectome, we show that emergent payoff structures, such as the snowdrift game, underpin the formation of chimera states. Our computational results demonstrate a promising neurogame-theoretic perspective, leveraging evolutionary graph theory to shed light on mechanisms of neuronal coordination beyond classical synchronization models.",Neuroscience
"Neural synchronization is central to cognition However, incomplete synchronization often produces chimera states where coherent and incoherent dynamics coexist. While previous studies have explored such patterns using networks of coupled oscillators, it remains unclear why neurons commit to communication or how chimera states persist. Here, we investigate the coevolution of neuronal phases and communication strategies on directed, weighted networks, where interaction payoffs depend on phase alignment and may be asymmetric due to unilateral communication. We find that both connection weights and directionality influence the stability of communicative strategies -- and, consequently, full synchronization -- as well as the strategic nature of neuronal interactions. Applying our framework to the C. elegans connectome, we show that emergent payoff structures, such as the snowdrift game, underpin the formation of chimera states. Our computational results demonstrate a promising neurogame-theoretic perspective, leveraging evolutionary graph theory to shed light on mechanisms of neuronal coordination beyond classical synchronization models. [SEP] [HINT] computational -> Neuroscience (Syns: ) | networks -> Neuroscience (Syns: network, meshwork, electronic network) | results -> Bioinformatics (Syns: final result, consequence, resultant role)",Neuroscience
"Mofasa is an all-atom latent diffusion model with state-of-the-art performance for generating Metal-Organic Frameworks (MOFs). These are highly porous crystalline materials used to harvest water from desert air, capture carbon dioxide, store toxic gases and catalyse chemical reactions. In recognition of their value, the development of MOFs recently received a Nobel Prize in Chemistry.   In many ways, MOFs are well-suited for exploiting generative models in chemistry: they are rationally-designable materials with a large combinatorial design space and strong structure-property couplings. And yet, to date, a high performance generative model has been lacking. To fill this gap, we introduce Mofasa, a general-purpose latent diffusion model that jointly samples positions, atom-types and lattice vectors for systems as large as 500 atoms. Mofasa avoids handcrafted assembly algorithms common in the literature, unlocking the simultaneous discovery of metal nodes, linkers and topologies.   To help the scientific community build on our work, we release MofasaDB, an annotated library of hundreds of thousands of sampled MOF structures, along with a user-friendly web interface for search and discovery: https://mofux.ai/ .",Materials Science
"Mofasa is an all-atom latent diffusion model with state-of-the-art performance for generating Metal-Organic Frameworks (MOFs). These are highly porous crystalline materials used to harvest water from desert air, capture carbon dioxide, store toxic gases and catalyse chemical reactions. In recognition of their value, the development of MOFs recently received a Nobel Prize in Chemistry.   In many ways, MOFs are well-suited for exploiting generative models in chemistry: they are rationally-designable materials with a large combinatorial design space and strong structure-property couplings. And yet, to date, a high performance generative model has been lacking. To fill this gap, we introduce Mofasa, a general-purpose latent diffusion model that jointly samples positions, atom-types and lattice vectors for systems as large as 500 atoms. Mofasa avoids handcrafted assembly algorithms common in the literature, unlocking the simultaneous discovery of metal nodes, linkers and topologies.   To help the scientific community build on our work, we release MofasaDB, an annotated library of hundreds of thousands of sampled MOF structures, along with a user-friendly web interface for search and discovery: https://mofux.ai/ . [SEP] [HINT] used -> Bioinformatics (Syns: utilize, ill-used, apply) | space -> Neuroscience (Syns: distance, place, outer space) | performance -> Bioinformatics (Syns: functioning, operation, carrying out)",Materials Science
"Understanding the representation of probability in the human mind has been of great interest to understanding human decision making. Classical paradoxes in decision making suggest that human perception distorts probability magnitudes. Previous accounts postulate a Probability Weighting Function that transforms perceived probabilities; however, its motivation has been debated. Recent work has sought to motivate this function in terms of noisy representations of probabilities in the human mind. Here, we present an account of the Probability Weighting Function grounded in rational inference over optimal decoding from noisy neural encoding of quantities. We show that our model accurately accounts for behavior in a lottery task and a dot counting task. It further accounts for adaptation to a bimodal short-term prior. Taken together, our results provide a unifying account grounding the human representation of probability in rational inference.",Neuroscience
"Understanding the representation of probability in the human mind has been of great interest to understanding human decision making. Classical paradoxes in decision making suggest that human perception distorts probability magnitudes. Previous accounts postulate a Probability Weighting Function that transforms perceived probabilities; however, its motivation has been debated. Recent work has sought to motivate this function in terms of noisy representations of probabilities in the human mind. Here, we present an account of the Probability Weighting Function grounded in rational inference over optimal decoding from noisy neural encoding of quantities. We show that our model accurately accounts for behavior in a lottery task and a dot counting task. It further accounts for adaptation to a bimodal short-term prior. Taken together, our results provide a unifying account grounding the human representation of probability in rational inference. [SEP] [HINT] task -> Neuroscience (Syns: tax, project, chore) | decoding -> Neuroscience (Syns: decrypt, decipherment, decryption) | understanding -> Neuroscience (Syns: savvy, intellect, sympathy)",Neuroscience
"In this study, theoretical investigation on structural, electronic, magnetic, elastic and thermoelectric properties of the full Heusler Co$_2$YPb (Y = Tc, Ti, Zr and Hf) alloys have been performed within density functional theory (DFT). The exchange and correlation potential is addressed using two approximations: the generalized gradient approximation (GGA) and the GGA augmented by the Tran--Blaha-modified Becke-Johnson (mBj-GGA) approximation, which provides a more accurate description of the energy band gap. The electronic and magnetic properties reveal that the full-Heusler alloys Co$_2$YPb (with Y = Tc, Ti, Zr, and Hf) display half-metallic ferromagnetic behavior. Furthermore, the elastic properties suggest that Co$_2$YPb are mechanically stable, with ductile characteristics. Full Heusler alloys P-type exhibit positive Seebeck coefficients and high ZT values, indicating good thermoelectric performance in terms of electrical and thermal conductivity. This leads us to the conclusions that these compounds are very interesting in improving the performance of embedded automotive systems and can also be used in spintronic devices.",Materials Science
"In this study, theoretical investigation on structural, electronic, magnetic, elastic and thermoelectric properties of the full Heusler Co$_2$YPb (Y = Tc, Ti, Zr and Hf) alloys have been performed within density functional theory (DFT). The exchange and correlation potential is addressed using two approximations: the generalized gradient approximation (GGA) and the GGA augmented by the Tran--Blaha-modified Becke-Johnson (mBj-GGA) approximation, which provides a more accurate description of the energy band gap. The electronic and magnetic properties reveal that the full-Heusler alloys Co$_2$YPb (with Y = Tc, Ti, Zr, and Hf) display half-metallic ferromagnetic behavior. Furthermore, the elastic properties suggest that Co$_2$YPb are mechanically stable, with ductile characteristics. Full Heusler alloys P-type exhibit positive Seebeck coefficients and high ZT values, indicating good thermoelectric performance in terms of electrical and thermal conductivity. This leads us to the conclusions that these compounds are very interesting in improving the performance of embedded automotive systems and can also be used in spintronic devices. [SEP] [HINT] used -> Bioinformatics (Syns: utilize, ill-used, apply) | electronic -> Materials Science (Syns: ) | functional -> Neuroscience (Syns: working, usable, running)",Materials Science
"A central challenge in cognitive neuroscience is to explain how semantic and episodic memory, two major forms of declarative memory, typically associated with cortical and hippocampal processing, interact to support learning, recall, and imagination. Despite significant advances, we still lack a unified computational framework that jointly accounts for core empirical phenomena across both semantic and episodic processing domains. Here, we introduce the Generative Episodic-Semantic Integration System (GENESIS), a computational model that formalizes memory as the interaction between two limited-capacity generative systems: a Cortical-VAE, supporting semantic learning and generalization, and a Hippocampal-VAE, supporting episodic encoding and retrieval within a retrieval-augmented generation (RAG) architecture. GENESIS reproduces hallmark behavioral findings, including generalization in semantic memory, recognition, serial recall effects and gist-based distortions in episodic memory, and constructive episodic simulation, while capturing their dynamic interactions. The model elucidates how capacity constraints shape the fidelity and memorability of experiences, how semantic processing introduces systematic distortions in episodic recall, and how episodic replay can recombine previous experiences. Together, these results provide a principled account of memory as an active, constructive, and resource-bounded process. GENESIS thus advances a unified theoretical framework that bridges semantic and episodic memory, offering new insights into the generative foundations of human cognition.",Neuroscience
"A central challenge in cognitive neuroscience is to explain how semantic and episodic memory, two major forms of declarative memory, typically associated with cortical and hippocampal processing, interact to support learning, recall, and imagination. Despite significant advances, we still lack a unified computational framework that jointly accounts for core empirical phenomena across both semantic and episodic processing domains. Here, we introduce the Generative Episodic-Semantic Integration System (GENESIS), a computational model that formalizes memory as the interaction between two limited-capacity generative systems: a Cortical-VAE, supporting semantic learning and generalization, and a Hippocampal-VAE, supporting episodic encoding and retrieval within a retrieval-augmented generation (RAG) architecture. GENESIS reproduces hallmark behavioral findings, including generalization in semantic memory, recognition, serial recall effects and gist-based distortions in episodic memory, and constructive episodic simulation, while capturing their dynamic interactions. The model elucidates how capacity constraints shape the fidelity and memorability of experiences, how semantic processing introduces systematic distortions in episodic recall, and how episodic replay can recombine previous experiences. Together, these results provide a principled account of memory as an active, constructive, and resource-bounded process. GENESIS thus advances a unified theoretical framework that bridges semantic and episodic memory, offering new insights into the generative foundations of human cognition. [SEP] [HINT] computational -> Neuroscience (Syns: ) | cortical -> Neuroscience (Syns: ) | learning -> Bioinformatics (Syns: take, teach, acquire)",Neuroscience
"Recent advances in high-resolution CT-imaging technology are creating a new class of ultra-high resolved micro-structural datasets that challenge the limits of traditional homogenization approaches. While state-of-the-art FFT-based homogenization techniques remain effective for moderate datasets, their memory footprint and computational cost grow rapidly with increasing resolution, making them increasingly inefficient for industrial-scale problems. To address these challenges, the recently developed Superfast-Fourier Transform (SFFT)-based homogenization algorithm leverages the memory-efficient low-rank representations of Tensor Trains (TTs), which reduce the storage and computational requirements of large-scale homogenization problems. Developed for CPU usage, SFFT-based Homogenization efficiently handles high-resolution datasets, assuming the underlying data is well-behaved. In this work, we investigate the performance of fundamental TT operations on modern hardware accelerators using the JAX framework. This benchmarking study, comparing CPUs, GPUs, and TPUs, evaluates execution times and computational efficiency. Building on these insights, we adapt the SFFT-based homogenization algorithm for usage on accelerators, achieving speed-ups of up to 10x relative to the CPU implementation, thus paving the road for the treatment of previously infeasible dataset sizes. Our results show that GPUs and TPUs achieve comparable performance in realistic scenarios, despite the relative immaturity of the TPU ecosystem, demonstrating the potential of both architectures to accelerate quantum-inspired techniques for industrial-scale simulations, particularly for homogenization problems.",Materials Science
"Recent advances in high-resolution CT-imaging technology are creating a new class of ultra-high resolved micro-structural datasets that challenge the limits of traditional homogenization approaches. While state-of-the-art FFT-based homogenization techniques remain effective for moderate datasets, their memory footprint and computational cost grow rapidly with increasing resolution, making them increasingly inefficient for industrial-scale problems. To address these challenges, the recently developed Superfast-Fourier Transform (SFFT)-based homogenization algorithm leverages the memory-efficient low-rank representations of Tensor Trains (TTs), which reduce the storage and computational requirements of large-scale homogenization problems. Developed for CPU usage, SFFT-based Homogenization efficiently handles high-resolution datasets, assuming the underlying data is well-behaved. In this work, we investigate the performance of fundamental TT operations on modern hardware accelerators using the JAX framework. This benchmarking study, comparing CPUs, GPUs, and TPUs, evaluates execution times and computational efficiency. Building on these insights, we adapt the SFFT-based homogenization algorithm for usage on accelerators, achieving speed-ups of up to 10x relative to the CPU implementation, thus paving the road for the treatment of previously infeasible dataset sizes. Our results show that GPUs and TPUs achieve comparable performance in realistic scenarios, despite the relative immaturity of the TPU ecosystem, demonstrating the potential of both architectures to accelerate quantum-inspired techniques for industrial-scale simulations, particularly for homogenization problems. [SEP] [HINT] computational -> Neuroscience (Syns: ) | datasets -> Bioinformatics (Syns: ) | performance -> Bioinformatics (Syns: functioning, operation, carrying out)",Materials Science
"As a newly identified single-crystalline van der Waals dielectric with a high dielectric constant, Bi2SeO5 plays a pivotal role in advancing 2D electronic devices. In this work, we systematically investigate the defect properties of Bi2SeO5 using first-principles calculations based on a hybrid functional. Although Bi2SeO5 is a chemically ternary compound, each constituent element occupies several crystallographically nonequivalent sites, rendering its defect chemistry highly complex. Due to the anomalous +4 cationic valence state of Se, the defect formation energies of same main group anion antisite defects (SeO and OSe) are prohibitively high, and their concentrations can therefore be neglected. In contrast, the extraordinary cation-cation antisite defects BiSe and SeBi emerge as the dominant defects. The pronounced variability in the formation energies of the six types of VO defects demonstrates that identical defect types located on nonequivalent atomic sites can exhibit markedly different properties. Under O-rich and Se/Bi-poor conditions, Bi2SeO5 shows relatively robust p-type behavior. Conversely, under O-poor and Se/Bi-rich conditions, or at intermediate O, Se, and Bi partial pressures, Bi2SeO5 behaves as an intrinsic semiconductor or displays very weak n-type conductivity due to strong donor-acceptor compensation. This study provides theoretical insights to guide the design and development of high-performance Bi2SeO5-based electronic devices.",Materials Science
"As a newly identified single-crystalline van der Waals dielectric with a high dielectric constant, Bi2SeO5 plays a pivotal role in advancing 2D electronic devices. In this work, we systematically investigate the defect properties of Bi2SeO5 using first-principles calculations based on a hybrid functional. Although Bi2SeO5 is a chemically ternary compound, each constituent element occupies several crystallographically nonequivalent sites, rendering its defect chemistry highly complex. Due to the anomalous +4 cationic valence state of Se, the defect formation energies of same main group anion antisite defects (SeO and OSe) are prohibitively high, and their concentrations can therefore be neglected. In contrast, the extraordinary cation-cation antisite defects BiSe and SeBi emerge as the dominant defects. The pronounced variability in the formation energies of the six types of VO defects demonstrates that identical defect types located on nonequivalent atomic sites can exhibit markedly different properties. Under O-rich and Se/Bi-poor conditions, Bi2SeO5 shows relatively robust p-type behavior. Conversely, under O-poor and Se/Bi-rich conditions, or at intermediate O, Se, and Bi partial pressures, Bi2SeO5 behaves as an intrinsic semiconductor or displays very weak n-type conductivity due to strong donor-acceptor compensation. This study provides theoretical insights to guide the design and development of high-performance Bi2SeO5-based electronic devices. [SEP] [HINT] based -> Bioinformatics (Syns: ground, free-base, base) | defect -> Materials Science (Syns: mar, shortcoming, fault) | electronic -> Materials Science (Syns: )",Materials Science
"Generative pretraining (the ""GPT"" in ChatGPT) enables language models to learn from vast amounts of internet text without human supervision. This approach has driven breakthroughs across AI by allowing deep neural networks to learn from massive, unstructured datasets. We use the term foundation models to refer to large pretrained systems that can be adapted to a wide range of tasks within and across domains, and these models are increasingly applied beyond language to the brain sciences. These models achieve strong predictive accuracy, raising hopes that they might illuminate computational principles. But predictive success alone does not guarantee scientific understanding. Here, we outline how foundation models can be productively integrated into the brain sciences, highlighting both their promise and their limitations. The central challenge is to move from prediction to explanation: linking model computations to mechanisms underlying neural activity and cognition.",Neuroscience
"Generative pretraining (the ""GPT"" in ChatGPT) enables language models to learn from vast amounts of internet text without human supervision. This approach has driven breakthroughs across AI by allowing deep neural networks to learn from massive, unstructured datasets. We use the term foundation models to refer to large pretrained systems that can be adapted to a wide range of tasks within and across domains, and these models are increasingly applied beyond language to the brain sciences. These models achieve strong predictive accuracy, raising hopes that they might illuminate computational principles. But predictive success alone does not guarantee scientific understanding. Here, we outline how foundation models can be productively integrated into the brain sciences, highlighting both their promise and their limitations. The central challenge is to move from prediction to explanation: linking model computations to mechanisms underlying neural activity and cognition. [SEP] [HINT] tasks -> Neuroscience (Syns: tax, task, project) | language -> Neuroscience (Syns: linguistic process, linguistic communication, spoken communication) | computational -> Neuroscience (Syns: )",Neuroscience
"The move towards personalized treatment and digital twins for cancer therapy requires a complete understanding of the mathematical models upon which these optimized simulation-based strategies are formulated. This study investigates the influence of mathematical model selection on the optimization of chemotherapy and radiotherapy protocols. By examining three chemotherapy models (log-kill, Norton-Simon, and Emax), and three radiotherapy models (linear-quadratic, proliferation saturation index, and continuous death-rate), we identify similarities and significant differences in the optimized protocols. We demonstrate how the assumptions built into the model formulations heavily influence optimal treatment dosing and sequencing, potentially leading to contradictory results. Further, we demonstrate how different model forms influence predictions in the adaptive therapy setting. As treatment decisions increasingly rely on simulation-based strategies, unexamined model assumptions can introduce bias, leading to model-dependent recommendations that may not be generalizable. This study highlights the importance of basing model selection on a full analysis of bias, sensitivity, practical parameter identifiability and/or inferred parameter posteriors, as a part of the uncertainty quantification process, rather than solely relying on information criterion. Understanding how model choice impacts predictions guiding personalized treatment planning with sufficient uncertainty quantification analysis, will lead to more robust and generalizable predictions.",Bioinformatics
"The move towards personalized treatment and digital twins for cancer therapy requires a complete understanding of the mathematical models upon which these optimized simulation-based strategies are formulated. This study investigates the influence of mathematical model selection on the optimization of chemotherapy and radiotherapy protocols. By examining three chemotherapy models (log-kill, Norton-Simon, and Emax), and three radiotherapy models (linear-quadratic, proliferation saturation index, and continuous death-rate), we identify similarities and significant differences in the optimized protocols. We demonstrate how the assumptions built into the model formulations heavily influence optimal treatment dosing and sequencing, potentially leading to contradictory results. Further, we demonstrate how different model forms influence predictions in the adaptive therapy setting. As treatment decisions increasingly rely on simulation-based strategies, unexamined model assumptions can introduce bias, leading to model-dependent recommendations that may not be generalizable. This study highlights the importance of basing model selection on a full analysis of bias, sensitivity, practical parameter identifiability and/or inferred parameter posteriors, as a part of the uncertainty quantification process, rather than solely relying on information criterion. Understanding how model choice impacts predictions guiding personalized treatment planning with sufficient uncertainty quantification analysis, will lead to more robust and generalizable predictions. [SEP] [HINT] understanding -> Neuroscience (Syns: savvy, intellect, sympathy) | information -> Bioinformatics (Syns: entropy, data, info) | different -> Neuroscience (Syns: unlike, dissimilar)",Bioinformatics
"Molecular dynamics (MD) simulations have become indispensable for exploring tribological deformation patterns at the atomic scale. However, transforming the resulting high-dimensional data into interpretable deformation pattern maps remains a resource-intensive and largely manual process. In this work, we introduce a data-driven workflow that automates this interpretation step using unsupervised and supervised learning. Grain-orientation-colored computational tomograph pictures obtained from CuNi alloy simulations were first compressed through an autoencoder to a 32-dimensional global feature vector. Despite this strong compression, the reconstructed images retained the essential microstructural motifs: grain boundaries, stacking faults, twins, and partial lattice rotations, while omitting only the finest defects. The learned representations were then combined with simulation metadata (composition, load, time, temperature, and spatial position) to train a CNN-MLP model to predict the dominant deformation pattern. The resulting model achieves a prediction accuracy of approximately 96% on validation data. A refined evaluation strategy, in which an entire spatial region containing distinct grains was excluded from training, provides a more robust measure of generalization. The approach demonstrates that essential tribological deformation signatures can be automatically identified and classified from structural images using Machine Learning. This proof of concept constitutes a first step towards fully automated, data-driven construction of tribological mechanism maps and, ultimately, toward predictive modeling frameworks that may reduce the need for large-scale MD simulation campaigns.",Materials Science
"Molecular dynamics (MD) simulations have become indispensable for exploring tribological deformation patterns at the atomic scale. However, transforming the resulting high-dimensional data into interpretable deformation pattern maps remains a resource-intensive and largely manual process. In this work, we introduce a data-driven workflow that automates this interpretation step using unsupervised and supervised learning. Grain-orientation-colored computational tomograph pictures obtained from CuNi alloy simulations were first compressed through an autoencoder to a 32-dimensional global feature vector. Despite this strong compression, the reconstructed images retained the essential microstructural motifs: grain boundaries, stacking faults, twins, and partial lattice rotations, while omitting only the finest defects. The learned representations were then combined with simulation metadata (composition, load, time, temperature, and spatial position) to train a CNN-MLP model to predict the dominant deformation pattern. The resulting model achieves a prediction accuracy of approximately 96% on validation data. A refined evaluation strategy, in which an entire spatial region containing distinct grains was excluded from training, provides a more robust measure of generalization. The approach demonstrates that essential tribological deformation signatures can be automatically identified and classified from structural images using Machine Learning. This proof of concept constitutes a first step towards fully automated, data-driven construction of tribological mechanism maps and, ultimately, toward predictive modeling frameworks that may reduce the need for large-scale MD simulation campaigns. [SEP] [HINT] computational -> Neuroscience (Syns: ) | molecular -> Bioinformatics (Syns: ) | using -> Bioinformatics (Syns: utilize, exploitation, apply)",Materials Science
"Correlated flat bands and altermagnetism are two important directions in quantum materials, centred respectively on interaction-dominated phases and symmetry-enforced spin-textured states, yet both derive from lattice symmetry and orbital hybridization. This common origin implies that extreme crystal distortion, by narrowing bandwidths, enhancing correlations and reshaping the symmetries of altermagnetic spin splittings, could unify flat-band and altermagnetic physics in a single material; in practice, however, achieving such large distortions in a crystalline altermagnet is a formidable challenge. Here we combine a dedicated strain device with a tailored single-crystal mounting scheme to impose a highly tensile strain gradient in bulk CrSb, a prototypical altermagnet, creating a near-surface layer in which the in-plane lattice is strongly distorted relative to the weakly strained bulk, while the average bulk distortion remains small. Angle-resolved photoemission reveals a reversible regime at moderate strain, where a deeper flat-band feature, attributed to a strain-gradient-driven suppression of Cr-Sb hybridization, coexists with a correlation-enhanced Cr 3d flat band, and an irreversible regime at larger strain where partial bond decoupling drives a predominantly insulating spectral response. Density-functional calculations show that an orbital-selective altermagnetic spin texture persists across this correlated regime despite strong bandwidth renormalisation. These results define a strain-symmetry-correlation map for CrSb and establish extreme tensile strain as a route to co-engineer flat-band tendencies and spin-textured, zero-net-moment correlated states in altermagnets, pointing toward strain-adaptive, spin-selective Mott filtering and related device concepts.",Materials Science
"Correlated flat bands and altermagnetism are two important directions in quantum materials, centred respectively on interaction-dominated phases and symmetry-enforced spin-textured states, yet both derive from lattice symmetry and orbital hybridization. This common origin implies that extreme crystal distortion, by narrowing bandwidths, enhancing correlations and reshaping the symmetries of altermagnetic spin splittings, could unify flat-band and altermagnetic physics in a single material; in practice, however, achieving such large distortions in a crystalline altermagnet is a formidable challenge. Here we combine a dedicated strain device with a tailored single-crystal mounting scheme to impose a highly tensile strain gradient in bulk CrSb, a prototypical altermagnet, creating a near-surface layer in which the in-plane lattice is strongly distorted relative to the weakly strained bulk, while the average bulk distortion remains small. Angle-resolved photoemission reveals a reversible regime at moderate strain, where a deeper flat-band feature, attributed to a strain-gradient-driven suppression of Cr-Sb hybridization, coexists with a correlation-enhanced Cr 3d flat band, and an irreversible regime at larger strain where partial bond decoupling drives a predominantly insulating spectral response. Density-functional calculations show that an orbital-selective altermagnetic spin texture persists across this correlated regime despite strong bandwidth renormalisation. These results define a strain-symmetry-correlation map for CrSb and establish extreme tensile strain as a route to co-engineer flat-band tendencies and spin-textured, zero-net-moment correlated states in altermagnets, pointing toward strain-adaptive, spin-selective Mott filtering and related device concepts. [SEP] [HINT] spin -> Materials Science (Syns: twisting, whirl, tailspin) | results -> Bioinformatics (Syns: final result, consequence, resultant role) | crystal -> Materials Science (Syns: crystallization, quartz, lechatelierite)",Materials Science
"The ability to discriminate similar visual stimuli is an important index of memory function. This ability is widely thought to be supported by expanding the dimensionality of relevant neural codes, such that neural representations for similar stimuli are maximally distinct, or ``separated.'' An alternative hypothesis is that discrimination is supported by lossy compression of visual inputs, efficiently coding sensory information by discarding seemingly irrelevant details. A benefit of compression, relative to expansion, is that it allows individuals to retain fewer essential dimensions underlying stimulus variation -- a process linked to higher-order visual processing -- without hindering discrimination. Under this hypothesis, pattern separation is facilitated when more information from similar stimuli can be discarded, rather than preserved. We test the compression versus expansion hypotheses by predicting performance on the canonical mnemonic similarity task. We train neural networks to compress perceptual and semantic factors of stimuli, measuring lossiness using the mathematical framework underlying compression. Consistent with the compression hypothesis, and not the expansion hypothesis, greater lossiness predicts the ease and performance of lure discrimination, especially in deeper convolutional network layers that predict higher-order visual brain activity. We then confirm these predictions across two image sets, four behavioral datasets, and alternative lossiness metrics. Finally, using task fMRI, we identify signatures of lossy compression -- neural dimensionality reduction and information loss -- in higher-order visual regions V4 and IT and hippocampal DG/CA3 and CA1 linked to lure discrimination. These results suggest lossy compression supports mnemonic discrimination by discarding redundant and overlapping information.",Neuroscience
"The ability to discriminate similar visual stimuli is an important index of memory function. This ability is widely thought to be supported by expanding the dimensionality of relevant neural codes, such that neural representations for similar stimuli are maximally distinct, or ``separated.'' An alternative hypothesis is that discrimination is supported by lossy compression of visual inputs, efficiently coding sensory information by discarding seemingly irrelevant details. A benefit of compression, relative to expansion, is that it allows individuals to retain fewer essential dimensions underlying stimulus variation -- a process linked to higher-order visual processing -- without hindering discrimination. Under this hypothesis, pattern separation is facilitated when more information from similar stimuli can be discarded, rather than preserved. We test the compression versus expansion hypotheses by predicting performance on the canonical mnemonic similarity task. We train neural networks to compress perceptual and semantic factors of stimuli, measuring lossiness using the mathematical framework underlying compression. Consistent with the compression hypothesis, and not the expansion hypothesis, greater lossiness predicts the ease and performance of lure discrimination, especially in deeper convolutional network layers that predict higher-order visual brain activity. We then confirm these predictions across two image sets, four behavioral datasets, and alternative lossiness metrics. Finally, using task fMRI, we identify signatures of lossy compression -- neural dimensionality reduction and information loss -- in higher-order visual regions V4 and IT and hippocampal DG/CA3 and CA1 linked to lure discrimination. These results suggest lossy compression supports mnemonic discrimination by discarding redundant and overlapping information. [SEP] [HINT] task -> Neuroscience (Syns: tax, project, chore) | networks -> Neuroscience (Syns: network, meshwork, electronic network) | information -> Bioinformatics (Syns: entropy, data, info)",Neuroscience
"Sleep disorder is a serious global public health issue, with cognitive-emotional dysfunction being a core symptom. The analysis of multimodal MRI data provides an effective method for detecting sleep deprivation-induced neural network abnormalities. The structure-function coupling (SC-FC) integrates functional connectivity with white matter structural information, which can enable comprehensive detection of brain network abnormalities and offer quantitative measures of sleep deprivation-induced neural damage. This study integrates diffusion tensor imaging (DTI) and resting-state fMRI (rs-fMRI) to systematically investigate brain network reorganization and their relationship with emotional functions in partial sleep deprivation (PSD). Our methodology employed DTI to construct structural connectivity (SC) networks and rs-fMRI to establish functional connectivity (FC) networks, then construct SC-FC coupling model . The experiment included 16 healthy controls (HC) and 20 PSD patients, with comprehensive whole-brain and nodal-level SC-FC analyses performed. The results show that (1) severe FC disruptions in PSD patients involving the limbic system, default mode network, sensorimotor network, and visual networks; (2) altered SC in default mode, sensorimotor, visual, language, and auditory networks; (3) significant SC-FC decoupling in these networks; and (4) strong correlations between these neural changes and clinical measures (KSQ and HADS scores). The SC-FC coupling approach achieved comprehensive detection of PSD-related network abnormalities. Compared to single-modal approaches, this integrated SC-FC analysis provides more comprehensive biomarkers for sleep-related emotional dysregulation. This innovative multimodal neuroimaging approach elucidates the neural mechanisms of SC-FC imbalance induced by PSD, establishing novel biomarkers for sleep-mediated emotional dysregulation.",Neuroscience
"Sleep disorder is a serious global public health issue, with cognitive-emotional dysfunction being a core symptom. The analysis of multimodal MRI data provides an effective method for detecting sleep deprivation-induced neural network abnormalities. The structure-function coupling (SC-FC) integrates functional connectivity with white matter structural information, which can enable comprehensive detection of brain network abnormalities and offer quantitative measures of sleep deprivation-induced neural damage. This study integrates diffusion tensor imaging (DTI) and resting-state fMRI (rs-fMRI) to systematically investigate brain network reorganization and their relationship with emotional functions in partial sleep deprivation (PSD). Our methodology employed DTI to construct structural connectivity (SC) networks and rs-fMRI to establish functional connectivity (FC) networks, then construct SC-FC coupling model . The experiment included 16 healthy controls (HC) and 20 PSD patients, with comprehensive whole-brain and nodal-level SC-FC analyses performed. The results show that (1) severe FC disruptions in PSD patients involving the limbic system, default mode network, sensorimotor network, and visual networks; (2) altered SC in default mode, sensorimotor, visual, language, and auditory networks; (3) significant SC-FC decoupling in these networks; and (4) strong correlations between these neural changes and clinical measures (KSQ and HADS scores). The SC-FC coupling approach achieved comprehensive detection of PSD-related network abnormalities. Compared to single-modal approaches, this integrated SC-FC analysis provides more comprehensive biomarkers for sleep-related emotional dysregulation. This innovative multimodal neuroimaging approach elucidates the neural mechanisms of SC-FC imbalance induced by PSD, establishing novel biomarkers for sleep-mediated emotional dysregulation. [SEP] [HINT] connectivity -> Neuroscience (Syns: ) | clinical -> Bioinformatics (Syns: ) | networks -> Neuroscience (Syns: network, meshwork, electronic network)",Neuroscience
"We ask where, and under what conditions, dyslexic reading costs arise in a large-scale naturalistic reading dataset. Using eye-tracking aligned to word-level features (word length, frequency, and predictability), we model how each feature influences dyslexic time costs. We find that all three features robustly change reading times in both typical and dyslexic readers, and that dyslexic readers show stronger sensitivities to each, especially predictability. Counterfactual manipulations of these features substantially narrow the dyslexic-control gap by about one third, with predictability showing the strongest effect, followed by length and frequency. These patterns align with dyslexia theories that posit heightened demands on linguistic working memory and phonological encoding, and they motivate further work on lexical complexity and parafoveal preview benefits to explain the remaining gap. In short, we quantify when extra dyslexic costs arise, how large they are, and offer actionable guidance for interventions and computational models for dyslexics.",Neuroscience
"We ask where, and under what conditions, dyslexic reading costs arise in a large-scale naturalistic reading dataset. Using eye-tracking aligned to word-level features (word length, frequency, and predictability), we model how each feature influences dyslexic time costs. We find that all three features robustly change reading times in both typical and dyslexic readers, and that dyslexic readers show stronger sensitivities to each, especially predictability. Counterfactual manipulations of these features substantially narrow the dyslexic-control gap by about one third, with predictability showing the strongest effect, followed by length and frequency. These patterns align with dyslexia theories that posit heightened demands on linguistic working memory and phonological encoding, and they motivate further work on lexical complexity and parafoveal preview benefits to explain the remaining gap. In short, we quantify when extra dyslexic costs arise, how large they are, and offer actionable guidance for interventions and computational models for dyslexics. [SEP] [HINT] computational -> Neuroscience (Syns: ) | features -> Bioinformatics (Syns: characteristic, lineament, feature of speech) | work -> Bioinformatics (Syns: work out, process, bring)",Neuroscience
"Controlling spatial patterns in synthetic biological systems remains challenging due to poor parameter robustness and limited experimental tunability. We introduce two complementary mechanisms-the pattern switch and the pattern dial-to systematically control Turing pattern formation in gene circuits. The switch toggles pattern onset via a single parameter, while the dial enables transitions between distinct pattern types using weakly nonlinear amplitude equations. Analyzing network size reveals a key trade-off: small networks are easier to control but less robust, while larger networks gain robustness at the cost of tunability-suggesting a sweet spot for both evolvability and designability. Our results offer practical design rules for engineering programmable patterns in living systems.",Bioinformatics
"Controlling spatial patterns in synthetic biological systems remains challenging due to poor parameter robustness and limited experimental tunability. We introduce two complementary mechanisms-the pattern switch and the pattern dial-to systematically control Turing pattern formation in gene circuits. The switch toggles pattern onset via a single parameter, while the dial enables transitions between distinct pattern types using weakly nonlinear amplitude equations. Analyzing network size reveals a key trade-off: small networks are easier to control but less robust, while larger networks gain robustness at the cost of tunability-suggesting a sweet spot for both evolvability and designability. Our results offer practical design rules for engineering programmable patterns in living systems. [SEP] [HINT] networks -> Neuroscience (Syns: network, meshwork, electronic network) | systems -> Bioinformatics (Syns: organization, organisation, system) | results -> Bioinformatics (Syns: final result, consequence, resultant role)",Bioinformatics
"In cell culture bioprocessing, real-time batch process monitoring (BPM) refers to the continuous tracking and analysis of key process variables such as viable cell density, nutrient levels, metabolite concentrations, and product titer throughout the duration of a batch run. This enables early detection of deviations and supports timely control actions to ensure optimal cell growth and product quality. BPM plays a critical role in ensuring the quality and regulatory compliance of biopharmaceutical manufacturing processes. However, the development of accurate soft sensors for BPM is hindered by key challenges, including limited historical data, infrequent feedback, heterogeneous process conditions, and high-dimensional sensory inputs. This study presents a comprehensive benchmarking analysis of machine learning (ML) methods designed to address these challenges, with a focus on learning from historical data with limited volume and relevance in the context of bioprocess monitoring. We evaluate multiple ML approaches including feature dimensionality reduction, online learning, and just-in-time learning across three datasets, one in silico dataset and two real-world experimental datasets. Our findings highlight the importance of training strategies in handling limited data and feedback, with batch learning proving effective in homogeneous settings, while just-in-time learning and online learning demonstrate superior adaptability in cold-start scenarios. Additionally, we identify key meta-features, such as feed media composition and process control strategies, that significantly impact model transferability. The results also suggest that integrating Raman-based predictions with lagged offline measurements enhances monitoring accuracy, offering a promising direction for future bioprocess soft sensor development.",Bioinformatics
"In cell culture bioprocessing, real-time batch process monitoring (BPM) refers to the continuous tracking and analysis of key process variables such as viable cell density, nutrient levels, metabolite concentrations, and product titer throughout the duration of a batch run. This enables early detection of deviations and supports timely control actions to ensure optimal cell growth and product quality. BPM plays a critical role in ensuring the quality and regulatory compliance of biopharmaceutical manufacturing processes. However, the development of accurate soft sensors for BPM is hindered by key challenges, including limited historical data, infrequent feedback, heterogeneous process conditions, and high-dimensional sensory inputs. This study presents a comprehensive benchmarking analysis of machine learning (ML) methods designed to address these challenges, with a focus on learning from historical data with limited volume and relevance in the context of bioprocess monitoring. We evaluate multiple ML approaches including feature dimensionality reduction, online learning, and just-in-time learning across three datasets, one in silico dataset and two real-world experimental datasets. Our findings highlight the importance of training strategies in handling limited data and feedback, with batch learning proving effective in homogeneous settings, while just-in-time learning and online learning demonstrate superior adaptability in cold-start scenarios. Additionally, we identify key meta-features, such as feed media composition and process control strategies, that significantly impact model transferability. The results also suggest that integrating Raman-based predictions with lagged offline measurements enhances monitoring accuracy, offering a promising direction for future bioprocess soft sensor development. [SEP] [HINT] learning -> Bioinformatics (Syns: take, teach, acquire) | quality -> Bioinformatics (Syns: lineament, tone, calibre) | results -> Bioinformatics (Syns: final result, consequence, resultant role)",Bioinformatics
"Arranging the stacking orders of A-type antiferromagnetic (A-AFM) bilayers offers an accessible pathway to two-dimensional altermagnets, but requires strict symmetry conditions such as layer groups, sliding positions, and twisting angles. Here, we find that circularly polarized light (CPL) irradiation breaks time-reversal symmetry, enabling the development of altermagnets beyond these constraints. Based on symmetrical analysis, our revealments indicate that A-AFM bilayer building-blocks with inversion symmetry exhibit altermagnetism robust to stacking sliding and variations of illumination directions. These bilayers can be constructed from arbitrary ferromagnetic monolayers and guided by the $d$-electron counting rule. Adopting bilayer MnBi$_2$Te$_4$ as a template, out-of-plane illumination with CPL reveals an $f$-wave altermagnetic feature at sliding positions $\left\{E|\left(0,0\right)\right\}$, $\left\{E|\left(\frac{1}{3},\frac{2}{3}\right)\right\}$ and $\left\{E|\left(\frac{2}{3},\frac{1}{3}\right)\right\}$, while a $p$-wave feature is predicted at other sliding positions. Our unveilings popularize the applicability of altermagnets in A-AFM bilayers with inversion symmetry, igniting a new wave of research in this field.",Materials Science
"Arranging the stacking orders of A-type antiferromagnetic (A-AFM) bilayers offers an accessible pathway to two-dimensional altermagnets, but requires strict symmetry conditions such as layer groups, sliding positions, and twisting angles. Here, we find that circularly polarized light (CPL) irradiation breaks time-reversal symmetry, enabling the development of altermagnets beyond these constraints. Based on symmetrical analysis, our revealments indicate that A-AFM bilayer building-blocks with inversion symmetry exhibit altermagnetism robust to stacking sliding and variations of illumination directions. These bilayers can be constructed from arbitrary ferromagnetic monolayers and guided by the $d$-electron counting rule. Adopting bilayer MnBi$_2$Te$_4$ as a template, out-of-plane illumination with CPL reveals an $f$-wave altermagnetic feature at sliding positions $\left\{E|\left(0,0\right)\right\}$, $\left\{E|\left(\frac{1}{3},\frac{2}{3}\right)\right\}$ and $\left\{E|\left(\frac{2}{3},\frac{1}{3}\right)\right\}$, while a $p$-wave feature is predicted at other sliding positions. Our unveilings popularize the applicability of altermagnets in A-AFM bilayers with inversion symmetry, igniting a new wave of research in this field. [SEP] [HINT] based -> Bioinformatics (Syns: ground, free-base, base) | symmetry -> Materials Science (Syns: proportion, correspondence, balance)",Materials Science
"Thermally Activated Delayed Fluorescence (TADF) emitters must satisfy two competing requirements: small singlet-triplet energy gaps for thermal upconversion and sufficient spin-orbit coupling for fast reverse intersystem crossing. Predicting these properties accurately demands expensive calculations. We address this using a validated semi-empirical protocol (GFN2-xTB geometries, sTDA/sTD-DFT-xTB excited states) on 747 molecules, combined with charge-transfer descriptors from Natural Transition Orbital analysis. The hole-electron spatial overlap She emerges as a key predictor, accounting for 21% of feature importance for the triplet state alone. Our best model (Support Vector Regression) reaches MAE = 0.024 eV and R2 = 0.96 for $ΔE_{ST}$. Active learning reduces the data needed to reach target accuracy by approximately 25% compared to random sampling. Three application domains are explored: NIR-emitting probes for bioimaging, photocatalytic sensitizers, and fast-response materials for photodetection.",Materials Science
"Thermally Activated Delayed Fluorescence (TADF) emitters must satisfy two competing requirements: small singlet-triplet energy gaps for thermal upconversion and sufficient spin-orbit coupling for fast reverse intersystem crossing. Predicting these properties accurately demands expensive calculations. We address this using a validated semi-empirical protocol (GFN2-xTB geometries, sTDA/sTD-DFT-xTB excited states) on 747 molecules, combined with charge-transfer descriptors from Natural Transition Orbital analysis. The hole-electron spatial overlap She emerges as a key predictor, accounting for 21% of feature importance for the triplet state alone. Our best model (Support Vector Regression) reaches MAE = 0.024 eV and R2 = 0.96 for $ΔE_{ST}$. Active learning reduces the data needed to reach target accuracy by approximately 25% compared to random sampling. Three application domains are explored: NIR-emitting probes for bioimaging, photocatalytic sensitizers, and fast-response materials for photodetection. [SEP] [HINT] transition -> Materials Science (Syns: passage, modulation, changeover) | learning -> Bioinformatics (Syns: take, teach, acquire) | using -> Bioinformatics (Syns: utilize, exploitation, apply)",Materials Science
"Artificial intelligence in medicine is built to serve the average patient. By minimizing error across large datasets, most systems deliver strong aggregate accuracy yet falter at the margins: patients with rare variants, multimorbidity, or underrepresented demographics. This average patient fallacy erodes both equity and trust. We propose a different design: a multi-agent ecosystem for N-of-1 decision support. In this environment, agents clustered by organ systems, patient populations, and analytic modalities draw on a shared library of models and evidence synthesis tools. Their results converge in a coordination layer that weighs reliability, uncertainty, and data density before presenting the clinician with a decision-support packet: risk estimates bounded by confidence ranges, outlier flags, and linked evidence. Validation shifts from population averages to individual reliability, measured by error in low-density regions, calibration in the small, and risk--coverage trade-offs. Anticipated challenges include computational demands, automation bias, and regulatory fit, addressed through caching strategies, consensus checks, and adaptive trial frameworks. By moving from monolithic models to orchestrated intelligence, this approach seeks to align medical AI with the first principle of medicine: care that is transparent, equitable, and centered on the individual.",Bioinformatics
"Artificial intelligence in medicine is built to serve the average patient. By minimizing error across large datasets, most systems deliver strong aggregate accuracy yet falter at the margins: patients with rare variants, multimorbidity, or underrepresented demographics. This average patient fallacy erodes both equity and trust. We propose a different design: a multi-agent ecosystem for N-of-1 decision support. In this environment, agents clustered by organ systems, patient populations, and analytic modalities draw on a shared library of models and evidence synthesis tools. Their results converge in a coordination layer that weighs reliability, uncertainty, and data density before presenting the clinician with a decision-support packet: risk estimates bounded by confidence ranges, outlier flags, and linked evidence. Validation shifts from population averages to individual reliability, measured by error in low-density regions, calibration in the small, and risk--coverage trade-offs. Anticipated challenges include computational demands, automation bias, and regulatory fit, addressed through caching strategies, consensus checks, and adaptive trial frameworks. By moving from monolithic models to orchestrated intelligence, this approach seeks to align medical AI with the first principle of medicine: care that is transparent, equitable, and centered on the individual. [SEP] [HINT] computational -> Neuroscience (Syns: ) | results -> Bioinformatics (Syns: final result, consequence, resultant role) | systems -> Bioinformatics (Syns: organization, organisation, system)",Bioinformatics
"Ratios of common biomarkers and blood analytes are well established for early detection and predictive purposes. Early risk stratification in critical care is often limited by the delayed availability of complex severity scores. Complete blood count (CBC) parameters, available within hours of admission, may enable rapid prognostication. We conducted an exhaustive and systematic evaluation of CBC-derived ratios for mortality prediction to identify robust, accessible, and generalizable biomarkers. We generated all feasible two-parameter CBC ratios with unit checks and plausibility filters on more than 90,000 ICU admissions (MIMIC-IV). Discrimination was assessed via cross-validated and external AUC, calibration via isotonic regression, and clinical utility with decision-curve analysis. Retrospective validation was performed on eICU-CRD (n = 156530) participants. The ratio of Red Cell Distribution Width (RDW) to Mean Corpuscular Hemoglobin Concentration (MCHC), denoted RDW:MCHC, emerged as the top biomarker (AUC = 0.699 discovery; 0.662 validation), outperforming RDW and NLR. It achieved near-universal availability (99.9\% vs.\ 35.0\% for NLR), excellent calibration (Hosmer--Lemeshow $p = 1.0$; $\mathrm{ECE} < 0.001$), and preserved performance across diagnostic groups, with only modest attenuation in respiratory cases. Expressed as a logistic odds ratio, each one standard deviation increase in RDW:MCHC nearly quadrupled 30-day mortality odds (OR = 3.81, 95\% CI [3.70, 3.95]). Decision-curve analysis showed positive net benefit at high-risk triage thresholds. A simple, widely available CBC-derived feature (RDW:MCHC) provides consistent, externally validated signal for early mortality risk. While not a substitute for multivariable scores, it offers a pragmatic adjunct for rapid triage when full scoring is impractical.",Bioinformatics
"Ratios of common biomarkers and blood analytes are well established for early detection and predictive purposes. Early risk stratification in critical care is often limited by the delayed availability of complex severity scores. Complete blood count (CBC) parameters, available within hours of admission, may enable rapid prognostication. We conducted an exhaustive and systematic evaluation of CBC-derived ratios for mortality prediction to identify robust, accessible, and generalizable biomarkers. We generated all feasible two-parameter CBC ratios with unit checks and plausibility filters on more than 90,000 ICU admissions (MIMIC-IV). Discrimination was assessed via cross-validated and external AUC, calibration via isotonic regression, and clinical utility with decision-curve analysis. Retrospective validation was performed on eICU-CRD (n = 156530) participants. The ratio of Red Cell Distribution Width (RDW) to Mean Corpuscular Hemoglobin Concentration (MCHC), denoted RDW:MCHC, emerged as the top biomarker (AUC = 0.699 discovery; 0.662 validation), outperforming RDW and NLR. It achieved near-universal availability (99.9\% vs.\ 35.0\% for NLR), excellent calibration (Hosmer--Lemeshow $p = 1.0$; $\mathrm{ECE} < 0.001$), and preserved performance across diagnostic groups, with only modest attenuation in respiratory cases. Expressed as a logistic odds ratio, each one standard deviation increase in RDW:MCHC nearly quadrupled 30-day mortality odds (OR = 3.81, 95\% CI [3.70, 3.95]). Decision-curve analysis showed positive net benefit at high-risk triage thresholds. A simple, widely available CBC-derived feature (RDW:MCHC) provides consistent, externally validated signal for early mortality risk. While not a substitute for multivariable scores, it offers a pragmatic adjunct for rapid triage when full scoring is impractical. [SEP] [HINT] clinical -> Bioinformatics (Syns: ) | complex -> Bioinformatics (Syns: building complex, coordination compound, composite) | performance -> Bioinformatics (Syns: functioning, operation, carrying out)",Bioinformatics
"Computing haplotypes from sequencing data, i.e. haplotype assembly, is an important component of foundational molecular and population genetics problems, including interpreting the effects of genetic variation on complex traits and reconstructing genealogical relationships. Assembling the haplotypes of polyploid genomes remains a significant challenge due to the exponential search space of haplotype phasings and read assignment ambiguity; the latter challenge is particularly difficult for polyploid haplotype assemblers since the information contained within the observed sequence reads is often insufficient for unambiguous haplotype assignment in polyploid genomes. We present pHapCompass, probabilistic haplotype assembly algorithms for diploid and polyploid genomes that explicitly model and propagate read assignment ambiguity to compute a distribution over polyploid haplotype phasings. We develop graph theoretic algorithms to enable statistical inference and uncertainty quantification despite an exponential space of possible phasings. Since prior work evaluates polyploid haplotype assembly on synthetic genomes that do not reflect the realistic genomic complexity of polyploidy organisms, we develop a computational workflow for simulating genomes and DNA-seq for auto- and allopolyploids. Additionally, we generalize the vector error rate and minimum error correction evaluation criteria for partially phased haplotypes. Benchmarking of pHapCompass and several existing polyploid haplotype assemblers shows that pHapCompass yields competitive performance across varying genomic complexities and polyploid structures while retaining an accurate quantification of phase uncertainty. The source code for pHapCompass, simulation scripts, and datasets are freely available at https://github.com/bayesomicslab/pHapCompass.",Bioinformatics
"Computing haplotypes from sequencing data, i.e. haplotype assembly, is an important component of foundational molecular and population genetics problems, including interpreting the effects of genetic variation on complex traits and reconstructing genealogical relationships. Assembling the haplotypes of polyploid genomes remains a significant challenge due to the exponential search space of haplotype phasings and read assignment ambiguity; the latter challenge is particularly difficult for polyploid haplotype assemblers since the information contained within the observed sequence reads is often insufficient for unambiguous haplotype assignment in polyploid genomes. We present pHapCompass, probabilistic haplotype assembly algorithms for diploid and polyploid genomes that explicitly model and propagate read assignment ambiguity to compute a distribution over polyploid haplotype phasings. We develop graph theoretic algorithms to enable statistical inference and uncertainty quantification despite an exponential space of possible phasings. Since prior work evaluates polyploid haplotype assembly on synthetic genomes that do not reflect the realistic genomic complexity of polyploidy organisms, we develop a computational workflow for simulating genomes and DNA-seq for auto- and allopolyploids. Additionally, we generalize the vector error rate and minimum error correction evaluation criteria for partially phased haplotypes. Benchmarking of pHapCompass and several existing polyploid haplotype assemblers shows that pHapCompass yields competitive performance across varying genomic complexities and polyploid structures while retaining an accurate quantification of phase uncertainty. The source code for pHapCompass, simulation scripts, and datasets are freely available at https://github.com/bayesomicslab/pHapCompass. [SEP] [HINT] computational -> Neuroscience (Syns: ) | space -> Neuroscience (Syns: distance, place, outer space) | information -> Bioinformatics (Syns: entropy, data, info)",Bioinformatics
"We present thermal conductivity data on single crystals of YAlO3 and YbAlO3 for temperatures between 2 K and 300 K and the heat current along b and c. Both materials are very good thermal conductors in the investigated temperature range. The thermal conductivity in these electrical insulators is due to phonons. The effect of Y-Yb exchange is found to be rather small despite the considerable difference in density and average atomic mass. For YAlO3 we find a moderate thermal conductivity anisotropy with weak temperature dependence and a ratio of c to b direction between at most 1 and 2.2. It is discussed with regard to the velocities of sound and relevant scattering processes. For YbAlO3 the small crystal size limits the precision of absolute thermal conductivity values and does not allow drawing conclusions on the anisotropy. Our results on YAlO3 confirm that the material is suitable for applications requiring a good thermal conductivity at temperatures down to liquid helium, such as lasers, substrates, and detectors.",Materials Science
"We present thermal conductivity data on single crystals of YAlO3 and YbAlO3 for temperatures between 2 K and 300 K and the heat current along b and c. Both materials are very good thermal conductors in the investigated temperature range. The thermal conductivity in these electrical insulators is due to phonons. The effect of Y-Yb exchange is found to be rather small despite the considerable difference in density and average atomic mass. For YAlO3 we find a moderate thermal conductivity anisotropy with weak temperature dependence and a ratio of c to b direction between at most 1 and 2.2. It is discussed with regard to the velocities of sound and relevant scattering processes. For YbAlO3 the small crystal size limits the precision of absolute thermal conductivity values and does not allow drawing conclusions on the anisotropy. Our results on YAlO3 confirm that the material is suitable for applications requiring a good thermal conductivity at temperatures down to liquid helium, such as lasers, substrates, and detectors. [SEP] [HINT] results -> Bioinformatics (Syns: final result, consequence, resultant role) | crystal -> Materials Science (Syns: crystallization, quartz, lechatelierite) | materials -> Materials Science (Syns: stuff, cloth, material)",Materials Science
"Tissue dynamics play a crucial role in biological processes ranging from inflammation to morphogenesis. However, these noisy multicellular dynamics are notoriously hard to predict. Here, we introduce a biomimetic machine learning framework capable of inferring noisy multicellular dynamics directly from experimental movies. This generative model combines graph neural networks, normalizing flows and WaveNet algorithms to represent tissues as neural stochastic differential equations where cells are edges of an evolving graph. Cell interactions are encoded in a dual signaling graph capable of handling signaling cascades. The dual graph architecture of our neural networks reflects the architecture of the underlying biological tissues, substantially reducing the amount of data needed for training, compared to convolutional or fully-connected neural networks. Taking epithelial tissue experiments as a case study, we show that our model not only captures stochastic cell motion but also predicts the evolution of cell states in their division cycle. Finally, we demonstrate that our method can accurately generate the experimental dynamics of developmental systems, such as the fly wing, and cell signaling processes mediated by stochastic ERK waves, paving the way for its use as a digital twin in bioengineering and clinical contexts.",Bioinformatics
"Tissue dynamics play a crucial role in biological processes ranging from inflammation to morphogenesis. However, these noisy multicellular dynamics are notoriously hard to predict. Here, we introduce a biomimetic machine learning framework capable of inferring noisy multicellular dynamics directly from experimental movies. This generative model combines graph neural networks, normalizing flows and WaveNet algorithms to represent tissues as neural stochastic differential equations where cells are edges of an evolving graph. Cell interactions are encoded in a dual signaling graph capable of handling signaling cascades. The dual graph architecture of our neural networks reflects the architecture of the underlying biological tissues, substantially reducing the amount of data needed for training, compared to convolutional or fully-connected neural networks. Taking epithelial tissue experiments as a case study, we show that our model not only captures stochastic cell motion but also predicts the evolution of cell states in their division cycle. Finally, we demonstrate that our method can accurately generate the experimental dynamics of developmental systems, such as the fly wing, and cell signaling processes mediated by stochastic ERK waves, paving the way for its use as a digital twin in bioengineering and clinical contexts. [SEP] [HINT] tissue -> Bioinformatics (Syns: tissue paper, weave) | clinical -> Bioinformatics (Syns: ) | learning -> Bioinformatics (Syns: take, teach, acquire)",Bioinformatics
"Neural dynamics underlie behaviors from memory to sleep, yet identifying mechanisms for higher-order phenomena (e.g., social interaction) is experimentally challenging. Existing whole-brain models often fail to scale to single-neuron resolution, omit behavioral readouts, or rely on PCA/conv pipelines that miss long-range, non-linear interactions. We introduce a sparse-attention whole-brain foundation model (SBM) for larval zebrafish that forecasts neuron spike probabilities conditioned on sensory stimuli and links brain state to behavior. SBM factorizes attention across neurons and along time, enabling whole-brain scale and interpretability. On a held-out subject, it achieves mean absolute error <0.02 with calibrated predictions and stable autoregressive rollouts. Coupled to a permutation-invariant behavior head, SBM enables gradient-based synthesis of neural patterns that elicit target behaviors. This framework supports rapid, behavior-grounded exploration of complex neural phenomena.",Neuroscience
"Neural dynamics underlie behaviors from memory to sleep, yet identifying mechanisms for higher-order phenomena (e.g., social interaction) is experimentally challenging. Existing whole-brain models often fail to scale to single-neuron resolution, omit behavioral readouts, or rely on PCA/conv pipelines that miss long-range, non-linear interactions. We introduce a sparse-attention whole-brain foundation model (SBM) for larval zebrafish that forecasts neuron spike probabilities conditioned on sensory stimuli and links brain state to behavior. SBM factorizes attention across neurons and along time, enabling whole-brain scale and interpretability. On a held-out subject, it achieves mean absolute error <0.02 with calibrated predictions and stable autoregressive rollouts. Coupled to a permutation-invariant behavior head, SBM enables gradient-based synthesis of neural patterns that elicit target behaviors. This framework supports rapid, behavior-grounded exploration of complex neural phenomena. [SEP] [HINT] complex -> Bioinformatics (Syns: building complex, coordination compound, composite) | framework -> Bioinformatics (Syns: theoretical account, model, fabric) | scale -> Bioinformatics (Syns: shell, graduated table, plate)",Neuroscience
"Flexible electronics and neuromorphic computing face key challenges in material integration and function retention. In particular, freestanding membranes suffer from slow sacrificial layer removal and interfacial strain, while neuromorphic hardware often relies on area-intensive dual-device schemes for bipolar synaptic weights. Here, we present a universal strategy based on water-soluble Sr4Al2O7 sacrificial layers, enabling the rapid release of freestanding ferrimagnetic metal membranes, which exhibit deterministic spin-orbit torque switching characteristics with well-preserved perpendicular magnetic anisotropy and are potential for next-generation ultrafast information technology. Extending this approach, we realize single-device ferrimagnetic synapses exhibiting intrinsic bipolar resistive switching. When implemented in a ResNet-18 architecture, these devices achieve 92% accuracy on CIFAR-10 - comparable to floating-point software models - while halving device counts relative to differential-pair implementations. These results establish a scalable platform linking flexible spintronics with compact, high-performance neuromorphic systems, offering foundational advances for next-generation electronics and brain-inspired hardware.",Materials Science
"Flexible electronics and neuromorphic computing face key challenges in material integration and function retention. In particular, freestanding membranes suffer from slow sacrificial layer removal and interfacial strain, while neuromorphic hardware often relies on area-intensive dual-device schemes for bipolar synaptic weights. Here, we present a universal strategy based on water-soluble Sr4Al2O7 sacrificial layers, enabling the rapid release of freestanding ferrimagnetic metal membranes, which exhibit deterministic spin-orbit torque switching characteristics with well-preserved perpendicular magnetic anisotropy and are potential for next-generation ultrafast information technology. Extending this approach, we realize single-device ferrimagnetic synapses exhibiting intrinsic bipolar resistive switching. When implemented in a ResNet-18 architecture, these devices achieve 92% accuracy on CIFAR-10 - comparable to floating-point software models - while halving device counts relative to differential-pair implementations. These results establish a scalable platform linking flexible spintronics with compact, high-performance neuromorphic systems, offering foundational advances for next-generation electronics and brain-inspired hardware. [SEP] [HINT] based -> Bioinformatics (Syns: ground, free-base, base) | information -> Bioinformatics (Syns: entropy, data, info) | results -> Bioinformatics (Syns: final result, consequence, resultant role)",Materials Science
"We investigate a conductance-based neuron model to explore how voltage-gated ion channel isoforms influence action-potential generation. The model combines a six-state Markov representation of NaV channels with a first-order KV3.1 model, allowing us to vary maximal sodium and potassium conductances and compare nine NaV isoforms. Using bifurcation theory and local stability analysis, we map regions of stable limit cycles and visualize excitability landscapes via heatmap-based diagrams. These analyses show that isoforms NaV1.3, NaV1.4 and NaV1.6 support broad excitable regimes, while isoforms NaV1.7 and NaV1.9 exhibit minimal oscillatory behavior. Our findings provide insights into the role of channel heterogeneity in neuronal dynamics and may help to guide the design of synthetic excitable systems by narrowing the parameter space needed for robust action-potential trains.",Neuroscience
"We investigate a conductance-based neuron model to explore how voltage-gated ion channel isoforms influence action-potential generation. The model combines a six-state Markov representation of NaV channels with a first-order KV3.1 model, allowing us to vary maximal sodium and potassium conductances and compare nine NaV isoforms. Using bifurcation theory and local stability analysis, we map regions of stable limit cycles and visualize excitability landscapes via heatmap-based diagrams. These analyses show that isoforms NaV1.3, NaV1.4 and NaV1.6 support broad excitable regimes, while isoforms NaV1.7 and NaV1.9 exhibit minimal oscillatory behavior. Our findings provide insights into the role of channel heterogeneity in neuronal dynamics and may help to guide the design of synthetic excitable systems by narrowing the parameter space needed for robust action-potential trains. [SEP] [HINT] space -> Neuroscience (Syns: distance, place, outer space) | systems -> Bioinformatics (Syns: organization, organisation, system) | using -> Bioinformatics (Syns: utilize, exploitation, apply)",Neuroscience
"Untargeted metabolomics using LC-MS/MS offers the potential to comprehensively profile the chemical diversity of biological samples. However, the process is fundamentally limited by the ""identification bottleneck,"" where only a small fraction of detected features can be annotated using existing spectral libraries, leaving the majority of data uncharacterized and unused. In addition, the inherently low reproducibility of LC-MS/MS instruments introduces alignment errors between runs, making feature alignment across large datasets both error-prone and challenging. To overcome these constraints, we developed a deep learning method that eliminates the requirement for metabolite identification and reduces the influence of alignment inaccuracies. Here, we propose MS2toImg, a method that converts raw LC-MS/MS data into a two-dimensional images representing the global fragmentation pattern of each sample. These images are then used as direct input for a convolutional neural network (CNN), enabling end-to-end prediction of biological activity without explicit feature engineering or alignment. Our approach was validated using wild soybean samples and multiple bioactivity assays (e.g., DPPH, elastase inhibition). The MS2toImg-CNN model outperformed conventional machine learning baselines (e.g., Random Forest, PCA), demonstrating robust classification accuracy across diverse tasks. By transforming raw spectral data into images, our framework is inherently less sensitive to alignment errors caused by low instrument reproducibility, as it leverages the overall fragmentation landscape rather than relying on precise feature matching. This identification-free, image-based approach enables more robust and scalable bioactivity prediction from untargeted metabolomics data, offering a new paradigm for high-throughput functional screening in complex biological systems.",Bioinformatics
"Untargeted metabolomics using LC-MS/MS offers the potential to comprehensively profile the chemical diversity of biological samples. However, the process is fundamentally limited by the ""identification bottleneck,"" where only a small fraction of detected features can be annotated using existing spectral libraries, leaving the majority of data uncharacterized and unused. In addition, the inherently low reproducibility of LC-MS/MS instruments introduces alignment errors between runs, making feature alignment across large datasets both error-prone and challenging. To overcome these constraints, we developed a deep learning method that eliminates the requirement for metabolite identification and reduces the influence of alignment inaccuracies. Here, we propose MS2toImg, a method that converts raw LC-MS/MS data into a two-dimensional images representing the global fragmentation pattern of each sample. These images are then used as direct input for a convolutional neural network (CNN), enabling end-to-end prediction of biological activity without explicit feature engineering or alignment. Our approach was validated using wild soybean samples and multiple bioactivity assays (e.g., DPPH, elastase inhibition). The MS2toImg-CNN model outperformed conventional machine learning baselines (e.g., Random Forest, PCA), demonstrating robust classification accuracy across diverse tasks. By transforming raw spectral data into images, our framework is inherently less sensitive to alignment errors caused by low instrument reproducibility, as it leverages the overall fragmentation landscape rather than relying on precise feature matching. This identification-free, image-based approach enables more robust and scalable bioactivity prediction from untargeted metabolomics data, offering a new paradigm for high-throughput functional screening in complex biological systems. [SEP] [HINT] used -> Bioinformatics (Syns: utilize, ill-used, apply) | low -> Materials Science (Syns: low-spirited, scurvy, depressed) | features -> Bioinformatics (Syns: characteristic, lineament, feature of speech)",Bioinformatics
"In soccer penalty kicks, goalkeepers that orient their arms upward compared to downward can be misperceived as being taller - effectively recreating the Muller-Lyer illusion. The present study elaborates on previous research surrounding a potential illusion-induced bias in penalty kicks. Participants were exposed to goalkeeper configurations within a virtual goal including arms-parallel, arms-down, arms-out and arms-up. They separately judged the perceived size of the goalkeeper, and executed penalty kicks. The perceived size was near fully consistent with the intended illusion. Meanwhile, the penalty kicks indicated wider a horizontal position following arms-out, and lower vertical position following arms-up. Likewise, there was no relation between the biases expressed in perception and action. While goalkeepers can elicit a perceptual illusion, this does not extend to influencing the penalty kick itself. Instead, other contextual cues appeared more relevant including the proximity between the goalkeeper and goalposts, and with it, the available space in the goal.",Neuroscience
"In soccer penalty kicks, goalkeepers that orient their arms upward compared to downward can be misperceived as being taller - effectively recreating the Muller-Lyer illusion. The present study elaborates on previous research surrounding a potential illusion-induced bias in penalty kicks. Participants were exposed to goalkeeper configurations within a virtual goal including arms-parallel, arms-down, arms-out and arms-up. They separately judged the perceived size of the goalkeeper, and executed penalty kicks. The perceived size was near fully consistent with the intended illusion. Meanwhile, the penalty kicks indicated wider a horizontal position following arms-out, and lower vertical position following arms-up. Likewise, there was no relation between the biases expressed in perception and action. While goalkeepers can elicit a perceptual illusion, this does not extend to influencing the penalty kick itself. Instead, other contextual cues appeared more relevant including the proximity between the goalkeeper and goalposts, and with it, the available space in the goal. [SEP] [HINT] space -> Neuroscience (Syns: distance, place, outer space) | including -> Bioinformatics (Syns: admit, include, let in) | perceptual -> Neuroscience (Syns: )",Neuroscience
"This study examines whether sentence-level memory load in comprehension is better explained by linear proximity between syntactically related words or by the structural density of the intervening material. Building on locality-based accounts and cross-linguistic evidence for dependency length minimization, the work advances Intervener Complexity-the number of intervening heads between a head and its dependent-as a structurally grounded lens that refines linear distance measures. Using harmonized dependency treebanks and a mixed-effects framework across multiple languages, the analysis jointly evaluates sentence length, dependency length, and Intervener Complexity as predictors of the Memory-load measure. Studies in Psycholinguistics have reported the contributions of feature interference and misbinding to memory load during processing. For this study, I operationalized sentence-level memory load as the linear sum of feature misbinding and feature interference for tractability; current evidence does not establish that their cognitive contributions combine additively. All three factors are positively associated with memory load, with sentence length exerting the broadest influence and Intervener Complexity offering explanatory power beyond linear distance. Conceptually, the findings reconcile linear and hierarchical perspectives on locality by treating dependency length as an important surface signature while identifying intervening heads as a more proximate indicator of integration and maintenance demands. Methodologically, the study illustrates how UD-based graph measures and cross-linguistic mixed-effects modelling can disentangle linear and structural contributions to processing efficiency, providing a principled path for evaluating competing theories of memory load in sentence comprehension.",Neuroscience
"This study examines whether sentence-level memory load in comprehension is better explained by linear proximity between syntactically related words or by the structural density of the intervening material. Building on locality-based accounts and cross-linguistic evidence for dependency length minimization, the work advances Intervener Complexity-the number of intervening heads between a head and its dependent-as a structurally grounded lens that refines linear distance measures. Using harmonized dependency treebanks and a mixed-effects framework across multiple languages, the analysis jointly evaluates sentence length, dependency length, and Intervener Complexity as predictors of the Memory-load measure. Studies in Psycholinguistics have reported the contributions of feature interference and misbinding to memory load during processing. For this study, I operationalized sentence-level memory load as the linear sum of feature misbinding and feature interference for tractability; current evidence does not establish that their cognitive contributions combine additively. All three factors are positively associated with memory load, with sentence length exerting the broadest influence and Intervener Complexity offering explanatory power beyond linear distance. Conceptually, the findings reconcile linear and hierarchical perspectives on locality by treating dependency length as an important surface signature while identifying intervening heads as a more proximate indicator of integration and maintenance demands. Methodologically, the study illustrates how UD-based graph measures and cross-linguistic mixed-effects modelling can disentangle linear and structural contributions to processing efficiency, providing a principled path for evaluating competing theories of memory load in sentence comprehension. [SEP] [HINT] work -> Bioinformatics (Syns: work out, process, bring) | processing -> Neuroscience (Syns: work, process, march) | framework -> Bioinformatics (Syns: theoretical account, model, fabric)",Neuroscience
"Area V4 is a mid-level stage of the macaque ventral visual stream, known to encode intermediate visual features such as color, curvature, corners, texture, three-dimensional (3D) solids, and local form. Classical neurophysiological studies have typically examined these dimensions in isolation, contrasting V4 selectivity for shape versus texture, 3D solid surfaces versus two-dimensional (2D) flat patterns, or object form versus texture. Yet how these tunings relate to one another within individual neurons, and how they are jointly organized across the cortical surface, remain unknown. For instance, does a neuron selective for 2D contour-defined shape prefer 3D solid surfaces or 2D flat surfaces? How are preferences for such heterogeneous attributes arranged in a common topographic map? To address these questions, we leverage V4 ""digital twins"" -- deep neural network models fitted to large-scale, wide-field calcium imaging data comprising tens of thousands of natural images. These digital twins allow us to systematically probe not only the stimulus dimensions explored in earlier studies, but also new, multidimensional stimulus sets that reveal additional aspects of the V4 code. In this study, we find that neural pixels preferring 2D contour-defined shapes also tend to prefer 3D surface shape defined by shading or texture gradients and by object form. In contrast, pixels preferring 2D texture tend to prefer flat surfaces defined by uniform texture or reflectance. We propose that this division of labor suggests that V4 may decompose the encoding of geometrical shape and surface appearance of visual stimuli into distinct populations of neurons, organized as interleaved clusters in the V4 topographic map.",Neuroscience
"Area V4 is a mid-level stage of the macaque ventral visual stream, known to encode intermediate visual features such as color, curvature, corners, texture, three-dimensional (3D) solids, and local form. Classical neurophysiological studies have typically examined these dimensions in isolation, contrasting V4 selectivity for shape versus texture, 3D solid surfaces versus two-dimensional (2D) flat patterns, or object form versus texture. Yet how these tunings relate to one another within individual neurons, and how they are jointly organized across the cortical surface, remain unknown. For instance, does a neuron selective for 2D contour-defined shape prefer 3D solid surfaces or 2D flat surfaces? How are preferences for such heterogeneous attributes arranged in a common topographic map? To address these questions, we leverage V4 ""digital twins"" -- deep neural network models fitted to large-scale, wide-field calcium imaging data comprising tens of thousands of natural images. These digital twins allow us to systematically probe not only the stimulus dimensions explored in earlier studies, but also new, multidimensional stimulus sets that reveal additional aspects of the V4 code. In this study, we find that neural pixels preferring 2D contour-defined shapes also tend to prefer 3D surface shape defined by shading or texture gradients and by object form. In contrast, pixels preferring 2D texture tend to prefer flat surfaces defined by uniform texture or reflectance. We propose that this division of labor suggests that V4 may decompose the encoding of geometrical shape and surface appearance of visual stimuli into distinct populations of neurons, organized as interleaved clusters in the V4 topographic map. [SEP] [HINT] features -> Bioinformatics (Syns: characteristic, lineament, feature of speech) | cortical -> Neuroscience (Syns: ) | visual -> Neuroscience (Syns: optical, ocular, optic)",Neuroscience
"During slow-wave sleep, the brain produces traveling waves of slow oscillations (SOs; $\leq 2$ Hz), characterized by the propagation of alternating high- and low-activity states. The question of internal mechanisms that modulate traveling waves of SOs is still unanswered although it is established that it is an adaptation mechanism that mediates them. One mechanism investigated is spike-frequency adaptation, a hyperpolarizing feedback current that is activated during periods of high-activity. An alternative mechanism is based on hyperpolarization-activated currents, which are positive feedback currents that are activated in low-activity states. Both adaptation mechanisms were shown to feature SO-like dynamics in neuronal populations, and the inclusion of a spatial domain seems to enhance observable differences in their effects. To investigate this in detail, we examine a spatially extended two-population Wilson-Cowan model with local spatial coupling and the excitatory populations equipped with either one of the two adaptation mechanisms. We describe them with the same dynamical equation and include the inverse mode of action by changing the signs of adaptation strength and gain. We show that the dynamical systems are mathematically equivalent under a compensatory external input, which depends on the adaptation strength, leading to a shift in state space of the otherwise equivalent bifurcation structure. Strong enough adaptation is required to induce traveling waves. Additionally, adaptation modulates the properties of the spatio-temporal activity patterns, such as temporal and spatial frequencies, and the speed of the traveling waves, all of which increase with increasing strength. Though being dynamically equivalent, our results also explain why location-dependent variations in feedback strength cause differences in the propagation of traveling waves between both adaptation mechanisms.",Neuroscience
"During slow-wave sleep, the brain produces traveling waves of slow oscillations (SOs; $\leq 2$ Hz), characterized by the propagation of alternating high- and low-activity states. The question of internal mechanisms that modulate traveling waves of SOs is still unanswered although it is established that it is an adaptation mechanism that mediates them. One mechanism investigated is spike-frequency adaptation, a hyperpolarizing feedback current that is activated during periods of high-activity. An alternative mechanism is based on hyperpolarization-activated currents, which are positive feedback currents that are activated in low-activity states. Both adaptation mechanisms were shown to feature SO-like dynamics in neuronal populations, and the inclusion of a spatial domain seems to enhance observable differences in their effects. To investigate this in detail, we examine a spatially extended two-population Wilson-Cowan model with local spatial coupling and the excitatory populations equipped with either one of the two adaptation mechanisms. We describe them with the same dynamical equation and include the inverse mode of action by changing the signs of adaptation strength and gain. We show that the dynamical systems are mathematically equivalent under a compensatory external input, which depends on the adaptation strength, leading to a shift in state space of the otherwise equivalent bifurcation structure. Strong enough adaptation is required to induce traveling waves. Additionally, adaptation modulates the properties of the spatio-temporal activity patterns, such as temporal and spatial frequencies, and the speed of the traveling waves, all of which increase with increasing strength. Though being dynamically equivalent, our results also explain why location-dependent variations in feedback strength cause differences in the propagation of traveling waves between both adaptation mechanisms. [SEP] [HINT] based -> Bioinformatics (Syns: ground, free-base, base) | space -> Neuroscience (Syns: distance, place, outer space) | results -> Bioinformatics (Syns: final result, consequence, resultant role)",Neuroscience
"The rapid aging of societies is intensifying demand for autonomous care robots; however, most existing systems are task-specific and rely on handcrafted preprocessing, limiting their ability to generalize across diverse scenarios. A prevailing theory in cognitive neuroscience proposes that the human brain operates through hierarchical predictive processing, which underlies flexible cognition and behavior by integrating multimodal sensory signals. Inspired by this principle, we introduce a hierarchical multimodal recurrent neural network grounded in predictive processing under the free-energy principle, capable of directly integrating over 30,000-dimensional visuo-proprioceptive inputs without dimensionality reduction. The model was able to learn two representative caregiving tasks, rigid-body repositioning and flexible-towel wiping, without task-specific feature engineering. We demonstrate three key properties: (i) self-organization of hierarchical latent dynamics that regulate task transitions, capture variability in uncertainty, and infer occluded states; (ii) robustness to degraded vision through visuo-proprioceptive integration; and (iii) asymmetric interference in multitask learning, where the more variable wiping task had little influence on repositioning, whereas learning the repositioning task led to a modest reduction in wiping performance, while the model maintained overall robustness. Although the evaluation was limited to simulation, these results establish predictive processing as a universal and scalable computational principle, pointing toward robust, flexible, and autonomous caregiving robots while offering theoretical insight into the human brain's ability to achieve flexible adaptation in uncertain real-world environments.",Neuroscience
"The rapid aging of societies is intensifying demand for autonomous care robots; however, most existing systems are task-specific and rely on handcrafted preprocessing, limiting their ability to generalize across diverse scenarios. A prevailing theory in cognitive neuroscience proposes that the human brain operates through hierarchical predictive processing, which underlies flexible cognition and behavior by integrating multimodal sensory signals. Inspired by this principle, we introduce a hierarchical multimodal recurrent neural network grounded in predictive processing under the free-energy principle, capable of directly integrating over 30,000-dimensional visuo-proprioceptive inputs without dimensionality reduction. The model was able to learn two representative caregiving tasks, rigid-body repositioning and flexible-towel wiping, without task-specific feature engineering. We demonstrate three key properties: (i) self-organization of hierarchical latent dynamics that regulate task transitions, capture variability in uncertainty, and infer occluded states; (ii) robustness to degraded vision through visuo-proprioceptive integration; and (iii) asymmetric interference in multitask learning, where the more variable wiping task had little influence on repositioning, whereas learning the repositioning task led to a modest reduction in wiping performance, while the model maintained overall robustness. Although the evaluation was limited to simulation, these results establish predictive processing as a universal and scalable computational principle, pointing toward robust, flexible, and autonomous caregiving robots while offering theoretical insight into the human brain's ability to achieve flexible adaptation in uncertain real-world environments. [SEP] [HINT] task -> Neuroscience (Syns: tax, project, chore) | computational -> Neuroscience (Syns: ) | learning -> Bioinformatics (Syns: take, teach, acquire)",Neuroscience
"Healthcare data are generated in many different formats, which makes it difficult to integrate and reuse across institutions and studies. Standardisation is required to enable consistent large-scale analysis. The OMOP-CDM, developed by the OHDSI community, provides one widely adopted standard. Our framework achieves schema-agnostic transformation by extending upon existing literature in using human-readable YAML specification to support both relational (Microsoft SQL Server (MSSQL)) and document-based (MongoDB) data sources. It also incorporates critical production readiness features: provenance-aware mapping and support for incremental updates. We validated the pipeline using 2.7 million patient records and 27 million encounters across six hospitals spanning two decades of records. The resulting OMOP-CDM dataset demonstrated an acceptable level of data quality with a 97% overall passing rate based on the OHDSI Data Quality Dashboard check. Our work provides a reusable blueprint for large-scale data harmonisation, directly supporting real-world medical data research.",Bioinformatics
"Healthcare data are generated in many different formats, which makes it difficult to integrate and reuse across institutions and studies. Standardisation is required to enable consistent large-scale analysis. The OMOP-CDM, developed by the OHDSI community, provides one widely adopted standard. Our framework achieves schema-agnostic transformation by extending upon existing literature in using human-readable YAML specification to support both relational (Microsoft SQL Server (MSSQL)) and document-based (MongoDB) data sources. It also incorporates critical production readiness features: provenance-aware mapping and support for incremental updates. We validated the pipeline using 2.7 million patient records and 27 million encounters across six hospitals spanning two decades of records. The resulting OMOP-CDM dataset demonstrated an acceptable level of data quality with a 97% overall passing rate based on the OHDSI Data Quality Dashboard check. Our work provides a reusable blueprint for large-scale data harmonisation, directly supporting real-world medical data research. [SEP] [HINT] based -> Bioinformatics (Syns: ground, free-base, base) | quality -> Bioinformatics (Syns: lineament, tone, calibre) | work -> Bioinformatics (Syns: work out, process, bring)",Bioinformatics
"Stochastic reaction networks (SRNs) are a general class of continuous-time Markov jump processes used to model a wide range of systems, including biochemical dynamics in single cells, ecological and epidemiological populations, and queueing or communication networks. Yet analyzing their dynamics remains challenging because these processes are high-dimensional and their transient behavior can vary substantially across different initial molecular or population states. Here we introduce a spectral framework for the stochastic Koopman operator that provides a tractable, low-dimensional representation of SRN dynamics over continuous time, together with computable error estimates. By exploiting the compactness of the Koopman operator, we recover dominant spectral modes directly from simulated or experimental data, enabling efficient prediction of moments, event probabilities, and other summary statistics across all initial states. We further derive continuous-time parameter sensitivities and cross-spectral densities, offering new tools for probing noise structure and frequency-domain behavior. We demonstrate the approach on biologically relevant systems, including synthetic intracellular feedback controllers, stochastic oscillators, and inference of initial-state distributions from high-temporal-resolution flow cytometry. Together, these results establish spectral Koopman analysis as a powerful and general framework for studying stochastic dynamical systems across the biological, ecological, and computational sciences.",Bioinformatics
"Stochastic reaction networks (SRNs) are a general class of continuous-time Markov jump processes used to model a wide range of systems, including biochemical dynamics in single cells, ecological and epidemiological populations, and queueing or communication networks. Yet analyzing their dynamics remains challenging because these processes are high-dimensional and their transient behavior can vary substantially across different initial molecular or population states. Here we introduce a spectral framework for the stochastic Koopman operator that provides a tractable, low-dimensional representation of SRN dynamics over continuous time, together with computable error estimates. By exploiting the compactness of the Koopman operator, we recover dominant spectral modes directly from simulated or experimental data, enabling efficient prediction of moments, event probabilities, and other summary statistics across all initial states. We further derive continuous-time parameter sensitivities and cross-spectral densities, offering new tools for probing noise structure and frequency-domain behavior. We demonstrate the approach on biologically relevant systems, including synthetic intracellular feedback controllers, stochastic oscillators, and inference of initial-state distributions from high-temporal-resolution flow cytometry. Together, these results establish spectral Koopman analysis as a powerful and general framework for studying stochastic dynamical systems across the biological, ecological, and computational sciences. [SEP] [HINT] used -> Bioinformatics (Syns: utilize, ill-used, apply) | computational -> Neuroscience (Syns: ) | networks -> Neuroscience (Syns: network, meshwork, electronic network)",Bioinformatics
"The reductionist approach commonly employed in scientific methods presupposes that both macro and micro phenomena can be explained by micro-level laws alone. This assumption implies intra-level causal closure, rendering all macro phenomena epiphenomenal. However, the integrative nature of consciousness suggests that it is a macro phenomenon. To ensure scientific testability and reject epiphenomenalism, the reductionist assumption of intra-level causal closure must be rejected. This implies that even neural-level behavior cannot be explained by observable neural-level laws alone. Therefore, a new methodology is necessary to acknowledge the causal efficacy of macro-level phenomena. We model the brain as operating under dual laws at different levels. This model includes hypothetical macro-level psychological laws that are not determined solely by micro-level neural laws, as well as the causal effects from macro to micro levels. In this study, we propose a constructive approach that explains both mental and physical phenomena through the interaction between these two sets of laws.",Neuroscience
"The reductionist approach commonly employed in scientific methods presupposes that both macro and micro phenomena can be explained by micro-level laws alone. This assumption implies intra-level causal closure, rendering all macro phenomena epiphenomenal. However, the integrative nature of consciousness suggests that it is a macro phenomenon. To ensure scientific testability and reject epiphenomenalism, the reductionist assumption of intra-level causal closure must be rejected. This implies that even neural-level behavior cannot be explained by observable neural-level laws alone. Therefore, a new methodology is necessary to acknowledge the causal efficacy of macro-level phenomena. We model the brain as operating under dual laws at different levels. This model includes hypothetical macro-level psychological laws that are not determined solely by micro-level neural laws, as well as the causal effects from macro to micro levels. In this study, we propose a constructive approach that explains both mental and physical phenomena through the interaction between these two sets of laws. [SEP] [HINT] different -> Neuroscience (Syns: unlike, dissimilar) | neural -> Bioinformatics (Syns: neuronic, nervous, neuronal) | methods -> Bioinformatics (Syns: method acting, method)",Neuroscience
"The global dimensionality of a neural representation manifold provides rich insight into the computational process underlying both artificial and biological neural networks. However, all existing measures of global dimensionality are sensitive to the number of samples, i.e., the number of rows and columns of the sample matrix. We show that, in particular, the participation ratio of eigenvalues, a popular measure of global dimensionality, is highly biased with small sample sizes, and propose a bias-corrected estimator that is more accurate with finite samples and with noise. On synthetic data examples, we demonstrate that our estimator can recover the true known dimensionality. We apply our estimator to neural brain recordings, including calcium imaging, electrophysiological recordings, and fMRI data, and to the neural activations in a large language model and show our estimator is invariant to the sample size. Finally, our estimators can additionally be used to measure the local dimensionalities of curved neural manifolds by weighting the finite samples appropriately.",Neuroscience
"The global dimensionality of a neural representation manifold provides rich insight into the computational process underlying both artificial and biological neural networks. However, all existing measures of global dimensionality are sensitive to the number of samples, i.e., the number of rows and columns of the sample matrix. We show that, in particular, the participation ratio of eigenvalues, a popular measure of global dimensionality, is highly biased with small sample sizes, and propose a bias-corrected estimator that is more accurate with finite samples and with noise. On synthetic data examples, we demonstrate that our estimator can recover the true known dimensionality. We apply our estimator to neural brain recordings, including calcium imaging, electrophysiological recordings, and fMRI data, and to the neural activations in a large language model and show our estimator is invariant to the sample size. Finally, our estimators can additionally be used to measure the local dimensionalities of curved neural manifolds by weighting the finite samples appropriately. [SEP] [HINT] used -> Bioinformatics (Syns: utilize, ill-used, apply) | language -> Neuroscience (Syns: linguistic process, linguistic communication, spoken communication) | computational -> Neuroscience (Syns: )",Neuroscience
"Accurate exploration of protein conformational ensembles is essential for uncovering function but remains hard because molecular-dynamics (MD) simulations suffer from high computational costs and energy-barrier trapping. This paper presents Energy Preference Optimization (EPO), an online refinement algorithm that turns a pretrained protein ensemble generator into an energy-aware sampler without extra MD trajectories. Specifically, EPO leverages stochastic differential equation sampling to explore the conformational landscape and incorporates a novel energy-ranking mechanism based on list-wise preference optimization. Crucially, EPO introduces a practical upper bound to efficiently approximate the intractable probability of long sampling trajectories in continuous-time generative models, making it easily adaptable to existing pretrained generators. On Tetrapeptides, ATLAS, and Fast-Folding benchmarks, EPO successfully generates diverse and physically realistic ensembles, establishing a new state-of-the-art in nine evaluation metrics. These results demonstrate that energy-only preference signals can efficiently steer generative models toward thermodynamically consistent conformational ensembles, providing an alternative to long MD simulations and widening the applicability of learned potentials in structural biology and drug discovery.",Bioinformatics
"Accurate exploration of protein conformational ensembles is essential for uncovering function but remains hard because molecular-dynamics (MD) simulations suffer from high computational costs and energy-barrier trapping. This paper presents Energy Preference Optimization (EPO), an online refinement algorithm that turns a pretrained protein ensemble generator into an energy-aware sampler without extra MD trajectories. Specifically, EPO leverages stochastic differential equation sampling to explore the conformational landscape and incorporates a novel energy-ranking mechanism based on list-wise preference optimization. Crucially, EPO introduces a practical upper bound to efficiently approximate the intractable probability of long sampling trajectories in continuous-time generative models, making it easily adaptable to existing pretrained generators. On Tetrapeptides, ATLAS, and Fast-Folding benchmarks, EPO successfully generates diverse and physically realistic ensembles, establishing a new state-of-the-art in nine evaluation metrics. These results demonstrate that energy-only preference signals can efficiently steer generative models toward thermodynamically consistent conformational ensembles, providing an alternative to long MD simulations and widening the applicability of learned potentials in structural biology and drug discovery. [SEP] [HINT] based -> Bioinformatics (Syns: ground, free-base, base) | computational -> Neuroscience (Syns: ) | results -> Bioinformatics (Syns: final result, consequence, resultant role)",Bioinformatics
"This work presents a finite element method for simulating dynamic processes that involve the coupled evolution of dislocation motion and crack propagation. The method numerically solves the Concurrent Atomistic-Continuum (CAC) formulation of the conservation of linear momentum. A crystalline material is discretized at the unit-cell level using 6-node prism elements whose geometry allows dislocations and cracks to nucleate and propagate along element facets. Nanoscale simulations of single-crystal Cu, Fe, and Si demonstrate the initiation and propagation of dislocations and cracks, and these results are reproduced by the finite element method in excellent agreement with fully atomistic molecular dynamics simulations. Mesoscale simulations of single-crystal Cu further demonstrate the ability of the method to capture size-dependent brittle and ductile behavior. Under plane-strain conditions the Cu model fractures in a brittle manner, while a fully three-dimensional model exhibits curved and intersecting dislocations that blunt the crack tip and prevent crack propagation, resulting in ductile behavior. The accuracy, efficiency, and applicability of the method are discussed.",Materials Science
"This work presents a finite element method for simulating dynamic processes that involve the coupled evolution of dislocation motion and crack propagation. The method numerically solves the Concurrent Atomistic-Continuum (CAC) formulation of the conservation of linear momentum. A crystalline material is discretized at the unit-cell level using 6-node prism elements whose geometry allows dislocations and cracks to nucleate and propagate along element facets. Nanoscale simulations of single-crystal Cu, Fe, and Si demonstrate the initiation and propagation of dislocations and cracks, and these results are reproduced by the finite element method in excellent agreement with fully atomistic molecular dynamics simulations. Mesoscale simulations of single-crystal Cu further demonstrate the ability of the method to capture size-dependent brittle and ductile behavior. Under plane-strain conditions the Cu model fractures in a brittle manner, while a fully three-dimensional model exhibits curved and intersecting dislocations that blunt the crack tip and prevent crack propagation, resulting in ductile behavior. The accuracy, efficiency, and applicability of the method are discussed. [SEP] [HINT] molecular -> Bioinformatics (Syns: ) | work -> Bioinformatics (Syns: work out, process, bring) | results -> Bioinformatics (Syns: final result, consequence, resultant role)",Materials Science
"Transcranial photobiomodulation (tPBM) therapy is an emerging, non-invasive neuromodulation technique that has demonstrated considerable potential in the field of neuropsychiatric disorders. Several studies have found that pulsed wave (PW) tPBM therapy yields superior biomodulatory effects. However, its neural mechanisms are still unknown which poses a significant barrier to the development of an optimized protocol. A randomized, single-blind study including 29 participants was conducted using a crossover design, with sham and continuous wave (CW) groups as controls. The EEG microstate analysis was utilized to explore the relative variations in temporal parameters and brain functional connectivity. To further elucidate the dynamic activity patterns of microstates, a 10-repeat 10-fold cross-validation with nine machine learning algorithms and kernel Shapley additive explanations analysis was employed. Results indicated that the pulsed wave mode enhanced the global efficiency, local efficiency, and betweenness centrality of microstate C in brain functional networks as well as the mean durations parameter achieving a middle to large effect size, with superior effects compared to the sham and continuous wave groups. Furthermore, the support vector machine based on the radial basis function method with kernel Shapley additive explanations analysis demonstrated the best performance with an area under the curve (AUC) reaching 0.956, and found that the 8 of top-10 microstate features related to microstate C contributed most significantly to the PW mode. In conclusion, the EEG microstate analysis found that PW tPBM therapy modulates the microstate C-specific patterns in the human brain, suggesting that microstate dynamics may serve as a state-dependent biomarker for the optimization of tPBM protocol.",Neuroscience
"Transcranial photobiomodulation (tPBM) therapy is an emerging, non-invasive neuromodulation technique that has demonstrated considerable potential in the field of neuropsychiatric disorders. Several studies have found that pulsed wave (PW) tPBM therapy yields superior biomodulatory effects. However, its neural mechanisms are still unknown which poses a significant barrier to the development of an optimized protocol. A randomized, single-blind study including 29 participants was conducted using a crossover design, with sham and continuous wave (CW) groups as controls. The EEG microstate analysis was utilized to explore the relative variations in temporal parameters and brain functional connectivity. To further elucidate the dynamic activity patterns of microstates, a 10-repeat 10-fold cross-validation with nine machine learning algorithms and kernel Shapley additive explanations analysis was employed. Results indicated that the pulsed wave mode enhanced the global efficiency, local efficiency, and betweenness centrality of microstate C in brain functional networks as well as the mean durations parameter achieving a middle to large effect size, with superior effects compared to the sham and continuous wave groups. Furthermore, the support vector machine based on the radial basis function method with kernel Shapley additive explanations analysis demonstrated the best performance with an area under the curve (AUC) reaching 0.956, and found that the 8 of top-10 microstate features related to microstate C contributed most significantly to the PW mode. In conclusion, the EEG microstate analysis found that PW tPBM therapy modulates the microstate C-specific patterns in the human brain, suggesting that microstate dynamics may serve as a state-dependent biomarker for the optimization of tPBM protocol. [SEP] [HINT] field -> Materials Science (Syns: field of honor, line of business, orbit) | based -> Bioinformatics (Syns: ground, free-base, base) | features -> Bioinformatics (Syns: characteristic, lineament, feature of speech)",Neuroscience
"The total energy is a fundamental characteristic of solids, molecules, and nanostructures. In most first-principles calculations of the total energy, the nuclear kinetic operator is decoupled from the many-body electronic Hamiltonian and the dynamics of the nuclei is reintroduced afterwards. This two-step procedure introduced by Born and Oppenheimer (BO) is approximate. Energies beyond the electronic and vibrational (or phononic) main contributions might be relevant when small energy differences are important, such as when predicting stable polymorphs or describing magnetic energy landscape. We clarify the different flavors of BO decoupling and give an exact formulation for the total energy in the basis of BO electronic wavefunctions. Then, we list contributions, beyond the main ones, that appear in a perturbative expansion in powers of $M_0^{-1/4}$, where $M_0$ is a typical nuclear mass, up to sixth order. Some of these might be grouped and denoted the electron-phonon contribution to total energy, $E^{\textrm{elph}}$, that first appears at fourth order. The electronic inertial mass contributes at sixth order. We clarify that the sum of the Allen-Heine-Cardona zero-point renormalization of eigenvalues over occupied states is not the electron-phonon contribution to the total energy but a part of the phononic contribution. The computation of the lowest-order $E^{\textrm{elph}}$ is implemented and shown to be small but non-negligible (3.8 meV per atom) in the case of diamond and its hexagonal polymorph. We also estimate the electronic inertial mass contribution and confirm the size-consistency of all computed terms.",Materials Science
"The total energy is a fundamental characteristic of solids, molecules, and nanostructures. In most first-principles calculations of the total energy, the nuclear kinetic operator is decoupled from the many-body electronic Hamiltonian and the dynamics of the nuclei is reintroduced afterwards. This two-step procedure introduced by Born and Oppenheimer (BO) is approximate. Energies beyond the electronic and vibrational (or phononic) main contributions might be relevant when small energy differences are important, such as when predicting stable polymorphs or describing magnetic energy landscape. We clarify the different flavors of BO decoupling and give an exact formulation for the total energy in the basis of BO electronic wavefunctions. Then, we list contributions, beyond the main ones, that appear in a perturbative expansion in powers of $M_0^{-1/4}$, where $M_0$ is a typical nuclear mass, up to sixth order. Some of these might be grouped and denoted the electron-phonon contribution to total energy, $E^{\textrm{elph}}$, that first appears at fourth order. The electronic inertial mass contributes at sixth order. We clarify that the sum of the Allen-Heine-Cardona zero-point renormalization of eigenvalues over occupied states is not the electron-phonon contribution to the total energy but a part of the phononic contribution. The computation of the lowest-order $E^{\textrm{elph}}$ is implemented and shown to be small but non-negligible (3.8 meV per atom) in the case of diamond and its hexagonal polymorph. We also estimate the electronic inertial mass contribution and confirm the size-consistency of all computed terms. [SEP] [HINT] electronic -> Materials Science (Syns: ) | different -> Neuroscience (Syns: unlike, dissimilar) | dynamics -> Bioinformatics (Syns: kinetics, dynamic, moral force)",Materials Science
"Understanding the structure and dynamics of Earth's inner core is essential for constraining its composition, thermal evolution, and seismic properties. Silicon is a probable major component of Earth's core. Using first-principles molecular dynamics and thermodynamic modeling, we investigate the structural, elastic, and transport properties of Fe-Si alloys at high pressures and temperatures. By computing the Gibbs free energies of B2, hcp, fcc, and bcc solid solutions, we construct the Fe-Si phase diagram applicable to the Earth's inner core. Our results reveal a pronounced miscibility gap between hcp and B2 Fe-Si, with the two phases coexisting over the compositional range of 6-11 wt% Si at 6000 K. The B2 Fe-Si alloy exhibits strong single-crystal shear anisotropy (22.9% at 6000 K) compared to the nearly isotropic hcp phase (0.6%), and yields a shear wave velocity (3.73 km/s) and Poisson's ratio consistent with seismological observations. Moreover, the computed transport properties reveal substantially lower thermal conductivity of B2 Fe-Si relative to pure iron or hcp Fe-Si under inner-core conditions. These results imply that Earth's inner core likely comprises multiple phases, whose distribution and crystallographic texture critically influence its seismic and thermal properties.",Materials Science
"Understanding the structure and dynamics of Earth's inner core is essential for constraining its composition, thermal evolution, and seismic properties. Silicon is a probable major component of Earth's core. Using first-principles molecular dynamics and thermodynamic modeling, we investigate the structural, elastic, and transport properties of Fe-Si alloys at high pressures and temperatures. By computing the Gibbs free energies of B2, hcp, fcc, and bcc solid solutions, we construct the Fe-Si phase diagram applicable to the Earth's inner core. Our results reveal a pronounced miscibility gap between hcp and B2 Fe-Si, with the two phases coexisting over the compositional range of 6-11 wt% Si at 6000 K. The B2 Fe-Si alloy exhibits strong single-crystal shear anisotropy (22.9% at 6000 K) compared to the nearly isotropic hcp phase (0.6%), and yields a shear wave velocity (3.73 km/s) and Poisson's ratio consistent with seismological observations. Moreover, the computed transport properties reveal substantially lower thermal conductivity of B2 Fe-Si relative to pure iron or hcp Fe-Si under inner-core conditions. These results imply that Earth's inner core likely comprises multiple phases, whose distribution and crystallographic texture critically influence its seismic and thermal properties. [SEP] [HINT] understanding -> Neuroscience (Syns: savvy, intellect, sympathy) | transport -> Materials Science (Syns: transferral, enthral, shipping) | structure -> Bioinformatics (Syns: social system, complex body part, social structure)",Materials Science
"The genetic evolution of SARS-CoV-2 has caused recurring epidemic waves, understanding its global dispersal patterns is critical for effective surveillance. We developed the Site-based mutation dynamics - Equal Power Sampling (S-EPS) framework, a phylogenetic-free, bias-correcting framework for profiling viral source-sink dynamics. Applying S-EPS to 6.6 million SARS-CoV-2 genomes (March 2020 - June 2024) from 13 regions worldwide, we identified Africa and the Indian subcontinent as the predominant sources of key mutations. Southeast Asia serves as an early transmission hub, while Russia and South America mainly acted as sinks. Key mutations took longer to establish fitness in source regions than externally. Once an amino acid substitution on the receptor-binding domain reached 1% prevalence in major sources, there is an 80% probability it would spread elsewhere, with a 2-month median lead time (IQR: 1-4). Our findings underscore the importance of genetic surveillance, with S-EPS offering enhanced capability for monitoring emerging viral threats.",Bioinformatics
"The genetic evolution of SARS-CoV-2 has caused recurring epidemic waves, understanding its global dispersal patterns is critical for effective surveillance. We developed the Site-based mutation dynamics - Equal Power Sampling (S-EPS) framework, a phylogenetic-free, bias-correcting framework for profiling viral source-sink dynamics. Applying S-EPS to 6.6 million SARS-CoV-2 genomes (March 2020 - June 2024) from 13 regions worldwide, we identified Africa and the Indian subcontinent as the predominant sources of key mutations. Southeast Asia serves as an early transmission hub, while Russia and South America mainly acted as sinks. Key mutations took longer to establish fitness in source regions than externally. Once an amino acid substitution on the receptor-binding domain reached 1% prevalence in major sources, there is an 80% probability it would spread elsewhere, with a 2-month median lead time (IQR: 1-4). Our findings underscore the importance of genetic surveillance, with S-EPS offering enhanced capability for monitoring emerging viral threats. [SEP] [HINT] understanding -> Neuroscience (Syns: savvy, intellect, sympathy) | framework -> Bioinformatics (Syns: theoretical account, model, fabric) | dynamics -> Bioinformatics (Syns: kinetics, dynamic, moral force)",Bioinformatics
"We report the results and unique instrument configuration of a novel experiment in which we successfully transitioned a DPPH sample from its natural paramagnetic state and essentially a non-magnetic material to a ferromagnetic state at room temperature. This was achieved using a specifically applied helical flux magnetic field. The DPPH sample (2,2-diphenyl-1-picrylhydrazyl) remained ferromagnetic for at least one hour after the experiment, indicating that a transformation in the material was induced by the external field rather than being merely a temporary magnetic phase transition observed only during the experiment. The external magnetic field used had a helical pitch angle of approximately $54.7°$, known mathematically as the Magic Angle, relative to the +z-axis, which is aligned with the normal S to N external field's magnetic moment vector. Based on the phenomenology of the experiment, we infer that this specific magic angle corresponding to the known quantization precession spin angle of free electrons under a homogeneous straight flux magnetic field potentially enhances the percentage of unpaired valence electrons within the DPPH material, allowing them to align in parallel with the applied external field. Typically, in paramagnetic materials, the distribution of unpaired electrons' quantum spins relative to an external field is nearly random, showing roughly a 50% chance of either parallel or antiparallel alignment. Only a slight majority preference exists in one alignment direction due to the Boltzmann thermal distribution, which contributes to the paramagnetic nature of these materials. In our measurements, we found that the induced ferromagnetism of the DPPH sample resulted in an abnormal thousand-fold decimal value increase in relative magnetic permeability at $μ{\approx}1.4$, compared to its typical paramagnetic value of $1.0001$ for this material.",Materials Science
"We report the results and unique instrument configuration of a novel experiment in which we successfully transitioned a DPPH sample from its natural paramagnetic state and essentially a non-magnetic material to a ferromagnetic state at room temperature. This was achieved using a specifically applied helical flux magnetic field. The DPPH sample (2,2-diphenyl-1-picrylhydrazyl) remained ferromagnetic for at least one hour after the experiment, indicating that a transformation in the material was induced by the external field rather than being merely a temporary magnetic phase transition observed only during the experiment. The external magnetic field used had a helical pitch angle of approximately $54.7°$, known mathematically as the Magic Angle, relative to the +z-axis, which is aligned with the normal S to N external field's magnetic moment vector. Based on the phenomenology of the experiment, we infer that this specific magic angle corresponding to the known quantization precession spin angle of free electrons under a homogeneous straight flux magnetic field potentially enhances the percentage of unpaired valence electrons within the DPPH material, allowing them to align in parallel with the applied external field. Typically, in paramagnetic materials, the distribution of unpaired electrons' quantum spins relative to an external field is nearly random, showing roughly a 50% chance of either parallel or antiparallel alignment. Only a slight majority preference exists in one alignment direction due to the Boltzmann thermal distribution, which contributes to the paramagnetic nature of these materials. In our measurements, we found that the induced ferromagnetism of the DPPH sample resulted in an abnormal thousand-fold decimal value increase in relative magnetic permeability at $μ{\approx}1.4$, compared to its typical paramagnetic value of $1.0001$ for this material. [SEP] [HINT] used -> Bioinformatics (Syns: utilize, ill-used, apply) | field -> Materials Science (Syns: field of honor, line of business, orbit) | transition -> Materials Science (Syns: passage, modulation, changeover)",Materials Science
"Accurately predicting protein-ligand binding free energies (BFEs) remains a central challenge in drug discovery, particularly because the most reliable methods, such as free energy perturbation (FEP), are computationally intensive and difficult to scale. Here, we introduce a hybrid quantum-classical framework that combines Mining Minima sampling with quantum mechanically refined ligand partial charges, QM/MM interaction evaluation, and variational quantum eigensolver (VQE)-based electronic energy correction. This design enables explicit treatment of polarization, charge redistribution, and electronic correlation effects that are often underestimated in purely classical scoring schemes, while retaining computational efficiency. Across 23 protein targets and 543 ligands, the method achieves a mean absolute error of about 1.10 kcal/mol with strong rank-order fidelity (Pearson R = 0.75, Spearman rho = 0.76, Kendall tau = 0.57), consistent with the performance of contemporary FEP protocols. Notably, the workflow requires only about 25 minutes per ligand on standard compute resources, resulting in an approximate 20-fold reduction in computational cost relative to alchemical free energy approaches. This level of accuracy and efficiency makes the method well-suited for high-throughput lead optimization and iterative design cycles in pharmaceutical discovery. The framework also provides a natural foundation for future integration with machine learning models to enable predictive, large-scale, and adaptive screening strategies.",Bioinformatics
"Accurately predicting protein-ligand binding free energies (BFEs) remains a central challenge in drug discovery, particularly because the most reliable methods, such as free energy perturbation (FEP), are computationally intensive and difficult to scale. Here, we introduce a hybrid quantum-classical framework that combines Mining Minima sampling with quantum mechanically refined ligand partial charges, QM/MM interaction evaluation, and variational quantum eigensolver (VQE)-based electronic energy correction. This design enables explicit treatment of polarization, charge redistribution, and electronic correlation effects that are often underestimated in purely classical scoring schemes, while retaining computational efficiency. Across 23 protein targets and 543 ligands, the method achieves a mean absolute error of about 1.10 kcal/mol with strong rank-order fidelity (Pearson R = 0.75, Spearman rho = 0.76, Kendall tau = 0.57), consistent with the performance of contemporary FEP protocols. Notably, the workflow requires only about 25 minutes per ligand on standard compute resources, resulting in an approximate 20-fold reduction in computational cost relative to alchemical free energy approaches. This level of accuracy and efficiency makes the method well-suited for high-throughput lead optimization and iterative design cycles in pharmaceutical discovery. The framework also provides a natural foundation for future integration with machine learning models to enable predictive, large-scale, and adaptive screening strategies. [SEP] [HINT] computational -> Neuroscience (Syns: ) | learning -> Bioinformatics (Syns: take, teach, acquire) | charge -> Materials Science (Syns: tear, bearing, burster)",Bioinformatics
"Forces transmitted by bones are routinely studied in human biomechanics, but it is challenging to measure them non-invasively, especially outside of the laboratory setting. We introduce a technique for non-invasive, in vivo measurement of tibial compression force using flexural waves propagating in the tibia. Modeling the tibia as an axially compressed Euler-Bernoulli beam, we show that tibial flexural waves have load-dependent frequency spectra. Specifically, under physiological conditions, peak locations in the acceleration amplitude spectrum shift linearly with the compression force on the tibia, and may be used as proxy force measure. We test the validity of this technique using a proof-of-principle wearable system that generates flexural waves via a skin-mounted mechanical transducer and measures the spectra of these waves using a skin-mounted accelerometer. In agreement with beam theory, data from three participants demonstrate linear relationships between tibial compression force and peak frequency location with Pearson correlation coefficients $r=0.88$--$0.97$ for medial-lateral swaying and $r=0.88$--$0.95$ for walking trials. Our flexural wave-based technique could give rise to a new class of wearable sensors for non-invasive physiological load monitoring and measurement, impacting research in human locomotion, sports medicine, and prosthetic design.",Bioinformatics
"Forces transmitted by bones are routinely studied in human biomechanics, but it is challenging to measure them non-invasively, especially outside of the laboratory setting. We introduce a technique for non-invasive, in vivo measurement of tibial compression force using flexural waves propagating in the tibia. Modeling the tibia as an axially compressed Euler-Bernoulli beam, we show that tibial flexural waves have load-dependent frequency spectra. Specifically, under physiological conditions, peak locations in the acceleration amplitude spectrum shift linearly with the compression force on the tibia, and may be used as proxy force measure. We test the validity of this technique using a proof-of-principle wearable system that generates flexural waves via a skin-mounted mechanical transducer and measures the spectra of these waves using a skin-mounted accelerometer. In agreement with beam theory, data from three participants demonstrate linear relationships between tibial compression force and peak frequency location with Pearson correlation coefficients $r=0.88$--$0.97$ for medial-lateral swaying and $r=0.88$--$0.95$ for walking trials. Our flexural wave-based technique could give rise to a new class of wearable sensors for non-invasive physiological load monitoring and measurement, impacting research in human locomotion, sports medicine, and prosthetic design. [SEP] [HINT] used -> Bioinformatics (Syns: utilize, ill-used, apply) | human -> Neuroscience (Syns: human being, man, homo) | using -> Bioinformatics (Syns: utilize, exploitation, apply)",Bioinformatics
"Estimating divergence times from molecular sequence data is central to reconstructing the evolutionary history of lineages. Although Bayesian relaxed-clock methods provide a principled framework for incorporating fossil information, their dependence on repeated evaluations of the full phylogenetic likelihood makes them computationally demanding for large genomic datasets. Furthermore, because disagreements in divergence-time estimates often arise from uncertainty or error in fossil placement and prior specification, there is a need for methods that are both computationally efficient and robust to fossil-calibration uncertainty. In this study, we introduce fast and accurate alternatives based on the phylogenetic pairwise composite likelihood, presenting two adjusted pairwise likelihood (APW) formulations that employ asymptotic moment-matching weights to better approximate the behavior of the full likelihood within a Bayesian MCMC framework. Extensive simulations across diverse fossil-calibration scenarios show that APW methods produce node-age estimates comparable to those obtained from the full likelihood while offering greater robustness to fossil misplacement and prior misspecification, due to the reduced sensitivity of composite likelihoods to local calibration errors. Applied to a genome-scale dataset of modern birds, APW methods recover divergence time patterns consistent with recent studies, while reducing computational cost by more than an order of magnitude. Overall, our results demonstrate that adjusted pairwise likelihoods provide a calibration-robust and computationally efficient framework for Bayesian node dating, especially suited for large phylogenomic datasets and analyses in which fossil priors may be uncertain or imperfectly placed.",Bioinformatics
"Estimating divergence times from molecular sequence data is central to reconstructing the evolutionary history of lineages. Although Bayesian relaxed-clock methods provide a principled framework for incorporating fossil information, their dependence on repeated evaluations of the full phylogenetic likelihood makes them computationally demanding for large genomic datasets. Furthermore, because disagreements in divergence-time estimates often arise from uncertainty or error in fossil placement and prior specification, there is a need for methods that are both computationally efficient and robust to fossil-calibration uncertainty. In this study, we introduce fast and accurate alternatives based on the phylogenetic pairwise composite likelihood, presenting two adjusted pairwise likelihood (APW) formulations that employ asymptotic moment-matching weights to better approximate the behavior of the full likelihood within a Bayesian MCMC framework. Extensive simulations across diverse fossil-calibration scenarios show that APW methods produce node-age estimates comparable to those obtained from the full likelihood while offering greater robustness to fossil misplacement and prior misspecification, due to the reduced sensitivity of composite likelihoods to local calibration errors. Applied to a genome-scale dataset of modern birds, APW methods recover divergence time patterns consistent with recent studies, while reducing computational cost by more than an order of magnitude. Overall, our results demonstrate that adjusted pairwise likelihoods provide a calibration-robust and computationally efficient framework for Bayesian node dating, especially suited for large phylogenomic datasets and analyses in which fossil priors may be uncertain or imperfectly placed. [SEP] [HINT] based -> Bioinformatics (Syns: ground, free-base, base) | computational -> Neuroscience (Syns: ) | molecular -> Bioinformatics (Syns: )",Bioinformatics
"This overview of integrated information theory (IIT) emphasizes IIT's ""consciousness-first"" approach to what exists. Consciousness demonstrates to each of us that something exists--experience--and reveals its essential properties--the axioms of phenomenal existence. IIT formulates these properties operationally, yielding the postulates of physical existence. To exist intrinsically or absolutely, an entity must have cause-effect power upon itself, in a specific, unitary, definite and structured manner. IIT's explanatory identity claims that an entity's cause-effect structure accounts for all properties of an experience--essential and accidental--with no additional ingredients. These include the feeling of spatial extendedness, temporal flow, of objects binding general concepts with particular configurations of features, and of qualia such as colors and sounds. IIT's intrinsic ontology has implications for understanding meaning, perception, and free will, for assessing consciousness in patients, infants, other species, and artifacts, and for reassessing our place in nature.",Neuroscience
"This overview of integrated information theory (IIT) emphasizes IIT's ""consciousness-first"" approach to what exists. Consciousness demonstrates to each of us that something exists--experience--and reveals its essential properties--the axioms of phenomenal existence. IIT formulates these properties operationally, yielding the postulates of physical existence. To exist intrinsically or absolutely, an entity must have cause-effect power upon itself, in a specific, unitary, definite and structured manner. IIT's explanatory identity claims that an entity's cause-effect structure accounts for all properties of an experience--essential and accidental--with no additional ingredients. These include the feeling of spatial extendedness, temporal flow, of objects binding general concepts with particular configurations of features, and of qualia such as colors and sounds. IIT's intrinsic ontology has implications for understanding meaning, perception, and free will, for assessing consciousness in patients, infants, other species, and artifacts, and for reassessing our place in nature. [SEP] [HINT] understanding -> Neuroscience (Syns: savvy, intellect, sympathy) | structure -> Bioinformatics (Syns: social system, complex body part, social structure) | information -> Bioinformatics (Syns: entropy, data, info)",Neuroscience
"In reservoir computing, the coupling strength of the initial untrained recurrent neural network (the reservoir) is an important hyperparameter that can be varied for accurate training. A common heuristic is to set this parameter near the ``edge of chaos"", where the untrained reservoir is near the transition to chaotic dynamics, and the chaos can be ``tamed"". Here, we investigate how the overall connectivity strength should be varied in threshold power-law recurrent neural networks, where the firing rate is 0 below some threshold of the current and is a power function of the current above this threshold. These networks have been previously shown to exhibit chaotic solutions for very small coupling strengths, which may imply that the chaos cannot be tamed at all. We show that for reservoirs constructed with threshold power-law transfer functions, if the reservoir can be trained for one single positive value of the initial reservoir coupling strength, then there exist networks with identical accuracy for all positive coupling strengths, implying that the chaotic dynamics can always be tamed or never be tamed. This is a direct consequence of the coupling strength of threshold power-law RNNs acting as a scale parameter that does not qualitatively influence the dynamics of the system, but only scales all system solutions in magnitude. This is independent of the power of the transfer function, with the exception of Rectified Linear Unit (ReLU) networks. This is in contrast with conventional RNNs/reservoirs employing sigmoidal firing rates, where the strength of the recurrent coupling in the initial reservoir determines the performance on different tasks during training and also influences the network dynamics explicitly.",Neuroscience
"In reservoir computing, the coupling strength of the initial untrained recurrent neural network (the reservoir) is an important hyperparameter that can be varied for accurate training. A common heuristic is to set this parameter near the ``edge of chaos"", where the untrained reservoir is near the transition to chaotic dynamics, and the chaos can be ``tamed"". Here, we investigate how the overall connectivity strength should be varied in threshold power-law recurrent neural networks, where the firing rate is 0 below some threshold of the current and is a power function of the current above this threshold. These networks have been previously shown to exhibit chaotic solutions for very small coupling strengths, which may imply that the chaos cannot be tamed at all. We show that for reservoirs constructed with threshold power-law transfer functions, if the reservoir can be trained for one single positive value of the initial reservoir coupling strength, then there exist networks with identical accuracy for all positive coupling strengths, implying that the chaotic dynamics can always be tamed or never be tamed. This is a direct consequence of the coupling strength of threshold power-law RNNs acting as a scale parameter that does not qualitatively influence the dynamics of the system, but only scales all system solutions in magnitude. This is independent of the power of the transfer function, with the exception of Rectified Linear Unit (ReLU) networks. This is in contrast with conventional RNNs/reservoirs employing sigmoidal firing rates, where the strength of the recurrent coupling in the initial reservoir determines the performance on different tasks during training and also influences the network dynamics explicitly. [SEP] [HINT] transition -> Materials Science (Syns: passage, modulation, changeover) | connectivity -> Neuroscience (Syns: ) | tasks -> Neuroscience (Syns: tax, task, project)",Neuroscience
"Diffusion models have emerged as a leading framework in generative modeling, poised to transform the traditionally slow and costly process of drug discovery. This review provides a systematic comparison of their application in designing two principal therapeutic modalities: small molecules and therapeutic peptides. We dissect how the unified framework of iterative denoising is adapted to the distinct molecular representations, chemical spaces, and design objectives of each modality. For small molecules, these models excel at structure-based design, generating novel, pocket-fitting ligands with desired physicochemical properties, yet face the critical hurdle of ensuring chemical synthesizability. Conversely, for therapeutic peptides, the focus shifts to generating functional sequences and designing de novo structures, where the primary challenges are achieving biological stability against proteolysis, ensuring proper folding, and minimizing immunogenicity. Despite these distinct challenges, both domains face shared hurdles: the scarcity of high-quality experimental data, the reliance on inaccurate scoring functions for validation, and the crucial need for experimental validation. We conclude that the full potential of diffusion models will be unlocked by bridging these modality-specific gaps and integrating them into automated, closed-loop Design-Build-Test-Learn (DBTL) platforms, thereby shifting the paradigm from mere chemical exploration to the on-demand engineering of novel~therapeutics.",Bioinformatics
"Diffusion models have emerged as a leading framework in generative modeling, poised to transform the traditionally slow and costly process of drug discovery. This review provides a systematic comparison of their application in designing two principal therapeutic modalities: small molecules and therapeutic peptides. We dissect how the unified framework of iterative denoising is adapted to the distinct molecular representations, chemical spaces, and design objectives of each modality. For small molecules, these models excel at structure-based design, generating novel, pocket-fitting ligands with desired physicochemical properties, yet face the critical hurdle of ensuring chemical synthesizability. Conversely, for therapeutic peptides, the focus shifts to generating functional sequences and designing de novo structures, where the primary challenges are achieving biological stability against proteolysis, ensuring proper folding, and minimizing immunogenicity. Despite these distinct challenges, both domains face shared hurdles: the scarcity of high-quality experimental data, the reliance on inaccurate scoring functions for validation, and the crucial need for experimental validation. We conclude that the full potential of diffusion models will be unlocked by bridging these modality-specific gaps and integrating them into automated, closed-loop Design-Build-Test-Learn (DBTL) platforms, thereby shifting the paradigm from mere chemical exploration to the on-demand engineering of novel~therapeutics. [SEP] [HINT] functional -> Neuroscience (Syns: working, usable, running) | molecular -> Bioinformatics (Syns: ) | framework -> Bioinformatics (Syns: theoretical account, model, fabric)",Bioinformatics
"We report the synthesis of ethylammonium lead iodide (EAPbI3) colloidal nanocrystals as another member of the lead halide perovskites family. The insertion of an unusually large A-cation (274 pm in diameter) in the perovskite structure, hitherto considered unlikely due to the unfavorable Goldschmidt tolerance factor, results in a significantly larger lattice parameter compared to the Cs-, methylammonium- and formamidinium-based lead halide perovskite homologues. As a consequence, EAPbI3 nanocrystals are highly unstable, evolving to a non-perovskite delta-EAPbI3 polymorph within one day. Also, EAPbI3 nanocrystals are very sensitive to electron irradiation and quickly degrade to PbI2 upon exposure to the electron beam, following a mechanism similar to that of other hybrid lead iodide perovskites (although degradation can be reduced by partially replacing the EA+ ions with Cs+ ions). Interestingly, in some cases during this degradation the formation of an epitaxial interface between (EAxCs1-x)PbI3 and PbI2 is observed. The photoluminescence emission of the EAPbI3 perovskite nanocrystals, albeit being characterized by a low quantum yield (around 1%), can be tuned in the 664-690 nm range by regulating their size during the synthesis. The emission efficiency can be improved upon partial alloying at the A site with Cs+ or formamidinium cations. Furthermore, the morphology of the EAPbI3 nanocrystals can be chosen to be either nanocube or nanoplatelet, depending on the synthesis conditions.",Materials Science
"We report the synthesis of ethylammonium lead iodide (EAPbI3) colloidal nanocrystals as another member of the lead halide perovskites family. The insertion of an unusually large A-cation (274 pm in diameter) in the perovskite structure, hitherto considered unlikely due to the unfavorable Goldschmidt tolerance factor, results in a significantly larger lattice parameter compared to the Cs-, methylammonium- and formamidinium-based lead halide perovskite homologues. As a consequence, EAPbI3 nanocrystals are highly unstable, evolving to a non-perovskite delta-EAPbI3 polymorph within one day. Also, EAPbI3 nanocrystals are very sensitive to electron irradiation and quickly degrade to PbI2 upon exposure to the electron beam, following a mechanism similar to that of other hybrid lead iodide perovskites (although degradation can be reduced by partially replacing the EA+ ions with Cs+ ions). Interestingly, in some cases during this degradation the formation of an epitaxial interface between (EAxCs1-x)PbI3 and PbI2 is observed. The photoluminescence emission of the EAPbI3 perovskite nanocrystals, albeit being characterized by a low quantum yield (around 1%), can be tuned in the 664-690 nm range by regulating their size during the synthesis. The emission efficiency can be improved upon partial alloying at the A site with Cs+ or formamidinium cations. Furthermore, the morphology of the EAPbI3 nanocrystals can be chosen to be either nanocube or nanoplatelet, depending on the synthesis conditions. [SEP] [HINT] low -> Materials Science (Syns: low-spirited, scurvy, depressed) | perovskite -> Materials Science (Syns: ) | electron -> Materials Science (Syns: negatron)",Materials Science
"Liquid chromatography-mass spectrometry (LC-MS/MS) data analysis requires adaptable software solutions to meet diverse analytical needs. We present eMZed 3, a modern Python framework for flexible and interactive analysis of LC-MS/MS data. eMZed 3 enables users to develop scalable workflows tailored to their specific requirements while leveraging Python's extensive ecosystem of libraries. Building on its predecessor, eMZed 3 is now Python 3-based and includes substantial enhancements, including support for chromatogram-based LC-MS data, a new SQLite-based backend supporting optional out-of-memory processing, and rich interactive visualization tools. Compared to the previous version, eMZed 3 is now split into three packages: emzed (core functionalities), emzed-gui (interactive data visualization), and emzed-spyder (an integrated development environment). This modular architecture allows straightforward integration of the emzed core library into headless Python environments, including computational notebooks (such as Jupyter) or high-performance computing clusters. eMZed 3 incorporates well-established libraries such as OpenMS, and is highly suited for both targeted and untargeted metabolomics. Overall, eMZed 3 supports the efficient development of scalable and reproducible LC-MS data analysis and is accessible to both novice and advanced programmers.   Availability and Implementation: eMZed 3 and its documentation are freely available at https://emzed.ethz.ch, the source code is hosted at https://gitlab.com/groups/emzed3. An online-executable example workflow is available on Binder at: https://mybinder.org/v2/gl/emzed3%2Femzed-example-workflow/HEAD?labpath=example.ipynb.",Bioinformatics
"Liquid chromatography-mass spectrometry (LC-MS/MS) data analysis requires adaptable software solutions to meet diverse analytical needs. We present eMZed 3, a modern Python framework for flexible and interactive analysis of LC-MS/MS data. eMZed 3 enables users to develop scalable workflows tailored to their specific requirements while leveraging Python's extensive ecosystem of libraries. Building on its predecessor, eMZed 3 is now Python 3-based and includes substantial enhancements, including support for chromatogram-based LC-MS data, a new SQLite-based backend supporting optional out-of-memory processing, and rich interactive visualization tools. Compared to the previous version, eMZed 3 is now split into three packages: emzed (core functionalities), emzed-gui (interactive data visualization), and emzed-spyder (an integrated development environment). This modular architecture allows straightforward integration of the emzed core library into headless Python environments, including computational notebooks (such as Jupyter) or high-performance computing clusters. eMZed 3 incorporates well-established libraries such as OpenMS, and is highly suited for both targeted and untargeted metabolomics. Overall, eMZed 3 supports the efficient development of scalable and reproducible LC-MS data analysis and is accessible to both novice and advanced programmers.   Availability and Implementation: eMZed 3 and its documentation are freely available at https://emzed.ethz.ch, the source code is hosted at https://gitlab.com/groups/emzed3. An online-executable example workflow is available on Binder at: https://mybinder.org/v2/gl/emzed3%2Femzed-example-workflow/HEAD?labpath=example.ipynb. [SEP] [HINT] computational -> Neuroscience (Syns: ) | including -> Bioinformatics (Syns: admit, include, let in) | framework -> Bioinformatics (Syns: theoretical account, model, fabric)",Bioinformatics
"The optical properties of molecular crystals are largely determined by the excitonic coupling of neighboring molecules. This coupling is extremely sensitive to the arrangement of adjacent molecular units, as their electronic interaction is defined by the relative orientation of the individual transition dipole moments and their wave function overlap. Hence, the optical properties, such as fluorescence, are usually highly anisotropic and good indicators of structural changes during the variation of intensive thermodynamic parameters like temperature or pressure. Here, we discuss the peculiar though archetypical case of $β$-phase zinc-phthalocyanine: In single crystals, we report a sudden change of spectral emission with temperature from a broad, unpolarized Frenkel-exciton type luminescence to a narrow, highly polarized superradiance-like fluorescence below 80 K. Surprisingly, we find that there is no sign of a discrete structural phase transition in this temperature regime. To understand this apparent contradiction, we perform polarization-, temperature- and time-dependent photoluminescence measurements along different crystallographic directions to fully map the emission characteristics of the crystal-exciton. By means of ab-initio calculations on a density functional theory level we conclude that our observations are consistent with a dimer exciton model when considering thermalized electronic states. As such, our study presents a representative case study on a well-established molecular material class demonstrating that caution is advised when attributing discrete changes in electronic observables to a structural phase transition. As we show for zinc-phthalocyanine in its $β$-phase modification, slowly varying excitonic couplings and thermal redistribution of excitations can mimic the same signatures attributed to a structural phase transition.",Materials Science
"The optical properties of molecular crystals are largely determined by the excitonic coupling of neighboring molecules. This coupling is extremely sensitive to the arrangement of adjacent molecular units, as their electronic interaction is defined by the relative orientation of the individual transition dipole moments and their wave function overlap. Hence, the optical properties, such as fluorescence, are usually highly anisotropic and good indicators of structural changes during the variation of intensive thermodynamic parameters like temperature or pressure. Here, we discuss the peculiar though archetypical case of $β$-phase zinc-phthalocyanine: In single crystals, we report a sudden change of spectral emission with temperature from a broad, unpolarized Frenkel-exciton type luminescence to a narrow, highly polarized superradiance-like fluorescence below 80 K. Surprisingly, we find that there is no sign of a discrete structural phase transition in this temperature regime. To understand this apparent contradiction, we perform polarization-, temperature- and time-dependent photoluminescence measurements along different crystallographic directions to fully map the emission characteristics of the crystal-exciton. By means of ab-initio calculations on a density functional theory level we conclude that our observations are consistent with a dimer exciton model when considering thermalized electronic states. As such, our study presents a representative case study on a well-established molecular material class demonstrating that caution is advised when attributing discrete changes in electronic observables to a structural phase transition. As we show for zinc-phthalocyanine in its $β$-phase modification, slowly varying excitonic couplings and thermal redistribution of excitations can mimic the same signatures attributed to a structural phase transition. [SEP] [HINT] transition -> Materials Science (Syns: passage, modulation, changeover) | electronic -> Materials Science (Syns: ) | functional -> Neuroscience (Syns: working, usable, running)",Materials Science
"We present a comprehensive first-principles investigation of carbon self-interstitial defects in diamond, ranging from mono- to hexa-interstitial complexes. By quantum mechanical density functional theory, empowered by interatomic potential models, we efficiently sample the complex configurational landscape and identify both known and previously unreported defect geometries. Our results reveal a pronounced energetic driving force for aggregation: the formation energy per interstitial decreases systematically from isolated split interstitials to compact multi-interstitial clusters, with the tetra-interstitial platelet emerging as a particularly stable structural motif. Additionally, charge analysis indicates that the predominantly covalent bonding in diamond becomes more polar within the defect centers. Analysis of defect energy levels shows that only the investigated mono-, di-, penta-, and hexa-interstitial complexes introduce in-gap electronic states, whereas the tri- and tetra-interstitial clusters are electronically inert. Vibrational spectroscopies further reveal that self-interstitials generate characteristic signatures. Short carbon-carbon bonds inside the defect cores give rise to high-frequency vibrational modes between 1375 and 1925 cm$^{-1}$, which are strongly IR-active but exhibit weak Raman activity. Taken together, these findings provide a coherent picture of the structural, electronic, and vibrational characteristics of carbon self-interstitials and establish a robust framework for their experimental identification.",Materials Science
"We present a comprehensive first-principles investigation of carbon self-interstitial defects in diamond, ranging from mono- to hexa-interstitial complexes. By quantum mechanical density functional theory, empowered by interatomic potential models, we efficiently sample the complex configurational landscape and identify both known and previously unreported defect geometries. Our results reveal a pronounced energetic driving force for aggregation: the formation energy per interstitial decreases systematically from isolated split interstitials to compact multi-interstitial clusters, with the tetra-interstitial platelet emerging as a particularly stable structural motif. Additionally, charge analysis indicates that the predominantly covalent bonding in diamond becomes more polar within the defect centers. Analysis of defect energy levels shows that only the investigated mono-, di-, penta-, and hexa-interstitial complexes introduce in-gap electronic states, whereas the tri- and tetra-interstitial clusters are electronically inert. Vibrational spectroscopies further reveal that self-interstitials generate characteristic signatures. Short carbon-carbon bonds inside the defect cores give rise to high-frequency vibrational modes between 1375 and 1925 cm$^{-1}$, which are strongly IR-active but exhibit weak Raman activity. Taken together, these findings provide a coherent picture of the structural, electronic, and vibrational characteristics of carbon self-interstitials and establish a robust framework for their experimental identification. [SEP] [HINT] charge -> Materials Science (Syns: tear, bearing, burster) | defect -> Materials Science (Syns: mar, shortcoming, fault) | electronic -> Materials Science (Syns: )",Materials Science
"Mechanistic models can provide an intuitive and interpretable explanation of network growth by specifying a set of generative rules. These rules can be defined by domain knowledge about real-world mechanisms governing network growth or may be designed to facilitate the appearance of certain network motifs. In the formation of real-world networks, multiple mechanisms may be simultaneously involved; it is then important to understand the relative contribution of each of these mechanisms. In this paper, we propose the use of a conditional density estimator, augmented with a graph neural network, to perform inference on a flexible mixture of network-forming mechanisms. This event-wise mixture-of-mechanisms model assigns mechanisms to each edge formation event rather than stipulating node-level mechanisms, thus allowing for an explanation of the network generation process, as well as the dynamic evolution of the network over time. We demonstrate that our approximate Bayesian approach yields valid inferences for the relative weights of the mechanisms in our model, and we utilize this method to investigate the mechanisms behind the formation of a variety of real-world networks.",Bioinformatics
"Mechanistic models can provide an intuitive and interpretable explanation of network growth by specifying a set of generative rules. These rules can be defined by domain knowledge about real-world mechanisms governing network growth or may be designed to facilitate the appearance of certain network motifs. In the formation of real-world networks, multiple mechanisms may be simultaneously involved; it is then important to understand the relative contribution of each of these mechanisms. In this paper, we propose the use of a conditional density estimator, augmented with a graph neural network, to perform inference on a flexible mixture of network-forming mechanisms. This event-wise mixture-of-mechanisms model assigns mechanisms to each edge formation event rather than stipulating node-level mechanisms, thus allowing for an explanation of the network generation process, as well as the dynamic evolution of the network over time. We demonstrate that our approximate Bayesian approach yields valid inferences for the relative weights of the mechanisms in our model, and we utilize this method to investigate the mechanisms behind the formation of a variety of real-world networks. [SEP] [HINT] method -> Bioinformatics (Syns: method acting) | demonstrate -> Bioinformatics (Syns: evidence, march, prove) | density -> Materials Science (Syns: tightness, concentration, compactness)",Bioinformatics
"A first-principles coupled electron-nuclear dynamics simulation based on real-time, time-dependent density functional theory and Ehrenfest dynamics quantitatively repro-duces bimodal translational energy loss and angular distributions observed in experiment for hydrogen atom scattering from Ge(111)-c(2*8). The theory elucidates a site-selective mechanism of electronically nonadiabatic energy transfer associated with the formation of different Ge-H bonds. When a hydrogen atom approaches a Ge rest-atom, it is strongly accelerated toward the potential minimum forming a transient Ge-H bond and then re-flected by the repulsive wall. This transient bond formation triggers an ultrafast electron transfer event from the rest-atom to an adjacent Ge-adatom, involving several crossings between valence and conduction bands of the substrate. Electronic equilibration is impos-sible within such a short time (Born-Oppenheimer failure) allowing the H-atom kinetic energy to be converted to inter-band electronic excitation of the substrate. H-atom colli-sions at other Ge atoms also form a transient bond but exhibit no electronic excitation, resulting in distinctly less efficient energy loss in scattered H-atoms. The nucle-ar-to-electronic energy transfer observed in this system reflects the electronic dynamics of covalent bond formation at a semiconductor surface, a mechanism that is quite distinct from previously identified nonadiabatic energy transfer mechanisms at metal surfaces mediated by electronic friction or transient negative ions.",Materials Science
"A first-principles coupled electron-nuclear dynamics simulation based on real-time, time-dependent density functional theory and Ehrenfest dynamics quantitatively repro-duces bimodal translational energy loss and angular distributions observed in experiment for hydrogen atom scattering from Ge(111)-c(2*8). The theory elucidates a site-selective mechanism of electronically nonadiabatic energy transfer associated with the formation of different Ge-H bonds. When a hydrogen atom approaches a Ge rest-atom, it is strongly accelerated toward the potential minimum forming a transient Ge-H bond and then re-flected by the repulsive wall. This transient bond formation triggers an ultrafast electron transfer event from the rest-atom to an adjacent Ge-adatom, involving several crossings between valence and conduction bands of the substrate. Electronic equilibration is impos-sible within such a short time (Born-Oppenheimer failure) allowing the H-atom kinetic energy to be converted to inter-band electronic excitation of the substrate. H-atom colli-sions at other Ge atoms also form a transient bond but exhibit no electronic excitation, resulting in distinctly less efficient energy loss in scattered H-atoms. The nucle-ar-to-electronic energy transfer observed in this system reflects the electronic dynamics of covalent bond formation at a semiconductor surface, a mechanism that is quite distinct from previously identified nonadiabatic energy transfer mechanisms at metal surfaces mediated by electronic friction or transient negative ions. [SEP] [HINT] based -> Bioinformatics (Syns: ground, free-base, base) | electronic -> Materials Science (Syns: ) | functional -> Neuroscience (Syns: working, usable, running)",Materials Science
"Simulating in silico cellular responses to interventions is a promising direction to accelerate high-content image-based assays, critical for advancing drug discovery and gene editing. To support this, we introduce MorphGen, a state-of-the-art diffusion-based generative model for fluorescent microscopy that enables controllable generation across multiple cell types and perturbations. To capture biologically meaningful patterns consistent with known cellular morphologies, MorphGen is trained with an alignment loss to match its representations to the phenotypic embeddings of OpenPhenom, a state-of-the-art biological foundation model. Unlike prior approaches that compress multichannel stains into RGB images -- thus sacrificing organelle-specific detail -- MorphGen generates the complete set of fluorescent channels jointly, preserving per-organelle structures and enabling a fine-grained morphological analysis that is essential for biological interpretation. We demonstrate biological consistency with real images via CellProfiler features, and MorphGen attains an FID score over 35% lower than the prior state-of-the-art MorphoDiff, which only generates RGB images for a single cell type. Code is available at https://github.com/czi-ai/MorphGen.",Bioinformatics
"Simulating in silico cellular responses to interventions is a promising direction to accelerate high-content image-based assays, critical for advancing drug discovery and gene editing. To support this, we introduce MorphGen, a state-of-the-art diffusion-based generative model for fluorescent microscopy that enables controllable generation across multiple cell types and perturbations. To capture biologically meaningful patterns consistent with known cellular morphologies, MorphGen is trained with an alignment loss to match its representations to the phenotypic embeddings of OpenPhenom, a state-of-the-art biological foundation model. Unlike prior approaches that compress multichannel stains into RGB images -- thus sacrificing organelle-specific detail -- MorphGen generates the complete set of fluorescent channels jointly, preserving per-organelle structures and enabling a fine-grained morphological analysis that is essential for biological interpretation. We demonstrate biological consistency with real images via CellProfiler features, and MorphGen attains an FID score over 35% lower than the prior state-of-the-art MorphoDiff, which only generates RGB images for a single cell type. Code is available at https://github.com/czi-ai/MorphGen. [SEP] [HINT] drug -> Bioinformatics (Syns: dose, do drugs) | demonstrate -> Bioinformatics (Syns: evidence, march, prove) | biological -> Bioinformatics (Syns: biologic)",Bioinformatics
"Uranium dihydride UH2 is a metastable phase unknown in bulk form but accessible through thin-film synthesis. We prepared UH2 films by reactive dc sputtering on CaF2(001) or Si(001) substrates, the latter equipped with a Mo buffer layer to suppress a U-Si interdiffusion. On CaF2, UH2 adopts the fluorite-type structure with a near-[1 1 1] out-of-plane texture, four rotational domains, and a lattice parameter a = 539 +- 3 pm without measurable strain, whereas the Mo-buffered film is polycrystalline. X-ray photoelectron spectroscopy confirmed complete hydrogenation and minimal oxidation. Magnetization and XMCD measurements show ferromagnetic ordering with Curie temperatures of 120-130 K and a uranium 5f moment of 0.9 μB/U, dominated by the orbital contribution (μL ~ 1.4 μB, μS ~ -0.5 μB), in a good agreement with GGA+U computations, which otherwise overestimate absolute values of the spin and orbital components. The slightly reduced moment in thinner CaF2-supported films is attributed to surface U(IV) species. These results demonstrate that thin-film synthesis enables stabilization of UH2 and direct probing of 5f magnetism, opening pathways toward higher uranium hydrides and interface-engineered actinide systems.",Materials Science
"Uranium dihydride UH2 is a metastable phase unknown in bulk form but accessible through thin-film synthesis. We prepared UH2 films by reactive dc sputtering on CaF2(001) or Si(001) substrates, the latter equipped with a Mo buffer layer to suppress a U-Si interdiffusion. On CaF2, UH2 adopts the fluorite-type structure with a near-[1 1 1] out-of-plane texture, four rotational domains, and a lattice parameter a = 539 +- 3 pm without measurable strain, whereas the Mo-buffered film is polycrystalline. X-ray photoelectron spectroscopy confirmed complete hydrogenation and minimal oxidation. Magnetization and XMCD measurements show ferromagnetic ordering with Curie temperatures of 120-130 K and a uranium 5f moment of 0.9 μB/U, dominated by the orbital contribution (μL ~ 1.4 μB, μS ~ -0.5 μB), in a good agreement with GGA+U computations, which otherwise overestimate absolute values of the spin and orbital components. The slightly reduced moment in thinner CaF2-supported films is attributed to surface U(IV) species. These results demonstrate that thin-film synthesis enables stabilization of UH2 and direct probing of 5f magnetism, opening pathways toward higher uranium hydrides and interface-engineered actinide systems. [SEP] [HINT] spin -> Materials Science (Syns: twisting, whirl, tailspin) | structure -> Bioinformatics (Syns: social system, complex body part, social structure) | results -> Bioinformatics (Syns: final result, consequence, resultant role)",Materials Science
"Refractory complex concentrated alloys, composed of multiple principal refractory elements, are promising candidates for high-temperature structural applications due to their exceptional thermal stability and high melting points. However, their mechanical performance is often compromised by interstitial impurities, particularly oxygen, nitrogen, and carbon, which segregate to grain boundaries and promote embrittlement. In this study, we investigate the solubility and thermodynamic behavior of oxygen interstitials in a model NbTiHfTa RCCA system. We synthesized NbTiHfTa alloys with varying oxygen contents via plasma arc melting and characterized their phase evolution and microstructure using XRD, SEM, and TEM. Complementary computational modeling was performed using machine-learning interatomic potentials integrated with Monte Carlo simulations to probe oxygen interactions at the atomic scale. Our results reveal a solubility limit for oxygen between 0.8 and 1.0 atomic percentage, beyond which HfO2 formation is energetically favorable. This combined experimental-computational framework provides a predictive approach for managing interstitial behavior in RCCAs, enabling improved alloy design strategies for enhanced mechanical performance.",Materials Science
"Refractory complex concentrated alloys, composed of multiple principal refractory elements, are promising candidates for high-temperature structural applications due to their exceptional thermal stability and high melting points. However, their mechanical performance is often compromised by interstitial impurities, particularly oxygen, nitrogen, and carbon, which segregate to grain boundaries and promote embrittlement. In this study, we investigate the solubility and thermodynamic behavior of oxygen interstitials in a model NbTiHfTa RCCA system. We synthesized NbTiHfTa alloys with varying oxygen contents via plasma arc melting and characterized their phase evolution and microstructure using XRD, SEM, and TEM. Complementary computational modeling was performed using machine-learning interatomic potentials integrated with Monte Carlo simulations to probe oxygen interactions at the atomic scale. Our results reveal a solubility limit for oxygen between 0.8 and 1.0 atomic percentage, beyond which HfO2 formation is energetically favorable. This combined experimental-computational framework provides a predictive approach for managing interstitial behavior in RCCAs, enabling improved alloy design strategies for enhanced mechanical performance. [SEP] [HINT] computational -> Neuroscience (Syns: ) | complex -> Bioinformatics (Syns: building complex, coordination compound, composite) | performance -> Bioinformatics (Syns: functioning, operation, carrying out)",Materials Science
"For the van der Waals magnet Fe$_3$GeTe$_2$, although a ferromagnetic ground state has been reported, there are also reports of complex magnetic behavior suggesting coexistence of ferromagnetism and antiferromagnetism due to the intricate interaction between Fe$^{+3}$ and Fe$^{+2}$ ions in this system. The exact nature of the interactions and the origin of antiferromagnetism are still under debate. Here, we report the observation of signature of ferromagnetic and antiferromagnetic couplings between different Fe-ions in the anomalous Hall effect measured for devices of mechanically exfoliated Fe$_3$GeTe$_2$ nano-flakes of thicknesses ranging from\,$\sim$\,15-20 layers. The temperature-dependent anomalous Hall effect data reveal two sharp step-like switchings at low temperature ($T\lesssim150\,$K). Our detailed analyses suggest the step-like sharp switchings in anomalous Hall resistance are due to the magnetization reversal behavior of different Fe-ions in individual layers of Fe$_3$GeTe$_2$. The experimental results can be explained by considering an intra-layer antiferromagnetic coupling between Fe$^{+3}$ and Fe$^{+3}$ ions, whereas intra-layer ferromagnetic coupling between Fe$^{+3}$ and Fe$^{+2}$ in the system. Our experimental results and the analyses are supported by the first-principles calculations for energetics and intralayer as well as interlayer exchange coupling constants.",Materials Science
"For the van der Waals magnet Fe$_3$GeTe$_2$, although a ferromagnetic ground state has been reported, there are also reports of complex magnetic behavior suggesting coexistence of ferromagnetism and antiferromagnetism due to the intricate interaction between Fe$^{+3}$ and Fe$^{+2}$ ions in this system. The exact nature of the interactions and the origin of antiferromagnetism are still under debate. Here, we report the observation of signature of ferromagnetic and antiferromagnetic couplings between different Fe-ions in the anomalous Hall effect measured for devices of mechanically exfoliated Fe$_3$GeTe$_2$ nano-flakes of thicknesses ranging from\,$\sim$\,15-20 layers. The temperature-dependent anomalous Hall effect data reveal two sharp step-like switchings at low temperature ($T\lesssim150\,$K). Our detailed analyses suggest the step-like sharp switchings in anomalous Hall resistance are due to the magnetization reversal behavior of different Fe-ions in individual layers of Fe$_3$GeTe$_2$. The experimental results can be explained by considering an intra-layer antiferromagnetic coupling between Fe$^{+3}$ and Fe$^{+3}$ ions, whereas intra-layer ferromagnetic coupling between Fe$^{+3}$ and Fe$^{+2}$ in the system. Our experimental results and the analyses are supported by the first-principles calculations for energetics and intralayer as well as interlayer exchange coupling constants. [SEP] [HINT] low -> Materials Science (Syns: low-spirited, scurvy, depressed) | complex -> Bioinformatics (Syns: building complex, coordination compound, composite) | results -> Bioinformatics (Syns: final result, consequence, resultant role)",Materials Science
"This paper introduces the Single-Cell Perturbation Prediction Diffusion Model (scPPDM), the first diffusion-based framework for single-cell drug-response prediction from scRNA-seq data. scPPDM couples two condition channels, pre-perturbation state and drug with dose, in a unified latent space via non-concatenative GD-Attn. During inference, factorized classifier-free guidance exposes two interpretable controls for state preservation and drug-response strength and maps dose to guidance magnitude for tunable intensity. Evaluated on the Tahoe-100M benchmark under two stringent regimes, unseen covariate combinations (UC) and unseen drugs (UD), scPPDM sets new state-of-the-art results across log fold-change recovery, delta correlations, explained variance, and DE-overlap. Representative gains include +36.11%/+34.21% on DEG logFC-Spearman/Pearson in UD over the second-best model. This control interface enables transparent what-if analyses and dose tuning, reducing experimental burden while preserving biological specificity.",Bioinformatics
"This paper introduces the Single-Cell Perturbation Prediction Diffusion Model (scPPDM), the first diffusion-based framework for single-cell drug-response prediction from scRNA-seq data. scPPDM couples two condition channels, pre-perturbation state and drug with dose, in a unified latent space via non-concatenative GD-Attn. During inference, factorized classifier-free guidance exposes two interpretable controls for state preservation and drug-response strength and maps dose to guidance magnitude for tunable intensity. Evaluated on the Tahoe-100M benchmark under two stringent regimes, unseen covariate combinations (UC) and unseen drugs (UD), scPPDM sets new state-of-the-art results across log fold-change recovery, delta correlations, explained variance, and DE-overlap. Representative gains include +36.11%/+34.21% on DEG logFC-Spearman/Pearson in UD over the second-best model. This control interface enables transparent what-if analyses and dose tuning, reducing experimental burden while preserving biological specificity. [SEP] [HINT] space -> Neuroscience (Syns: distance, place, outer space) | results -> Bioinformatics (Syns: final result, consequence, resultant role) | framework -> Bioinformatics (Syns: theoretical account, model, fabric)",Bioinformatics
"We report the synthesis of colloidal core@shell AgBr@CsPbBr3 nanocubes by a one-pot approach, where the nucleation and growth of AgBr nanocrystals occurs rapidly after the injection of chemical precursors. This is immediately followed by the overgrowth of CsPbBr3, delivering AgBr@CsPbBr3 nanocubes of several tens of nanometers in size, with the volume of the AgBr core being only a small fraction of the overall nanocrystal volume. The formation of a core@shell geometry is facilitated by the epitaxial compatibility between AgBr and CsPbBr3 along multiple crystallographic directions. Exchange with Cl-ions leads to Ag@CsPbCl3 nanocubes, whereas exchange with I-ions leads to hollow CsPbI3 nanocubes, due to selective etching of the AgBr (or Ag) core region by the I-ions diffusing in the nanocubes. These hollow CsPbI3 nanocubes can then be converted into hollow CsPbBr3 and CsPbCl3 nanocubes by halide exchange. The optical emission properties of the hollow CsPbX3 (X=Cl, Br, I) nanocubes are in line with those expected from large, non-hollow halide perovskite nanocrystals, indicating that the small hollow region in the cubes has no major influence on their optical properties.",Materials Science
"We report the synthesis of colloidal core@shell AgBr@CsPbBr3 nanocubes by a one-pot approach, where the nucleation and growth of AgBr nanocrystals occurs rapidly after the injection of chemical precursors. This is immediately followed by the overgrowth of CsPbBr3, delivering AgBr@CsPbBr3 nanocubes of several tens of nanometers in size, with the volume of the AgBr core being only a small fraction of the overall nanocrystal volume. The formation of a core@shell geometry is facilitated by the epitaxial compatibility between AgBr and CsPbBr3 along multiple crystallographic directions. Exchange with Cl-ions leads to Ag@CsPbCl3 nanocubes, whereas exchange with I-ions leads to hollow CsPbI3 nanocubes, due to selective etching of the AgBr (or Ag) core region by the I-ions diffusing in the nanocubes. These hollow CsPbI3 nanocubes can then be converted into hollow CsPbBr3 and CsPbCl3 nanocubes by halide exchange. The optical emission properties of the hollow CsPbX3 (X=Cl, Br, I) nanocubes are in line with those expected from large, non-hollow halide perovskite nanocrystals, indicating that the small hollow region in the cubes has no major influence on their optical properties. [SEP] [HINT] perovskite -> Materials Science (Syns: ) | optical -> Materials Science (Syns: ocular, opthalmic, optic) | properties -> Materials Science (Syns: place, prop, property)",Materials Science
"Quantitative analysis of multidimensional biological images is useful for understanding complex cellular phenotypes and accelerating advances in biomedical research. As modern microscopy generates ever-larger 2D and 3D datasets, existing computational approaches are increasingly limited by their scalability, efficiency, and integration with modern scientific computing workflows. Existing bioimage analysis tools often lack application programmable interfaces (APIs), do not support graphics processing unit (GPU) acceleration, lack broad 3D image processing capabilities, and/or have poor interoperability for compute-heavy workflows. Here, we introduce cubic, an open-source Python library that addresses these challenges by augmenting widely used SciPy and scikit-image APIs with GPU-accelerated alternatives from CuPy and RAPIDS cuCIM. cubic's API is device-agnostic and dispatches operations to GPU when data reside on the device and otherwise executes on CPU, seamlessly accelerating a broad range of image processing routines. This approach enables GPU acceleration of existing bioimage analysis workflows, from preprocessing to segmentation and feature extraction for 2D and 3D data. We evaluate cubic both by benchmarking individual operations and by reproducing existing deconvolution and segmentation pipelines, achieving substantial speedups while maintaining algorithmic fidelity. These advances establish a robust foundation for scalable, reproducible bioimage analysis that integrates with the broader Python scientific computing ecosystem, including other GPU-accelerated methods, enabling both interactive exploration and automated high-throughput analysis workflows. cubic is openly available at https://github$.$com/alxndrkalinin/cubic",Bioinformatics
"Quantitative analysis of multidimensional biological images is useful for understanding complex cellular phenotypes and accelerating advances in biomedical research. As modern microscopy generates ever-larger 2D and 3D datasets, existing computational approaches are increasingly limited by their scalability, efficiency, and integration with modern scientific computing workflows. Existing bioimage analysis tools often lack application programmable interfaces (APIs), do not support graphics processing unit (GPU) acceleration, lack broad 3D image processing capabilities, and/or have poor interoperability for compute-heavy workflows. Here, we introduce cubic, an open-source Python library that addresses these challenges by augmenting widely used SciPy and scikit-image APIs with GPU-accelerated alternatives from CuPy and RAPIDS cuCIM. cubic's API is device-agnostic and dispatches operations to GPU when data reside on the device and otherwise executes on CPU, seamlessly accelerating a broad range of image processing routines. This approach enables GPU acceleration of existing bioimage analysis workflows, from preprocessing to segmentation and feature extraction for 2D and 3D data. We evaluate cubic both by benchmarking individual operations and by reproducing existing deconvolution and segmentation pipelines, achieving substantial speedups while maintaining algorithmic fidelity. These advances establish a robust foundation for scalable, reproducible bioimage analysis that integrates with the broader Python scientific computing ecosystem, including other GPU-accelerated methods, enabling both interactive exploration and automated high-throughput analysis workflows. cubic is openly available at https://github$.$com/alxndrkalinin/cubic [SEP] [HINT] used -> Bioinformatics (Syns: utilize, ill-used, apply) | computational -> Neuroscience (Syns: ) | understanding -> Neuroscience (Syns: savvy, intellect, sympathy)",Bioinformatics
"Piezoelectric micromachined ultrasonic transducers (PMUTs) are widely used in applications that demand mechanical resilience, thermal stability, and compact form factors. Lead zirconate titanate (PZT) and aluminum nitride (AlN) active layers are used in PMUTs to enable acoustic actuation, sensing, or bidirectional operation. These platforms rely on bimorph films to maximize electromechanical coupling ($k^2$) through thin-film deposition, which uses intermediate electrode layers to establish opposing electric fields. Consequently, incumbent PMUT platforms are limited in achievable film thickness and feature material interfaces that compromise mechanical integrity and thermal performance. Combined with the intrinsic limitations of PZT and AlN, these factors motivate exploration of alternative PMUT material platforms. Recent efforts have sought to demonstrate that single-crystal lithium niobate (LN) is a promising candidate, offering substantially higher $k^2$ and bidirectional performance. Advances in LN film transfer technology have enabled the formation of periodically poled piezoelectric (P3F) LN, facilitating a bimorph stack without intermediate electrodes. In this work, we showcase bimorph PMUTs incorporating a mechanically robust, 20 micron thick P3F LN active layer. We establish the motivation for LN PMUTs through a material comparison, followed by extensive membrane geometry optimization and subsequent enhancement of the PMUT's $k^2$. We demonstrate a 775 kHz flexural mode device with a quality factor (Q) of 200 and an extracted $k^2$ of 6.4%, yielding a high transmit efficiency of 65 nm/V with a mechanically robust active layer. We leverage the high performance to demonstrate extreme-temperature resilience, showcasing stable device operation up to 600 degrees C and survival up to 900 degrees C, highlighting LN's potential as a resilient PMUT platform.",Materials Science
"Piezoelectric micromachined ultrasonic transducers (PMUTs) are widely used in applications that demand mechanical resilience, thermal stability, and compact form factors. Lead zirconate titanate (PZT) and aluminum nitride (AlN) active layers are used in PMUTs to enable acoustic actuation, sensing, or bidirectional operation. These platforms rely on bimorph films to maximize electromechanical coupling ($k^2$) through thin-film deposition, which uses intermediate electrode layers to establish opposing electric fields. Consequently, incumbent PMUT platforms are limited in achievable film thickness and feature material interfaces that compromise mechanical integrity and thermal performance. Combined with the intrinsic limitations of PZT and AlN, these factors motivate exploration of alternative PMUT material platforms. Recent efforts have sought to demonstrate that single-crystal lithium niobate (LN) is a promising candidate, offering substantially higher $k^2$ and bidirectional performance. Advances in LN film transfer technology have enabled the formation of periodically poled piezoelectric (P3F) LN, facilitating a bimorph stack without intermediate electrodes. In this work, we showcase bimorph PMUTs incorporating a mechanically robust, 20 micron thick P3F LN active layer. We establish the motivation for LN PMUTs through a material comparison, followed by extensive membrane geometry optimization and subsequent enhancement of the PMUT's $k^2$. We demonstrate a 775 kHz flexural mode device with a quality factor (Q) of 200 and an extracted $k^2$ of 6.4%, yielding a high transmit efficiency of 65 nm/V with a mechanically robust active layer. We leverage the high performance to demonstrate extreme-temperature resilience, showcasing stable device operation up to 600 degrees C and survival up to 900 degrees C, highlighting LN's potential as a resilient PMUT platform. [SEP] [HINT] used -> Bioinformatics (Syns: utilize, ill-used, apply) | quality -> Bioinformatics (Syns: lineament, tone, calibre) | performance -> Bioinformatics (Syns: functioning, operation, carrying out)",Materials Science
"The motor cortex (MC) is often described as an autonomous dynamical system during movement execution. In an autonomous dynamical system, flexible movement generation depends on reconfiguring the initial conditions, which then unwind along known dynamics. An open question is whether these dynamics govern MC activity during brain-machine interface (BMI) control. We investigated MC activity during BMI cursor movements of multiple durations, ranging from hundreds of milliseconds to sustained over seconds. These durations were chosen to cover the range of movement durations necessary to control modern BMIs under varying precision levels. Movements shared their MC initial condition with movements of different durations in the same direction. Long-duration movements sustained MC activity, effectively pausing the neural population dynamics until each movement goal was reached. The difference across durations in MC population dynamics may be attributed to external inputs. Our results highlight the role of sustained inputs to MC during movement.",Neuroscience
"The motor cortex (MC) is often described as an autonomous dynamical system during movement execution. In an autonomous dynamical system, flexible movement generation depends on reconfiguring the initial conditions, which then unwind along known dynamics. An open question is whether these dynamics govern MC activity during brain-machine interface (BMI) control. We investigated MC activity during BMI cursor movements of multiple durations, ranging from hundreds of milliseconds to sustained over seconds. These durations were chosen to cover the range of movement durations necessary to control modern BMIs under varying precision levels. Movements shared their MC initial condition with movements of different durations in the same direction. Long-duration movements sustained MC activity, effectively pausing the neural population dynamics until each movement goal was reached. The difference across durations in MC population dynamics may be attributed to external inputs. Our results highlight the role of sustained inputs to MC during movement. [SEP] [HINT] results -> Bioinformatics (Syns: final result, consequence, resultant role) | different -> Neuroscience (Syns: unlike, dissimilar) | activity -> Neuroscience (Syns: activeness, body process, bodily process)",Neuroscience
"Artificial Neural Networks, the building blocks of AI, were inspired by the human brain's network of neurons. Over the years, these networks have evolved to replicate the complex capabilities of the brain, allowing them to handle tasks such as image and language processing. In the realm of Large Language Models, there has been a keen interest in making the language learning process more akin to that of humans. While neuroscientific research has shown that different grammatical categories are processed by different neurons in the brain, we show that LLMs operate in a similar way. Utilizing Llama 3, we identify the most important neurons associated with the prediction of words belonging to different part-of-speech tags. Using the achieved knowledge, we train a classifier on a dataset, which shows that the activation patterns of these key neurons can reliably predict part-of-speech tags on fresh data. The results suggest the presence of a subspace in LLMs focused on capturing part-of-speech tag concepts, resembling patterns observed in lesion studies of the brain in neuroscience.",Neuroscience
"Artificial Neural Networks, the building blocks of AI, were inspired by the human brain's network of neurons. Over the years, these networks have evolved to replicate the complex capabilities of the brain, allowing them to handle tasks such as image and language processing. In the realm of Large Language Models, there has been a keen interest in making the language learning process more akin to that of humans. While neuroscientific research has shown that different grammatical categories are processed by different neurons in the brain, we show that LLMs operate in a similar way. Utilizing Llama 3, we identify the most important neurons associated with the prediction of words belonging to different part-of-speech tags. Using the achieved knowledge, we train a classifier on a dataset, which shows that the activation patterns of these key neurons can reliably predict part-of-speech tags on fresh data. The results suggest the presence of a subspace in LLMs focused on capturing part-of-speech tag concepts, resembling patterns observed in lesion studies of the brain in neuroscience. [SEP] [HINT] tasks -> Neuroscience (Syns: tax, task, project) | language -> Neuroscience (Syns: linguistic process, linguistic communication, spoken communication) | learning -> Bioinformatics (Syns: take, teach, acquire)",Neuroscience
"Lightweight inference is critical for biomolecular structure prediction and downstream tasks, enabling efficient real-world deployment and inference-time scaling for large-scale applications. While AF3 and its variants (e.g., Protenix, Chai-1) have advanced structure prediction results, they suffer from critical limitations: high inference latency and cubic time complexity with respect to token count, both of which restrict scalability for large biomolecular complexes. To address the core challenge of balancing model efficiency and prediction accuracy, we introduce three key innovations: (1) compressing non-scalable operations to mitigate cubic time complexity, (2) removing redundant blocks across modules to reduce unnecessary overhead, and (3) adopting a few-step sampler for the atom diffusion module to accelerate inference. Building on these design principles, we develop Protenix-Mini+, a highly lightweight and scalable variant of the Protenix model. Within an acceptable range of performance degradation, it substantially improves computational efficiency. For example, in the case of low-homology single-chain proteins, Protenix-Mini+ experiences an intra-protein LDDT drop of approximately 3% relative to the full Protenix model -- an acceptable performance trade-off given its substantially 90%+ improved computational efficiency.",Bioinformatics
"Lightweight inference is critical for biomolecular structure prediction and downstream tasks, enabling efficient real-world deployment and inference-time scaling for large-scale applications. While AF3 and its variants (e.g., Protenix, Chai-1) have advanced structure prediction results, they suffer from critical limitations: high inference latency and cubic time complexity with respect to token count, both of which restrict scalability for large biomolecular complexes. To address the core challenge of balancing model efficiency and prediction accuracy, we introduce three key innovations: (1) compressing non-scalable operations to mitigate cubic time complexity, (2) removing redundant blocks across modules to reduce unnecessary overhead, and (3) adopting a few-step sampler for the atom diffusion module to accelerate inference. Building on these design principles, we develop Protenix-Mini+, a highly lightweight and scalable variant of the Protenix model. Within an acceptable range of performance degradation, it substantially improves computational efficiency. For example, in the case of low-homology single-chain proteins, Protenix-Mini+ experiences an intra-protein LDDT drop of approximately 3% relative to the full Protenix model -- an acceptable performance trade-off given its substantially 90%+ improved computational efficiency. [SEP] [HINT] computational -> Neuroscience (Syns: ) | structure -> Bioinformatics (Syns: social system, complex body part, social structure) | performance -> Bioinformatics (Syns: functioning, operation, carrying out)",Bioinformatics
"Prussian blue analogues (PBAs) and related organic materials are promising platforms for next-generation memory and energy-storage technologies due to their redox activity, ionic mobility, and compatibility with low-cost and scalable fabrication. Electrodeposited Prussian Blue (PB) and Prussian White (PW) thin films show robust resistive switching with ON/OFF ratios from one to three orders of magnitude in both bipolar and unipolar modes. Structural and spectroscopic analyses reveal homogeneous films with well-defined grain boundaries and ionic pathways that enable filamentary conduction. Current-voltage measurements, impedance spectroscopy, and quantum transport modeling indicate switching mechanisms governed by ohmic or space-charge-limited conduction, driven by potassium-ion migration and reversible redox processes. PB-based devices also exhibit conductance quantization with discrete steps at integer and half-integer multiples of G0, consistent with ballistic electron transport through atomic-scale channels. Complementary studies on perylene-based liquid crystals and FeHCF on graphene oxide highlight the versatility of PBAs for memory and supercapacitor applications. Together, these results demonstrate the multifunctionality and scalability of PBAs for future ReRAM, neuromorphic computing, multilevel memory, cryptographic hardware, and high-performance energy-storage devices.",Materials Science
"Prussian blue analogues (PBAs) and related organic materials are promising platforms for next-generation memory and energy-storage technologies due to their redox activity, ionic mobility, and compatibility with low-cost and scalable fabrication. Electrodeposited Prussian Blue (PB) and Prussian White (PW) thin films show robust resistive switching with ON/OFF ratios from one to three orders of magnitude in both bipolar and unipolar modes. Structural and spectroscopic analyses reveal homogeneous films with well-defined grain boundaries and ionic pathways that enable filamentary conduction. Current-voltage measurements, impedance spectroscopy, and quantum transport modeling indicate switching mechanisms governed by ohmic or space-charge-limited conduction, driven by potassium-ion migration and reversible redox processes. PB-based devices also exhibit conductance quantization with discrete steps at integer and half-integer multiples of G0, consistent with ballistic electron transport through atomic-scale channels. Complementary studies on perylene-based liquid crystals and FeHCF on graphene oxide highlight the versatility of PBAs for memory and supercapacitor applications. Together, these results demonstrate the multifunctionality and scalability of PBAs for future ReRAM, neuromorphic computing, multilevel memory, cryptographic hardware, and high-performance energy-storage devices. [SEP] [HINT] transport -> Materials Science (Syns: transferral, enthral, shipping) | electron -> Materials Science (Syns: negatron) | results -> Bioinformatics (Syns: final result, consequence, resultant role)",Materials Science
"Copper-graphene composite (CGC) conductors are widely considered as a potential alternative to pure copper (Cu). Yet, the effect of graphene (Gr) on the electrical conductivity of CGCs remains elusive, and their electrical performance is still controversial. This work addresses these unresolved questions by unambiguously quantifying how the electrical properties of CGCs depend on the characteristics of Gr and Cu. Gr is synthesized on Cu foils, foams, and wires by utilizing a wide range of chemical vapor deposition conditions to independently control their characteristics. Then the Gr-enhanced electrical conductivity (Δσ) is characterized for CGCs with different Cu geometries and Gr qualities. This study confirms that unprecedented electrical conductivity (Δσ = 17.1%) can be achieved only when both Gr and Cu are carefully optimized. Specifically, the study reveals three key factors: (1) Δσ is positively correlated with continuity of Gr; (2) CGCs with a continuous monolayer Gr exhibit a strong Δσ-A_s linear relation where A_s is the specific surface area of a CGC; and (3) Δσ becomes more pronounced when a Cu matrix has a curved cross-section. This work reveals the fundamental mechanisms of how Gr influences the overall electrical conductivity of CGCs and, therefore, is a crucial step toward designing and manufacturing high-performance CGC conductors for emerging applications.",Materials Science
"Copper-graphene composite (CGC) conductors are widely considered as a potential alternative to pure copper (Cu). Yet, the effect of graphene (Gr) on the electrical conductivity of CGCs remains elusive, and their electrical performance is still controversial. This work addresses these unresolved questions by unambiguously quantifying how the electrical properties of CGCs depend on the characteristics of Gr and Cu. Gr is synthesized on Cu foils, foams, and wires by utilizing a wide range of chemical vapor deposition conditions to independently control their characteristics. Then the Gr-enhanced electrical conductivity (Δσ) is characterized for CGCs with different Cu geometries and Gr qualities. This study confirms that unprecedented electrical conductivity (Δσ = 17.1%) can be achieved only when both Gr and Cu are carefully optimized. Specifically, the study reveals three key factors: (1) Δσ is positively correlated with continuity of Gr; (2) CGCs with a continuous monolayer Gr exhibit a strong Δσ-A_s linear relation where A_s is the specific surface area of a CGC; and (3) Δσ becomes more pronounced when a Cu matrix has a curved cross-section. This work reveals the fundamental mechanisms of how Gr influences the overall electrical conductivity of CGCs and, therefore, is a crucial step toward designing and manufacturing high-performance CGC conductors for emerging applications. [SEP] [HINT] work -> Bioinformatics (Syns: work out, process, bring) | performance -> Bioinformatics (Syns: functioning, operation, carrying out) | different -> Neuroscience (Syns: unlike, dissimilar)",Materials Science
"DSC-MRI perfusion is a medical imaging technique for diagnosing and prognosing brain tumors and strokes. Its analysis relies on mathematical deconvolution, but noise or motion artifacts in a clinical environment can disrupt this process, leading to incorrect estimate of perfusion parameters. Although deep learning approaches have shown promising results, their calibration typically rely on third-party deconvolution algorithms to generate reference outputs and are bound to reproduce their limitations.   To adress this problem, we propose a physics-informed autoencoder that leverages an analytical model to decode the perfusion parameters and guide the learning of the encoding network. This autoencoder is trained in a self-supervised fashion without any third-party software and its performance is evaluated on a database with glioma patients. Our method shows reliable results for glioma grading in accordance with other well-known deconvolution algorithms despite a lower computation time. It also achieved competitive performance even in the presence of high noise which is critical in a medical environment.",Bioinformatics
"DSC-MRI perfusion is a medical imaging technique for diagnosing and prognosing brain tumors and strokes. Its analysis relies on mathematical deconvolution, but noise or motion artifacts in a clinical environment can disrupt this process, leading to incorrect estimate of perfusion parameters. Although deep learning approaches have shown promising results, their calibration typically rely on third-party deconvolution algorithms to generate reference outputs and are bound to reproduce their limitations.   To adress this problem, we propose a physics-informed autoencoder that leverages an analytical model to decode the perfusion parameters and guide the learning of the encoding network. This autoencoder is trained in a self-supervised fashion without any third-party software and its performance is evaluated on a database with glioma patients. Our method shows reliable results for glioma grading in accordance with other well-known deconvolution algorithms despite a lower computation time. It also achieved competitive performance even in the presence of high noise which is critical in a medical environment. [SEP] [HINT] clinical -> Bioinformatics (Syns: ) | learning -> Bioinformatics (Syns: take, teach, acquire) | performance -> Bioinformatics (Syns: functioning, operation, carrying out)",Bioinformatics
"Proteins are traditionally optimized through the costly construction and measurement of many mutants. Active Learning-assisted Directed Evolution (ALDE) alleviates that cost by predicting the best improvements and iteratively testing mutants to inform predictions. However, existing ALDE methods face a critical limitation: selecting the highest-predicted mutants in each round yields homogeneous training data insufficient for accurate prediction models in subsequent rounds. Here we present FolDE, an ALDE method designed to maximize end-of-campaign success. In simulations across 20 protein targets, FolDE discovers 23% more top 10% mutants than the best baseline ALDE method (p=0.005) and is 55% more likely to find top 1% mutants. FolDE achieves this primarily through naturalness-based warm-starting, which augments limited activity measurements with protein language model outputs to improve activity prediction. We also introduce a constant-liar batch selector, which improves batch diversity; this is important in multi-mutation campaigns but had limited effect in our benchmarks. The complete workflow is freely available as open-source software, making efficient protein optimization accessible to any laboratory.",Bioinformatics
"Proteins are traditionally optimized through the costly construction and measurement of many mutants. Active Learning-assisted Directed Evolution (ALDE) alleviates that cost by predicting the best improvements and iteratively testing mutants to inform predictions. However, existing ALDE methods face a critical limitation: selecting the highest-predicted mutants in each round yields homogeneous training data insufficient for accurate prediction models in subsequent rounds. Here we present FolDE, an ALDE method designed to maximize end-of-campaign success. In simulations across 20 protein targets, FolDE discovers 23% more top 10% mutants than the best baseline ALDE method (p=0.005) and is 55% more likely to find top 1% mutants. FolDE achieves this primarily through naturalness-based warm-starting, which augments limited activity measurements with protein language model outputs to improve activity prediction. We also introduce a constant-liar batch selector, which improves batch diversity; this is important in multi-mutation campaigns but had limited effect in our benchmarks. The complete workflow is freely available as open-source software, making efficient protein optimization accessible to any laboratory. [SEP] [HINT] language -> Neuroscience (Syns: linguistic process, linguistic communication, spoken communication) | existing -> Bioinformatics (Syns: subsist, existent, survive) | activity -> Neuroscience (Syns: activeness, body process, bodily process)",Bioinformatics
"Transformer-based deep learning models have shown promise for disease risk prediction using electronic health records(EHRs), but modeling temporal dependencies remains a key challenge due to irregular visit intervals and lack of uniform structure. We propose a Bi-Positional Embedding Transformer Encoder or BiPETE for single-disease prediction, which integrates rotary positional embeddings to encode relative visit timing and sinusoidal embeddings to preserve visit order. Without relying on large-scale pretraining, BiPETE is trained on EHR data from two mental health cohorts-depressive disorder and post-traumatic stress disorder (PTSD)-to predict the risk of alcohol and substance use disorders (ASUD). BiPETE outperforms baseline models, improving the area under the precision-recall curve (AUPRC) by 34% and 50% in the depression and PTSD cohorts, respectively. An ablation study further confirms the effectiveness of the dual positional encoding strategy. We apply the Integrated Gradients method to interpret model predictions, identifying key clinical features associated with ASUD risk and protection, such as abnormal inflammatory, hematologic, and metabolic markers, as well as specific medications and comorbidities. Overall, these key clinical features identified by the attribution methods contribute to a deeper understanding of the risk assessment process and offer valuable clues for mitigating potential risks. In summary, our study presents a practical and interpretable framework for disease risk prediction using EHR data, which can achieve strong performance.",Bioinformatics
"Transformer-based deep learning models have shown promise for disease risk prediction using electronic health records(EHRs), but modeling temporal dependencies remains a key challenge due to irregular visit intervals and lack of uniform structure. We propose a Bi-Positional Embedding Transformer Encoder or BiPETE for single-disease prediction, which integrates rotary positional embeddings to encode relative visit timing and sinusoidal embeddings to preserve visit order. Without relying on large-scale pretraining, BiPETE is trained on EHR data from two mental health cohorts-depressive disorder and post-traumatic stress disorder (PTSD)-to predict the risk of alcohol and substance use disorders (ASUD). BiPETE outperforms baseline models, improving the area under the precision-recall curve (AUPRC) by 34% and 50% in the depression and PTSD cohorts, respectively. An ablation study further confirms the effectiveness of the dual positional encoding strategy. We apply the Integrated Gradients method to interpret model predictions, identifying key clinical features associated with ASUD risk and protection, such as abnormal inflammatory, hematologic, and metabolic markers, as well as specific medications and comorbidities. Overall, these key clinical features identified by the attribution methods contribute to a deeper understanding of the risk assessment process and offer valuable clues for mitigating potential risks. In summary, our study presents a practical and interpretable framework for disease risk prediction using EHR data, which can achieve strong performance. [SEP] [HINT] clinical -> Bioinformatics (Syns: ) | features -> Bioinformatics (Syns: characteristic, lineament, feature of speech) | understanding -> Neuroscience (Syns: savvy, intellect, sympathy)",Bioinformatics
"The brain predicts the external world through an internal model refined by prediction errors. A complete prediction specifies what will happen, when it will happen, and with what probability, a construct we call the ""prediction object."" Existing models usually capture only what and when, omit probabilities, and rely on algorithms that are not biologically plausible. We show that a single population of spiking neurons can learn the full prediction object through a biologically grounded three factor Hebbian rule. In a heterogeneous Izhikevich reservoir, online timing learning and offline identity consolidation allow the network to fire at the correct times with amplitudes proportional to probability and to adapt instantly when the environment changes. Unlike global least squares methods such as FORCE, which require resets to relearn, our model recalibrates continuously through local error gated modulation. This single circuit provides a biologically grounded, flexible mechanism for predictive cognition.",Neuroscience
"The brain predicts the external world through an internal model refined by prediction errors. A complete prediction specifies what will happen, when it will happen, and with what probability, a construct we call the ""prediction object."" Existing models usually capture only what and when, omit probabilities, and rely on algorithms that are not biologically plausible. We show that a single population of spiking neurons can learn the full prediction object through a biologically grounded three factor Hebbian rule. In a heterogeneous Izhikevich reservoir, online timing learning and offline identity consolidation allow the network to fire at the correct times with amplitudes proportional to probability and to adapt instantly when the environment changes. Unlike global least squares methods such as FORCE, which require resets to relearn, our model recalibrates continuously through local error gated modulation. This single circuit provides a biologically grounded, flexible mechanism for predictive cognition. [SEP] [HINT] learning -> Bioinformatics (Syns: take, teach, acquire) | existing -> Bioinformatics (Syns: subsist, existent, survive) | models -> Bioinformatics (Syns: framework, modelling, good example)",Neuroscience
"Sodium-ion batteries have gained much interest over the past years and especially layered oxides are highly considered as cathodes for the next generation of batteries. However, there are still significant challenges to overcome in these materials for practical applications mainly related to capacity degradation and voltage fading. A key influence factor for these challenges are phase transitions that occur by gliding of layers during operation of these materials. Until now there is limited atomistic-level understanding on such transitions as simulations of these processes are computationally demanding. In this work, we trained a classical pairwise Coulomb-Buckingham potential versus extensive \textit{ab initio} data using a genetic algorithm to study O2-P2 phase transitions in Na\textsubscript{\textit{x}}CoO\textsubscript{2}. Our density functional theory~(DFT) and classical potential calculations show that phase transition barriers decrease upon desodiation and are further lowered if dynamic conditions are considered through molecular dynamics simulations. Our developed classical potential is able to capture phase transitions and its related increase in the Na-ion diffusivity under standard lab conditions at the $\upmu$s timescale of molecular dynamics simulation. Furthermore, it is found that the phase transition occurs gradually \textit{via} various OP\textit{n} phases.",Materials Science
"Sodium-ion batteries have gained much interest over the past years and especially layered oxides are highly considered as cathodes for the next generation of batteries. However, there are still significant challenges to overcome in these materials for practical applications mainly related to capacity degradation and voltage fading. A key influence factor for these challenges are phase transitions that occur by gliding of layers during operation of these materials. Until now there is limited atomistic-level understanding on such transitions as simulations of these processes are computationally demanding. In this work, we trained a classical pairwise Coulomb-Buckingham potential versus extensive \textit{ab initio} data using a genetic algorithm to study O2-P2 phase transitions in Na\textsubscript{\textit{x}}CoO\textsubscript{2}. Our density functional theory~(DFT) and classical potential calculations show that phase transition barriers decrease upon desodiation and are further lowered if dynamic conditions are considered through molecular dynamics simulations. Our developed classical potential is able to capture phase transitions and its related increase in the Na-ion diffusivity under standard lab conditions at the $\upmu$s timescale of molecular dynamics simulation. Furthermore, it is found that the phase transition occurs gradually \textit{via} various OP\textit{n} phases. [SEP] [HINT] transition -> Materials Science (Syns: passage, modulation, changeover) | understanding -> Neuroscience (Syns: savvy, intellect, sympathy) | functional -> Neuroscience (Syns: working, usable, running)",Materials Science
"Scalable assessments of mental illness, the leading driver of disability worldwide, remain a critical roadblock toward accessible and equitable care. Here, we show that human-computer interactions encode multiple dimensions of self-reported mental health and their changes over time.   We introduce MAILA, a MAchine-learning framework for Inferring Latent mental states from digital Activity. We trained MAILA to predict 1.3 million mental-health self-reports from 20,000 cursor and touchscreen recordings recorded in 9,000 online participants. The dataset includes 2,000 individuals assessed longitudinally, 1,500 diagnosed with depression, and 500 with obsessive-compulsive disorder. MAILA tracks dynamic mental states along three orthogonal dimensions, generalizes across contexts, and achieves near-ceiling accuracy when predicting group-level mental health. The model translates from general to clinical populations, identifies individuals living with mental illness, and captures signatures of psychological function that are not conveyed by language.   Our results demonstrate how everyday human-computer interactions can power passive, reliable, dynamic, and maximally scalable mental health assessments. The ability to decode mental states at zero marginal cost sets new benchmarks for precision medicine and public health, while raising important questions about privacy, agency, and autonomy online.",Neuroscience
"Scalable assessments of mental illness, the leading driver of disability worldwide, remain a critical roadblock toward accessible and equitable care. Here, we show that human-computer interactions encode multiple dimensions of self-reported mental health and their changes over time.   We introduce MAILA, a MAchine-learning framework for Inferring Latent mental states from digital Activity. We trained MAILA to predict 1.3 million mental-health self-reports from 20,000 cursor and touchscreen recordings recorded in 9,000 online participants. The dataset includes 2,000 individuals assessed longitudinally, 1,500 diagnosed with depression, and 500 with obsessive-compulsive disorder. MAILA tracks dynamic mental states along three orthogonal dimensions, generalizes across contexts, and achieves near-ceiling accuracy when predicting group-level mental health. The model translates from general to clinical populations, identifies individuals living with mental illness, and captures signatures of psychological function that are not conveyed by language.   Our results demonstrate how everyday human-computer interactions can power passive, reliable, dynamic, and maximally scalable mental health assessments. The ability to decode mental states at zero marginal cost sets new benchmarks for precision medicine and public health, while raising important questions about privacy, agency, and autonomy online. [SEP] [HINT] clinical -> Bioinformatics (Syns: ) | results -> Bioinformatics (Syns: final result, consequence, resultant role) | framework -> Bioinformatics (Syns: theoretical account, model, fabric)",Neuroscience
"Magnetic exchange interactions govern the macroscopic magnetic behavior of solids and underpin both fundamental spin phenomena and emerging technologies. The accurate and efficient determination of these interactions is therefore critical for predictive modeling of magnetic materials. Here we present a systematic first-principles comparison of three widely used approaches-the Least-Squares Total Energy (LSTE), the Four-State Total Energy (FSTE), and the Green's function-based Liechtenstein \textit{et al.} (LKAG) methods-applied to thirteen antiferromagnetic compounds. We introduce an framework for identifying the minimal supercells required for an accurate exchange parameter extraction in the FSTE method, significantly reducing computational cost while preserving precision. Our results show that LSTE and FSTE yield nearly identical exchange parameters, whereas the LKAG method reproduces the dominant exchange interactions but exhibits quantitative deviations. A detailed analysis of computational efficiency versus accuracy reveals that the LSTE scheme offers the most favorable balance, establishing a general, reproducible, and scalable workflow for Heisenberg mapping, while the FSTE approach remains the most straightforward for extracting specific exchange interactions.",Materials Science
"Magnetic exchange interactions govern the macroscopic magnetic behavior of solids and underpin both fundamental spin phenomena and emerging technologies. The accurate and efficient determination of these interactions is therefore critical for predictive modeling of magnetic materials. Here we present a systematic first-principles comparison of three widely used approaches-the Least-Squares Total Energy (LSTE), the Four-State Total Energy (FSTE), and the Green's function-based Liechtenstein \textit{et al.} (LKAG) methods-applied to thirteen antiferromagnetic compounds. We introduce an framework for identifying the minimal supercells required for an accurate exchange parameter extraction in the FSTE method, significantly reducing computational cost while preserving precision. Our results show that LSTE and FSTE yield nearly identical exchange parameters, whereas the LKAG method reproduces the dominant exchange interactions but exhibits quantitative deviations. A detailed analysis of computational efficiency versus accuracy reveals that the LSTE scheme offers the most favorable balance, establishing a general, reproducible, and scalable workflow for Heisenberg mapping, while the FSTE approach remains the most straightforward for extracting specific exchange interactions. [SEP] [HINT] used -> Bioinformatics (Syns: utilize, ill-used, apply) | computational -> Neuroscience (Syns: ) | spin -> Materials Science (Syns: twisting, whirl, tailspin)",Materials Science
"Cortical circuits exhibit high levels of response diversity, even across apparently uniform neuronal populations. While emerging data-driven approaches exploit this heterogeneity to infer effective models of cortical circuit computation (e.g. Genkin et al. Nature 2025), the power of response diversity to enable inference of mechanistic circuit models is largely unexplored. Within the landscape of cortical circuit models, spiking neuron networks in the balanced state naturally exhibit high levels of response and tuning diversity emerging from their internal dynamics. A statistical theory for this emergent tuning heterogeneity, however, has only been formulated for binary spin models (Vreeswijk & Sompolinsky, 2005). Here we present a formulation of feature-tuned balanced state networks that allows for arbitrary and diverse dynamics of postsynaptic currents and variable levels of heterogeneity in cellular excitability but nevertheless is analytically exactly tractable with respect to the emergent tuning curve heterogeneity. Using this framework, we present a case study demonstrating that, for a wide range of parameters even the population mean response is non-universal and sensitive to mechanistic circuit details. As our theory enables exactly and analytically obtaining the likelihood-function of tuning heterogeneity given circuit parameters, we argue that it forms a powerful and rigorous basis for neural circuit inference.",Neuroscience
"Cortical circuits exhibit high levels of response diversity, even across apparently uniform neuronal populations. While emerging data-driven approaches exploit this heterogeneity to infer effective models of cortical circuit computation (e.g. Genkin et al. Nature 2025), the power of response diversity to enable inference of mechanistic circuit models is largely unexplored. Within the landscape of cortical circuit models, spiking neuron networks in the balanced state naturally exhibit high levels of response and tuning diversity emerging from their internal dynamics. A statistical theory for this emergent tuning heterogeneity, however, has only been formulated for binary spin models (Vreeswijk & Sompolinsky, 2005). Here we present a formulation of feature-tuned balanced state networks that allows for arbitrary and diverse dynamics of postsynaptic currents and variable levels of heterogeneity in cellular excitability but nevertheless is analytically exactly tractable with respect to the emergent tuning curve heterogeneity. Using this framework, we present a case study demonstrating that, for a wide range of parameters even the population mean response is non-universal and sensitive to mechanistic circuit details. As our theory enables exactly and analytically obtaining the likelihood-function of tuning heterogeneity given circuit parameters, we argue that it forms a powerful and rigorous basis for neural circuit inference. [SEP] [HINT] spin -> Materials Science (Syns: twisting, whirl, tailspin) | cortical -> Neuroscience (Syns: ) | networks -> Neuroscience (Syns: network, meshwork, electronic network)",Neuroscience
"Understanding the crystallization pathways of water-rich ammonia-water (NH3-H2O) solutions and the stability of ammonia hydrates is key to unraveling the behavior of complex hydrogen-bonding networks as well as for planetary interior modelling. Yet, there are still inconsistencies in the crystallization sequence reported upon pressure-induced crystallization of H2O-rich NH3-H2O solutions at room temperature. Here, we investigate the effect of compression rates on the crystallization pathways of 25 wt% NH3 aqueous solutions at room temperature using dynamically compressed diamond anvil cells (dDAC) coupled with time-resolved X-ray diffraction. We show that compression rates exceeding 0.5 GPa/sec promote direct crystallization of a body-centered cubic (bcc) phase (DMA') with possible AMH stoichiometry coexisting with H2O ice VII, while rates below 0.2 GPa/sec stabilize monoclinic NH3-rich AHH-II and ice VII phases. Intermediate rates between 0.2-0.5 GPa/sec produce a mixture of both hydrates alongside ice VII, hence demonstrating the role of compression rate on the crystallization sequence of ammonia solutions. The compression behavior and phase stability of the distinct phase assemblies (AHH-II/DMA' + ice VII) are investigated further to place constraints on the composition of the DMA' phase, the effect of ice VII on the compressibility of ammonia hydrates, and the plausible incorporation of NH3 impurities within the lattice of high-pressure ice phases.",Materials Science
"Understanding the crystallization pathways of water-rich ammonia-water (NH3-H2O) solutions and the stability of ammonia hydrates is key to unraveling the behavior of complex hydrogen-bonding networks as well as for planetary interior modelling. Yet, there are still inconsistencies in the crystallization sequence reported upon pressure-induced crystallization of H2O-rich NH3-H2O solutions at room temperature. Here, we investigate the effect of compression rates on the crystallization pathways of 25 wt% NH3 aqueous solutions at room temperature using dynamically compressed diamond anvil cells (dDAC) coupled with time-resolved X-ray diffraction. We show that compression rates exceeding 0.5 GPa/sec promote direct crystallization of a body-centered cubic (bcc) phase (DMA') with possible AMH stoichiometry coexisting with H2O ice VII, while rates below 0.2 GPa/sec stabilize monoclinic NH3-rich AHH-II and ice VII phases. Intermediate rates between 0.2-0.5 GPa/sec produce a mixture of both hydrates alongside ice VII, hence demonstrating the role of compression rate on the crystallization sequence of ammonia solutions. The compression behavior and phase stability of the distinct phase assemblies (AHH-II/DMA' + ice VII) are investigated further to place constraints on the composition of the DMA' phase, the effect of ice VII on the compressibility of ammonia hydrates, and the plausible incorporation of NH3 impurities within the lattice of high-pressure ice phases. [SEP] [HINT] understanding -> Neuroscience (Syns: savvy, intellect, sympathy) | networks -> Neuroscience (Syns: network, meshwork, electronic network) | complex -> Bioinformatics (Syns: building complex, coordination compound, composite)",Materials Science
"In our common experience, crumpling a sheet requires external compressive force and leads to a random network of folds. However, thin sheets have been theoretically predicted to spontaneously transition from a flat to a crumpled state driven by thermal fluctuations, a phenomenon that has been elusive in experiments. We report the first observation of a similar crumpling transition driven instead by surface energy. Using a sensitive experimental protocol, when we gently compress a thin polymer sheet weakly adhered to a hydrogel substrate it transitions to a self-crumpling state at a well defined critical compression independent of system details. The transition is marked by the percolation of a fold network, and a power law increase in fold density. Most remarkably, the crumpled state shows a tunable order of folds establishing the phenomenon's potential as a simple and scalable technique to do origami with extremely thin sheets.",Materials Science
"In our common experience, crumpling a sheet requires external compressive force and leads to a random network of folds. However, thin sheets have been theoretically predicted to spontaneously transition from a flat to a crumpled state driven by thermal fluctuations, a phenomenon that has been elusive in experiments. We report the first observation of a similar crumpling transition driven instead by surface energy. Using a sensitive experimental protocol, when we gently compress a thin polymer sheet weakly adhered to a hydrogel substrate it transitions to a self-crumpling state at a well defined critical compression independent of system details. The transition is marked by the percolation of a fold network, and a power law increase in fold density. Most remarkably, the crumpled state shows a tunable order of folds establishing the phenomenon's potential as a simple and scalable technique to do origami with extremely thin sheets. [SEP] [HINT] transition -> Materials Science (Syns: passage, modulation, changeover) | order -> Materials Science (Syns: enjoin, dictate, social club) | using -> Bioinformatics (Syns: utilize, exploitation, apply)",Materials Science
"Understanding how systems evolve over time often requires discovering the differential equations that govern their behavior. Automatically learning these equations from experimental data is challenging when the data are noisy or limited, and existing approaches struggle, in particular, with the estimation of unobserved derivatives. Here, we introduce an integral Bayesian symbolic regression method that learns governing equations directly from raw time-series data, without requiring manual assumptions or error-prone derivative estimation. By sampling the space of symbolic differential equations and evaluating them via numerical integration, our method robustly identifies governing equations even from noisy or scarce data. We show that this approach accurately recovers ground-truth models in synthetic benchmarks, and that it makes quasi-optimal predictions of system dynamics for all noise regimes. Applying this method to bacterial growth experiments across multiple species and substrates, we discover novel growth equations that outperform classical models in accurately capturing all phases of microbial proliferation, including lag, exponential, and saturation. Unlike standard approaches, our method reveals subtle shifts in growth dynamics, such as double ramp-ups or non-canonical transitions, offering a deeper, data-driven understanding of microbial physiology.",Bioinformatics
"Understanding how systems evolve over time often requires discovering the differential equations that govern their behavior. Automatically learning these equations from experimental data is challenging when the data are noisy or limited, and existing approaches struggle, in particular, with the estimation of unobserved derivatives. Here, we introduce an integral Bayesian symbolic regression method that learns governing equations directly from raw time-series data, without requiring manual assumptions or error-prone derivative estimation. By sampling the space of symbolic differential equations and evaluating them via numerical integration, our method robustly identifies governing equations even from noisy or scarce data. We show that this approach accurately recovers ground-truth models in synthetic benchmarks, and that it makes quasi-optimal predictions of system dynamics for all noise regimes. Applying this method to bacterial growth experiments across multiple species and substrates, we discover novel growth equations that outperform classical models in accurately capturing all phases of microbial proliferation, including lag, exponential, and saturation. Unlike standard approaches, our method reveals subtle shifts in growth dynamics, such as double ramp-ups or non-canonical transitions, offering a deeper, data-driven understanding of microbial physiology. [SEP] [HINT] understanding -> Neuroscience (Syns: savvy, intellect, sympathy) | learning -> Bioinformatics (Syns: take, teach, acquire) | space -> Neuroscience (Syns: distance, place, outer space)",Bioinformatics
"Sensory representation is typically understood through a hierarchical-causal framework where progressively abstract features are extracted sequentially. However, this causal view fails to explain misrepresentation, a phenomenon better handled by an informational view based on decodable content. This creates a tension: how does a system that abstracts away details still preserve the fine-grained information needed for downstream functions? We propose readout representation to resolve this, defining representation by the information recoverable from features rather than their causal origin. Empirically, we show that inputs can be accurately reconstructed even from heavily perturbed mid-level features, demonstrating that a single input corresponds to a broad, redundant region of feature space, challenging the causal mapping perspective. To quantify this property, we introduce representation size, a metric linked to model robustness and representational redundancy. Our framework offers a new lens for analyzing how both biological and artificial neural systems learn complex features while maintaining robust, information-rich representations of the world.",Neuroscience
"Sensory representation is typically understood through a hierarchical-causal framework where progressively abstract features are extracted sequentially. However, this causal view fails to explain misrepresentation, a phenomenon better handled by an informational view based on decodable content. This creates a tension: how does a system that abstracts away details still preserve the fine-grained information needed for downstream functions? We propose readout representation to resolve this, defining representation by the information recoverable from features rather than their causal origin. Empirically, we show that inputs can be accurately reconstructed even from heavily perturbed mid-level features, demonstrating that a single input corresponds to a broad, redundant region of feature space, challenging the causal mapping perspective. To quantify this property, we introduce representation size, a metric linked to model robustness and representational redundancy. Our framework offers a new lens for analyzing how both biological and artificial neural systems learn complex features while maintaining robust, information-rich representations of the world. [SEP] [HINT] based -> Bioinformatics (Syns: ground, free-base, base) | features -> Bioinformatics (Syns: characteristic, lineament, feature of speech) | information -> Bioinformatics (Syns: entropy, data, info)",Neuroscience
"This short note comments on \citet{Aerts2024Origin}, which proposes that ranked word frequencies in texts should be read through the lens of Bose--Einstein (BE) statistics and even used to illuminate the origin of quantum statistics in physics. The core message here is modest: the paper offers an interesting analogy and an eye-catching fit, but several key steps mix physical claims with definitions and curve-fitting choices. We highlight three such points: (i) a normalization issue that is presented as ""bosonic enhancement"", (ii) an identification of rank with energy that makes the BE fit only weakly diagnostic of an underlying mechanism, and (iii) a baseline comparison that is too weak to support an ontological conclusion. We also briefly flag a few additional concerns (interpretation drift, parameter semantics, and reproducibility).",Neuroscience
"This short note comments on \citet{Aerts2024Origin}, which proposes that ranked word frequencies in texts should be read through the lens of Bose--Einstein (BE) statistics and even used to illuminate the origin of quantum statistics in physics. The core message here is modest: the paper offers an interesting analogy and an eye-catching fit, but several key steps mix physical claims with definitions and curve-fitting choices. We highlight three such points: (i) a normalization issue that is presented as ""bosonic enhancement"", (ii) an identification of rank with energy that makes the BE fit only weakly diagnostic of an underlying mechanism, and (iii) a baseline comparison that is too weak to support an ontological conclusion. We also briefly flag a few additional concerns (interpretation drift, parameter semantics, and reproducibility). [SEP] [HINT] used -> Bioinformatics (Syns: utilize, ill-used, apply) | quantum -> Materials Science (Syns: ) | energy -> Materials Science (Syns: vim, muscularity, zip)",Neuroscience
"Intracellular compartmentalization of proteins underpins their function and the metabolic processes they sustain. Various mass spectrometry-based proteomics methods (subcellular spatial proteomics) now allow high throughput subcellular protein localization. Yet, the curation, analysis and interpretation of these data remain challenging, particularly in non-model organisms where establishing reliable marker proteins is difficult, and in contexts where experimental replication and subcellular fractionation are constrained. Here, we develop FSPmix, a semi-supervised functional clustering method implemented as an open-source R package, which leverages partial annotations from a subset of marker proteins to predict protein subcellular localization from subcellular spatial proteomics data. This method explicitly assumes that protein signatures vary smoothly across subcellular fractions, enabling more robust inference under low signal-to-noise data regimes. We applied FSPmix to a subcellular proteomics dataset from a marine diatom, allowing us to assign probabilistic localizations to proteins and uncover potentially new protein functions. Altogether, this work lays the foundation for more robust statistical analysis and interpretation of subcellular proteomics datasets, particularly in understudied organisms.",Bioinformatics
"Intracellular compartmentalization of proteins underpins their function and the metabolic processes they sustain. Various mass spectrometry-based proteomics methods (subcellular spatial proteomics) now allow high throughput subcellular protein localization. Yet, the curation, analysis and interpretation of these data remain challenging, particularly in non-model organisms where establishing reliable marker proteins is difficult, and in contexts where experimental replication and subcellular fractionation are constrained. Here, we develop FSPmix, a semi-supervised functional clustering method implemented as an open-source R package, which leverages partial annotations from a subset of marker proteins to predict protein subcellular localization from subcellular spatial proteomics data. This method explicitly assumes that protein signatures vary smoothly across subcellular fractions, enabling more robust inference under low signal-to-noise data regimes. We applied FSPmix to a subcellular proteomics dataset from a marine diatom, allowing us to assign probabilistic localizations to proteins and uncover potentially new protein functions. Altogether, this work lays the foundation for more robust statistical analysis and interpretation of subcellular proteomics datasets, particularly in understudied organisms. [SEP] [HINT] low -> Materials Science (Syns: low-spirited, scurvy, depressed) | functional -> Neuroscience (Syns: working, usable, running) | work -> Bioinformatics (Syns: work out, process, bring)",Bioinformatics
"The origin of the superior high-temperature strength of γ-TiAl with high Nb addition remains highly controversial, largely due to the unclear role of Nb atoms. Using large-scale hybrid Monte Carlo and molecular dynamics simulations with a self-developed neural network potential,we show that Nb atoms predominantly occupy Ti sites and form short-range order with neighboring Al atoms, but a non-negligible fraction also occupies Al sites (NbAl) and promotes the formation of antisite defects (TiAl). Both the NbAl and TiAl antisites exceptionally reduce stacking fault energies and facilitate deformation twinning, thereby enhancing plasticity. Meanwhile, these substitutional and antisite defects also increase the Peierls stress of both screw and edge dislocations, which hinders dislocation motion to cause pronounced solid-solution strengthening. This work provides mechanistic insights into the dual role of Nb in enhancing both strength and ductility in γ-TiAl and further offers guidance for defect and composition engineering in advanced alloy systems.",Materials Science
"The origin of the superior high-temperature strength of γ-TiAl with high Nb addition remains highly controversial, largely due to the unclear role of Nb atoms. Using large-scale hybrid Monte Carlo and molecular dynamics simulations with a self-developed neural network potential,we show that Nb atoms predominantly occupy Ti sites and form short-range order with neighboring Al atoms, but a non-negligible fraction also occupies Al sites (NbAl) and promotes the formation of antisite defects (TiAl). Both the NbAl and TiAl antisites exceptionally reduce stacking fault energies and facilitate deformation twinning, thereby enhancing plasticity. Meanwhile, these substitutional and antisite defects also increase the Peierls stress of both screw and edge dislocations, which hinders dislocation motion to cause pronounced solid-solution strengthening. This work provides mechanistic insights into the dual role of Nb in enhancing both strength and ductility in γ-TiAl and further offers guidance for defect and composition engineering in advanced alloy systems. [SEP] [HINT] defect -> Materials Science (Syns: mar, shortcoming, fault) | molecular -> Bioinformatics (Syns: ) | order -> Materials Science (Syns: enjoin, dictate, social club)",Materials Science
"The spin Hall magnetoresistance (SMR) is widely used to study the interplay between charge and spin currents in bilayers of a magnetic insulator and a normal metal. However, not much is known about the spatial variation of the SMR across the surface of one and the same sample. In this work, we investigate the statistical distribution of the SMR in hundreds of nominally identical Hall bar structures patterned into prototypical yttrium iron garnet (YIG)/Pt heterostructures. We find a Gaussian-distributed SMR with a narrow standard deviation of approximately 10$\,$% of the mean value in each YIG/Pt bilayer studied. However, the variation of the mean SMR between different YIG/Pt samples can be as large as ~30$\,$%, despite nominally identical fabrication conditions. This demonstrates that spatial variations of the SMR amplitude must not be neglected, in particular when comparing different heterostructures. On a microscopic level, local variations of the interface quality captured by the spin mixing conductance are the most likely origin for the observed SMR amplitude variations.",Materials Science
"The spin Hall magnetoresistance (SMR) is widely used to study the interplay between charge and spin currents in bilayers of a magnetic insulator and a normal metal. However, not much is known about the spatial variation of the SMR across the surface of one and the same sample. In this work, we investigate the statistical distribution of the SMR in hundreds of nominally identical Hall bar structures patterned into prototypical yttrium iron garnet (YIG)/Pt heterostructures. We find a Gaussian-distributed SMR with a narrow standard deviation of approximately 10$\,$% of the mean value in each YIG/Pt bilayer studied. However, the variation of the mean SMR between different YIG/Pt samples can be as large as ~30$\,$%, despite nominally identical fabrication conditions. This demonstrates that spatial variations of the SMR amplitude must not be neglected, in particular when comparing different heterostructures. On a microscopic level, local variations of the interface quality captured by the spin mixing conductance are the most likely origin for the observed SMR amplitude variations. [SEP] [HINT] used -> Bioinformatics (Syns: utilize, ill-used, apply) | spin -> Materials Science (Syns: twisting, whirl, tailspin) | charge -> Materials Science (Syns: tear, bearing, burster)",Materials Science
"The theta rhythm is important for many cognitive functions including spatial processing, memory encoding, and memory recall. The information processing underlying these functions is thought to rely on consistent, phase-specific spiking throughout a theta oscillation that may fluctuate significantly in baseline (center of oscillations), frequency, or amplitude. Experimental evidence shows that spikes can occur at specific phases even when the baseline membrane potential varies significantly, such that the integrity of phase-locking persists across a large variability in spike threshold. The mechanism of this precise spike timing during the theta rhythm is not yet known and previous mathematical models have not reflected the large variability in threshold potential seen experimentally. Here we introduce a straightforward mathematical neural model capable of demonstrating a phase-locked spiking in the face of significant baseline membrane potential fluctuation during theta rhythm. This novel approach incorporates a degenerate grazing bifurcation of an asymptotically stable oscillation. This model suggests a potential mechanism for how biological neurons can consistently produce spikes near the peak of a variable membrane potential oscillation.",Neuroscience
"The theta rhythm is important for many cognitive functions including spatial processing, memory encoding, and memory recall. The information processing underlying these functions is thought to rely on consistent, phase-specific spiking throughout a theta oscillation that may fluctuate significantly in baseline (center of oscillations), frequency, or amplitude. Experimental evidence shows that spikes can occur at specific phases even when the baseline membrane potential varies significantly, such that the integrity of phase-locking persists across a large variability in spike threshold. The mechanism of this precise spike timing during the theta rhythm is not yet known and previous mathematical models have not reflected the large variability in threshold potential seen experimentally. Here we introduce a straightforward mathematical neural model capable of demonstrating a phase-locked spiking in the face of significant baseline membrane potential fluctuation during theta rhythm. This novel approach incorporates a degenerate grazing bifurcation of an asymptotically stable oscillation. This model suggests a potential mechanism for how biological neurons can consistently produce spikes near the peak of a variable membrane potential oscillation. [SEP] [HINT] information -> Bioinformatics (Syns: entropy, data, info) | processing -> Neuroscience (Syns: work, process, march) | including -> Bioinformatics (Syns: admit, include, let in)",Neuroscience
"The magnetic nature of the altermagnet candidate RuO$_2$ remains under debate. It has been recently shown from quantum oscillations and angle-resolved photoemission spectroscopy (ARPES) that the high-quality RuO$_2$ bulk single crystal is a paramagnetic metal. However, the low-temperature specific heat exhibits a clear deviation from the conventional $C(T)$=$γT$ + $βT^3$ dependence; it is well described with nonanalytic Fermi-liquid correction for a clean paramagnetic metal: $C(T)$ = $γT$ + $βT^3$ + $δT^3 \textrm{ln}(T/T^*)$. Correspondingly, the magnetic susceptibility is well fitted with the inclusion of $T^2\textrm{ln}T$ term as well as $H^2\mathrm{ln}H$ term. In contrast to the spin fluctuation mechanism applicable to some heavy-electron compounds with positive $δ$, RuO$_2$ shows negative $δ$ suggesting a different origin. The observation of such nonanalytic Fermi liquid corrections is attributable to the availability of an ultra-clean sample. The electronic specific heat, the magnetic susceptibility, and the $T^2$ coefficient in resistivity point to a weakly-correlated 3D Fermi-liquid state with a modest electron correlation, as supported by the Wilson and Kadowaki-Woods ratios.",Materials Science
"The magnetic nature of the altermagnet candidate RuO$_2$ remains under debate. It has been recently shown from quantum oscillations and angle-resolved photoemission spectroscopy (ARPES) that the high-quality RuO$_2$ bulk single crystal is a paramagnetic metal. However, the low-temperature specific heat exhibits a clear deviation from the conventional $C(T)$=$γT$ + $βT^3$ dependence; it is well described with nonanalytic Fermi-liquid correction for a clean paramagnetic metal: $C(T)$ = $γT$ + $βT^3$ + $δT^3 \textrm{ln}(T/T^*)$. Correspondingly, the magnetic susceptibility is well fitted with the inclusion of $T^2\textrm{ln}T$ term as well as $H^2\mathrm{ln}H$ term. In contrast to the spin fluctuation mechanism applicable to some heavy-electron compounds with positive $δ$, RuO$_2$ shows negative $δ$ suggesting a different origin. The observation of such nonanalytic Fermi liquid corrections is attributable to the availability of an ultra-clean sample. The electronic specific heat, the magnetic susceptibility, and the $T^2$ coefficient in resistivity point to a weakly-correlated 3D Fermi-liquid state with a modest electron correlation, as supported by the Wilson and Kadowaki-Woods ratios. [SEP] [HINT] spin -> Materials Science (Syns: twisting, whirl, tailspin) | electronic -> Materials Science (Syns: ) | electron -> Materials Science (Syns: negatron)",Materials Science
"We present Genie-CAT, a tool-augmented large-language-model (LLM) system designed to accelerate scientific hypothesis generation in protein design. Using metalloproteins (e.g., ferredoxins) as a case study, Genie-CAT integrates four capabilities -- literature-grounded reasoning through retrieval-augmented generation (RAG), structural parsing of Protein Data Bank files, electrostatic potential calculations, and machine-learning prediction of redox properties -- into a unified agentic workflow. By coupling natural-language reasoning with data-driven and physics-based computation, the system generates mechanistically interpretable, testable hypotheses linking sequence, structure, and function. In proof-of-concept demonstrations, Genie-CAT autonomously identifies residue-level modifications near [Fe--S] clusters that affect redox tuning, reproducing expert-derived hypotheses in a fraction of the time. The framework highlights how AI agents combining language models with domain-specific tools can bridge symbolic reasoning and numerical simulation, transforming LLMs from conversational assistants into partners for computational discovery.",Bioinformatics
"We present Genie-CAT, a tool-augmented large-language-model (LLM) system designed to accelerate scientific hypothesis generation in protein design. Using metalloproteins (e.g., ferredoxins) as a case study, Genie-CAT integrates four capabilities -- literature-grounded reasoning through retrieval-augmented generation (RAG), structural parsing of Protein Data Bank files, electrostatic potential calculations, and machine-learning prediction of redox properties -- into a unified agentic workflow. By coupling natural-language reasoning with data-driven and physics-based computation, the system generates mechanistically interpretable, testable hypotheses linking sequence, structure, and function. In proof-of-concept demonstrations, Genie-CAT autonomously identifies residue-level modifications near [Fe--S] clusters that affect redox tuning, reproducing expert-derived hypotheses in a fraction of the time. The framework highlights how AI agents combining language models with domain-specific tools can bridge symbolic reasoning and numerical simulation, transforming LLMs from conversational assistants into partners for computational discovery. [SEP] [HINT] language -> Neuroscience (Syns: linguistic process, linguistic communication, spoken communication) | computational -> Neuroscience (Syns: ) | framework -> Bioinformatics (Syns: theoretical account, model, fabric)",Bioinformatics
"Accurate protein function prediction requires integrating heterogeneous intrinsic signals (e.g., sequence and structure) with noisy extrinsic contexts (e.g., protein-protein interactions and GO term annotations). However, two key challenges hinder effective fusion: (i) cross-modal distributional mismatch among embeddings produced by pre-trained intrinsic encoders, and (ii) noisy relational graphs of extrinsic data that degrade GNN-based information aggregation. We propose Diffused and Aligned Multi-modal Protein Embedding (DAMPE), a unified framework that addresses these through two core mechanisms. First, we propose Optimal Transport (OT)-based representation alignment that establishes correspondence between intrinsic embedding spaces of different modalities, effectively mitigating cross-modal heterogeneity. Second, we develop a Conditional Graph Generation (CGG)-based information fusion method, where a condition encoder fuses the aligned intrinsic embeddings to provide informative cues for graph reconstruction. Meanwhile, our theoretical analysis implies that the CGG objective drives this condition encoder to absorb graph-aware knowledge into its produced protein representations. Empirically, DAMPE outperforms or matches state-of-the-art methods such as DPFunc on standard GO benchmarks, achieving AUPR gains of 0.002-0.013 pp and Fmax gains 0.004-0.007 pp. Ablation studies further show that OT-based alignment contributes 0.043-0.064 pp AUPR, while CGG-based fusion adds 0.005-0.111 pp Fmax. Overall, DAMPE offers a scalable and theoretically grounded approach for robust multi-modal protein representation learning, substantially enhancing protein function prediction.",Bioinformatics
"Accurate protein function prediction requires integrating heterogeneous intrinsic signals (e.g., sequence and structure) with noisy extrinsic contexts (e.g., protein-protein interactions and GO term annotations). However, two key challenges hinder effective fusion: (i) cross-modal distributional mismatch among embeddings produced by pre-trained intrinsic encoders, and (ii) noisy relational graphs of extrinsic data that degrade GNN-based information aggregation. We propose Diffused and Aligned Multi-modal Protein Embedding (DAMPE), a unified framework that addresses these through two core mechanisms. First, we propose Optimal Transport (OT)-based representation alignment that establishes correspondence between intrinsic embedding spaces of different modalities, effectively mitigating cross-modal heterogeneity. Second, we develop a Conditional Graph Generation (CGG)-based information fusion method, where a condition encoder fuses the aligned intrinsic embeddings to provide informative cues for graph reconstruction. Meanwhile, our theoretical analysis implies that the CGG objective drives this condition encoder to absorb graph-aware knowledge into its produced protein representations. Empirically, DAMPE outperforms or matches state-of-the-art methods such as DPFunc on standard GO benchmarks, achieving AUPR gains of 0.002-0.013 pp and Fmax gains 0.004-0.007 pp. Ablation studies further show that OT-based alignment contributes 0.043-0.064 pp AUPR, while CGG-based fusion adds 0.005-0.111 pp Fmax. Overall, DAMPE offers a scalable and theoretically grounded approach for robust multi-modal protein representation learning, substantially enhancing protein function prediction. [SEP] [HINT] transport -> Materials Science (Syns: transferral, enthral, shipping) | information -> Bioinformatics (Syns: entropy, data, info) | different -> Neuroscience (Syns: unlike, dissimilar)",Bioinformatics
"Imperfect molecular detection in single-cell experiments introduces technical noise that obscures the true stochastic dynamics of gene regulatory networks. While binomial models of molecular capture provide a principled description of imperfect detection, they have so far been analyzed only for simple gene-expression models that do not explicitly account for regulation. Here, we extend binomial models of capture to general gene regulatory networks to understand how imperfect capture reshapes the observed time-dependent statistics of molecular counts. Our results reveal when capture effects correspond to a renormalization of a subset of the kinetic rates and when they cannot be absorbed into effective rates, providing a systematic basis for interpreting noisy single-cell measurements. In particular, we show that rate renormalization emerges either under significant transcription factor abundance or when promoter-state transitions occur on a distinct (much slower or faster) timescale than other reactions. In these cases, technical noise causes the apparent mean burst size of synthesized gene products to appear reduced while transcription factor binding reactions appear faster. These effects hold for gene regulatory networks of arbitrary connectivity and remain valid under time-dependent kinetic rates.",Bioinformatics
"Imperfect molecular detection in single-cell experiments introduces technical noise that obscures the true stochastic dynamics of gene regulatory networks. While binomial models of molecular capture provide a principled description of imperfect detection, they have so far been analyzed only for simple gene-expression models that do not explicitly account for regulation. Here, we extend binomial models of capture to general gene regulatory networks to understand how imperfect capture reshapes the observed time-dependent statistics of molecular counts. Our results reveal when capture effects correspond to a renormalization of a subset of the kinetic rates and when they cannot be absorbed into effective rates, providing a systematic basis for interpreting noisy single-cell measurements. In particular, we show that rate renormalization emerges either under significant transcription factor abundance or when promoter-state transitions occur on a distinct (much slower or faster) timescale than other reactions. In these cases, technical noise causes the apparent mean burst size of synthesized gene products to appear reduced while transcription factor binding reactions appear faster. These effects hold for gene regulatory networks of arbitrary connectivity and remain valid under time-dependent kinetic rates. [SEP] [HINT] connectivity -> Neuroscience (Syns: ) | networks -> Neuroscience (Syns: network, meshwork, electronic network) | molecular -> Bioinformatics (Syns: )",Bioinformatics
"Complex concentrated alloys with intrinsic chemical heterogeneity are promising candidates for nuclear applications, where local chemical order can strongly influence defect evolution under irradiation. Grain boundaries also contribute to radiation damage mitigation by serving as defect sinks, yet this interaction can alter interfacial structure, typically leading to destabilization and grain growth. This study investigates how chemical ordering influences grain boundary migration and stability during successive radiation events in CrCoNi. Using atomistic simulations, bicrystals were equilibrated to induce segregation-enhanced chemical order, followed by prolonged irradiation at 1100 K. Our results show that grain boundaries in random CrCoNi begin to migrate after only a few collision cascades, whereas those in the ordered alloy remain immobile until the chemical order is sufficiently disrupted. Single-cascade simulations reveal key mechanistic differences, where cascades near chemically ordered interfaces produce smaller damage volumes and reduced atomic displacement due to enhanced Frenkel pair combination within the cascade core. This limits both the residual defect population and the energetic driving force for interfacial rearrangement. Subsequent simulations of irradiated interfaces show that interstitial absorption induces a structural transition that modifies the segregation morphology at and near the grain boundary, demonstrating a dynamic coupling between ordering stability and defect evolution. These findings offer new insights into the role of local chemical order on defect-interface interactions under extreme conditions and highlight pathways for designing radiation-tolerant materials for next-generation nuclear systems.",Materials Science
"Complex concentrated alloys with intrinsic chemical heterogeneity are promising candidates for nuclear applications, where local chemical order can strongly influence defect evolution under irradiation. Grain boundaries also contribute to radiation damage mitigation by serving as defect sinks, yet this interaction can alter interfacial structure, typically leading to destabilization and grain growth. This study investigates how chemical ordering influences grain boundary migration and stability during successive radiation events in CrCoNi. Using atomistic simulations, bicrystals were equilibrated to induce segregation-enhanced chemical order, followed by prolonged irradiation at 1100 K. Our results show that grain boundaries in random CrCoNi begin to migrate after only a few collision cascades, whereas those in the ordered alloy remain immobile until the chemical order is sufficiently disrupted. Single-cascade simulations reveal key mechanistic differences, where cascades near chemically ordered interfaces produce smaller damage volumes and reduced atomic displacement due to enhanced Frenkel pair combination within the cascade core. This limits both the residual defect population and the energetic driving force for interfacial rearrangement. Subsequent simulations of irradiated interfaces show that interstitial absorption induces a structural transition that modifies the segregation morphology at and near the grain boundary, demonstrating a dynamic coupling between ordering stability and defect evolution. These findings offer new insights into the role of local chemical order on defect-interface interactions under extreme conditions and highlight pathways for designing radiation-tolerant materials for next-generation nuclear systems. [SEP] [HINT] transition -> Materials Science (Syns: passage, modulation, changeover) | defect -> Materials Science (Syns: mar, shortcoming, fault) | complex -> Bioinformatics (Syns: building complex, coordination compound, composite)",Materials Science
"The epitaxial growth of group 13-nitride semiconductors (GaN, AlN, and AlGaN alloys) for the mass production and fabrication of high-frequency and high-power devices relies on metal-organic chemical vapor deposition (MOCVD) using metal-organic molecules, also called precursors. While this growth method ensures high productivity and low operation costs compared to other methods, its most significant disadvantage lies in the presence of carbon atoms in the precursors, which are unavoidably incorporated into the epitaxial layers and hamper the performance of most types of fabricated devices. Carbon-free precursors for the CVD process could enhance the performance of high-frequency and high-power nitride-based devices while maintaining growth capability in industrial equipment. In this work, we implement gallium- and aluminum-brominated precursors, which contain no carbon atoms, to grow GaN and AlN layers in an industrial CVD system. We compare the results of this alternative CVD process with the conventional method using trimethyl precursors through several characterization techniques, indicating a clear reduction in optically active carbon-related defects.",Materials Science
"The epitaxial growth of group 13-nitride semiconductors (GaN, AlN, and AlGaN alloys) for the mass production and fabrication of high-frequency and high-power devices relies on metal-organic chemical vapor deposition (MOCVD) using metal-organic molecules, also called precursors. While this growth method ensures high productivity and low operation costs compared to other methods, its most significant disadvantage lies in the presence of carbon atoms in the precursors, which are unavoidably incorporated into the epitaxial layers and hamper the performance of most types of fabricated devices. Carbon-free precursors for the CVD process could enhance the performance of high-frequency and high-power nitride-based devices while maintaining growth capability in industrial equipment. In this work, we implement gallium- and aluminum-brominated precursors, which contain no carbon atoms, to grow GaN and AlN layers in an industrial CVD system. We compare the results of this alternative CVD process with the conventional method using trimethyl precursors through several characterization techniques, indicating a clear reduction in optically active carbon-related defects. [SEP] [HINT] low -> Materials Science (Syns: low-spirited, scurvy, depressed) | performance -> Bioinformatics (Syns: functioning, operation, carrying out) | results -> Bioinformatics (Syns: final result, consequence, resultant role)",Materials Science
"Neural recording implants are a crucial tool for both neuroscience research and enabling new clinical applications. The power consumption of high channel count implants is dominated by the circuits used to amplify and digitize neural signals. Since circuit designers have pushed the efficiency of these circuits close to the theoretical physical limits, reducing power further requires system level optimization. Recent advances use a strategy called channel selection, in which less important channels are turned off to save power. We demonstrate resolution reconfiguration, in which the resolution of less important channels is scaled down to save power. Our approach leverages variable importance of each channel inside machine-learning-based decoders and we trial this methodology across three applications: seizure detection, gesture recognition, and force regression. With linear decoders, resolution reconfiguration saves 8.7x, 12.8x, and 23.0x power compared to a traditional recording array for each task respectively. It further saves 1.6x, 3.4x, and 5.2x power compared to channel selection. The results demonstrate the power benefits of resolution reconfigurable front-ends and their wide applicability to neural decoding problems.",Neuroscience
"Neural recording implants are a crucial tool for both neuroscience research and enabling new clinical applications. The power consumption of high channel count implants is dominated by the circuits used to amplify and digitize neural signals. Since circuit designers have pushed the efficiency of these circuits close to the theoretical physical limits, reducing power further requires system level optimization. Recent advances use a strategy called channel selection, in which less important channels are turned off to save power. We demonstrate resolution reconfiguration, in which the resolution of less important channels is scaled down to save power. Our approach leverages variable importance of each channel inside machine-learning-based decoders and we trial this methodology across three applications: seizure detection, gesture recognition, and force regression. With linear decoders, resolution reconfiguration saves 8.7x, 12.8x, and 23.0x power compared to a traditional recording array for each task respectively. It further saves 1.6x, 3.4x, and 5.2x power compared to channel selection. The results demonstrate the power benefits of resolution reconfigurable front-ends and their wide applicability to neural decoding problems. [SEP] [HINT] used -> Bioinformatics (Syns: utilize, ill-used, apply) | task -> Neuroscience (Syns: tax, project, chore) | decoding -> Neuroscience (Syns: decrypt, decipherment, decryption)",Neuroscience
"Long COVID ""brain fog"" is a common and debilitating subjective syndrome often associated with persistent cognitive impairment after COVID-19 infection. Here we identify a specific regional brain dysfunction that mediates this cognitive impairment and provide evidence that targeted neuromodulation improves this deficit. In 120 patients with long COVID brain fog, we found an aberrant perceptual processing pattern. Patients with more severe brain fog committed significantly more false alarms (impulsive responses to non-signals) despite preserved overall accuracy. Both high-density (128-channel) EEG and structural MRI analyses provided converging evidence of a right inferior insula deficit, characterized by a blunted neural monitoring signal and cortical atrophy. We confirmed this deficit in a separate 796-participant UK Biobank longitudinal COVID re-imaging cohort, where COVID-19 survivors also showed selective impairment on a perceptual processing task and corresponding longitudinal atrophy of the right inferior insula compared with healthy controls. Finally, in a proof-of-principle randomized, sham-controlled trial (n = 40), a non-invasive, excitatory theta-burst ultrasound stimulation protocol targeting the right inferior insula rescued the perceptual deficit by reducing false alarms. These findings provide evidence of a causal role for right inferior insula dysfunction in long COVID-related perceptual impairment and show that modulation of this region can rescue the deficit, establishing it as a novel therapeutic target for long COVID cognitive impairment.",Neuroscience
"Long COVID ""brain fog"" is a common and debilitating subjective syndrome often associated with persistent cognitive impairment after COVID-19 infection. Here we identify a specific regional brain dysfunction that mediates this cognitive impairment and provide evidence that targeted neuromodulation improves this deficit. In 120 patients with long COVID brain fog, we found an aberrant perceptual processing pattern. Patients with more severe brain fog committed significantly more false alarms (impulsive responses to non-signals) despite preserved overall accuracy. Both high-density (128-channel) EEG and structural MRI analyses provided converging evidence of a right inferior insula deficit, characterized by a blunted neural monitoring signal and cortical atrophy. We confirmed this deficit in a separate 796-participant UK Biobank longitudinal COVID re-imaging cohort, where COVID-19 survivors also showed selective impairment on a perceptual processing task and corresponding longitudinal atrophy of the right inferior insula compared with healthy controls. Finally, in a proof-of-principle randomized, sham-controlled trial (n = 40), a non-invasive, excitatory theta-burst ultrasound stimulation protocol targeting the right inferior insula rescued the perceptual deficit by reducing false alarms. These findings provide evidence of a causal role for right inferior insula dysfunction in long COVID-related perceptual impairment and show that modulation of this region can rescue the deficit, establishing it as a novel therapeutic target for long COVID cognitive impairment. [SEP] [HINT] task -> Neuroscience (Syns: tax, project, chore) | cortical -> Neuroscience (Syns: ) | processing -> Neuroscience (Syns: work, process, march)",Neuroscience
"Understanding the relationship between brain activity and behavior is a central goal of neuroscience. Despite significant advances, a fundamental dichotomy persists: neural activity manifests as both discrete spikes of individual neurons and collective waves of populations. Both neural codes correlate with behavior, yet correlation alone cannot determine whether waves exert a causal influence or merely reflect spiking dynamics without causal efficacy. According to the Causal Hierarchy Theorem, no amount of observational data--however extensive--can settle this question; causal conclusions require explicit structural assumptions or careful experiment designs that directly correspond to the causal effect of interest. We develop a formal framework that makes this limitation precise and constructive. Formalizing epiphenomenality via the invariance of interventional distributions in Structural Causal Models (SCMs), we derive a certificate of sufficiency from Pearl's do-calculus that specifies when variables can be removed from the model without loss of causal explainability and clarifies how interventions should be interpreted under different causal structures of spike-wave duality. The purpose of this work is not to resolve the spike-wave debate, but to reformulate it. We shift the problem from asking which signal matters most to asking under what conditions any signal can be shown to matter at all. This reframing distinguishes prediction from explanation and offers neuroscience a principled route for deciding when waves belong to mechanism and when they constitute a byproduct of underlying coordination",Neuroscience
"Understanding the relationship between brain activity and behavior is a central goal of neuroscience. Despite significant advances, a fundamental dichotomy persists: neural activity manifests as both discrete spikes of individual neurons and collective waves of populations. Both neural codes correlate with behavior, yet correlation alone cannot determine whether waves exert a causal influence or merely reflect spiking dynamics without causal efficacy. According to the Causal Hierarchy Theorem, no amount of observational data--however extensive--can settle this question; causal conclusions require explicit structural assumptions or careful experiment designs that directly correspond to the causal effect of interest. We develop a formal framework that makes this limitation precise and constructive. Formalizing epiphenomenality via the invariance of interventional distributions in Structural Causal Models (SCMs), we derive a certificate of sufficiency from Pearl's do-calculus that specifies when variables can be removed from the model without loss of causal explainability and clarifies how interventions should be interpreted under different causal structures of spike-wave duality. The purpose of this work is not to resolve the spike-wave debate, but to reformulate it. We shift the problem from asking which signal matters most to asking under what conditions any signal can be shown to matter at all. This reframing distinguishes prediction from explanation and offers neuroscience a principled route for deciding when waves belong to mechanism and when they constitute a byproduct of underlying coordination [SEP] [HINT] understanding -> Neuroscience (Syns: savvy, intellect, sympathy) | work -> Bioinformatics (Syns: work out, process, bring) | different -> Neuroscience (Syns: unlike, dissimilar)",Neuroscience
"Reactive dopant atoms embedded in inert host metal surfaces define the active sites in single-atom alloys (SAAs), yet SAA synthesis remains challenging. To address this, we elucidate how dopant adatoms deposited on Cu and Ag surfaces become incorporated into the metal and identify periodic trends from early to late transition metals (TMs) using density functional theory. Adatoms diffuse nearly freely across terraces, as diffusion barriers are small, whereas direct incorporation into terraces is unfavourable. In line with conventional wisdom, step edges and kink sites strongly facilitate dopant incorporation, confirming their critical role in alloy formation. Attachment of adatoms to steps and kinks from the lower terrace is favoured. Incorporation then proceeds either from this attached state or when adatoms approach a step edge from above, where reactions often proceed without barrier. Incorporation barriers are generally lower for early and central TMs, increase towards late TMs, and are slightly higher on Cu than on Ag surfaces. Repulsive interactions between Pd adatoms and dopants explain the experimental observation that a dopant-rich brim on the upper terrace of Cu surfaces inhibits incorporation from above. In contrast, attractive interactions, as found for Ru, anchor diffusing adatoms (even on terraces) and promote the formation of adatom islands, yet hinder incorporation next to the dopant and may impede the growth of embedded dopant clusters. By rationalising periodic trends and experimental observations, we show how specific surface sites and adatom--dopant interactions shape dopant incorporation, offering guidance on the surface environments most conducive to SAA synthesis for different dopant elements.",Materials Science
"Reactive dopant atoms embedded in inert host metal surfaces define the active sites in single-atom alloys (SAAs), yet SAA synthesis remains challenging. To address this, we elucidate how dopant adatoms deposited on Cu and Ag surfaces become incorporated into the metal and identify periodic trends from early to late transition metals (TMs) using density functional theory. Adatoms diffuse nearly freely across terraces, as diffusion barriers are small, whereas direct incorporation into terraces is unfavourable. In line with conventional wisdom, step edges and kink sites strongly facilitate dopant incorporation, confirming their critical role in alloy formation. Attachment of adatoms to steps and kinks from the lower terrace is favoured. Incorporation then proceeds either from this attached state or when adatoms approach a step edge from above, where reactions often proceed without barrier. Incorporation barriers are generally lower for early and central TMs, increase towards late TMs, and are slightly higher on Cu than on Ag surfaces. Repulsive interactions between Pd adatoms and dopants explain the experimental observation that a dopant-rich brim on the upper terrace of Cu surfaces inhibits incorporation from above. In contrast, attractive interactions, as found for Ru, anchor diffusing adatoms (even on terraces) and promote the formation of adatom islands, yet hinder incorporation next to the dopant and may impede the growth of embedded dopant clusters. By rationalising periodic trends and experimental observations, we show how specific surface sites and adatom--dopant interactions shape dopant incorporation, offering guidance on the surface environments most conducive to SAA synthesis for different dopant elements. [SEP] [HINT] transition -> Materials Science (Syns: passage, modulation, changeover) | functional -> Neuroscience (Syns: working, usable, running) | different -> Neuroscience (Syns: unlike, dissimilar)",Materials Science
"A prominent hypothesis in neuroscience proposes that brains achieve optimal performance by operating near a critical point. However, this framework, which often assumes a universal critical point, fails to account for the extensive individual variability observed in neural dynamics and cognitive functions. These variabilities are not noise but rather an inherent manifestation of a fundamental systems-biology principle: the necessary trade-off between robustness and flexibility in human populations. Here, we propose that the Griffiths phase (GP), an extended critical regime synergically induced by two kinds of heterogeneities in brain network region and connectivity, offers a unified framework for brain criticality that better reconciles robustness and flexibility and accounts for individual variability. Using Human Connectome Project data and whole-brain modeling, we demonstrated that the synergic interplay between structural network modularity and regional heterogeneity in local excitability yields biologically viable GP featured with widely extended global excitability ranges, with an embedded optimal point that balances global/local information transmission. Crucially, an individua's position within the GP gives rise to unique global network dynamics, which in turn confer a distinctive cognitive profile via flexible configuration of functional connectivity for segregation, integration, and balance between them. These results establish GP as an evolved adaptive mechanism resolving the robustness-flexibility trade-off, fulfilling diverse cognitive demands through individualized criticality landscapes, providing a new framework of brain criticality.",Neuroscience
"A prominent hypothesis in neuroscience proposes that brains achieve optimal performance by operating near a critical point. However, this framework, which often assumes a universal critical point, fails to account for the extensive individual variability observed in neural dynamics and cognitive functions. These variabilities are not noise but rather an inherent manifestation of a fundamental systems-biology principle: the necessary trade-off between robustness and flexibility in human populations. Here, we propose that the Griffiths phase (GP), an extended critical regime synergically induced by two kinds of heterogeneities in brain network region and connectivity, offers a unified framework for brain criticality that better reconciles robustness and flexibility and accounts for individual variability. Using Human Connectome Project data and whole-brain modeling, we demonstrated that the synergic interplay between structural network modularity and regional heterogeneity in local excitability yields biologically viable GP featured with widely extended global excitability ranges, with an embedded optimal point that balances global/local information transmission. Crucially, an individua's position within the GP gives rise to unique global network dynamics, which in turn confer a distinctive cognitive profile via flexible configuration of functional connectivity for segregation, integration, and balance between them. These results establish GP as an evolved adaptive mechanism resolving the robustness-flexibility trade-off, fulfilling diverse cognitive demands through individualized criticality landscapes, providing a new framework of brain criticality. [SEP] [HINT] connectivity -> Neuroscience (Syns: ) | functional -> Neuroscience (Syns: working, usable, running) | information -> Bioinformatics (Syns: entropy, data, info)",Neuroscience
"Motivation: Drug synergy is strongly influenced by cellular context. Variations in protein interaction landscapes and pathway activities across cell types can reshape how drugs act in combination. However, most existing models overlook this heterogeneity and rely on static or bulk level protein protein interaction networks that ignore cell specific molecular wiring. With the availability of single cell transcriptomic data, it is now possible to reconstruct cell line specific interactomes, offering a new foundation for contextualized drug synergy modeling.   Results: We present SynCell, a contextualized drug synergy framework that integrates drug protein, protein protein, and protein cell line relations within a unified graph architecture. SynCell leverages single cell derived, cell line specific PPI networks to embed the molecular context in which drugs act, and employs graph convolutional learning to model how pharmacological effects propagate through cell specific signaling networks. This formulation treats synergy prediction as a cell line contextualized drug drug interaction problem. Across two large scale benchmarks (NCI ALMANAC and ONeil), SynCell consistently outperforms state of the art baselines including DeepDDS, HypergraphSynergy, and HERMES, especially in predicting synergies involving unseen drugs or novel cell lines. Ablation analyses show that contextualizing PPIs with single cell resolution yields substantial gains in generalization and biological interpretability.",Bioinformatics
"Motivation: Drug synergy is strongly influenced by cellular context. Variations in protein interaction landscapes and pathway activities across cell types can reshape how drugs act in combination. However, most existing models overlook this heterogeneity and rely on static or bulk level protein protein interaction networks that ignore cell specific molecular wiring. With the availability of single cell transcriptomic data, it is now possible to reconstruct cell line specific interactomes, offering a new foundation for contextualized drug synergy modeling.   Results: We present SynCell, a contextualized drug synergy framework that integrates drug protein, protein protein, and protein cell line relations within a unified graph architecture. SynCell leverages single cell derived, cell line specific PPI networks to embed the molecular context in which drugs act, and employs graph convolutional learning to model how pharmacological effects propagate through cell specific signaling networks. This formulation treats synergy prediction as a cell line contextualized drug drug interaction problem. Across two large scale benchmarks (NCI ALMANAC and ONeil), SynCell consistently outperforms state of the art baselines including DeepDDS, HypergraphSynergy, and HERMES, especially in predicting synergies involving unseen drugs or novel cell lines. Ablation analyses show that contextualizing PPIs with single cell resolution yields substantial gains in generalization and biological interpretability. [SEP] [HINT] learning -> Bioinformatics (Syns: take, teach, acquire) | networks -> Neuroscience (Syns: network, meshwork, electronic network) | molecular -> Bioinformatics (Syns: )",Bioinformatics
"Accurate cell nuclei segmentation is critical for downstream tasks in kidney pathology and remains a major challenge due to the morphological diversity and imaging variability of renal tissues. While our prior work has evaluated early-generation AI cell foundation models in this domain, the effectiveness of recent cell foundation models remains unclear. In this study, we benchmark advanced AI cell foundation models (2025), including CellViT++ variants and Cellpose-SAM, against three widely used cell foundation models developed prior to 2024, using a diverse large-scale set of kidney image patches within a human-in-the-loop rating framework. We further performed fusion-based ensemble evaluation and model agreement analysis to assess the segmentation capabilities of the different models. Our results show that CellViT++ [Virchow] yields the highest standalone performance with 40.3% of predictions rated as ""Good"" on a curated set of 2,091 challenging samples, outperforming all prior models. In addition, our fused model achieves 62.2% ""Good"" predictions and only 0.4% ""Bad"", substantially reducing segmentation errors. Notably, the fusion model (2025) successfully resolved the majority of challenging cases that remained unaddressed in our previous study. These findings demonstrate the potential of AI cell foundation model development in renal pathology and provide a curated dataset of challenging samples to support future kidney-specific model refinement.",Bioinformatics
"Accurate cell nuclei segmentation is critical for downstream tasks in kidney pathology and remains a major challenge due to the morphological diversity and imaging variability of renal tissues. While our prior work has evaluated early-generation AI cell foundation models in this domain, the effectiveness of recent cell foundation models remains unclear. In this study, we benchmark advanced AI cell foundation models (2025), including CellViT++ variants and Cellpose-SAM, against three widely used cell foundation models developed prior to 2024, using a diverse large-scale set of kidney image patches within a human-in-the-loop rating framework. We further performed fusion-based ensemble evaluation and model agreement analysis to assess the segmentation capabilities of the different models. Our results show that CellViT++ [Virchow] yields the highest standalone performance with 40.3% of predictions rated as ""Good"" on a curated set of 2,091 challenging samples, outperforming all prior models. In addition, our fused model achieves 62.2% ""Good"" predictions and only 0.4% ""Bad"", substantially reducing segmentation errors. Notably, the fusion model (2025) successfully resolved the majority of challenging cases that remained unaddressed in our previous study. These findings demonstrate the potential of AI cell foundation model development in renal pathology and provide a curated dataset of challenging samples to support future kidney-specific model refinement. [SEP] [HINT] used -> Bioinformatics (Syns: utilize, ill-used, apply) | tasks -> Neuroscience (Syns: tax, task, project) | work -> Bioinformatics (Syns: work out, process, bring)",Bioinformatics
"Single-crystal X-ray diffraction (SC-XRD) is the gold standard technique to characterize crystal structures in solid state. Despite significant advances in automation for structure solution, the refinement stage still depends heavily on expert intervention and subjective judgment, limiting accessibility and scalability. Herein, we introduce RefrActor, an end-to-end deep learning framework that enables crystal structure determination directly from HKL data. By coupling a physics-informed reciprocal-space encoder (ReciEncoder) with a symmetry-aware diffusion-based generator (StruDiffuser), RefrActor produces fully refined atomic models without requiring initial structural guesses or manual input. Comprehensive evaluations on the GenRef-10k benchmark demonstrates that RefrActor achieves low R1-factors across diverse systems, including low-symmetry, light-atom, and heavy-atom crystals. Case studies further confirm that RefrActor can correctly resolve hydrogen positions, elemental assignments, and moderate disorder. This work establishes a new data-driven paradigm for autonomous crystallographic analysis, offering a foundation for fully automated, high-throughput crystal structure determination.",Materials Science
"Single-crystal X-ray diffraction (SC-XRD) is the gold standard technique to characterize crystal structures in solid state. Despite significant advances in automation for structure solution, the refinement stage still depends heavily on expert intervention and subjective judgment, limiting accessibility and scalability. Herein, we introduce RefrActor, an end-to-end deep learning framework that enables crystal structure determination directly from HKL data. By coupling a physics-informed reciprocal-space encoder (ReciEncoder) with a symmetry-aware diffusion-based generator (StruDiffuser), RefrActor produces fully refined atomic models without requiring initial structural guesses or manual input. Comprehensive evaluations on the GenRef-10k benchmark demonstrates that RefrActor achieves low R1-factors across diverse systems, including low-symmetry, light-atom, and heavy-atom crystals. Case studies further confirm that RefrActor can correctly resolve hydrogen positions, elemental assignments, and moderate disorder. This work establishes a new data-driven paradigm for autonomous crystallographic analysis, offering a foundation for fully automated, high-throughput crystal structure determination. [SEP] [HINT] low -> Materials Science (Syns: low-spirited, scurvy, depressed) | learning -> Bioinformatics (Syns: take, teach, acquire) | structure -> Bioinformatics (Syns: social system, complex body part, social structure)",Materials Science
"Although quantum systems are generally described by quantum state vectors, we show that in certain cases their measurement processes can be reformulated as probabilistic equations expressed in terms of probabilistic state vectors. These probabilistic representations can, in turn, be approximated by the neural network dynamics of the Tensor Brain (TB) model.   The Tensor Brain is a recently proposed framework for modeling perception and memory in the brain, providing a biologically inspired mechanism for efficiently integrating generated symbolic representations into reasoning processes.",Neuroscience
"Although quantum systems are generally described by quantum state vectors, we show that in certain cases their measurement processes can be reformulated as probabilistic equations expressed in terms of probabilistic state vectors. These probabilistic representations can, in turn, be approximated by the neural network dynamics of the Tensor Brain (TB) model.   The Tensor Brain is a recently proposed framework for modeling perception and memory in the brain, providing a biologically inspired mechanism for efficiently integrating generated symbolic representations into reasoning processes. [SEP] [HINT] network -> Bioinformatics (Syns: meshwork, electronic network, mesh) | dynamics -> Bioinformatics (Syns: kinetics, dynamic, moral force) | systems -> Bioinformatics (Syns: organization, organisation, system)",Neuroscience
"Detecting anomalies in irregularly sampled multi-variate time-series is challenging, especially in data-scarce settings. Here we introduce an anomaly detection framework for irregularly sampled time-series that leverages neural jump ordinary differential equations (NJODEs). The method infers conditional mean and variance trajectories in a fully path dependent way and computes anomaly scores. On synthetic data containing jump, drift, diffusion, and noise anomalies, the framework accurately identifies diverse deviations. Applied to infant gut microbiome trajectories, it delineates the magnitude and persistence of antibiotic-induced disruptions: revealing prolonged anomalies after second antibiotic courses, extended duration treatments, and exposures during the second year of life. We further demonstrate the predictive capabilities of the inferred anomaly scores in accurately predicting antibiotic events and outperforming diversity-based baselines. Our approach accommodates unevenly spaced longitudinal observations, adjusts for static and dynamic covariates, and provides a foundation for inferring microbial anomalies induced by perturbations, offering a translational opportunity to optimize intervention regimens by minimizing microbial disruptions.",Bioinformatics
"Detecting anomalies in irregularly sampled multi-variate time-series is challenging, especially in data-scarce settings. Here we introduce an anomaly detection framework for irregularly sampled time-series that leverages neural jump ordinary differential equations (NJODEs). The method infers conditional mean and variance trajectories in a fully path dependent way and computes anomaly scores. On synthetic data containing jump, drift, diffusion, and noise anomalies, the framework accurately identifies diverse deviations. Applied to infant gut microbiome trajectories, it delineates the magnitude and persistence of antibiotic-induced disruptions: revealing prolonged anomalies after second antibiotic courses, extended duration treatments, and exposures during the second year of life. We further demonstrate the predictive capabilities of the inferred anomaly scores in accurately predicting antibiotic events and outperforming diversity-based baselines. Our approach accommodates unevenly spaced longitudinal observations, adjusts for static and dynamic covariates, and provides a foundation for inferring microbial anomalies induced by perturbations, offering a translational opportunity to optimize intervention regimens by minimizing microbial disruptions. [SEP] [HINT] framework -> Bioinformatics (Syns: theoretical account, model, fabric) | method -> Bioinformatics (Syns: method acting) | demonstrate -> Bioinformatics (Syns: evidence, march, prove)",Bioinformatics
"Antiperovskite nitrides with the general formula M$_3$N have attracted significant attention due to their tunable electronic and magnetic properties. Among them are many cobalt-based compounds predicted to exhibit high thermodynamic stability and intriguing magnetic behavior. Here, we report the synthesis and magnetic characterization of epitaxial Co$_3$ZnN thin films grown by radio frequency sputtering on SrTiO$_3$ (STO) and MgO substrates. X-ray diffraction confirms phase-pure (00l)-oriented films with cube-on-cube epitaxy on STO, with a c-lattice parameter of 3.752 angstroms. Magnetic measurements reveal clear hysteresis at 2 K with a coercive field of ~ 0.12 T and a small net moment of 0.11 $μ_B$/f.u., suggesting either a canted antiferromagnetic (AFM) or ferrimagnetic (FiM) configuration. Temperature-dependent magnetization measurements show a transition near 25 K, with strong AFM interactions (Curie-Weiss $Θ$ = -80.6 K) at high temperatures and short-range ferromagnetic correlations ($Θ$ = +9.7 K) emerging near the transition. Complementary density functional theory (DFT) and Monte Carlo simulations indicate a ferromagnetic (FM) ground state, with the FM-AFM energy difference decreasing systematically with increasing supercell size, consistent with competition between FM and AFM/FiM interactions. These results highlight Co$_3$ZnN as a magnetically complex antiperovskite nitride with competing exchange interactions.",Materials Science
"Antiperovskite nitrides with the general formula M$_3$N have attracted significant attention due to their tunable electronic and magnetic properties. Among them are many cobalt-based compounds predicted to exhibit high thermodynamic stability and intriguing magnetic behavior. Here, we report the synthesis and magnetic characterization of epitaxial Co$_3$ZnN thin films grown by radio frequency sputtering on SrTiO$_3$ (STO) and MgO substrates. X-ray diffraction confirms phase-pure (00l)-oriented films with cube-on-cube epitaxy on STO, with a c-lattice parameter of 3.752 angstroms. Magnetic measurements reveal clear hysteresis at 2 K with a coercive field of ~ 0.12 T and a small net moment of 0.11 $μ_B$/f.u., suggesting either a canted antiferromagnetic (AFM) or ferrimagnetic (FiM) configuration. Temperature-dependent magnetization measurements show a transition near 25 K, with strong AFM interactions (Curie-Weiss $Θ$ = -80.6 K) at high temperatures and short-range ferromagnetic correlations ($Θ$ = +9.7 K) emerging near the transition. Complementary density functional theory (DFT) and Monte Carlo simulations indicate a ferromagnetic (FM) ground state, with the FM-AFM energy difference decreasing systematically with increasing supercell size, consistent with competition between FM and AFM/FiM interactions. These results highlight Co$_3$ZnN as a magnetically complex antiperovskite nitride with competing exchange interactions. [SEP] [HINT] field -> Materials Science (Syns: field of honor, line of business, orbit) | transition -> Materials Science (Syns: passage, modulation, changeover) | electronic -> Materials Science (Syns: )",Materials Science
"Cardiovascular disease (CVD) risk stratification remains a major challenge due to its multifactorial nature and limited availability of high-quality labeled datasets. While genomic and electrophysiological data such as SNP variants and ECG phenotypes are increasingly accessible, effectively integrating these modalities in low-label settings is non-trivial. This challenge arises from the scarcity of well-annotated multimodal datasets and the high dimensionality of biological signals, which limit the effectiveness of conventional supervised models. To address this, we present a few-label multimodal framework that leverages large language models (LLMs) to combine genetic and electrophysiological information for cardiovascular risk stratification. Our approach incorporates a pseudo-label refinement strategy to adaptively distill high-confidence labels from weakly supervised predictions, enabling robust model fine-tuning with only a small set of ground-truth annotations. To enhance the interpretability, we frame the task as a Chain of Thought (CoT) reasoning problem, prompting the model to produce clinically relevant rationales alongside predictions. Experimental results demonstrate that the integration of multimodal inputs, few-label supervision, and CoT reasoning improves robustness and generalizability across diverse patient profiles. Experimental results using multimodal SNP variants and ECG-derived features demonstrated comparable performance to models trained on the full dataset, underscoring the promise of LLM-based few-label multimodal modeling for advancing personalized cardiovascular care.",Bioinformatics
"Cardiovascular disease (CVD) risk stratification remains a major challenge due to its multifactorial nature and limited availability of high-quality labeled datasets. While genomic and electrophysiological data such as SNP variants and ECG phenotypes are increasingly accessible, effectively integrating these modalities in low-label settings is non-trivial. This challenge arises from the scarcity of well-annotated multimodal datasets and the high dimensionality of biological signals, which limit the effectiveness of conventional supervised models. To address this, we present a few-label multimodal framework that leverages large language models (LLMs) to combine genetic and electrophysiological information for cardiovascular risk stratification. Our approach incorporates a pseudo-label refinement strategy to adaptively distill high-confidence labels from weakly supervised predictions, enabling robust model fine-tuning with only a small set of ground-truth annotations. To enhance the interpretability, we frame the task as a Chain of Thought (CoT) reasoning problem, prompting the model to produce clinically relevant rationales alongside predictions. Experimental results demonstrate that the integration of multimodal inputs, few-label supervision, and CoT reasoning improves robustness and generalizability across diverse patient profiles. Experimental results using multimodal SNP variants and ECG-derived features demonstrated comparable performance to models trained on the full dataset, underscoring the promise of LLM-based few-label multimodal modeling for advancing personalized cardiovascular care. [SEP] [HINT] task -> Neuroscience (Syns: tax, project, chore) | language -> Neuroscience (Syns: linguistic process, linguistic communication, spoken communication) | features -> Bioinformatics (Syns: characteristic, lineament, feature of speech)",Bioinformatics
"Background: Wearable spectrometers enable field quantification of biologically relevant light, yet reproducible pipelines for contextual classification remain under-specified.   Objective: To establish and validate a subject-wise evaluated, reproducible pipeline and actionable design rules for classifying natural vs. artificial light from wearable spectral data.   Methods: We analysed ActLumus recordings from 26 participants, each monitored for at least 7 days at 10-second sampling, paired with daily exposure diaries. The pipeline fixes the sequence: domain selection, log-base-10 transform, L2 normalisation excluding total intensity (to avoid brightness shortcuts), hour-level medoid aggregation, sine/cosine hour encoding, and MLP classifier, evaluated under participant-wise cross-validation.   Results: The proposed sequence consistently achieved high performance on the primary task, with representative configurations reaching AUC = 0.938 (accuracy 88%) for natural vs. artificial classification on the held-out subject split. In contrast, indoor vs. outdoor classification remained at feasibility level due to spectral overlap and class imbalance (best AUC approximately 0.75; majority-class collapse without contextual sensors). Threshold baselines were insufficient on our data, supporting the need for spectral-temporal modelling beyond illuminance cut-offs.   Conclusions: We provide a reproducible, auditable baseline pipeline and design rules for contextual light classification under subject-wise generalisation. All code, configuration files, and derived artefacts will be openly archived (GitHub + Zenodo DOI) to support reuse and benchmarking.",Bioinformatics
"Background: Wearable spectrometers enable field quantification of biologically relevant light, yet reproducible pipelines for contextual classification remain under-specified.   Objective: To establish and validate a subject-wise evaluated, reproducible pipeline and actionable design rules for classifying natural vs. artificial light from wearable spectral data.   Methods: We analysed ActLumus recordings from 26 participants, each monitored for at least 7 days at 10-second sampling, paired with daily exposure diaries. The pipeline fixes the sequence: domain selection, log-base-10 transform, L2 normalisation excluding total intensity (to avoid brightness shortcuts), hour-level medoid aggregation, sine/cosine hour encoding, and MLP classifier, evaluated under participant-wise cross-validation.   Results: The proposed sequence consistently achieved high performance on the primary task, with representative configurations reaching AUC = 0.938 (accuracy 88%) for natural vs. artificial classification on the held-out subject split. In contrast, indoor vs. outdoor classification remained at feasibility level due to spectral overlap and class imbalance (best AUC approximately 0.75; majority-class collapse without contextual sensors). Threshold baselines were insufficient on our data, supporting the need for spectral-temporal modelling beyond illuminance cut-offs.   Conclusions: We provide a reproducible, auditable baseline pipeline and design rules for contextual light classification under subject-wise generalisation. All code, configuration files, and derived artefacts will be openly archived (GitHub + Zenodo DOI) to support reuse and benchmarking. [SEP] [HINT] field -> Materials Science (Syns: field of honor, line of business, orbit) | performance -> Bioinformatics (Syns: functioning, operation, carrying out) | level -> Bioinformatics (Syns: level off, raze, layer)",Bioinformatics
"Arterial aneurysm (Fig.1) is a bulb-shape local expansion of human arteries, the rupture of which is a leading cause of morbidity and mortality in US. Therefore, the prediction of arterial aneurysm rupture is of great significance for aneurysm management and treatment selection. The prediction of aneurysm rupture depends on the analysis of the time series of aneurysm growth history. However, due to the long time scale of aneurysm growth, the time series of aneurysm growth is not always accessible. We here proposed a method to reconstruct the aneurysm growth time series directly from patient parameters. The prediction is based on data pairs of [patient parameters, patient aneurysm growth time history]. To obtain the mapping from patient parameters to patient aneurysm growth time history, we first apply autoencoder to obtain a compact representation of the time series for each patient. Then a mapping is learned from patient parameters to the corresponding compact representation of time series via a five-layer neural network. Moving average and convolutional output layer are implemented to explicitly taking account the time dependency of the time series.   Apart from that, we also propose to use prior knowledge about the mechanism of aneurysm growth to improve the time series reconstruction results. The prior physics-based knowledge is incorporated as constraints for the optimization problem associated with autoencoder. The model can handle both algebraic and differential constraints. Our results show that including physical model information about the data will not significantly improve the time series reconstruction results if the training data is error-free. However, in the case of training data with noise and bias error, incorporating physical model constraints can significantly improve the predicted time series.",Bioinformatics
"Arterial aneurysm (Fig.1) is a bulb-shape local expansion of human arteries, the rupture of which is a leading cause of morbidity and mortality in US. Therefore, the prediction of arterial aneurysm rupture is of great significance for aneurysm management and treatment selection. The prediction of aneurysm rupture depends on the analysis of the time series of aneurysm growth history. However, due to the long time scale of aneurysm growth, the time series of aneurysm growth is not always accessible. We here proposed a method to reconstruct the aneurysm growth time series directly from patient parameters. The prediction is based on data pairs of [patient parameters, patient aneurysm growth time history]. To obtain the mapping from patient parameters to patient aneurysm growth time history, we first apply autoencoder to obtain a compact representation of the time series for each patient. Then a mapping is learned from patient parameters to the corresponding compact representation of time series via a five-layer neural network. Moving average and convolutional output layer are implemented to explicitly taking account the time dependency of the time series.   Apart from that, we also propose to use prior knowledge about the mechanism of aneurysm growth to improve the time series reconstruction results. The prior physics-based knowledge is incorporated as constraints for the optimization problem associated with autoencoder. The model can handle both algebraic and differential constraints. Our results show that including physical model information about the data will not significantly improve the time series reconstruction results if the training data is error-free. However, in the case of training data with noise and bias error, incorporating physical model constraints can significantly improve the predicted time series. [SEP] [HINT] based -> Bioinformatics (Syns: ground, free-base, base) | information -> Bioinformatics (Syns: entropy, data, info) | results -> Bioinformatics (Syns: final result, consequence, resultant role)",Bioinformatics
"Functional variability in both gray matter (GM) and white matter (WM) is closely associated with human brain cognitive and developmental processes, and is commonly assessed using functional connectivity (FC). However, as a correlation-based approach, FC captures the co-fluctuation between brain regions rather than the intensity of neural activity in each region. Consequently, FC provides only a partial view of functional variability, and this limitation is particularly pronounced in WM, where functional signals are weaker and more susceptible to noise. To tackle this limitation, we introduce fractional amplitude of low-frequency fluctuation (fALFF) to measure the intensity of spontaneous neural activity and analyze functional variability in WM. Specifically, we propose a novel method to quantify WM functional variability by estimating the differential identifiability of fALFF. Higher differential identifiability is observed in WM fALFF compared to FC, which indicates that fALFF is more sensitive to WM functional variability. Through fALFF differential identifiability, we evaluate the functional variabilities of both WM and GM, and find the overall functional variability pattern is similar although WM shows slightly lower variability than GM. The regional functional variabilities of WM are associated with structural connectivity, where commissural fiber regions generally exhibit higher variability than projection fiber regions. Furthermore, we discover that WM functional variability demonstrates a spatial gradient ascending from the brainstem to the cortex by hypothesis testing, which aligns well with the evolutionary expansion. The gradient of functional variability in WM provides novel insights for understanding WM function. To the best of our knowledge, this is the first attempt to investigate WM functional variability via fALFF.",Neuroscience
"Functional variability in both gray matter (GM) and white matter (WM) is closely associated with human brain cognitive and developmental processes, and is commonly assessed using functional connectivity (FC). However, as a correlation-based approach, FC captures the co-fluctuation between brain regions rather than the intensity of neural activity in each region. Consequently, FC provides only a partial view of functional variability, and this limitation is particularly pronounced in WM, where functional signals are weaker and more susceptible to noise. To tackle this limitation, we introduce fractional amplitude of low-frequency fluctuation (fALFF) to measure the intensity of spontaneous neural activity and analyze functional variability in WM. Specifically, we propose a novel method to quantify WM functional variability by estimating the differential identifiability of fALFF. Higher differential identifiability is observed in WM fALFF compared to FC, which indicates that fALFF is more sensitive to WM functional variability. Through fALFF differential identifiability, we evaluate the functional variabilities of both WM and GM, and find the overall functional variability pattern is similar although WM shows slightly lower variability than GM. The regional functional variabilities of WM are associated with structural connectivity, where commissural fiber regions generally exhibit higher variability than projection fiber regions. Furthermore, we discover that WM functional variability demonstrates a spatial gradient ascending from the brainstem to the cortex by hypothesis testing, which aligns well with the evolutionary expansion. The gradient of functional variability in WM provides novel insights for understanding WM function. To the best of our knowledge, this is the first attempt to investigate WM functional variability via fALFF. [SEP] [HINT] connectivity -> Neuroscience (Syns: ) | understanding -> Neuroscience (Syns: savvy, intellect, sympathy) | functional -> Neuroscience (Syns: working, usable, running)",Neuroscience
"We analyze continuous Hopfield associative memories augmented by additional, rapid short-term associative synaptic plasticity. Through the cavity method, we determine the boundary between the retrieval and forgetting, or spin-glass phase, of the network as a function of the fraction of stored memories and the neuronal gain. We find that short-term synaptic plasticity yields marginal improvements in critical memory capacity. However, through dynamical mean field theory, backed by extensive numerical simulations, we find that short-term synaptic plasticity has a dramatic impact on memory retrieval above the critical capacity. When short-term synaptic plasticity is turned on, the combined neuronal and synaptic dynamics descends a high-dimensional energy landscape over both neurons and synapses. The energy landscape over neurons alone is thus dynamic, and is lowered in the vicinity of recent neuronal patterns visited by the network, just like the surface of a trampoline is lowered in the vicinity of regions recently visited by a heavy ball. This trampoline-like reactivity of the neuronal energy landscape to short-term plasticity in synapses can lead to the recall of stored memories that would otherwise have been forgotten. This occurs because the dynamics without short-term plasticity transiently moves towards a stored memory before departing away from it. Thus short-term plasticity, operating during the transient, lowers the energy in the vicinity of the stored memory, eventually trapping the combined neuronal and synaptic dynamics at a fixed point close to the stored memory. In this manner, short-term plasticity enables the recall of memories that would otherwise be forgotten, by trapping transients that would otherwise escape. We furthermore find an optimal time constant for short-term synaptic plasticity, matched to the transient dynamics, to empower recall of forgotten memories.",Neuroscience
"We analyze continuous Hopfield associative memories augmented by additional, rapid short-term associative synaptic plasticity. Through the cavity method, we determine the boundary between the retrieval and forgetting, or spin-glass phase, of the network as a function of the fraction of stored memories and the neuronal gain. We find that short-term synaptic plasticity yields marginal improvements in critical memory capacity. However, through dynamical mean field theory, backed by extensive numerical simulations, we find that short-term synaptic plasticity has a dramatic impact on memory retrieval above the critical capacity. When short-term synaptic plasticity is turned on, the combined neuronal and synaptic dynamics descends a high-dimensional energy landscape over both neurons and synapses. The energy landscape over neurons alone is thus dynamic, and is lowered in the vicinity of recent neuronal patterns visited by the network, just like the surface of a trampoline is lowered in the vicinity of regions recently visited by a heavy ball. This trampoline-like reactivity of the neuronal energy landscape to short-term plasticity in synapses can lead to the recall of stored memories that would otherwise have been forgotten. This occurs because the dynamics without short-term plasticity transiently moves towards a stored memory before departing away from it. Thus short-term plasticity, operating during the transient, lowers the energy in the vicinity of the stored memory, eventually trapping the combined neuronal and synaptic dynamics at a fixed point close to the stored memory. In this manner, short-term plasticity enables the recall of memories that would otherwise be forgotten, by trapping transients that would otherwise escape. We furthermore find an optimal time constant for short-term synaptic plasticity, matched to the transient dynamics, to empower recall of forgotten memories. [SEP] [HINT] field -> Materials Science (Syns: field of honor, line of business, orbit) | dynamics -> Bioinformatics (Syns: kinetics, dynamic, moral force) | memory -> Neuroscience (Syns: remembering, memory board, storage)",Neuroscience
"The lack of standardization in seizure forecasting slows progress in the field and limits the clinical translation of forecasting models. In this work, we introduce a Python-based framework aimed at streamlining the development, assessment, and documentation of individualized seizure forecasting algorithms.   The framework automates data labeling, cross-validation splitting, forecast post-processing, performance evaluation, and reporting. It supports various forecasting horizons and includes a model card that documents implementation details, training and evaluation settings, and performance metrics. Three different models were implemented as a proof-of-concept. The models leveraged features extracted from time series data and seizure periodicity. Model performance was assessed using time series cross-validation and key deterministic and probabilistic metrics.   Implementation of the three models was successful, demonstrating the flexibility of the framework. The results also emphasize the importance of careful model interpretation due to variations in probability scaling, calibration, and subject-specific differences. Although formal usability metrics were not recorded, empirical observations suggest reduced development time and methodological consistency, minimizing unintentional variations that could affect the comparability of different approaches.   As a proof-of-concept, this validation is inherently limited, relying on a single-user experiment without statistical analyses or replication across independent datasets. At this stage, our objective is to make the framework publicly available to foster community engagement, facilitate experimentation, and gather feedback. In the long term, we aim to contribute to the establishment of a consensus on a standardized methodology for the development and validation of seizure forecasting algorithms in people with epilepsy.",Bioinformatics
"The lack of standardization in seizure forecasting slows progress in the field and limits the clinical translation of forecasting models. In this work, we introduce a Python-based framework aimed at streamlining the development, assessment, and documentation of individualized seizure forecasting algorithms.   The framework automates data labeling, cross-validation splitting, forecast post-processing, performance evaluation, and reporting. It supports various forecasting horizons and includes a model card that documents implementation details, training and evaluation settings, and performance metrics. Three different models were implemented as a proof-of-concept. The models leveraged features extracted from time series data and seizure periodicity. Model performance was assessed using time series cross-validation and key deterministic and probabilistic metrics.   Implementation of the three models was successful, demonstrating the flexibility of the framework. The results also emphasize the importance of careful model interpretation due to variations in probability scaling, calibration, and subject-specific differences. Although formal usability metrics were not recorded, empirical observations suggest reduced development time and methodological consistency, minimizing unintentional variations that could affect the comparability of different approaches.   As a proof-of-concept, this validation is inherently limited, relying on a single-user experiment without statistical analyses or replication across independent datasets. At this stage, our objective is to make the framework publicly available to foster community engagement, facilitate experimentation, and gather feedback. In the long term, we aim to contribute to the establishment of a consensus on a standardized methodology for the development and validation of seizure forecasting algorithms in people with epilepsy. [SEP] [HINT] field -> Materials Science (Syns: field of honor, line of business, orbit) | clinical -> Bioinformatics (Syns: ) | features -> Bioinformatics (Syns: characteristic, lineament, feature of speech)",Bioinformatics
"Accurate and efficient registration of whole slide images (WSIs) is essential for high-resolution, nuclei-level analysis in multi-stained tissue slides. We propose a novel coarse-to-fine framework CORE for accurate nuclei-level registration across diverse multimodal whole-slide image (WSI) datasets. The coarse registration stage leverages prompt-based tissue mask extraction to effectively filter out artefacts and non-tissue regions, followed by global alignment using tissue morphology and ac- celerated dense feature matching with a pre-trained feature extractor. From the coarsely aligned slides, nuclei centroids are detected and subjected to fine-grained rigid registration using a custom, shape-aware point-set registration model. Finally, non-rigid alignment at the cellular level is achieved by estimating a non-linear dis- placement field using Coherent Point Drift (CPD). Our approach benefits from automatically generated nuclei that enhance the accuracy of deformable registra- tion and ensure precise nuclei-level correspondence across modalities. The pro- posed model is evaluated on three publicly available WSI registration datasets, and two private datasets. We show that CORE outperforms current state-of-the-art methods in terms of generalisability, precision, and robustness in bright-field and immunofluorescence microscopy WSIs",Bioinformatics
"Accurate and efficient registration of whole slide images (WSIs) is essential for high-resolution, nuclei-level analysis in multi-stained tissue slides. We propose a novel coarse-to-fine framework CORE for accurate nuclei-level registration across diverse multimodal whole-slide image (WSI) datasets. The coarse registration stage leverages prompt-based tissue mask extraction to effectively filter out artefacts and non-tissue regions, followed by global alignment using tissue morphology and ac- celerated dense feature matching with a pre-trained feature extractor. From the coarsely aligned slides, nuclei centroids are detected and subjected to fine-grained rigid registration using a custom, shape-aware point-set registration model. Finally, non-rigid alignment at the cellular level is achieved by estimating a non-linear dis- placement field using Coherent Point Drift (CPD). Our approach benefits from automatically generated nuclei that enhance the accuracy of deformable registra- tion and ensure precise nuclei-level correspondence across modalities. The pro- posed model is evaluated on three publicly available WSI registration datasets, and two private datasets. We show that CORE outperforms current state-of-the-art methods in terms of generalisability, precision, and robustness in bright-field and immunofluorescence microscopy WSIs [SEP] [HINT] field -> Materials Science (Syns: field of honor, line of business, orbit) | tissue -> Bioinformatics (Syns: tissue paper, weave) | framework -> Bioinformatics (Syns: theoretical account, model, fabric)",Bioinformatics
"Thermal plasma has emerged as an effective approach for producing carbon nanostructures without the need for specific catalysts nor substrates. While efforts have focused on the effect of process parameters such as reaction pressure, input power or carbon source, the intricate role and relationship with plasma characteristics like density and temperature are often overlooked due to the complexity of the environment. This study addresses this gap by establishing a correlation between process parameters, plasma characteristics, and product morphology, essential for controlling the growth of carbon nanostructures. We explored the impact of carbon precursor type (CH4 and C2H2), hydrogen, pressure, and flow rate on nanostructure formation. Using in situ optical emission spectroscopy (OES), we mapped the distribution of both temperature and dicarbon molecule (C2) density within the plasma jet. We demonstrate that the growth of low-density nanostructures, such as carbon nanohorns (CNHs), is favoured at dilute C2 local densities and high temperatures, while denser nanostructures, such as onion-like polyhedral graphitic nanocapsules (GNCs), are favoured at higher C2 densities and lower temperatures. The carbon density can be controlled by the flow rate and the pressure, which in turn significantly influence the nanostructure morphology, evolving from graphene nanoflakes (GNFs) to GNCs as either parameter increases. Increasing the H/C ratio from 1 to 8 resulted in a morphological transition from CNHs to GNFs. During the synthesis, the plasma jet temperature surpassed 3,000 K, with crystalline growth occurring 50 to 100 mm below the nozzle.",Materials Science
"Thermal plasma has emerged as an effective approach for producing carbon nanostructures without the need for specific catalysts nor substrates. While efforts have focused on the effect of process parameters such as reaction pressure, input power or carbon source, the intricate role and relationship with plasma characteristics like density and temperature are often overlooked due to the complexity of the environment. This study addresses this gap by establishing a correlation between process parameters, plasma characteristics, and product morphology, essential for controlling the growth of carbon nanostructures. We explored the impact of carbon precursor type (CH4 and C2H2), hydrogen, pressure, and flow rate on nanostructure formation. Using in situ optical emission spectroscopy (OES), we mapped the distribution of both temperature and dicarbon molecule (C2) density within the plasma jet. We demonstrate that the growth of low-density nanostructures, such as carbon nanohorns (CNHs), is favoured at dilute C2 local densities and high temperatures, while denser nanostructures, such as onion-like polyhedral graphitic nanocapsules (GNCs), are favoured at higher C2 densities and lower temperatures. The carbon density can be controlled by the flow rate and the pressure, which in turn significantly influence the nanostructure morphology, evolving from graphene nanoflakes (GNFs) to GNCs as either parameter increases. Increasing the H/C ratio from 1 to 8 resulted in a morphological transition from CNHs to GNFs. During the synthesis, the plasma jet temperature surpassed 3,000 K, with crystalline growth occurring 50 to 100 mm below the nozzle. [SEP] [HINT] transition -> Materials Science (Syns: passage, modulation, changeover) | using -> Bioinformatics (Syns: utilize, exploitation, apply) | optical -> Materials Science (Syns: ocular, opthalmic, optic)",Materials Science
"Numerous diseases, particularly autoimmune disorders, are associated with the human leukocyte antigen (HLA), a small genomic region located on human chromosome 6. Adequate characterization of linkage disequilibrium (LD) in the HLA across populations is crucial for identifying genetic markers associated with specific traits and phenotypes. However, current LD measures often fail to capture HLA's structural complexity due to methodological limitations and sensitivity to low-frequency variants, marginal allele frequencies, and haplotype composition. To address these challenges, we introduced the Conditional Informatics Correlation Coefficient (CICC), which integrates conditional probability, information content, and haplotype-aware XOR logic to quantify LD robustly. When applied to high-resolution haploid genomes from the Human Pangenome Reference Consortium (HPRC), CICC revealed 10 novel high-LD regions in HLA. Further analyses using the 1000 Genomes Project and Genome Asia datasets identified nine strongly linked regions shared across five global populations-five in Class I and four in Class II. These results demonstrate CICC's ability to capture complex HLA LD structures across populations, highlighting its broad potential for disease gene mapping, population genomics, and guiding precision medicine.",Bioinformatics
"Numerous diseases, particularly autoimmune disorders, are associated with the human leukocyte antigen (HLA), a small genomic region located on human chromosome 6. Adequate characterization of linkage disequilibrium (LD) in the HLA across populations is crucial for identifying genetic markers associated with specific traits and phenotypes. However, current LD measures often fail to capture HLA's structural complexity due to methodological limitations and sensitivity to low-frequency variants, marginal allele frequencies, and haplotype composition. To address these challenges, we introduced the Conditional Informatics Correlation Coefficient (CICC), which integrates conditional probability, information content, and haplotype-aware XOR logic to quantify LD robustly. When applied to high-resolution haploid genomes from the Human Pangenome Reference Consortium (HPRC), CICC revealed 10 novel high-LD regions in HLA. Further analyses using the 1000 Genomes Project and Genome Asia datasets identified nine strongly linked regions shared across five global populations-five in Class I and four in Class II. These results demonstrate CICC's ability to capture complex HLA LD structures across populations, highlighting its broad potential for disease gene mapping, population genomics, and guiding precision medicine. [SEP] [HINT] information -> Bioinformatics (Syns: entropy, data, info) | complex -> Bioinformatics (Syns: building complex, coordination compound, composite) | datasets -> Bioinformatics (Syns: )",Bioinformatics
"Early theories of perception as probabilistic inference propose that uncertainty about the interpretation of sensory input is represented as a probability distribution over many interpretations -- a relatively complex representation. However, critics argue that persistent demonstrations of suboptimal perceptual decision-making indicate limits in representational complexity. We contend that suboptimality arises not from genuine limits, but participants' resource-rational adaptations to task demands. For example, when tasks are solvable with minimal attention to stimuli, participants may neglect information needed for complex representations, relying instead on simpler ones that engender suboptimality. Across three experiments, we progressively reduced the efficacy of resource-rational strategies on a carefully controlled decision task. Model fits favored simple representations when resource-rational strategies were effective, and favored complex representations when ineffective, suggesting that perceptual representations can be simple or complex depending on task demands. We conclude that resource-rationality is an epistemic constraint for experimental design and essential to a complete theory of perception.",Neuroscience
"Early theories of perception as probabilistic inference propose that uncertainty about the interpretation of sensory input is represented as a probability distribution over many interpretations -- a relatively complex representation. However, critics argue that persistent demonstrations of suboptimal perceptual decision-making indicate limits in representational complexity. We contend that suboptimality arises not from genuine limits, but participants' resource-rational adaptations to task demands. For example, when tasks are solvable with minimal attention to stimuli, participants may neglect information needed for complex representations, relying instead on simpler ones that engender suboptimality. Across three experiments, we progressively reduced the efficacy of resource-rational strategies on a carefully controlled decision task. Model fits favored simple representations when resource-rational strategies were effective, and favored complex representations when ineffective, suggesting that perceptual representations can be simple or complex depending on task demands. We conclude that resource-rationality is an epistemic constraint for experimental design and essential to a complete theory of perception. [SEP] [HINT] task -> Neuroscience (Syns: tax, project, chore) | tasks -> Neuroscience (Syns: tax, task, project) | information -> Bioinformatics (Syns: entropy, data, info)",Neuroscience
"Adiabatic demagnetization refrigeration (ADR) is regaining relevance for the refrigeration to temperatures below 1 K as global helium-3 supply is increasingly strained. While ADR at these temperatures is long established with paramagnetic hydrated salts, more recently frustrated rare-earth oxides were found to offer higher entropy densities and practical advantages since they do not degrade under heating or evacuation. We report structural, magnetic and thermodynamic properties of the rare-earth borates Ba$_3$XB$_9$O$_{18}$ and Ba$_3$XB$_3$O$_9$ with X = (Yb, Gd). Except for Ba$_3$GdB$_9$O$_{18}$, which orders at 108 mK, the three other materials remain paramagnetic down to their lowest measured temperatures. ADR performance starting at 2 K in a field of 5 T is analyzed and compared to literature results.",Materials Science
"Adiabatic demagnetization refrigeration (ADR) is regaining relevance for the refrigeration to temperatures below 1 K as global helium-3 supply is increasingly strained. While ADR at these temperatures is long established with paramagnetic hydrated salts, more recently frustrated rare-earth oxides were found to offer higher entropy densities and practical advantages since they do not degrade under heating or evacuation. We report structural, magnetic and thermodynamic properties of the rare-earth borates Ba$_3$XB$_9$O$_{18}$ and Ba$_3$XB$_3$O$_9$ with X = (Yb, Gd). Except for Ba$_3$GdB$_9$O$_{18}$, which orders at 108 mK, the three other materials remain paramagnetic down to their lowest measured temperatures. ADR performance starting at 2 K in a field of 5 T is analyzed and compared to literature results. [SEP] [HINT] field -> Materials Science (Syns: field of honor, line of business, orbit) | performance -> Bioinformatics (Syns: functioning, operation, carrying out) | materials -> Materials Science (Syns: stuff, cloth, material)",Materials Science
"Cognitive control is a suite of processes that helps individuals pursue goals despite resistance or uncertainty about what to do. Although cognitive control has been extensively studied as a dynamic feedback loop of perception, valuation, and action, it remains incompletely understood as a cohesive dynamic and distributed neural process. Here, we critically examine the history of and advances in the study of cognitive control, including how metaphors and cultural norms of power, morality, and rationality are intertwined with definitions of control, to consider holistically how different models explain which brain regions act as controllers. Controllers, the source of top-down signals, are typically localized in regions whose neural activations implement elementary component processes of control, including conflict monitoring and behavioral inhibition. Top-down signals from these regions guide the activation of other task-specific regions, biasing them towards task-specific activity patterns. A relatively new approach, network control theory, has roots in dynamical systems theory and systems engineering. This approach can mathematically show that controllers are regions with strongly nested and recurrent anatomical connectivity that efficiently propagate top-down signals, and precisely estimate the amount, location, and timing of signaling required to bias global activity to task-specific patterns. The theory converges with prior evidence, offers new mathematical tools and intuitions for understanding control loops across levels of analysis, and naturally produces graded predictions of control across brain regions and modules of psychological function that have been unconsidered or marginalized. We describe how prior approaches converge and diverge, noting directions for future integration to improve understanding of how the brain instantiates cognitive control.",Neuroscience
"Cognitive control is a suite of processes that helps individuals pursue goals despite resistance or uncertainty about what to do. Although cognitive control has been extensively studied as a dynamic feedback loop of perception, valuation, and action, it remains incompletely understood as a cohesive dynamic and distributed neural process. Here, we critically examine the history of and advances in the study of cognitive control, including how metaphors and cultural norms of power, morality, and rationality are intertwined with definitions of control, to consider holistically how different models explain which brain regions act as controllers. Controllers, the source of top-down signals, are typically localized in regions whose neural activations implement elementary component processes of control, including conflict monitoring and behavioral inhibition. Top-down signals from these regions guide the activation of other task-specific regions, biasing them towards task-specific activity patterns. A relatively new approach, network control theory, has roots in dynamical systems theory and systems engineering. This approach can mathematically show that controllers are regions with strongly nested and recurrent anatomical connectivity that efficiently propagate top-down signals, and precisely estimate the amount, location, and timing of signaling required to bias global activity to task-specific patterns. The theory converges with prior evidence, offers new mathematical tools and intuitions for understanding control loops across levels of analysis, and naturally produces graded predictions of control across brain regions and modules of psychological function that have been unconsidered or marginalized. We describe how prior approaches converge and diverge, noting directions for future integration to improve understanding of how the brain instantiates cognitive control. [SEP] [HINT] connectivity -> Neuroscience (Syns: ) | understanding -> Neuroscience (Syns: savvy, intellect, sympathy) | systems -> Bioinformatics (Syns: organization, organisation, system)",Neuroscience
"In living systems, DNA undergoes continuous and rhythmic mechanical remodeling through condensation, looping, and disentangling to regulate gene expression, segregate chromosomes, and guide morphogenesis. Here, we demonstrate a purely mechanical route to rhythmic DNA reorganization in a minimal active composite of microtubules, kinesin motors, and DNA. We embed a DNA polymer in an active turbulent microtubule-kinesin fluid, creating a self-morphing material. The active flows stretch and entangle the DNA, forming a self-organized viscoelastic network that resists active stresses and affects flow over large length scales. This mechanical feedback loop progressively amplifies velocity correlations and drives a nonequilibrium phase transition tuned by DNA contour length: from disordered flow to synchronized, millimeter-scale oscillations with vortices. We rationalize the phase transition with an active-gel model that predicts a growing length scale and an oscillatory instability emerging from the interplay between activity, orientational order, and self-generated viscoelasticity, rather than chemical signaling. The dependence of the oscillation frequency on system size and activity quantitatively agrees with experiment. Thus, flow-driven DNA remodeling provides a minimal physical route to autonomous, system-spanning oscillations in three dimensions and suggests design principles for programmable soft matter that coordinates, actuates, and reshapes itself.",Materials Science
"In living systems, DNA undergoes continuous and rhythmic mechanical remodeling through condensation, looping, and disentangling to regulate gene expression, segregate chromosomes, and guide morphogenesis. Here, we demonstrate a purely mechanical route to rhythmic DNA reorganization in a minimal active composite of microtubules, kinesin motors, and DNA. We embed a DNA polymer in an active turbulent microtubule-kinesin fluid, creating a self-morphing material. The active flows stretch and entangle the DNA, forming a self-organized viscoelastic network that resists active stresses and affects flow over large length scales. This mechanical feedback loop progressively amplifies velocity correlations and drives a nonequilibrium phase transition tuned by DNA contour length: from disordered flow to synchronized, millimeter-scale oscillations with vortices. We rationalize the phase transition with an active-gel model that predicts a growing length scale and an oscillatory instability emerging from the interplay between activity, orientational order, and self-generated viscoelasticity, rather than chemical signaling. The dependence of the oscillation frequency on system size and activity quantitatively agrees with experiment. Thus, flow-driven DNA remodeling provides a minimal physical route to autonomous, system-spanning oscillations in three dimensions and suggests design principles for programmable soft matter that coordinates, actuates, and reshapes itself. [SEP] [HINT] transition -> Materials Science (Syns: passage, modulation, changeover) | scale -> Bioinformatics (Syns: shell, graduated table, plate) | activity -> Neuroscience (Syns: activeness, body process, bodily process)",Materials Science
"Boundary Vector Cells (BVCs) are a class of neurons in the brains of vertebrates that encode environmental boundaries at specific distances and allocentric directions, playing a central role in forming place fields in the hippocampus. Most computational BVC models are restricted to two-dimensional (2D) environments, making them prone to spatial ambiguities in the presence of horizontal symmetries in the environment. To address this limitation, we incorporate vertical angular sensitivity into the BVC framework, thereby enabling robust boundary detection in three dimensions, and leading to significantly more accurate spatial localization in a biologically-inspired robot model.   The proposed model processes LiDAR data to capture vertical contours, thereby disambiguating locations that would be indistinguishable under a purely 2D representation. Experimental results show that in environments with minimal vertical variation, the proposed 3D model matches the performance of a 2D baseline; yet, as 3D complexity increases, it yields substantially more distinct place fields and markedly reduces spatial aliasing. These findings show that adding a vertical dimension to BVC-based localization can significantly enhance navigation and mapping in real-world 3D spaces while retaining performance parity in simpler, near-planar scenarios.",Neuroscience
"Boundary Vector Cells (BVCs) are a class of neurons in the brains of vertebrates that encode environmental boundaries at specific distances and allocentric directions, playing a central role in forming place fields in the hippocampus. Most computational BVC models are restricted to two-dimensional (2D) environments, making them prone to spatial ambiguities in the presence of horizontal symmetries in the environment. To address this limitation, we incorporate vertical angular sensitivity into the BVC framework, thereby enabling robust boundary detection in three dimensions, and leading to significantly more accurate spatial localization in a biologically-inspired robot model.   The proposed model processes LiDAR data to capture vertical contours, thereby disambiguating locations that would be indistinguishable under a purely 2D representation. Experimental results show that in environments with minimal vertical variation, the proposed 3D model matches the performance of a 2D baseline; yet, as 3D complexity increases, it yields substantially more distinct place fields and markedly reduces spatial aliasing. These findings show that adding a vertical dimension to BVC-based localization can significantly enhance navigation and mapping in real-world 3D spaces while retaining performance parity in simpler, near-planar scenarios. [SEP] [HINT] computational -> Neuroscience (Syns: ) | performance -> Bioinformatics (Syns: functioning, operation, carrying out) | results -> Bioinformatics (Syns: final result, consequence, resultant role)",Neuroscience
"Supported nanoparticle catalysts are widely used in the chemical industry. Computational modeling of supported nanoparticles based on density functional theory (DFT) often involves structural searches of stable local minimum energy configurations and molecular dynamics simulations at finite temperature. These are computationally demanding tasks that are intractable within DFT for large systems. In the last two decades, machine learning interatomic potentials (MLIPs) have been successfully used to substantially increase the size and time scales accessible to simulations that retain DFT accuracy. However, training reliable MLIPs is non-trivial as it requires many costly DFT calculations. Recently, several universal MLIPs (uMLIPs) have been developed, which are trained on large datasets that cover a wide range of molecules and materials. Here, we benchmark the accuracy and the efficiency of these uMLIPs in describing Cu nanoparticles supported on Al$_2$O$_3$ surfaces against our domain-specific DP-UniAlCu model. We find that the MACE-OMAT can reproduce reasonably well the low-energy configurations found in global optimization at an energy accuracy comparable to DP-UniAlCu. Interestingly, the MatterSim-v1.0.0-1M model, which exhibits larger deviations in the binding energies, can find even more stable configurations than the other two models in some supported nanoparticle sizes, showing its capability in structure exploration. For MD simulations, MACE-OMAT and MatterSim-v1.0.0-1M can qualitatively reproduce the mean-squared displacements of Cu atoms (MSD$_\mathrm{Cu}$) predicted by DP-UniAlCu, albeit at roughly two orders of magnitude higher cost. We demonstrate that the uMLIPs can be very useful in simulating supported nanoparticles even without any fine-tuning, though their reduced efficiency remains a limiting factor for large-scale simulations.",Materials Science
"Supported nanoparticle catalysts are widely used in the chemical industry. Computational modeling of supported nanoparticles based on density functional theory (DFT) often involves structural searches of stable local minimum energy configurations and molecular dynamics simulations at finite temperature. These are computationally demanding tasks that are intractable within DFT for large systems. In the last two decades, machine learning interatomic potentials (MLIPs) have been successfully used to substantially increase the size and time scales accessible to simulations that retain DFT accuracy. However, training reliable MLIPs is non-trivial as it requires many costly DFT calculations. Recently, several universal MLIPs (uMLIPs) have been developed, which are trained on large datasets that cover a wide range of molecules and materials. Here, we benchmark the accuracy and the efficiency of these uMLIPs in describing Cu nanoparticles supported on Al$_2$O$_3$ surfaces against our domain-specific DP-UniAlCu model. We find that the MACE-OMAT can reproduce reasonably well the low-energy configurations found in global optimization at an energy accuracy comparable to DP-UniAlCu. Interestingly, the MatterSim-v1.0.0-1M model, which exhibits larger deviations in the binding energies, can find even more stable configurations than the other two models in some supported nanoparticle sizes, showing its capability in structure exploration. For MD simulations, MACE-OMAT and MatterSim-v1.0.0-1M can qualitatively reproduce the mean-squared displacements of Cu atoms (MSD$_\mathrm{Cu}$) predicted by DP-UniAlCu, albeit at roughly two orders of magnitude higher cost. We demonstrate that the uMLIPs can be very useful in simulating supported nanoparticles even without any fine-tuning, though their reduced efficiency remains a limiting factor for large-scale simulations. [SEP] [HINT] used -> Bioinformatics (Syns: utilize, ill-used, apply) | tasks -> Neuroscience (Syns: tax, task, project) | based -> Bioinformatics (Syns: ground, free-base, base)",Materials Science
"The transport and localization of RNA molecules, crucial for cellular function and development, involve a combination of diffusion and active transport mechanisms. Here, we are motivated by understanding the dynamics of RNA in Xenopus laevis oocytes. Fluorescence Recovery After Photobleaching (FRAP) is an experimental technique that is widely used to investigate the dynamics of molecular movement within cells by observing the recovery of fluorescence intensity in a photobleached region over time. To advance the understanding of RNA dynamics, we develop a reaction-diffusion-advection partial differential equation (PDE) model integrating both transport and diffusion mechanisms. We propose a pipeline for identifiability analysis to assess the model's ability to uniquely determine parameter values from observed FRAP data. Based on profile likelihood analysis and reparametrization, we examine the relationship between non- identifiable parameters, which improves the robustness of parameter estimation. We find out that the identifiability of the four parameters of interest is not exactly the same in different regions of the cell. Specifically, transport velocity and diffusion coefficient are identifiable in all regions of the cell, while some combinations of binding rate and unbinding rate are found to be identifiable near the nucleus.",Bioinformatics
"The transport and localization of RNA molecules, crucial for cellular function and development, involve a combination of diffusion and active transport mechanisms. Here, we are motivated by understanding the dynamics of RNA in Xenopus laevis oocytes. Fluorescence Recovery After Photobleaching (FRAP) is an experimental technique that is widely used to investigate the dynamics of molecular movement within cells by observing the recovery of fluorescence intensity in a photobleached region over time. To advance the understanding of RNA dynamics, we develop a reaction-diffusion-advection partial differential equation (PDE) model integrating both transport and diffusion mechanisms. We propose a pipeline for identifiability analysis to assess the model's ability to uniquely determine parameter values from observed FRAP data. Based on profile likelihood analysis and reparametrization, we examine the relationship between non- identifiable parameters, which improves the robustness of parameter estimation. We find out that the identifiability of the four parameters of interest is not exactly the same in different regions of the cell. Specifically, transport velocity and diffusion coefficient are identifiable in all regions of the cell, while some combinations of binding rate and unbinding rate are found to be identifiable near the nucleus. [SEP] [HINT] used -> Bioinformatics (Syns: utilize, ill-used, apply) | based -> Bioinformatics (Syns: ground, free-base, base) | understanding -> Neuroscience (Syns: savvy, intellect, sympathy)",Bioinformatics
"Human core object recognition depends on the selective use of visual information, but the strategies guiding these choices are difficult to measure directly. We present MAPS (Masked Attribution-based Probing of Strategies), a behaviorally validated computational tool that tests whether explanations derived from artificial neural networks (ANNs) can also explain human vision. MAPS converts attribution maps into explanation-masked images (EMIs) and compares image-by-image human accuracies on these minimal images with limited pixel budgets with accuracies on the full stimuli. MAPS provides a principled way to evaluate and choose among competing ANN interpretability methods. In silico, EMI-based behavioral similarity between models reliably recovers the ground-truth similarity computed from their attribution maps, establishing which explanation methods best capture the model's strategy. When applied to humans and macaques, MAPS identifies ANN-explanation combinations whose explanations align most closely with biological vision, achieving the behavioral validity of Bubble masks while requiring far fewer behavioral trials. Because it needs only access to model attributions and a modest set of behavioral data on the original images, MAPS avoids exhaustive psychophysics while offering a scalable tool for adjudicating explanations and linking human behavior, neural activity, and model decisions under a common standard.",Neuroscience
"Human core object recognition depends on the selective use of visual information, but the strategies guiding these choices are difficult to measure directly. We present MAPS (Masked Attribution-based Probing of Strategies), a behaviorally validated computational tool that tests whether explanations derived from artificial neural networks (ANNs) can also explain human vision. MAPS converts attribution maps into explanation-masked images (EMIs) and compares image-by-image human accuracies on these minimal images with limited pixel budgets with accuracies on the full stimuli. MAPS provides a principled way to evaluate and choose among competing ANN interpretability methods. In silico, EMI-based behavioral similarity between models reliably recovers the ground-truth similarity computed from their attribution maps, establishing which explanation methods best capture the model's strategy. When applied to humans and macaques, MAPS identifies ANN-explanation combinations whose explanations align most closely with biological vision, achieving the behavioral validity of Bubble masks while requiring far fewer behavioral trials. Because it needs only access to model attributions and a modest set of behavioral data on the original images, MAPS avoids exhaustive psychophysics while offering a scalable tool for adjudicating explanations and linking human behavior, neural activity, and model decisions under a common standard. [SEP] [HINT] computational -> Neuroscience (Syns: ) | networks -> Neuroscience (Syns: network, meshwork, electronic network) | human -> Neuroscience (Syns: human being, man, homo)",Neuroscience
"The structural flexibility and multifunctional nature of double perovskite oxides make them attractive for applications requiring coupled optical, mechanical, and thermal performance. Using first-principles computations, this study examines the structural, electronic, elastic, optical, and thermoelectric stability of K2NbTaO6 and Rb2NbTaO6. The two compounds combine to form a cubic double perovskite structure with ordered Nb$^{5+}$ and Ta$^{5+}$ cations. The calculated elastic constants satisfy the Born stability criteria, confirming mechanical stability; however, both K2NbTaO6 and Rb2NbTaO6 exhibit brittle behavior according to Pugh's ratio, reflecting limited ductility. Semiconducting behavior is revealed by band structure analysis with energy gaps of 2.79 eV for K2NbTaO6 and 2.63 eV for Rb2NbTaO6. Optical spectra show noticeable absorption in the high-energy region near the UV, indicating relevance for theoretical studies of optoelectronic and photocatalytic processes, without implying practical device efficiency. Therm",Materials Science
"The structural flexibility and multifunctional nature of double perovskite oxides make them attractive for applications requiring coupled optical, mechanical, and thermal performance. Using first-principles computations, this study examines the structural, electronic, elastic, optical, and thermoelectric stability of K2NbTaO6 and Rb2NbTaO6. The two compounds combine to form a cubic double perovskite structure with ordered Nb$^{5+}$ and Ta$^{5+}$ cations. The calculated elastic constants satisfy the Born stability criteria, confirming mechanical stability; however, both K2NbTaO6 and Rb2NbTaO6 exhibit brittle behavior according to Pugh's ratio, reflecting limited ductility. Semiconducting behavior is revealed by band structure analysis with energy gaps of 2.79 eV for K2NbTaO6 and 2.63 eV for Rb2NbTaO6. Optical spectra show noticeable absorption in the high-energy region near the UV, indicating relevance for theoretical studies of optoelectronic and photocatalytic processes, without implying practical device efficiency. Therm [SEP] [HINT] perovskite -> Materials Science (Syns: ) | structure -> Bioinformatics (Syns: social system, complex body part, social structure) | using -> Bioinformatics (Syns: utilize, exploitation, apply)",Materials Science
"Spatial world models, representations that support flexible reasoning about spatial relations, are central to developing computational models that could operate in the physical world, but their precise mechanistic underpinnings are nuanced by the borrowing of underspecified or misguided accounts of human cognition. This paper revisits the simulation versus rendering dichotomy and draws on evidence from aphantasia to argue that fine-grained perceptual content is critical for model-based spatial reasoning. Drawing on recent research into the neural basis of visual awareness, we propose that spatial simulation and perceptual experience depend on shared representational geometries captured by higher-order indices of perceptual relations. We argue that recent developments in embodied AI support this claim, where rich perceptual details improve performance on physics-based world engagements. To this end, we call for the development of architectures capable of maintaining structured perceptual representations as a step toward spatial world modelling in AI.",Neuroscience
"Spatial world models, representations that support flexible reasoning about spatial relations, are central to developing computational models that could operate in the physical world, but their precise mechanistic underpinnings are nuanced by the borrowing of underspecified or misguided accounts of human cognition. This paper revisits the simulation versus rendering dichotomy and draws on evidence from aphantasia to argue that fine-grained perceptual content is critical for model-based spatial reasoning. Drawing on recent research into the neural basis of visual awareness, we propose that spatial simulation and perceptual experience depend on shared representational geometries captured by higher-order indices of perceptual relations. We argue that recent developments in embodied AI support this claim, where rich perceptual details improve performance on physics-based world engagements. To this end, we call for the development of architectures capable of maintaining structured perceptual representations as a step toward spatial world modelling in AI. [SEP] [HINT] computational -> Neuroscience (Syns: ) | performance -> Bioinformatics (Syns: functioning, operation, carrying out) | human -> Neuroscience (Syns: human being, man, homo)",Neuroscience
"Fabrication of porous GaN distributed Bragg reflectors (DBRs) via the selective electrochemical etching (ECE) of conductive Si-doped layers, separated by non-intentionally doped (NID) layers, provides a straightforward methodology for producing highly reflective DBRs suitable for device overgrowth and integration, which has otherwise proven difficult in the III-nitride epitaxial system via conventional alloying. Such photonic materials can be fabricated by a lithography-free defect-driven etching process, where threading dislocations intrinsic to heteroepitaxy form nanoscale channels that facilitate etchant transport through NID layers. Here, we report the first three-dimensional characterisation of porous GaN-on-Si DBRs fabricated in this methodology with different ECE voltages, using serial-section tomography in a focused ion beam scanning electron microscope (FIB-SEM). These datasets reconstruct the pore morphology as etching proliferates through the alternating Si-doped/NID layer stack. Volumetric reconstruction enabled us to enhance the established `kebab' model for defect-driven etching by proposing a `cascade' model where etchant cascades through the material via vertical etching down nanopipes and horizontal etching across pores, forming complex networks directly related to the pathways taken. This accounts for premature nanopipe termination and discontinuities in nanopipe formation, where dislocations are observed to activate and deactivate individually. Statistical analysis of individual etching behaviour, across all dislocations for each tomograph, revealed a greater tendency to form continuous structures that follow conventional kebab behaviour at higher ECE voltages. We propose that higher ECE voltages alter the probability of dislocation etching relative to doped layer etching, thereby empowering morphological optimization through improved mechanistic understanding of ECE.",Materials Science
"Fabrication of porous GaN distributed Bragg reflectors (DBRs) via the selective electrochemical etching (ECE) of conductive Si-doped layers, separated by non-intentionally doped (NID) layers, provides a straightforward methodology for producing highly reflective DBRs suitable for device overgrowth and integration, which has otherwise proven difficult in the III-nitride epitaxial system via conventional alloying. Such photonic materials can be fabricated by a lithography-free defect-driven etching process, where threading dislocations intrinsic to heteroepitaxy form nanoscale channels that facilitate etchant transport through NID layers. Here, we report the first three-dimensional characterisation of porous GaN-on-Si DBRs fabricated in this methodology with different ECE voltages, using serial-section tomography in a focused ion beam scanning electron microscope (FIB-SEM). These datasets reconstruct the pore morphology as etching proliferates through the alternating Si-doped/NID layer stack. Volumetric reconstruction enabled us to enhance the established `kebab' model for defect-driven etching by proposing a `cascade' model where etchant cascades through the material via vertical etching down nanopipes and horizontal etching across pores, forming complex networks directly related to the pathways taken. This accounts for premature nanopipe termination and discontinuities in nanopipe formation, where dislocations are observed to activate and deactivate individually. Statistical analysis of individual etching behaviour, across all dislocations for each tomograph, revealed a greater tendency to form continuous structures that follow conventional kebab behaviour at higher ECE voltages. We propose that higher ECE voltages alter the probability of dislocation etching relative to doped layer etching, thereby empowering morphological optimization through improved mechanistic understanding of ECE. [SEP] [HINT] understanding -> Neuroscience (Syns: savvy, intellect, sympathy) | transport -> Materials Science (Syns: transferral, enthral, shipping) | networks -> Neuroscience (Syns: network, meshwork, electronic network)",Materials Science
"Memory, a fundamental component of human cognition, exhibits adaptive yet fallible characteristics as illustrated by Schacter's memory ""sins"".These cognitive phenomena have been studied extensively in psychology and neuroscience, but the extent to which artificial systems, specifically Large Language Models (LLMs), emulate these cognitive phenomena remains underexplored. This study uses human memory research as a lens for understanding LLMs and systematically investigates human memory effects in state-of-the-art LLMs using paradigms drawn from psychological research. We evaluate seven key memory phenomena, comparing human behavior to LLM performance. Both people and models remember less when overloaded with information (list length effect) and remember better with repeated exposure (list strength effect). They also show similar difficulties when retrieving overlapping information, where storing too many similar facts leads to confusion (fan effect). Like humans, LLMs are susceptible to falsely ""remembering"" words that were never shown but are related to others (false memories), and they can apply prior learning to new, related situations (cross-domain generalization). However, LLMs differ in two key ways: they are less influenced by the order in which information is presented (positional bias) and more robust when processing random or meaningless material (nonsense effect). These results reveal both alignments and divergences in how LLMs and humans reconstruct memory. The findings help clarify how memory-like behavior in LLMs echoes core features of human cognition, while also highlighting the architectural differences that lead to distinct patterns of error and success.",Neuroscience
"Memory, a fundamental component of human cognition, exhibits adaptive yet fallible characteristics as illustrated by Schacter's memory ""sins"".These cognitive phenomena have been studied extensively in psychology and neuroscience, but the extent to which artificial systems, specifically Large Language Models (LLMs), emulate these cognitive phenomena remains underexplored. This study uses human memory research as a lens for understanding LLMs and systematically investigates human memory effects in state-of-the-art LLMs using paradigms drawn from psychological research. We evaluate seven key memory phenomena, comparing human behavior to LLM performance. Both people and models remember less when overloaded with information (list length effect) and remember better with repeated exposure (list strength effect). They also show similar difficulties when retrieving overlapping information, where storing too many similar facts leads to confusion (fan effect). Like humans, LLMs are susceptible to falsely ""remembering"" words that were never shown but are related to others (false memories), and they can apply prior learning to new, related situations (cross-domain generalization). However, LLMs differ in two key ways: they are less influenced by the order in which information is presented (positional bias) and more robust when processing random or meaningless material (nonsense effect). These results reveal both alignments and divergences in how LLMs and humans reconstruct memory. The findings help clarify how memory-like behavior in LLMs echoes core features of human cognition, while also highlighting the architectural differences that lead to distinct patterns of error and success. [SEP] [HINT] language -> Neuroscience (Syns: linguistic process, linguistic communication, spoken communication) | features -> Bioinformatics (Syns: characteristic, lineament, feature of speech) | understanding -> Neuroscience (Syns: savvy, intellect, sympathy)",Neuroscience
"Silicon nitride has emerged as a promising photonic platform for integrated single-photon sources, yet the microscopic origin of the recently observed bright quantum emissions remains unclear. Using hybrid density functional theory, we show that the negatively charged N$_\text{Si}$V$_\text{N}$ center (NV$^{-}$) in the C$_{1h}$ configuration exhibits a linearly polarized zero-phonon line (ZPL) at 2.46 eV, with a radiative lifetime of 9.01 ns and a high Debye-Waller (DW) factor of 33%. We further find that the C$_{1h}$ configuration is prone to a pseudo-Jahn-Teller distortion, yielding two symmetrically equivalent defect structures that emit bright, linearly polarized ZPL at 1.80 eV with a lifetime of 10.17 ns and an increased DW factor of 41%. These nitrogen-vacancy-related defects explain the origins of visible quantum emissions, paving the way for deterministic and monolithically integrated silicon-nitride quantum photonics.",Materials Science
"Silicon nitride has emerged as a promising photonic platform for integrated single-photon sources, yet the microscopic origin of the recently observed bright quantum emissions remains unclear. Using hybrid density functional theory, we show that the negatively charged N$_\text{Si}$V$_\text{N}$ center (NV$^{-}$) in the C$_{1h}$ configuration exhibits a linearly polarized zero-phonon line (ZPL) at 2.46 eV, with a radiative lifetime of 9.01 ns and a high Debye-Waller (DW) factor of 33%. We further find that the C$_{1h}$ configuration is prone to a pseudo-Jahn-Teller distortion, yielding two symmetrically equivalent defect structures that emit bright, linearly polarized ZPL at 1.80 eV with a lifetime of 10.17 ns and an increased DW factor of 41%. These nitrogen-vacancy-related defects explain the origins of visible quantum emissions, paving the way for deterministic and monolithically integrated silicon-nitride quantum photonics. [SEP] [HINT] defect -> Materials Science (Syns: mar, shortcoming, fault) | functional -> Neuroscience (Syns: working, usable, running) | using -> Bioinformatics (Syns: utilize, exploitation, apply)",Materials Science
"Ferrohydrodynamic microfluidics relies on magnetic field gradients to manipulate diamagnetic particles in ferrofluid-filled microenvironments. It has emerged as a promising tool for label-free manipulation of bioparticles, including their separation and phenotyping. This perspective reviews recent progress in the development and applications of ferrofluid-based microfluidic platforms for multiscale bioparticle separation, ranging from micron-scale cells to submicron extracellular vesicles. We highlight the fundamental physical principles for ferrohydrodynamic manipulation, including the dominant magnetic buoyancy force resulting from the interaction of ferrofluids and particles. We then describe how these principles enable high-resolution size-based bioparticle separation, subcellular bioparticle enrichment, and phenotypic screening based on physical traits. We also discuss key challenges in ferrohydrodynamic microfluidics from the aspects of ferrofluid biocompatibility, system throughput, and nanoparticle depletion. Finally, we outline future research directions involving machine learning, 3D printing, and multiplexed detection. These insights chart a path for advancing ferrofluid-based technologies in precision biomedicine, diagnostics, and cellular engineering.",Bioinformatics
"Ferrohydrodynamic microfluidics relies on magnetic field gradients to manipulate diamagnetic particles in ferrofluid-filled microenvironments. It has emerged as a promising tool for label-free manipulation of bioparticles, including their separation and phenotyping. This perspective reviews recent progress in the development and applications of ferrofluid-based microfluidic platforms for multiscale bioparticle separation, ranging from micron-scale cells to submicron extracellular vesicles. We highlight the fundamental physical principles for ferrohydrodynamic manipulation, including the dominant magnetic buoyancy force resulting from the interaction of ferrofluids and particles. We then describe how these principles enable high-resolution size-based bioparticle separation, subcellular bioparticle enrichment, and phenotypic screening based on physical traits. We also discuss key challenges in ferrohydrodynamic microfluidics from the aspects of ferrofluid biocompatibility, system throughput, and nanoparticle depletion. Finally, we outline future research directions involving machine learning, 3D printing, and multiplexed detection. These insights chart a path for advancing ferrofluid-based technologies in precision biomedicine, diagnostics, and cellular engineering. [SEP] [HINT] field -> Materials Science (Syns: field of honor, line of business, orbit) | based -> Bioinformatics (Syns: ground, free-base, base) | including -> Bioinformatics (Syns: admit, include, let in)",Bioinformatics
"Interfaces are the key to next generation high energy batteries including solid state Li metal batteries. In solid state batteries, the buried nature of solid solid electrolyte electrode interfaces makes studying them difficult. Neutrons have significant potential to non destructively probe these buried solid solid interfaces. This work presents a comparative study using both neutron depth profiling (NDP) and neutron reflectometry (NR) to study a model lithium metal-lithium phosphorus oxynitride (LiPON) solid electrolyte system. In the NDP data, no distinct interphase is observed at the interface. NR shows a difference between electrodeposited, and vapor deposited LiPON -Li interfaces but finds both are gradient interphases that are less than 30 nm thick. Additional simulations of the LiPON-Li2O-Li system demonstrate that NDP has an excellent resolution in the 50 nm-1 mm regime while NR has an ideal resolution from 0.1 - 200 nm with different sample requirements. Together NDP and NR can provide a complementary understanding of interfaces between Li metal and solid electrolytes across relevant length scales.",Materials Science
"Interfaces are the key to next generation high energy batteries including solid state Li metal batteries. In solid state batteries, the buried nature of solid solid electrolyte electrode interfaces makes studying them difficult. Neutrons have significant potential to non destructively probe these buried solid solid interfaces. This work presents a comparative study using both neutron depth profiling (NDP) and neutron reflectometry (NR) to study a model lithium metal-lithium phosphorus oxynitride (LiPON) solid electrolyte system. In the NDP data, no distinct interphase is observed at the interface. NR shows a difference between electrodeposited, and vapor deposited LiPON -Li interfaces but finds both are gradient interphases that are less than 30 nm thick. Additional simulations of the LiPON-Li2O-Li system demonstrate that NDP has an excellent resolution in the 50 nm-1 mm regime while NR has an ideal resolution from 0.1 - 200 nm with different sample requirements. Together NDP and NR can provide a complementary understanding of interfaces between Li metal and solid electrolytes across relevant length scales. [SEP] [HINT] non -> Materials Science (Syns: not) | understanding -> Neuroscience (Syns: savvy, intellect, sympathy) | work -> Bioinformatics (Syns: work out, process, bring)",Materials Science
"We present Crystalyse, an open, provenance-enforced scientific agent for computational materials design of inorganic crystals that orchestrates tools for compositional screening, crystal structure generation, and machine-learning force-field evaluation. Crystalyse offers three operating modes to trade exploration speed against validation depth: creative (rapid query), adaptive (context-aware routing) and rigorous (comprehensive checks). We release the underlying source code and evaluation scripts to enable plug-and-play use and development. In demonstrations on quaternary oxide exploration, sodium-ion cathode design, and lead-free indoor photovoltaic candidate generation, the agent integrates chemical compound generation with fast stability and property filters. Under adversarial testing, provenance enforcement eliminated material-property hallucinations (a broad adversarial suite pass rate reached 86% from a 57% baseline). Crystalyse provides an agentic artificial intelligence system that can complement existing materials design pipelines, assisting in hypothesis generation while preserving transparency and reproducibility.",Materials Science
"We present Crystalyse, an open, provenance-enforced scientific agent for computational materials design of inorganic crystals that orchestrates tools for compositional screening, crystal structure generation, and machine-learning force-field evaluation. Crystalyse offers three operating modes to trade exploration speed against validation depth: creative (rapid query), adaptive (context-aware routing) and rigorous (comprehensive checks). We release the underlying source code and evaluation scripts to enable plug-and-play use and development. In demonstrations on quaternary oxide exploration, sodium-ion cathode design, and lead-free indoor photovoltaic candidate generation, the agent integrates chemical compound generation with fast stability and property filters. Under adversarial testing, provenance enforcement eliminated material-property hallucinations (a broad adversarial suite pass rate reached 86% from a 57% baseline). Crystalyse provides an agentic artificial intelligence system that can complement existing materials design pipelines, assisting in hypothesis generation while preserving transparency and reproducibility. [SEP] [HINT] computational -> Neuroscience (Syns: ) | structure -> Bioinformatics (Syns: social system, complex body part, social structure) | crystal -> Materials Science (Syns: crystallization, quartz, lechatelierite)",Materials Science
"Single-particle small-angle X-ray scattering (SP-SAXS) enables quantitative morphological analysis by recording diffraction snapshots from isolated particles using X-ray free-electron laser (XFEL) pulses. Unlike conventional X-ray techniques, which average over the entire illuminated sample volume, SP-SAXS resolves low-contrast, less abundant, or transient species within heterogeneous particle populations that would otherwise remain hidden. Here, we apply SP-SAXS to investigate the solvothermal formation of CoO nanocrystal assemblies from a Co(acac)$_3$ precursor in benzyl alcohol. The single-particle data reveal amorphous, uniform-density Co(acac)$_2$ spheres as transient intermediates that directly crystallize into cavernous CoO nanocrystal assemblies, which explains why CoO forms as hierarchical aggregates rather than as isolated nanocrystals. These results demonstrate that SP-SAXS provides a powerful framework for disentangling morphological heterogeneity in nanoparticle formation processes.",Materials Science
"Single-particle small-angle X-ray scattering (SP-SAXS) enables quantitative morphological analysis by recording diffraction snapshots from isolated particles using X-ray free-electron laser (XFEL) pulses. Unlike conventional X-ray techniques, which average over the entire illuminated sample volume, SP-SAXS resolves low-contrast, less abundant, or transient species within heterogeneous particle populations that would otherwise remain hidden. Here, we apply SP-SAXS to investigate the solvothermal formation of CoO nanocrystal assemblies from a Co(acac)$_3$ precursor in benzyl alcohol. The single-particle data reveal amorphous, uniform-density Co(acac)$_2$ spheres as transient intermediates that directly crystallize into cavernous CoO nanocrystal assemblies, which explains why CoO forms as hierarchical aggregates rather than as isolated nanocrystals. These results demonstrate that SP-SAXS provides a powerful framework for disentangling morphological heterogeneity in nanoparticle formation processes. [SEP] [HINT] results -> Bioinformatics (Syns: final result, consequence, resultant role) | framework -> Bioinformatics (Syns: theoretical account, model, fabric) | using -> Bioinformatics (Syns: utilize, exploitation, apply)",Materials Science
"Recent evidence suggests that beta-band activity plays a key role in decision-making. Here we review our recent work in humans and non-human primates showing that beta-band frequency shifts in frontal cortex signal categorical decision outcomes. We revisit our previous proposal suggesting that content-specific beta reflects the flexible recruiting of transient neural ensembles and update it to emphasize frequency as the relevant parameter. We argue that beta frequency shifts arise from changes in connectivity between weakly coupled oscillators and that, more than a spectral fingerprint, they reflect an active mechanism to (re)-activate behaviorally relevant communication channels in the brain.",Neuroscience
"Recent evidence suggests that beta-band activity plays a key role in decision-making. Here we review our recent work in humans and non-human primates showing that beta-band frequency shifts in frontal cortex signal categorical decision outcomes. We revisit our previous proposal suggesting that content-specific beta reflects the flexible recruiting of transient neural ensembles and update it to emphasize frequency as the relevant parameter. We argue that beta frequency shifts arise from changes in connectivity between weakly coupled oscillators and that, more than a spectral fingerprint, they reflect an active mechanism to (re)-activate behaviorally relevant communication channels in the brain. [SEP] [HINT] work -> Bioinformatics (Syns: work out, process, bring) | connectivity -> Neuroscience (Syns: ) | neural -> Bioinformatics (Syns: neuronic, nervous, neuronal)",Neuroscience
"High-dimensional imaging of neural activity, such as widefield calcium and functional ultrasound imaging, provide a rich source of information for understanding the relationship between brain activity and behavior. Accurately modeling neural dynamics in these modalities is crucial for understanding this relationship but is hindered by the high-dimensionality, complex spatiotemporal dependencies, and prevalent behaviorally irrelevant dynamics in these modalities. Existing dynamical models often employ preprocessing steps to obtain low-dimensional representations from neural image modalities. However, this process can discard behaviorally relevant information and miss spatiotemporal structure. We propose SBIND, a novel data-driven deep learning framework to model spatiotemporal dependencies in neural images and disentangle their behaviorally relevant dynamics from other neural dynamics. We validate SBIND on widefield imaging datasets, and show its extension to functional ultrasound imaging, a recent modality whose dynamical modeling has largely remained unexplored. We find that our model effectively identifies both local and long-range spatial dependencies across the brain while also dissociating behaviorally relevant neural dynamics. Doing so, SBIND outperforms existing models in neural-behavioral prediction. Overall, SBIND provides a versatile tool for investigating the neural mechanisms underlying behavior using imaging modalities.",Neuroscience
"High-dimensional imaging of neural activity, such as widefield calcium and functional ultrasound imaging, provide a rich source of information for understanding the relationship between brain activity and behavior. Accurately modeling neural dynamics in these modalities is crucial for understanding this relationship but is hindered by the high-dimensionality, complex spatiotemporal dependencies, and prevalent behaviorally irrelevant dynamics in these modalities. Existing dynamical models often employ preprocessing steps to obtain low-dimensional representations from neural image modalities. However, this process can discard behaviorally relevant information and miss spatiotemporal structure. We propose SBIND, a novel data-driven deep learning framework to model spatiotemporal dependencies in neural images and disentangle their behaviorally relevant dynamics from other neural dynamics. We validate SBIND on widefield imaging datasets, and show its extension to functional ultrasound imaging, a recent modality whose dynamical modeling has largely remained unexplored. We find that our model effectively identifies both local and long-range spatial dependencies across the brain while also dissociating behaviorally relevant neural dynamics. Doing so, SBIND outperforms existing models in neural-behavioral prediction. Overall, SBIND provides a versatile tool for investigating the neural mechanisms underlying behavior using imaging modalities. [SEP] [HINT] understanding -> Neuroscience (Syns: savvy, intellect, sympathy) | learning -> Bioinformatics (Syns: take, teach, acquire) | functional -> Neuroscience (Syns: working, usable, running)",Neuroscience
"Understanding how the human brain progresses from processing simple linguistic inputs to performing high-level reasoning is a fundamental challenge in neuroscience. While modern large language models (LLMs) are increasingly used to model neural responses to language, their internal representations are highly ""entangled,"" mixing information about lexicon, syntax, meaning, and reasoning. This entanglement biases conventional brain encoding analyses toward linguistically shallow features (e.g., lexicon and syntax), making it difficult to isolate the neural substrates of cognitively deeper processes. Here, we introduce a residual disentanglement method that computationally isolates these components. By first probing an LM to identify feature-specific layers, our method iteratively regresses out lower-level representations to produce four nearly orthogonal embeddings for lexicon, syntax, meaning, and, critically, reasoning. We used these disentangled embeddings to model intracranial (ECoG) brain recordings from neurosurgical patients listening to natural speech. We show that: 1) This isolated reasoning embedding exhibits unique predictive power, accounting for variance in neural activity not explained by other linguistic features and even extending to the recruitment of visual regions beyond classical language areas. 2) The neural signature for reasoning is temporally distinct, peaking later (~350-400ms) than signals related to lexicon, syntax, and meaning, consistent with its position atop a processing hierarchy. 3) Standard, non-disentangled LLM embeddings can be misleading, as their predictive success is primarily attributable to linguistically shallow features, masking the more subtle contributions of deeper cognitive processing.",Neuroscience
"Understanding how the human brain progresses from processing simple linguistic inputs to performing high-level reasoning is a fundamental challenge in neuroscience. While modern large language models (LLMs) are increasingly used to model neural responses to language, their internal representations are highly ""entangled,"" mixing information about lexicon, syntax, meaning, and reasoning. This entanglement biases conventional brain encoding analyses toward linguistically shallow features (e.g., lexicon and syntax), making it difficult to isolate the neural substrates of cognitively deeper processes. Here, we introduce a residual disentanglement method that computationally isolates these components. By first probing an LM to identify feature-specific layers, our method iteratively regresses out lower-level representations to produce four nearly orthogonal embeddings for lexicon, syntax, meaning, and, critically, reasoning. We used these disentangled embeddings to model intracranial (ECoG) brain recordings from neurosurgical patients listening to natural speech. We show that: 1) This isolated reasoning embedding exhibits unique predictive power, accounting for variance in neural activity not explained by other linguistic features and even extending to the recruitment of visual regions beyond classical language areas. 2) The neural signature for reasoning is temporally distinct, peaking later (~350-400ms) than signals related to lexicon, syntax, and meaning, consistent with its position atop a processing hierarchy. 3) Standard, non-disentangled LLM embeddings can be misleading, as their predictive success is primarily attributable to linguistically shallow features, masking the more subtle contributions of deeper cognitive processing. [SEP] [HINT] used -> Bioinformatics (Syns: utilize, ill-used, apply) | language -> Neuroscience (Syns: linguistic process, linguistic communication, spoken communication) | features -> Bioinformatics (Syns: characteristic, lineament, feature of speech)",Neuroscience
"Protein language models (PLMs) have transformed sequence-based protein analysis, yet most applications rely only on final-layer embeddings, which may overlook biologically meaningful information encoded in earlier layers. We systematically evaluate all 33 layers of ESM-2 for kinase functional prediction using both unsupervised clustering and supervised classification. We show that mid-to-late transformer layers (layers 20-33) outperform the final layer by 32 percent in unsupervised Adjusted Rand Index and improve homology-aware supervised accuracy to 75.7 percent. Domain-level extraction, calibrated probability estimates, and a reproducible benchmarking pipeline further strengthen reliability. Our results demonstrate that transformer depth contains functionally distinct biological signals and that principled layer selection significantly improves kinase function prediction.",Bioinformatics
"Protein language models (PLMs) have transformed sequence-based protein analysis, yet most applications rely only on final-layer embeddings, which may overlook biologically meaningful information encoded in earlier layers. We systematically evaluate all 33 layers of ESM-2 for kinase functional prediction using both unsupervised clustering and supervised classification. We show that mid-to-late transformer layers (layers 20-33) outperform the final layer by 32 percent in unsupervised Adjusted Rand Index and improve homology-aware supervised accuracy to 75.7 percent. Domain-level extraction, calibrated probability estimates, and a reproducible benchmarking pipeline further strengthen reliability. Our results demonstrate that transformer depth contains functionally distinct biological signals and that principled layer selection significantly improves kinase function prediction. [SEP] [HINT] language -> Neuroscience (Syns: linguistic process, linguistic communication, spoken communication) | functional -> Neuroscience (Syns: working, usable, running) | information -> Bioinformatics (Syns: entropy, data, info)",Bioinformatics
"When people pursue rewards in stochastic environments, they often match their choice frequencies to the observed target frequencies, even when this policy is demonstrably sub-optimal. We used a ``hide and seek'' task to evaluate this behavior under conditions where pursuit (seeking) could be toggled to avoidance (hiding), while leaving the probability distribution fixed, or varying complexity by changing the number of possible choices. We developed a model for participant choice built from choice frequency histograms treated as vectors. We posited the existence of a probability antimatching strategy for avoidance (hiding) rounds, and formalized this as a vector reflection of probability matching. We found that only two basis policies: matching/antimatching and maximizing/minimizing were sufficient to account for participant choices across a range of room numbers and opponent probability distributions. This schema requires only that people have the ability to remember the relative frequency of the different outcomes. With this knowledge simple operations can construct the maximizing and minimizing policies as well as matching and antimatching strategies. A mixture of these two policies captures human choice patterns in a stochastic environment.",Neuroscience
"When people pursue rewards in stochastic environments, they often match their choice frequencies to the observed target frequencies, even when this policy is demonstrably sub-optimal. We used a ``hide and seek'' task to evaluate this behavior under conditions where pursuit (seeking) could be toggled to avoidance (hiding), while leaving the probability distribution fixed, or varying complexity by changing the number of possible choices. We developed a model for participant choice built from choice frequency histograms treated as vectors. We posited the existence of a probability antimatching strategy for avoidance (hiding) rounds, and formalized this as a vector reflection of probability matching. We found that only two basis policies: matching/antimatching and maximizing/minimizing were sufficient to account for participant choices across a range of room numbers and opponent probability distributions. This schema requires only that people have the ability to remember the relative frequency of the different outcomes. With this knowledge simple operations can construct the maximizing and minimizing policies as well as matching and antimatching strategies. A mixture of these two policies captures human choice patterns in a stochastic environment. [SEP] [HINT] used -> Bioinformatics (Syns: utilize, ill-used, apply) | task -> Neuroscience (Syns: tax, project, chore) | human -> Neuroscience (Syns: human being, man, homo)",Neuroscience
"Artificial Recurrent Neural Networks (RNNs) are widely used in neuroscience to model the collective activity of neurons during behavioral tasks. The high dimensionality of their parameter and activity spaces, however, often make it challenging to infer and interpret the fundamental features of their dynamics.   In this study, we employ recent nonlinear dynamical system techniques to uncover the core dynamics of several RNNs used in contemporary neuroscience. Specifically, using a data-driven approach, we identify Spectral Submanifolds (SSMs), i.e., low-dimensional attracting invariant manifolds tangent to the eigenspaces of fixed points. The internal dynamics of SSMs serve as nonlinear models that reduce the dimensionality of the full RNNs by orders of magnitude.   Through low-dimensional, SSM-reduced models, we give mathematically precise definitions of line and ring attractors, which are intuitive concepts commonly used to explain decision-making and working memory. The new level of understanding of RNNs obtained from SSM reduction enables the interpretation of mathematically well-defined and robust structures in neuronal dynamics, leading to novel predictions about the neural computations underlying behavior.",Neuroscience
"Artificial Recurrent Neural Networks (RNNs) are widely used in neuroscience to model the collective activity of neurons during behavioral tasks. The high dimensionality of their parameter and activity spaces, however, often make it challenging to infer and interpret the fundamental features of their dynamics.   In this study, we employ recent nonlinear dynamical system techniques to uncover the core dynamics of several RNNs used in contemporary neuroscience. Specifically, using a data-driven approach, we identify Spectral Submanifolds (SSMs), i.e., low-dimensional attracting invariant manifolds tangent to the eigenspaces of fixed points. The internal dynamics of SSMs serve as nonlinear models that reduce the dimensionality of the full RNNs by orders of magnitude.   Through low-dimensional, SSM-reduced models, we give mathematically precise definitions of line and ring attractors, which are intuitive concepts commonly used to explain decision-making and working memory. The new level of understanding of RNNs obtained from SSM reduction enables the interpretation of mathematically well-defined and robust structures in neuronal dynamics, leading to novel predictions about the neural computations underlying behavior. [SEP] [HINT] used -> Bioinformatics (Syns: utilize, ill-used, apply) | features -> Bioinformatics (Syns: characteristic, lineament, feature of speech) | understanding -> Neuroscience (Syns: savvy, intellect, sympathy)",Neuroscience
"We present a data-efficient framework for constructing general classical spin Hamiltonians from the spin-cluster expansion (SCE) combined with fully self-consistent noncollinear spin density functional theory (DFT). The key idea is to fit an SCE model to magnetic torques rather than to total energies. Because torques are site-resolved vectors, each configuration supplies many independent constraints, which makes the regression well conditioned and sharply reduces the number of DFT calculations needed, especially in large supercells. Applied to the B20-type chiral magnets ${\rm Mn}_{1-x}{\rm Fe}_{x}{\rm Ge}$ and ${\rm Fe}_{1-y}{\rm Co}_{y}{\rm Ge}$, the resulting models nonperturbatively extract the full pairwise exchange tensor (isotropic exchange, anisotropic symmetric exchange, and the Dzyaloshinskii--Moriya interaction) and predict helical spin period via a micromagnetic mapping. The composition trends and the divergence of the period near the chirality sign change are reproduced in line with experiments. Because the SCE framework is systematic, it also enables systematic analysis of interaction order; training on increasingly disordered spin configurations shows that the lowest-order model loses torque accuracy, whereas including higher-order interactions restores predictive power. These advances enable near-DFT-accurate spin models for finite-temperature magnetism and complex textures at modest data cost, while providing a systematic, extensible, and nonperturbative route to quantitative first-principles parameterization and predictive materials design. An open-source implementation is available as the Julia package, \textit{Magesty.jl}.",Materials Science
"We present a data-efficient framework for constructing general classical spin Hamiltonians from the spin-cluster expansion (SCE) combined with fully self-consistent noncollinear spin density functional theory (DFT). The key idea is to fit an SCE model to magnetic torques rather than to total energies. Because torques are site-resolved vectors, each configuration supplies many independent constraints, which makes the regression well conditioned and sharply reduces the number of DFT calculations needed, especially in large supercells. Applied to the B20-type chiral magnets ${\rm Mn}_{1-x}{\rm Fe}_{x}{\rm Ge}$ and ${\rm Fe}_{1-y}{\rm Co}_{y}{\rm Ge}$, the resulting models nonperturbatively extract the full pairwise exchange tensor (isotropic exchange, anisotropic symmetric exchange, and the Dzyaloshinskii--Moriya interaction) and predict helical spin period via a micromagnetic mapping. The composition trends and the divergence of the period near the chirality sign change are reproduced in line with experiments. Because the SCE framework is systematic, it also enables systematic analysis of interaction order; training on increasingly disordered spin configurations shows that the lowest-order model loses torque accuracy, whereas including higher-order interactions restores predictive power. These advances enable near-DFT-accurate spin models for finite-temperature magnetism and complex textures at modest data cost, while providing a systematic, extensible, and nonperturbative route to quantitative first-principles parameterization and predictive materials design. An open-source implementation is available as the Julia package, \textit{Magesty.jl}. [SEP] [HINT] dft -> Materials Science (Syns: ) | spin -> Materials Science (Syns: twisting, whirl, tailspin) | functional -> Neuroscience (Syns: working, usable, running)",Materials Science
"The discovery of quantized Chern numbers in twisted transition metal dichalcogenide (TMD) homobilayers,including 3.7{deg} twisted MoTe2 and 1.23{deg} twisted WSe2,has emerged as a defining breakthrough in physics. A striking and unresolved puzzle from these studies is the unexpected opposite sign of the observed Chern numbers between the two systems. Recent theory has proposed a twist-angle-dependent Chern number sign reversal in both twisted MoTe2 and WSe2, offering a potential explanation for the disparate experimental observations6. However, a direct experimental verification of the twist-angle-dependent Chern number sign reversal in a specific twisted TMD homobilayer is still elusive. Here, we report the first experimental demonstration that the Chern numbers of the moire frontier bands undergo sign reversal at a critical twist angle 1.42{deg} in twisted WSe2 bilayers (tWSe2). Using scanning tunnelling microscopy and spectroscopy, we direct measure layer-pseudospin skyrmion textures of tWSe2 and our results reveal that tWSe2 in the vicinity of the 1.42{deg} exhibits a twist-angle-dependent layer-pseudospin polarization, an effect that serves as the fundamental origin of the observed Chern number sigh reversal6-12.",Materials Science
"The discovery of quantized Chern numbers in twisted transition metal dichalcogenide (TMD) homobilayers,including 3.7{deg} twisted MoTe2 and 1.23{deg} twisted WSe2,has emerged as a defining breakthrough in physics. A striking and unresolved puzzle from these studies is the unexpected opposite sign of the observed Chern numbers between the two systems. Recent theory has proposed a twist-angle-dependent Chern number sign reversal in both twisted MoTe2 and WSe2, offering a potential explanation for the disparate experimental observations6. However, a direct experimental verification of the twist-angle-dependent Chern number sign reversal in a specific twisted TMD homobilayer is still elusive. Here, we report the first experimental demonstration that the Chern numbers of the moire frontier bands undergo sign reversal at a critical twist angle 1.42{deg} in twisted WSe2 bilayers (tWSe2). Using scanning tunnelling microscopy and spectroscopy, we direct measure layer-pseudospin skyrmion textures of tWSe2 and our results reveal that tWSe2 in the vicinity of the 1.42{deg} exhibits a twist-angle-dependent layer-pseudospin polarization, an effect that serves as the fundamental origin of the observed Chern number sigh reversal6-12. [SEP] [HINT] transition -> Materials Science (Syns: passage, modulation, changeover) | results -> Bioinformatics (Syns: final result, consequence, resultant role) | metal -> Materials Science (Syns: metallic element, metallic, alloy)",Materials Science
"Dengue remains one of Brazil's major epidemiological challenges, marked by strong intra-urban inequalities and the influence of climatic and socio-environmental factors. This study analyzed confirmed dengue cases in Recife from 2015 to 2024 using a Bayesian hierarchical spatio-temporal model implemented in R-INLA, combining a BYM2 spatial structure with an RW1 temporal component. Covariates included population density, household size, income, drainage channels, lagged precipitation, and mean temperature. Population density and household size had positive effects on dengue risk, while income and channel presence were protective. Lagged precipitation increased risk, and higher temperatures showed an inverse association, suggesting thermal thresholds for vector activity. The model achieved good fit (DIC=65817; WAIC=64506) and stable convergence, with moderate residual spatial autocorrelation (phi=0.06) and a smooth temporal trend between 2016 and 2019. Spatio-temporal estimates revealed persistent high-risk clusters in northern and western Recife, overlapping with areas of higher density and social vulnerability. Beyond reproducing historical patterns, the Bayesian model supports probabilistic forecasting and early warning systems. Compared with classical models (GLM, SAR, GWR, GTWR), INLA explicitly integrates uncertainty and spatial-temporal dependence, offering credible interval inference for decision-making in urban health management.",Bioinformatics
"Dengue remains one of Brazil's major epidemiological challenges, marked by strong intra-urban inequalities and the influence of climatic and socio-environmental factors. This study analyzed confirmed dengue cases in Recife from 2015 to 2024 using a Bayesian hierarchical spatio-temporal model implemented in R-INLA, combining a BYM2 spatial structure with an RW1 temporal component. Covariates included population density, household size, income, drainage channels, lagged precipitation, and mean temperature. Population density and household size had positive effects on dengue risk, while income and channel presence were protective. Lagged precipitation increased risk, and higher temperatures showed an inverse association, suggesting thermal thresholds for vector activity. The model achieved good fit (DIC=65817; WAIC=64506) and stable convergence, with moderate residual spatial autocorrelation (phi=0.06) and a smooth temporal trend between 2016 and 2019. Spatio-temporal estimates revealed persistent high-risk clusters in northern and western Recife, overlapping with areas of higher density and social vulnerability. Beyond reproducing historical patterns, the Bayesian model supports probabilistic forecasting and early warning systems. Compared with classical models (GLM, SAR, GWR, GTWR), INLA explicitly integrates uncertainty and spatial-temporal dependence, offering credible interval inference for decision-making in urban health management. [SEP] [HINT] structure -> Bioinformatics (Syns: social system, complex body part, social structure) | using -> Bioinformatics (Syns: utilize, exploitation, apply) | thermal -> Materials Science (Syns: thermic, caloric)",Bioinformatics
"This paper presents the Model Gateway, a management platform for managing machine learning (ML) and scientific computational models in the drug discovery pipeline. The platform supports Large Language Model (LLM) Agents and Generative AI-based tools to perform ML model management tasks in our Machine Learning operations (MLOps) pipelines, such as the dynamic consensus model, a model that aggregates several scientific computational models, registration and management, retrieving model information, asynchronous submission/execution of models, and receiving results once the model complete executions. The platform includes a Model Owner Control Panel, Platform Admin Tools, and Model Gateway API service for interacting with the platform and tracking model execution. The platform achieves a 0% failure rate when testing scaling beyond 10k simultaneous application clients consume models. The Model Gateway is a fundamental part of our model-driven drug discovery pipeline. It has the potential to significantly accelerate the development of new drugs with the maturity of our MLOps infrastructure and the integration of LLM Agents and Generative AI tools.",Bioinformatics
"This paper presents the Model Gateway, a management platform for managing machine learning (ML) and scientific computational models in the drug discovery pipeline. The platform supports Large Language Model (LLM) Agents and Generative AI-based tools to perform ML model management tasks in our Machine Learning operations (MLOps) pipelines, such as the dynamic consensus model, a model that aggregates several scientific computational models, registration and management, retrieving model information, asynchronous submission/execution of models, and receiving results once the model complete executions. The platform includes a Model Owner Control Panel, Platform Admin Tools, and Model Gateway API service for interacting with the platform and tracking model execution. The platform achieves a 0% failure rate when testing scaling beyond 10k simultaneous application clients consume models. The Model Gateway is a fundamental part of our model-driven drug discovery pipeline. It has the potential to significantly accelerate the development of new drugs with the maturity of our MLOps infrastructure and the integration of LLM Agents and Generative AI tools. [SEP] [HINT] tasks -> Neuroscience (Syns: tax, task, project) | language -> Neuroscience (Syns: linguistic process, linguistic communication, spoken communication) | computational -> Neuroscience (Syns: )",Bioinformatics
"Retrieval-Augmented Generation (RAG) is a powerful technique for enriching Large Language Models (LLMs) with external knowledge, allowing for factually grounded responses, a critical requirement in high-stakes domains such as healthcare. However, the efficacy of RAG systems is fundamentally restricted by the performance of their retrieval module, since irrelevant or semantically misaligned documents directly compromise the accuracy of the final generated response. General-purpose dense retrievers can struggle with the nuanced language of specialised domains, while the high accuracy of in-domain models is often achieved at prohibitive computational costs. In this work, we aim to address this trade-off by developing and evaluating a two-stage retrieval architecture that combines a lightweight ModernBERT bidirectional encoder for efficient initial candidate retrieval with a ColBERTv2 late-interaction model for fine-grained re-ranking. We conduct comprehensive evaluations of our retriever module performance and RAG system performance in the biomedical context, fine-tuning the IR module using 10k question-passage pairs from PubMedQA. Our analysis of the retriever module confirmed the positive impact of the ColBERT re-ranker, which improved Recall@3 by up to 4.2 percentage points compared to its retrieve-only counterpart. When integrated into the biomedical RAG, our IR module leads to a state-of-the-art average accuracy of 0.4448 on the five tasks of the MIRAGE question-answering benchmark, outperforming strong baselines such as MedCPT (0.4436). Our ablation studies reveal that this performance is critically dependent on a joint fine-tuning process that aligns the retriever and re-ranker; otherwise, the re-ranker might degrade the performance.",Bioinformatics
"Retrieval-Augmented Generation (RAG) is a powerful technique for enriching Large Language Models (LLMs) with external knowledge, allowing for factually grounded responses, a critical requirement in high-stakes domains such as healthcare. However, the efficacy of RAG systems is fundamentally restricted by the performance of their retrieval module, since irrelevant or semantically misaligned documents directly compromise the accuracy of the final generated response. General-purpose dense retrievers can struggle with the nuanced language of specialised domains, while the high accuracy of in-domain models is often achieved at prohibitive computational costs. In this work, we aim to address this trade-off by developing and evaluating a two-stage retrieval architecture that combines a lightweight ModernBERT bidirectional encoder for efficient initial candidate retrieval with a ColBERTv2 late-interaction model for fine-grained re-ranking. We conduct comprehensive evaluations of our retriever module performance and RAG system performance in the biomedical context, fine-tuning the IR module using 10k question-passage pairs from PubMedQA. Our analysis of the retriever module confirmed the positive impact of the ColBERT re-ranker, which improved Recall@3 by up to 4.2 percentage points compared to its retrieve-only counterpart. When integrated into the biomedical RAG, our IR module leads to a state-of-the-art average accuracy of 0.4448 on the five tasks of the MIRAGE question-answering benchmark, outperforming strong baselines such as MedCPT (0.4436). Our ablation studies reveal that this performance is critically dependent on a joint fine-tuning process that aligns the retriever and re-ranker; otherwise, the re-ranker might degrade the performance. [SEP] [HINT] tasks -> Neuroscience (Syns: tax, task, project) | language -> Neuroscience (Syns: linguistic process, linguistic communication, spoken communication) | computational -> Neuroscience (Syns: )",Bioinformatics
"Background and Objectives: This paper focuses on using AI to assess the cognitive function of older adults with mild cognitive impairment or mild dementia using physiological data provided by a wearable device. Cognitive screening tools are disruptive, time-consuming, and only capture brief snapshots of activity. Wearable sensors offer an attractive alternative by continuously monitoring physiological signals. This study investigated whether physiological data can accurately predict scores on established cognitive tests. Research Design and Methods: We recorded physiological signals from 23 older adults completing three NIH Toolbox Cognitive Battery tests, which assess working memory, processing speed, and attention. The Empatica EmbracePlus, a wearable device, measured blood volume pulse, skin conductance, temperature, and movement. Statistical features were extracted using wavelet-based and segmentation methods. We then applied supervised learning and validated predictions via cross-validation, hold-out testing, and bootstrapping. Results: Our models showed strong performance with Spearman's ρof 0.73-0.82 and mean absolute errors of 0.14-0.16, significantly outperforming a naive mean predictor. Sensor roles varied: heart-related signals combined with movement and temperature best predicted working memory, movement paired with skin conductance was most informative for processing speed, and heart in tandem with skin conductance worked best for attention. Discussion and Implications: These findings suggest that wearable sensors paired with AI tools such as supervised learning and feature engineering can noninvasively track specific cognitive functions in older adults, enabling continuous monitoring. Our study demonstrates how AI can be leveraged when the data sample is small. This approach may support remote assessments and facilitate clinical interventions.",Neuroscience
"Background and Objectives: This paper focuses on using AI to assess the cognitive function of older adults with mild cognitive impairment or mild dementia using physiological data provided by a wearable device. Cognitive screening tools are disruptive, time-consuming, and only capture brief snapshots of activity. Wearable sensors offer an attractive alternative by continuously monitoring physiological signals. This study investigated whether physiological data can accurately predict scores on established cognitive tests. Research Design and Methods: We recorded physiological signals from 23 older adults completing three NIH Toolbox Cognitive Battery tests, which assess working memory, processing speed, and attention. The Empatica EmbracePlus, a wearable device, measured blood volume pulse, skin conductance, temperature, and movement. Statistical features were extracted using wavelet-based and segmentation methods. We then applied supervised learning and validated predictions via cross-validation, hold-out testing, and bootstrapping. Results: Our models showed strong performance with Spearman's ρof 0.73-0.82 and mean absolute errors of 0.14-0.16, significantly outperforming a naive mean predictor. Sensor roles varied: heart-related signals combined with movement and temperature best predicted working memory, movement paired with skin conductance was most informative for processing speed, and heart in tandem with skin conductance worked best for attention. Discussion and Implications: These findings suggest that wearable sensors paired with AI tools such as supervised learning and feature engineering can noninvasively track specific cognitive functions in older adults, enabling continuous monitoring. Our study demonstrates how AI can be leveraged when the data sample is small. This approach may support remote assessments and facilitate clinical interventions. [SEP] [HINT] clinical -> Bioinformatics (Syns: ) | features -> Bioinformatics (Syns: characteristic, lineament, feature of speech) | learning -> Bioinformatics (Syns: take, teach, acquire)",Neuroscience
"The integration of artificial intelligence (AI) into pathology is advancing precision medicine by improving diagnosis, treatment planning, and patient outcomes. Digitised whole-slide images (WSIs) capture rich spatial and morphological information vital for understanding disease biology, yet their gigapixel scale and variability pose major challenges for standardisation and analysis. Robust preprocessing, covering tissue detection, tessellation, stain normalisation, and annotation parsing is critical but often limited by fragmented and inconsistent workflows. We present PySlyde, a lightweight, open-source Python toolkit built on OpenSlide to simplify and standardise WSI preprocessing. PySlyde provides an intuitive API for slide loading, annotation management, tissue detection, tiling, and feature extraction, compatible with modern pathology foundation models. By unifying these processes, it streamlines WSI preprocessing, enhances reproducibility, and accelerates the generation of AI-ready datasets, enabling researchers to focus on model development and downstream analysis.",Bioinformatics
"The integration of artificial intelligence (AI) into pathology is advancing precision medicine by improving diagnosis, treatment planning, and patient outcomes. Digitised whole-slide images (WSIs) capture rich spatial and morphological information vital for understanding disease biology, yet their gigapixel scale and variability pose major challenges for standardisation and analysis. Robust preprocessing, covering tissue detection, tessellation, stain normalisation, and annotation parsing is critical but often limited by fragmented and inconsistent workflows. We present PySlyde, a lightweight, open-source Python toolkit built on OpenSlide to simplify and standardise WSI preprocessing. PySlyde provides an intuitive API for slide loading, annotation management, tissue detection, tiling, and feature extraction, compatible with modern pathology foundation models. By unifying these processes, it streamlines WSI preprocessing, enhances reproducibility, and accelerates the generation of AI-ready datasets, enabling researchers to focus on model development and downstream analysis. [SEP] [HINT] tissue -> Bioinformatics (Syns: tissue paper, weave) | understanding -> Neuroscience (Syns: savvy, intellect, sympathy) | information -> Bioinformatics (Syns: entropy, data, info)",Bioinformatics
"Electrode density optimization in electroencephalography (EEG)-based Brain-Computer Interfaces (BCIs) requires balancing practical usability against signal fidelity, particularly for source localization. Reducing electrodes enhances portability but its effects on neural source reconstruction quality and source connectivity - treated as proxies to BCI performance - remain understudied. We address this gap through systematic evaluation of 62-, 32-, and 16-channel configurations using a fixed, fully automated processing pipeline applied to the well-characterized P300 potential. This approach's rationale is to minimize variability and bias inherent to EEG analysis by leveraging the P300's stimulus-locked reproducibility and pipeline standardization. Analyzing 63 sessions (31 subjects) from the Eye-BCI dataset with rigorous artifact correction and channel validation, we demonstrate: (1) Progressive degradation in source reconstruction quality with sparser configurations, including obscured deep neural generators and spatiotemporal distortions; (2) A novel sqrt(Re) scaling law linking electrode reduction ratio (Re) to localization accuracy - a previously unquantified relationship to the best of our knowledge; (3) While reduced configurations preserve basic P300 topography and may suffice for communicative BCIs, higher-density channels are essential for reliable deep source reconstruction. Overall, this study establishes a first step towards quantitative benchmarks for electrode selection, with critical implications for clinical BCIs requiring anatomical precision in applications like neurodegenerative disease monitoring, where compromised spatial resolution could mask pathological signatures. Most importantly, the sqrt(Re) scaling law may provide the first principled method to determine the minimal electrode density required based on acceptable error margins or expected effect sizes.",Bioinformatics
"Electrode density optimization in electroencephalography (EEG)-based Brain-Computer Interfaces (BCIs) requires balancing practical usability against signal fidelity, particularly for source localization. Reducing electrodes enhances portability but its effects on neural source reconstruction quality and source connectivity - treated as proxies to BCI performance - remain understudied. We address this gap through systematic evaluation of 62-, 32-, and 16-channel configurations using a fixed, fully automated processing pipeline applied to the well-characterized P300 potential. This approach's rationale is to minimize variability and bias inherent to EEG analysis by leveraging the P300's stimulus-locked reproducibility and pipeline standardization. Analyzing 63 sessions (31 subjects) from the Eye-BCI dataset with rigorous artifact correction and channel validation, we demonstrate: (1) Progressive degradation in source reconstruction quality with sparser configurations, including obscured deep neural generators and spatiotemporal distortions; (2) A novel sqrt(Re) scaling law linking electrode reduction ratio (Re) to localization accuracy - a previously unquantified relationship to the best of our knowledge; (3) While reduced configurations preserve basic P300 topography and may suffice for communicative BCIs, higher-density channels are essential for reliable deep source reconstruction. Overall, this study establishes a first step towards quantitative benchmarks for electrode selection, with critical implications for clinical BCIs requiring anatomical precision in applications like neurodegenerative disease monitoring, where compromised spatial resolution could mask pathological signatures. Most importantly, the sqrt(Re) scaling law may provide the first principled method to determine the minimal electrode density required based on acceptable error margins or expected effect sizes. [SEP] [HINT] connectivity -> Neuroscience (Syns: ) | based -> Bioinformatics (Syns: ground, free-base, base) | clinical -> Bioinformatics (Syns: )",Bioinformatics
"The effective mass of charge carriers is a fundamental descriptor of the electronic structure of materials, and can be used to assess performance in electronics applications, or to screen for thermoelectrics and transparent conductors. Here, we perform a high-throughput computational screening of approximately 20,000 experimentally known three-dimensional stoichiometric inorganics obtained from the Materials Cloud 3D structure database. By combining density-functional theory calculations and maximally localized Wannier functions, we are able to compute the full conductivity effective mass tensor for electrons and holes from the Boltzmann transport equation in the constant relaxation-time approximation. This approach captures the effects of band non-parabolicity, anisotropy, and valley multiplicity that would be neglected by standard parabolic fittings. The screening identifies a curated set of candidates exhibiting extreme electronic properties, from ultra-low to ultra-large effective masses, these latter associated with flat-band physics. We validate the workflow by recovering established high-mobility semiconductors and highlight promising novel candidates. Furthermore, we classify materials by their mass anisotropy and discuss the physical limits of defining a conductivity effective mass in narrow-gap regimes at room temperature. The resulting dataset provides a systematic roadmap to search for high-performance materials in novel chemical spaces.",Materials Science
"The effective mass of charge carriers is a fundamental descriptor of the electronic structure of materials, and can be used to assess performance in electronics applications, or to screen for thermoelectrics and transparent conductors. Here, we perform a high-throughput computational screening of approximately 20,000 experimentally known three-dimensional stoichiometric inorganics obtained from the Materials Cloud 3D structure database. By combining density-functional theory calculations and maximally localized Wannier functions, we are able to compute the full conductivity effective mass tensor for electrons and holes from the Boltzmann transport equation in the constant relaxation-time approximation. This approach captures the effects of band non-parabolicity, anisotropy, and valley multiplicity that would be neglected by standard parabolic fittings. The screening identifies a curated set of candidates exhibiting extreme electronic properties, from ultra-low to ultra-large effective masses, these latter associated with flat-band physics. We validate the workflow by recovering established high-mobility semiconductors and highlight promising novel candidates. Furthermore, we classify materials by their mass anisotropy and discuss the physical limits of defining a conductivity effective mass in narrow-gap regimes at room temperature. The resulting dataset provides a systematic roadmap to search for high-performance materials in novel chemical spaces. [SEP] [HINT] used -> Bioinformatics (Syns: utilize, ill-used, apply) | computational -> Neuroscience (Syns: ) | transport -> Materials Science (Syns: transferral, enthral, shipping)",Materials Science
"Starting from the foundational axiomatization of the perceptual color space initiated by Schrödinger in 1920 and eventually refined by Resnikoff in 1974, Berthier, Provenzi and their collaborators have recently proposed a reformulation of perceptual color attributes within the framework of quantum information. Their work is based on the Jordan algebra formalism of quantum theories and, more specifically, on a quantum system described by a spin factor over the field of real numbers. This theoretical framework is not that of ordinary quantum mechanics, mainly because it requires dealing with rebits, whereas the latter uses qubits. The aim of this paper is to show that this difference in no way hinders the implementation of experimental protocols for testing the validity of the predictions of the color perception model. In particular, we show how to compute the quantum information based perceptual attributes of perceived colors in terms of qubit density matrices.",Neuroscience
"Starting from the foundational axiomatization of the perceptual color space initiated by Schrödinger in 1920 and eventually refined by Resnikoff in 1974, Berthier, Provenzi and their collaborators have recently proposed a reformulation of perceptual color attributes within the framework of quantum information. Their work is based on the Jordan algebra formalism of quantum theories and, more specifically, on a quantum system described by a spin factor over the field of real numbers. This theoretical framework is not that of ordinary quantum mechanics, mainly because it requires dealing with rebits, whereas the latter uses qubits. The aim of this paper is to show that this difference in no way hinders the implementation of experimental protocols for testing the validity of the predictions of the color perception model. In particular, we show how to compute the quantum information based perceptual attributes of perceived colors in terms of qubit density matrices. [SEP] [HINT] field -> Materials Science (Syns: field of honor, line of business, orbit) | based -> Bioinformatics (Syns: ground, free-base, base) | spin -> Materials Science (Syns: twisting, whirl, tailspin)",Neuroscience
"Two-dimensional ferroelectrics have recently emerged as a promising avenue for next-generation optoelectronic and photovoltaic devices. Due to the intrinsic absence of inversion symmetry, 2D ferroelectrics exhibit bulk photovoltaic effect (BPVE), which relies on hot, non-thermalized photo-excited carriers to generate a photo-induced current with enhanced performances thanks to efficient charge separation mechanisms. The absence of a required p-n junction architecture makes these materials particularly attractive for nanoscale energy harvesting. Recent studies have reported enhanced BPVE in nanometer-thick CuInP$_2$S$_6$ ferroelectric embedded between two graphene wafers, driven by relatively strong polarization and reduced dimensionality. Short circuit photocurrent density values have been observed to reach up to mA/cm$^2$. In this paper, we demonstrate that the shift-current mechanism alone cannot fully account for these high conductivity values, suggesting that additional mechanisms may play a significant role. Furthermore, our work confirms the existence of a strong size effect, which drastically reduces the shift-conductivity response in the bulk limit, in agreement with experimental observations.",Materials Science
"Two-dimensional ferroelectrics have recently emerged as a promising avenue for next-generation optoelectronic and photovoltaic devices. Due to the intrinsic absence of inversion symmetry, 2D ferroelectrics exhibit bulk photovoltaic effect (BPVE), which relies on hot, non-thermalized photo-excited carriers to generate a photo-induced current with enhanced performances thanks to efficient charge separation mechanisms. The absence of a required p-n junction architecture makes these materials particularly attractive for nanoscale energy harvesting. Recent studies have reported enhanced BPVE in nanometer-thick CuInP$_2$S$_6$ ferroelectric embedded between two graphene wafers, driven by relatively strong polarization and reduced dimensionality. Short circuit photocurrent density values have been observed to reach up to mA/cm$^2$. In this paper, we demonstrate that the shift-current mechanism alone cannot fully account for these high conductivity values, suggesting that additional mechanisms may play a significant role. Furthermore, our work confirms the existence of a strong size effect, which drastically reduces the shift-conductivity response in the bulk limit, in agreement with experimental observations. [SEP] [HINT] charge -> Materials Science (Syns: tear, bearing, burster) | work -> Bioinformatics (Syns: work out, process, bring) | materials -> Materials Science (Syns: stuff, cloth, material)",Materials Science
"Assessing the practical identifiability of epidemic models is essential for determining whether parameters can be meaningfully estimated from observed data. Monte Carlo (MC) methods provide an accessible and intuitive framework; however, their standard implementation - perturbing deterministic trajectories with independent Gaussian noise - rests on assumptions poorly suited to epidemic processes, which are inherently stochastic, temporally correlated, and highly variable, especially in small populations or under slow transmission. In this study, we investigate the structure of stochastic variability in the classic Susceptible-Infected-Recovered (SIR) model across a range of epidemiological regimes, and assess whether it can be represented within the independent Gaussian noise framework. We show that continuous-time Markov chain (CTMC) trajectories consistently exhibit super-Poissonian variability and strong temporal dependence. Through coverage analysis, we further demonstrate that independent Gaussian noise systematically underestimates the variability of the underlying stochastic process, leading to overly optimistic conclusions about parameter identifiability. In addition, we propose a hybrid simulation approach that introduces time- and amplitude-dependent variability into deterministic ODE trajectories, preserving computational efficiency while capturing key features of epidemic stochasticity. Our findings highlight the limitations of the standard MC algorithm and provide a pathway for incorporating more realistic noise structures into epidemic inference.",Bioinformatics
"Assessing the practical identifiability of epidemic models is essential for determining whether parameters can be meaningfully estimated from observed data. Monte Carlo (MC) methods provide an accessible and intuitive framework; however, their standard implementation - perturbing deterministic trajectories with independent Gaussian noise - rests on assumptions poorly suited to epidemic processes, which are inherently stochastic, temporally correlated, and highly variable, especially in small populations or under slow transmission. In this study, we investigate the structure of stochastic variability in the classic Susceptible-Infected-Recovered (SIR) model across a range of epidemiological regimes, and assess whether it can be represented within the independent Gaussian noise framework. We show that continuous-time Markov chain (CTMC) trajectories consistently exhibit super-Poissonian variability and strong temporal dependence. Through coverage analysis, we further demonstrate that independent Gaussian noise systematically underestimates the variability of the underlying stochastic process, leading to overly optimistic conclusions about parameter identifiability. In addition, we propose a hybrid simulation approach that introduces time- and amplitude-dependent variability into deterministic ODE trajectories, preserving computational efficiency while capturing key features of epidemic stochasticity. Our findings highlight the limitations of the standard MC algorithm and provide a pathway for incorporating more realistic noise structures into epidemic inference. [SEP] [HINT] computational -> Neuroscience (Syns: ) | features -> Bioinformatics (Syns: characteristic, lineament, feature of speech) | structure -> Bioinformatics (Syns: social system, complex body part, social structure)",Bioinformatics
"Understanding energy level alignment at organic interfaces is crucial for optimizing the performance of organic devices. Interface dipole and band bending significantly influence carrier recombination and generation mechanisms. A method of simulating energy level alignment at metal/organic and organic/organic interfaces by assuming a thermal equilibrium model has been proposed, but its validation against experimental methods is still limited. In this study, the work function change in the $α$-NPD/HAT-CN/Au interface was measured as a typical donor/acceptor system using a rotary Kelvin probe (RKP). Our findings demonstrate good agreement with simulations only at metal/organic interfaces which have ""active"" charge transfer. It is suggested that thermal equilibrium is not achieved simply by depositing the film under dark condition, and some treatment to supply carriers, such as exposure to UV light, is necessary for accurate evaluation. At the organic/organic interface, the the experimental results did not agree with thermal equilibrium model, highlighting the need to consider substrate-driven carrier supply and polarization effects when evaluating energy level alignment.",Materials Science
"Understanding energy level alignment at organic interfaces is crucial for optimizing the performance of organic devices. Interface dipole and band bending significantly influence carrier recombination and generation mechanisms. A method of simulating energy level alignment at metal/organic and organic/organic interfaces by assuming a thermal equilibrium model has been proposed, but its validation against experimental methods is still limited. In this study, the work function change in the $α$-NPD/HAT-CN/Au interface was measured as a typical donor/acceptor system using a rotary Kelvin probe (RKP). Our findings demonstrate good agreement with simulations only at metal/organic interfaces which have ""active"" charge transfer. It is suggested that thermal equilibrium is not achieved simply by depositing the film under dark condition, and some treatment to supply carriers, such as exposure to UV light, is necessary for accurate evaluation. At the organic/organic interface, the the experimental results did not agree with thermal equilibrium model, highlighting the need to consider substrate-driven carrier supply and polarization effects when evaluating energy level alignment. [SEP] [HINT] understanding -> Neuroscience (Syns: savvy, intellect, sympathy) | charge -> Materials Science (Syns: tear, bearing, burster) | work -> Bioinformatics (Syns: work out, process, bring)",Materials Science
"Large language models (LLMs) are rapidly transforming various domains, including biomedicine and healthcare, and demonstrate remarkable potential from scientific research to new drug discovery. Graph-based retrieval-augmented generation (RAG) systems, as a useful application of LLMs, can improve contextual reasoning through structured entity and relationship identification from long-context knowledge, e.g. biomedical literature. Even though many advantages over naive RAGs, most of graph-based RAGs are computationally intensive, which limits their application to large-scale dataset. To address this issue, we introduce fastbmRAG, an fast graph-based RAG optimized for biomedical literature. Utilizing well organized structure of biomedical papers, fastbmRAG divides the construction of knowledge graph into two stages, first drafting graphs using abstracts; and second, refining them using main texts guided by vector-based entity linking, which minimizes redundancy and computational load. Our evaluations demonstrate that fastbmRAG is over 10x faster than existing graph-RAG tools and achieve superior coverage and accuracy to input knowledge. FastbmRAG provides a fast solution for quickly understanding, summarizing, and answering questions about biomedical literature on a large scale. FastbmRAG is public available in https://github.com/menggf/fastbmRAG.",Bioinformatics
"Large language models (LLMs) are rapidly transforming various domains, including biomedicine and healthcare, and demonstrate remarkable potential from scientific research to new drug discovery. Graph-based retrieval-augmented generation (RAG) systems, as a useful application of LLMs, can improve contextual reasoning through structured entity and relationship identification from long-context knowledge, e.g. biomedical literature. Even though many advantages over naive RAGs, most of graph-based RAGs are computationally intensive, which limits their application to large-scale dataset. To address this issue, we introduce fastbmRAG, an fast graph-based RAG optimized for biomedical literature. Utilizing well organized structure of biomedical papers, fastbmRAG divides the construction of knowledge graph into two stages, first drafting graphs using abstracts; and second, refining them using main texts guided by vector-based entity linking, which minimizes redundancy and computational load. Our evaluations demonstrate that fastbmRAG is over 10x faster than existing graph-RAG tools and achieve superior coverage and accuracy to input knowledge. FastbmRAG provides a fast solution for quickly understanding, summarizing, and answering questions about biomedical literature on a large scale. FastbmRAG is public available in https://github.com/menggf/fastbmRAG. [SEP] [HINT] language -> Neuroscience (Syns: linguistic process, linguistic communication, spoken communication) | computational -> Neuroscience (Syns: ) | structure -> Bioinformatics (Syns: social system, complex body part, social structure)",Bioinformatics
"Boron vacancies ($V_B^-$) in hexagonal boron nitride (hBN) have emerged as a promising platform for two-dimensional quantum sensors capable of operating at atomic-scale proximity. However, the mechanisms responsible for photoluminescence quenching in thin hBN sensing layers when placed in contact with absorptive materials remain largely unexplored. In this Letter, we investigate non-radiative Förster resonance energy transfer (FRET) between $V_B^-$ centers and either monolayer graphene or 2D semiconductors. Strikingly, we find that the FRET rate is negligible for hBN sensing layers thicker than 3 nm, highlighting the potential of $V_B^-$ centers for integration into ultra-thin quantum sensors within van der Waals heterostructures. Furthermore, we experimentally extract the intrinsic radiative decay rate of $V_B^-$ defects.",Materials Science
"Boron vacancies ($V_B^-$) in hexagonal boron nitride (hBN) have emerged as a promising platform for two-dimensional quantum sensors capable of operating at atomic-scale proximity. However, the mechanisms responsible for photoluminescence quenching in thin hBN sensing layers when placed in contact with absorptive materials remain largely unexplored. In this Letter, we investigate non-radiative Förster resonance energy transfer (FRET) between $V_B^-$ centers and either monolayer graphene or 2D semiconductors. Strikingly, we find that the FRET rate is negligible for hBN sensing layers thicker than 3 nm, highlighting the potential of $V_B^-$ centers for integration into ultra-thin quantum sensors within van der Waals heterostructures. Furthermore, we experimentally extract the intrinsic radiative decay rate of $V_B^-$ defects. [SEP] [HINT] materials -> Materials Science (Syns: stuff, cloth, material) | potential -> Bioinformatics (Syns: voltage, potential difference, electric potential) | quantum -> Materials Science (Syns: )",Materials Science
"Alzheimer's disease (AD) emerges from a complex interplay of molecular, cellular, and network-level disturbances that are not easily captured by traditional reductionist frameworks. Conventional analyses of gene expression often rely on thresholded correlation networks or clustering-based module detection, approaches that may obscure nonlinear structure and higher-order organization. Here, we introduce a comparative topological framework that makes use of topological data analysis (TDA) and the Mapper algorithm to detect discontinuities - localized disruptions in the topology of gene co-expression space between healthy and AD brain tissue. Using gene expression data from 3 brain regions, we mapped how AD reshapes the global topology of gene-gene relationships. Discontinuity hotspots were identified via variability-based node scoring and subjected to Gene Ontology Biological Process enrichment analysis. This work illustrates the potential of TDA to uncover disease-relevant structure in high-dimensional transcriptomic data and motivates broader application of shape-based comparative methods in neurodegeneration research and other areas that benefit from comparative analysis.",Bioinformatics
"Alzheimer's disease (AD) emerges from a complex interplay of molecular, cellular, and network-level disturbances that are not easily captured by traditional reductionist frameworks. Conventional analyses of gene expression often rely on thresholded correlation networks or clustering-based module detection, approaches that may obscure nonlinear structure and higher-order organization. Here, we introduce a comparative topological framework that makes use of topological data analysis (TDA) and the Mapper algorithm to detect discontinuities - localized disruptions in the topology of gene co-expression space between healthy and AD brain tissue. Using gene expression data from 3 brain regions, we mapped how AD reshapes the global topology of gene-gene relationships. Discontinuity hotspots were identified via variability-based node scoring and subjected to Gene Ontology Biological Process enrichment analysis. This work illustrates the potential of TDA to uncover disease-relevant structure in high-dimensional transcriptomic data and motivates broader application of shape-based comparative methods in neurodegeneration research and other areas that benefit from comparative analysis. [SEP] [HINT] networks -> Neuroscience (Syns: network, meshwork, electronic network) | space -> Neuroscience (Syns: distance, place, outer space) | structure -> Bioinformatics (Syns: social system, complex body part, social structure)",Bioinformatics
"Image denoising is a fundamental problem in computer vision and medical imaging. However, real-world images are often degraded by structured noise with strong anisotropic correlations that existing methods struggle to remove. Most data-driven approaches rely on large datasets with high-quality labels and still suffer from limited generalizability, whereas existing zero-shot methods avoid this limitation but remain effective only for independent and identically distributed (i.i.d.) noise. To address this gap, we propose Median2Median (M2M), a zero-shot denoising framework designed for structured noise. M2M introduces a novel sampling strategy that generates pseudo-independent sub-image pairs from a single noisy input. This strategy leverages directional interpolation and generalized median filtering to adaptively exclude values distorted by structured artifacts. To further enlarge the effective sampling space and eliminate systematic bias, a randomized assignment strategy is employed, ensuring that the sampled sub-image pairs are suitable for Noise2Noise training. In our realistic simulation studies, M2M performs on par with state-of-the-art zero-shot methods under i.i.d. noise, while consistently outperforming them under correlated noise. These findings establish M2M as an efficient, data-free solution for structured noise suppression and mark the first step toward effective zero-shot denoising beyond the strict i.i.d. assumption.",Bioinformatics
"Image denoising is a fundamental problem in computer vision and medical imaging. However, real-world images are often degraded by structured noise with strong anisotropic correlations that existing methods struggle to remove. Most data-driven approaches rely on large datasets with high-quality labels and still suffer from limited generalizability, whereas existing zero-shot methods avoid this limitation but remain effective only for independent and identically distributed (i.i.d.) noise. To address this gap, we propose Median2Median (M2M), a zero-shot denoising framework designed for structured noise. M2M introduces a novel sampling strategy that generates pseudo-independent sub-image pairs from a single noisy input. This strategy leverages directional interpolation and generalized median filtering to adaptively exclude values distorted by structured artifacts. To further enlarge the effective sampling space and eliminate systematic bias, a randomized assignment strategy is employed, ensuring that the sampled sub-image pairs are suitable for Noise2Noise training. In our realistic simulation studies, M2M performs on par with state-of-the-art zero-shot methods under i.i.d. noise, while consistently outperforming them under correlated noise. These findings establish M2M as an efficient, data-free solution for structured noise suppression and mark the first step toward effective zero-shot denoising beyond the strict i.i.d. assumption. [SEP] [HINT] space -> Neuroscience (Syns: distance, place, outer space) | datasets -> Bioinformatics (Syns: ) | framework -> Bioinformatics (Syns: theoretical account, model, fabric)",Bioinformatics
"We consider the problem of fitting a reinforcement learning (RL) model to some given behavioral data under a multi-armed bandit environment. These models have received much attention in recent years for characterizing human and animal decision making behavior. We provide a generic mathematical optimization problem formulation for the fitting problem of a wide range of RL models that appear frequently in scientific research applications, followed by a detailed theoretical analysis of its convexity properties. Based on the theoretical results, we introduce a novel solution method for the fitting problem of RL models based on convex relaxation and optimization. Our method is then evaluated in several simulated bandit environments to compare with some benchmark methods that appear in the literature. Numerical results indicate that our method achieves comparable performance to the state-of-the-art, while significantly reducing computation time. We also provide an open-source Python package for our proposed method to empower researchers to apply it in the analysis of their datasets directly, without prior knowledge of convex optimization.",Neuroscience
"We consider the problem of fitting a reinforcement learning (RL) model to some given behavioral data under a multi-armed bandit environment. These models have received much attention in recent years for characterizing human and animal decision making behavior. We provide a generic mathematical optimization problem formulation for the fitting problem of a wide range of RL models that appear frequently in scientific research applications, followed by a detailed theoretical analysis of its convexity properties. Based on the theoretical results, we introduce a novel solution method for the fitting problem of RL models based on convex relaxation and optimization. Our method is then evaluated in several simulated bandit environments to compare with some benchmark methods that appear in the literature. Numerical results indicate that our method achieves comparable performance to the state-of-the-art, while significantly reducing computation time. We also provide an open-source Python package for our proposed method to empower researchers to apply it in the analysis of their datasets directly, without prior knowledge of convex optimization. [SEP] [HINT] based -> Bioinformatics (Syns: ground, free-base, base) | learning -> Bioinformatics (Syns: take, teach, acquire) | datasets -> Bioinformatics (Syns: )",Neuroscience
"Accurate assessment of PD-L1 expression is critical for guiding immunotherapy, yet current immunohistochemistry (IHC) based methods are resource-intensive. We present nnUNet-B: a Bayesian segmentation framework that infers PD-L1 expression directly from H&E-stained histology images using Multimodal Posterior Sampling (MPS). Built upon nnUNet-v2, our method samples diverse model checkpoints during cyclic training to approximate the posterior, enabling both accurate segmentation and epistemic uncertainty estimation via entropy and standard deviation. Evaluated on a dataset of lung squamous cell carcinoma, our approach achieves competitive performance against established baselines with mean Dice Score and mean IoU of 0.805 and 0.709, respectively, while providing pixel-wise uncertainty maps. Uncertainty estimates show strong correlation with segmentation error, though calibration remains imperfect. These results suggest that uncertainty-aware H&E-based PD-L1 prediction is a promising step toward scalable, interpretable biomarker assessment in clinical workflows.",Bioinformatics
"Accurate assessment of PD-L1 expression is critical for guiding immunotherapy, yet current immunohistochemistry (IHC) based methods are resource-intensive. We present nnUNet-B: a Bayesian segmentation framework that infers PD-L1 expression directly from H&E-stained histology images using Multimodal Posterior Sampling (MPS). Built upon nnUNet-v2, our method samples diverse model checkpoints during cyclic training to approximate the posterior, enabling both accurate segmentation and epistemic uncertainty estimation via entropy and standard deviation. Evaluated on a dataset of lung squamous cell carcinoma, our approach achieves competitive performance against established baselines with mean Dice Score and mean IoU of 0.805 and 0.709, respectively, while providing pixel-wise uncertainty maps. Uncertainty estimates show strong correlation with segmentation error, though calibration remains imperfect. These results suggest that uncertainty-aware H&E-based PD-L1 prediction is a promising step toward scalable, interpretable biomarker assessment in clinical workflows. [SEP] [HINT] based -> Bioinformatics (Syns: ground, free-base, base) | clinical -> Bioinformatics (Syns: ) | performance -> Bioinformatics (Syns: functioning, operation, carrying out)",Bioinformatics
"Studies of the 3D quantum Hall effect (QHE) have primarily emphasized transport features that mimic the well-established 2D QHE. In this work, we show that qualitatively new features arise when an in-plane magnetic field is applied to a 3D Weyl semimetal in the quantum Hall regime. An unexpected Hall quantum oscillation, distinct from the Weyl-orbit oscillation, coexists with the QHE, along with an unquantized two-terminal magnetoresistance. Moreover, unconventional antichiral transmission enables a peculiar disorder-robust negative longitudinal resistance. Quantization tunable by the lead configuration is further found in this transport geometry. A unique type of nonlocal quantum backscattering channels underlies these phenomena. Our work demonstrates a breakdown of the topological characterization of transport even with 3D Chern numbers and reveals hidden 3D QHE transport properties. It opens a new class of transport measurements and phenomena.",Materials Science
"Studies of the 3D quantum Hall effect (QHE) have primarily emphasized transport features that mimic the well-established 2D QHE. In this work, we show that qualitatively new features arise when an in-plane magnetic field is applied to a 3D Weyl semimetal in the quantum Hall regime. An unexpected Hall quantum oscillation, distinct from the Weyl-orbit oscillation, coexists with the QHE, along with an unquantized two-terminal magnetoresistance. Moreover, unconventional antichiral transmission enables a peculiar disorder-robust negative longitudinal resistance. Quantization tunable by the lead configuration is further found in this transport geometry. A unique type of nonlocal quantum backscattering channels underlies these phenomena. Our work demonstrates a breakdown of the topological characterization of transport even with 3D Chern numbers and reveals hidden 3D QHE transport properties. It opens a new class of transport measurements and phenomena. [SEP] [HINT] field -> Materials Science (Syns: field of honor, line of business, orbit) | features -> Bioinformatics (Syns: characteristic, lineament, feature of speech) | transport -> Materials Science (Syns: transferral, enthral, shipping)",Materials Science
